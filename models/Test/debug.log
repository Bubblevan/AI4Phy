2024-11-13 16:49:46,974 - logger.py:50 - Namespace(output_dir='models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-13 16:50:30,262 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-13 16:50:31,881 - logger.py:50 - Number of params: 2978805
2024-11-13 16:58:04,067 - logger.py:50 - Namespace(output_dir='models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-13 16:58:27,253 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-13 16:58:28,897 - logger.py:50 - Number of params: 2978805
2024-11-13 17:01:31,311 - logger.py:50 - Namespace(output_dir='models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-13 17:01:54,462 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-13 17:01:56,086 - logger.py:50 - Number of params: 2978805
2024-11-13 17:02:00,093 - logger.py:50 - Epoch: [0][0/1000] loss: 4.08479, MAE: 0.73749, time/step=4001ms, lr=1.00e-06
2024-11-13 17:04:14,615 - logger.py:50 - Epoch: [0][50/1000] loss: 2.39461, MAE: 0.54465, time/step=2716ms, lr=1.00e-06
2024-11-13 17:06:25,268 - logger.py:50 - Epoch: [0][100/1000] loss: 4.00998, MAE: 0.56150, time/step=2665ms, lr=1.00e-06
2024-11-19 11:13:42,518 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-19 11:14:05,227 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-19 11:14:06,958 - logger.py:50 - Number of params: 2978805
2024-11-19 11:14:10,560 - logger.py:50 - Epoch: [0][0/1000] loss: 4.08479, MAE: 0.73749, time/step=3596ms, lr=1.00e-06
2024-11-19 11:16:52,457 - logger.py:50 - Epoch: [0][50/1000] loss: 2.39461, MAE: 0.54465, time/step=3245ms, lr=1.00e-06
2024-11-19 11:19:35,680 - logger.py:50 - Epoch: [0][100/1000] loss: 4.00998, MAE: 0.56150, time/step=3255ms, lr=1.00e-06
2024-11-19 11:22:14,353 - logger.py:50 - Epoch: [0][150/1000] loss: 3.34495, MAE: 0.53141, time/step=3228ms, lr=1.00e-06
2024-11-19 11:59:10,581 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-19 11:59:33,677 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-19 11:59:34,362 - logger.py:50 - Number of params: 2978805
2024-11-19 11:59:36,400 - logger.py:50 - Epoch: [0][0/1000] loss: 4.08479, MAE: 0.73749, time/step=2034ms, lr=1.00e-06
2024-11-19 12:00:16,437 - logger.py:50 - Epoch: [0][50/1000] loss: 2.39461, MAE: 0.54465, time/step=825ms, lr=1.00e-06
2024-11-19 12:00:52,066 - logger.py:50 - Epoch: [0][100/1000] loss: 4.00998, MAE: 0.56150, time/step=769ms, lr=1.00e-06
2024-11-19 12:01:29,966 - logger.py:50 - Epoch: [0][150/1000] loss: 3.34495, MAE: 0.53141, time/step=766ms, lr=1.00e-06
2024-11-19 12:02:08,028 - logger.py:50 - Epoch: [0][200/1000] loss: 2.94265, MAE: 0.50938, time/step=764ms, lr=1.00e-06
2024-11-19 12:02:44,868 - logger.py:50 - Epoch: [0][250/1000] loss: 2.69098, MAE: 0.49336, time/step=759ms, lr=1.00e-06
2024-11-19 12:03:20,837 - logger.py:50 - Epoch: [0][300/1000] loss: 2.51212, MAE: 0.47946, time/step=752ms, lr=1.00e-06
2024-11-19 12:03:56,989 - logger.py:50 - Epoch: [0][350/1000] loss: 2.40072, MAE: 0.46972, time/step=748ms, lr=1.00e-06
2024-11-19 12:04:34,546 - logger.py:50 - Epoch: [0][400/1000] loss: 2.33360, MAE: 0.46291, time/step=749ms, lr=1.00e-06
2024-11-19 12:05:10,558 - logger.py:50 - Epoch: [0][450/1000] loss: 2.24490, MAE: 0.45512, time/step=745ms, lr=1.00e-06
2024-11-19 12:05:47,227 - logger.py:50 - Epoch: [0][500/1000] loss: 2.19597, MAE: 0.44947, time/step=744ms, lr=1.00e-06
2024-11-19 12:06:23,355 - logger.py:50 - Epoch: [0][550/1000] loss: 2.14571, MAE: 0.44520, time/step=742ms, lr=1.00e-06
2024-11-19 12:06:59,659 - logger.py:50 - Epoch: [0][600/1000] loss: 2.10254, MAE: 0.44083, time/step=741ms, lr=1.00e-06
2024-11-19 12:07:35,662 - logger.py:50 - Epoch: [0][650/1000] loss: 2.05775, MAE: 0.43619, time/step=739ms, lr=1.00e-06
2024-11-19 12:08:12,363 - logger.py:50 - Epoch: [0][700/1000] loss: 2.01442, MAE: 0.43108, time/step=739ms, lr=1.00e-06
2024-11-19 12:08:48,960 - logger.py:50 - Epoch: [0][750/1000] loss: 1.97945, MAE: 0.42699, time/step=738ms, lr=1.00e-06
2024-11-19 12:09:28,255 - logger.py:50 - Epoch: [0][800/1000] loss: 1.94619, MAE: 0.42363, time/step=741ms, lr=1.00e-06
2024-11-19 12:10:10,581 - logger.py:50 - Epoch: [0][850/1000] loss: 1.90929, MAE: 0.41953, time/step=748ms, lr=1.00e-06
2024-11-19 12:10:48,965 - logger.py:50 - Epoch: [0][900/1000] loss: 1.87917, MAE: 0.41566, time/step=749ms, lr=1.00e-06
2024-11-19 12:11:30,231 - logger.py:50 - Epoch: [0][950/1000] loss: 1.87210, MAE: 0.41327, time/step=753ms, lr=1.00e-06
2024-11-19 12:12:09,830 - logger.py:50 - Epoch: [0][999/1000] loss: 1.86014, MAE: 0.41058, time/step=755ms, lr=1.00e-06
2024-11-19 12:13:22,290 - logger.py:50 - Epoch: [0] train loss: 1.86014, train MAE: 0.41058,val loss: 0.36432, val MAE: 0.36432,test loss: 0.37547, test MAE: 0.37547,Time: 827.93s
2024-11-19 12:13:22,290 - logger.py:50 - Best -- epoch=0, train loss: 1.86014, val loss: 0.36432, test loss: 0.37547

2024-11-19 12:13:22,877 - logger.py:50 - Epoch: [1][0/1000] loss: 2.31553, MAE: 0.46497, time/step=584ms, lr=1.01e-04
2024-11-19 12:13:59,493 - logger.py:50 - Epoch: [1][50/1000] loss: 1.41797, MAE: 0.34562, time/step=729ms, lr=1.01e-04
2024-11-19 12:14:42,014 - logger.py:50 - Epoch: [1][100/1000] loss: 1.34102, MAE: 0.33008, time/step=789ms, lr=1.01e-04
2024-11-19 12:15:26,370 - logger.py:50 - Epoch: [1][150/1000] loss: 1.36004, MAE: 0.32754, time/step=822ms, lr=1.01e-04
2024-11-19 12:16:10,826 - logger.py:50 - Epoch: [1][200/1000] loss: 1.38593, MAE: 0.32854, time/step=838ms, lr=1.01e-04
2024-11-19 12:16:55,456 - logger.py:50 - Epoch: [1][250/1000] loss: 1.34351, MAE: 0.32394, time/step=849ms, lr=1.01e-04
2024-11-19 12:17:42,125 - logger.py:50 - Epoch: [1][300/1000] loss: 1.33671, MAE: 0.32147, time/step=863ms, lr=1.01e-04
2024-11-19 12:18:29,373 - logger.py:50 - Epoch: [1][350/1000] loss: 1.31781, MAE: 0.32207, time/step=875ms, lr=1.01e-04
2024-11-19 12:19:16,040 - logger.py:50 - Epoch: [1][400/1000] loss: 1.30395, MAE: 0.32040, time/step=882ms, lr=1.01e-04
2024-11-19 12:20:02,307 - logger.py:50 - Epoch: [1][450/1000] loss: 1.30425, MAE: 0.31985, time/step=887ms, lr=1.01e-04
2024-11-19 12:20:45,498 - logger.py:50 - Epoch: [1][500/1000] loss: 1.30143, MAE: 0.31874, time/step=885ms, lr=1.01e-04
2024-11-19 12:21:30,496 - logger.py:50 - Epoch: [1][550/1000] loss: 1.30084, MAE: 0.31698, time/step=886ms, lr=1.01e-04
2024-11-19 12:22:15,626 - logger.py:50 - Epoch: [1][600/1000] loss: 1.30383, MAE: 0.31786, time/step=887ms, lr=1.01e-04
2024-11-19 12:23:00,717 - logger.py:50 - Epoch: [1][650/1000] loss: 1.31419, MAE: 0.31769, time/step=889ms, lr=1.01e-04
2024-11-19 12:23:47,101 - logger.py:50 - Epoch: [1][700/1000] loss: 1.31467, MAE: 0.31675, time/step=891ms, lr=1.01e-04
2024-11-19 12:24:30,896 - logger.py:50 - Epoch: [1][750/1000] loss: 1.30640, MAE: 0.31601, time/step=890ms, lr=1.01e-04
2024-11-19 12:25:18,018 - logger.py:50 - Epoch: [1][800/1000] loss: 1.33228, MAE: 0.31678, time/step=894ms, lr=1.01e-04
2024-11-19 12:26:05,962 - logger.py:50 - Epoch: [1][850/1000] loss: 1.32480, MAE: 0.31578, time/step=897ms, lr=1.01e-04
2024-11-19 12:26:53,461 - logger.py:50 - Epoch: [1][900/1000] loss: 1.31866, MAE: 0.31584, time/step=900ms, lr=1.01e-04
2024-11-19 12:27:41,678 - logger.py:50 - Epoch: [1][950/1000] loss: 1.49180, MAE: 0.31811, time/step=904ms, lr=1.01e-04
2024-11-19 12:28:28,620 - logger.py:50 - Epoch: [1][999/1000] loss: 1.47858, MAE: 0.31774, time/step=906ms, lr=1.01e-04
2024-11-19 12:29:42,472 - logger.py:50 - Epoch: [1] train loss: 1.47858, train MAE: 0.31774,val loss: 0.31352, val MAE: 0.31352,test loss: 0.32568, test MAE: 0.32568,Time: 980.18s
2024-11-19 12:29:42,473 - logger.py:50 - Best -- epoch=1, train loss: 1.47858, val loss: 0.31352, test loss: 0.32568

2024-11-19 12:29:42,970 - logger.py:50 - Epoch: [2][0/1000] loss: 1.35929, MAE: 0.37652, time/step=495ms, lr=2.01e-04
2024-11-19 12:30:22,179 - logger.py:50 - Epoch: [2][50/1000] loss: 4.74458, MAE: 0.39428, time/step=779ms, lr=2.01e-04
2024-11-19 12:31:05,259 - logger.py:50 - Epoch: [2][100/1000] loss: 3.06277, MAE: 0.35880, time/step=820ms, lr=2.01e-04
2024-11-19 12:31:47,056 - logger.py:50 - Epoch: [2][150/1000] loss: 2.44622, MAE: 0.34064, time/step=825ms, lr=2.01e-04
2024-11-19 12:32:30,118 - logger.py:50 - Epoch: [2][200/1000] loss: 2.13833, MAE: 0.33227, time/step=834ms, lr=2.01e-04
2024-11-19 12:33:13,327 - logger.py:50 - Epoch: [2][250/1000] loss: 1.98275, MAE: 0.32485, time/step=840ms, lr=2.01e-04
2024-11-19 12:33:57,215 - logger.py:50 - Epoch: [2][300/1000] loss: 1.85144, MAE: 0.32197, time/step=846ms, lr=2.01e-04
2024-11-19 12:34:39,359 - logger.py:50 - Epoch: [2][350/1000] loss: 1.77092, MAE: 0.32036, time/step=846ms, lr=2.01e-04
2024-11-19 12:35:18,670 - logger.py:50 - Epoch: [2][400/1000] loss: 1.69512, MAE: 0.31868, time/step=838ms, lr=2.01e-04
2024-11-19 12:36:06,042 - logger.py:50 - Epoch: [2][450/1000] loss: 1.65554, MAE: 0.31811, time/step=850ms, lr=2.01e-04
2024-11-19 12:36:51,096 - logger.py:50 - Epoch: [2][500/1000] loss: 1.64520, MAE: 0.31912, time/step=856ms, lr=2.01e-04
2024-11-19 12:37:37,478 - logger.py:50 - Epoch: [2][550/1000] loss: 1.61052, MAE: 0.31802, time/step=862ms, lr=2.01e-04
2024-11-19 12:38:23,598 - logger.py:50 - Epoch: [2][600/1000] loss: 1.57489, MAE: 0.31648, time/step=867ms, lr=2.01e-04
2024-11-19 12:39:13,541 - logger.py:50 - Epoch: [2][650/1000] loss: 1.55783, MAE: 0.31586, time/step=877ms, lr=2.01e-04
2024-11-19 12:40:01,028 - logger.py:50 - Epoch: [2][700/1000] loss: 1.54296, MAE: 0.31537, time/step=882ms, lr=2.01e-04
2024-11-19 12:40:43,762 - logger.py:50 - Epoch: [2][750/1000] loss: 1.53993, MAE: 0.31640, time/step=881ms, lr=2.01e-04
2024-11-19 12:41:28,756 - logger.py:50 - Epoch: [2][800/1000] loss: 1.52141, MAE: 0.31602, time/step=882ms, lr=2.01e-04
2024-11-19 12:42:12,752 - logger.py:50 - Epoch: [2][850/1000] loss: 1.49892, MAE: 0.31442, time/step=882ms, lr=2.01e-04
2024-11-19 12:42:57,801 - logger.py:50 - Epoch: [2][900/1000] loss: 1.48488, MAE: 0.31356, time/step=883ms, lr=2.01e-04
2024-11-19 12:43:44,530 - logger.py:50 - Epoch: [2][950/1000] loss: 1.47508, MAE: 0.31364, time/step=885ms, lr=2.01e-04
2024-11-19 12:44:30,089 - logger.py:50 - Epoch: [2][999/1000] loss: 1.46141, MAE: 0.31330, time/step=888ms, lr=2.01e-04
2024-11-19 12:45:50,499 - logger.py:50 - Epoch: [2] train loss: 1.46141, train MAE: 0.31330,val loss: 0.31221, val MAE: 0.31221,test loss: 0.32396, test MAE: 0.32396,Time: 968.03s
2024-11-19 12:45:50,499 - logger.py:50 - Best -- epoch=2, train loss: 1.46141, val loss: 0.31221, test loss: 0.32396

2024-11-19 12:45:51,129 - logger.py:50 - Epoch: [3][0/1000] loss: 2.19703, MAE: 0.44021, time/step=626ms, lr=3.00e-04
2024-11-19 12:46:31,347 - logger.py:50 - Epoch: [3][50/1000] loss: 1.41982, MAE: 0.32452, time/step=801ms, lr=3.00e-04
2024-11-19 12:47:16,104 - logger.py:50 - Epoch: [3][100/1000] loss: 1.41122, MAE: 0.31772, time/step=848ms, lr=3.00e-04
2024-11-19 12:48:01,317 - logger.py:50 - Epoch: [3][150/1000] loss: 1.39696, MAE: 0.31899, time/step=866ms, lr=3.00e-04
2024-11-19 12:48:46,889 - logger.py:50 - Epoch: [3][200/1000] loss: 1.38523, MAE: 0.32210, time/step=878ms, lr=3.00e-04
2024-11-19 12:49:33,357 - logger.py:50 - Epoch: [3][250/1000] loss: 1.34081, MAE: 0.31825, time/step=888ms, lr=3.00e-04
2024-11-19 12:50:17,513 - logger.py:50 - Epoch: [3][300/1000] loss: 1.30770, MAE: 0.31389, time/step=887ms, lr=3.00e-04
2024-11-19 12:51:02,105 - logger.py:50 - Epoch: [3][350/1000] loss: 1.32093, MAE: 0.31357, time/step=888ms, lr=3.00e-04
2024-11-19 12:51:46,938 - logger.py:50 - Epoch: [3][400/1000] loss: 1.33830, MAE: 0.31287, time/step=889ms, lr=3.00e-04
2024-11-19 12:52:31,308 - logger.py:50 - Epoch: [3][450/1000] loss: 1.31542, MAE: 0.31225, time/step=889ms, lr=3.00e-04
2024-11-19 12:53:16,968 - logger.py:50 - Epoch: [3][500/1000] loss: 1.31687, MAE: 0.31274, time/step=891ms, lr=3.00e-04
2024-11-19 12:54:04,497 - logger.py:50 - Epoch: [3][550/1000] loss: 1.31480, MAE: 0.31256, time/step=897ms, lr=3.00e-04
2024-11-19 12:54:52,080 - logger.py:50 - Epoch: [3][600/1000] loss: 1.31696, MAE: 0.31215, time/step=901ms, lr=3.00e-04
2024-11-19 12:55:38,991 - logger.py:50 - Epoch: [3][650/1000] loss: 1.31243, MAE: 0.31239, time/step=904ms, lr=3.00e-04
2024-11-19 12:56:24,834 - logger.py:50 - Epoch: [3][700/1000] loss: 1.30364, MAE: 0.31200, time/step=905ms, lr=3.00e-04
2024-11-19 12:57:09,118 - logger.py:50 - Epoch: [3][750/1000] loss: 1.53400, MAE: 0.31588, time/step=904ms, lr=3.00e-04
2024-11-19 12:57:55,231 - logger.py:50 - Epoch: [3][800/1000] loss: 1.51728, MAE: 0.31557, time/step=905ms, lr=3.00e-04
2024-11-19 12:58:40,620 - logger.py:50 - Epoch: [3][850/1000] loss: 1.49508, MAE: 0.31402, time/step=905ms, lr=3.00e-04
2024-11-19 12:59:24,575 - logger.py:50 - Epoch: [3][900/1000] loss: 1.48609, MAE: 0.31355, time/step=904ms, lr=3.00e-04
2024-11-19 13:00:09,972 - logger.py:50 - Epoch: [3][950/1000] loss: 1.46476, MAE: 0.31233, time/step=904ms, lr=3.00e-04
2024-11-19 13:00:55,808 - logger.py:50 - Epoch: [3][999/1000] loss: 1.46048, MAE: 0.31296, time/step=905ms, lr=3.00e-04
2024-11-19 13:02:10,897 - logger.py:50 - Epoch: [3] train loss: 1.46048, train MAE: 0.31296,val loss: 0.31919, val MAE: 0.31919,test loss: 0.33135, test MAE: 0.33135,Time: 980.40s
2024-11-19 13:02:10,898 - logger.py:50 - Best -- epoch=2, train loss: 1.46141, val loss: 0.31221, test loss: 0.32396

2024-11-19 13:02:11,602 - logger.py:50 - Epoch: [4][0/1000] loss: 1.31363, MAE: 0.28772, time/step=702ms, lr=4.00e-04
2024-11-19 13:02:50,551 - logger.py:50 - Epoch: [4][50/1000] loss: 1.29008, MAE: 0.30314, time/step=777ms, lr=4.00e-04
2024-11-19 13:03:31,920 - logger.py:50 - Epoch: [4][100/1000] loss: 1.24188, MAE: 0.29946, time/step=802ms, lr=4.00e-04
2024-11-19 13:04:11,723 - logger.py:50 - Epoch: [4][150/1000] loss: 1.26928, MAE: 0.29850, time/step=800ms, lr=4.00e-04
2024-11-19 13:04:49,298 - logger.py:50 - Epoch: [4][200/1000] loss: 1.21898, MAE: 0.29734, time/step=788ms, lr=4.00e-04
2024-11-19 13:05:28,509 - logger.py:50 - Epoch: [4][250/1000] loss: 1.23985, MAE: 0.29963, time/step=787ms, lr=4.00e-04
2024-11-19 13:06:08,326 - logger.py:50 - Epoch: [4][300/1000] loss: 1.81183, MAE: 0.31202, time/step=789ms, lr=4.00e-04
2024-11-19 13:06:45,654 - logger.py:50 - Epoch: [4][350/1000] loss: 1.75170, MAE: 0.31297, time/step=783ms, lr=4.00e-04
2024-11-19 13:07:25,913 - logger.py:50 - Epoch: [4][400/1000] loss: 1.70390, MAE: 0.31432, time/step=786ms, lr=4.00e-04
2024-11-19 13:08:06,194 - logger.py:50 - Epoch: [4][450/1000] loss: 1.64268, MAE: 0.31204, time/step=788ms, lr=4.00e-04
2024-11-19 13:08:46,408 - logger.py:50 - Epoch: [4][500/1000] loss: 1.60267, MAE: 0.31246, time/step=789ms, lr=4.00e-04
2024-11-19 13:09:28,052 - logger.py:50 - Epoch: [4][550/1000] loss: 1.57859, MAE: 0.31254, time/step=793ms, lr=4.00e-04
2024-11-19 13:10:08,754 - logger.py:50 - Epoch: [4][600/1000] loss: 1.56901, MAE: 0.31193, time/step=795ms, lr=4.00e-04
2024-11-19 13:10:49,814 - logger.py:50 - Epoch: [4][650/1000] loss: 1.54698, MAE: 0.31176, time/step=797ms, lr=4.00e-04
2024-11-19 13:11:32,213 - logger.py:50 - Epoch: [4][700/1000] loss: 1.52651, MAE: 0.31102, time/step=801ms, lr=4.00e-04
2024-11-19 13:12:14,854 - logger.py:50 - Epoch: [4][750/1000] loss: 1.50867, MAE: 0.30996, time/step=804ms, lr=4.00e-04
2024-11-19 13:12:56,145 - logger.py:50 - Epoch: [4][800/1000] loss: 1.49236, MAE: 0.30979, time/step=806ms, lr=4.00e-04
2024-11-19 13:13:35,189 - logger.py:50 - Epoch: [4][850/1000] loss: 1.48588, MAE: 0.30966, time/step=804ms, lr=4.00e-04
2024-11-19 13:14:17,009 - logger.py:50 - Epoch: [4][900/1000] loss: 1.47616, MAE: 0.30966, time/step=806ms, lr=4.00e-04
2024-11-19 13:14:57,567 - logger.py:50 - Epoch: [4][950/1000] loss: 1.46219, MAE: 0.30958, time/step=806ms, lr=4.00e-04
2024-11-19 13:15:36,391 - logger.py:50 - Epoch: [4][999/1000] loss: 1.45941, MAE: 0.30997, time/step=805ms, lr=4.00e-04
2024-11-19 13:16:47,219 - logger.py:50 - Epoch: [4] train loss: 1.45941, train MAE: 0.30997,val loss: 0.30991, val MAE: 0.30991,test loss: 0.32198, test MAE: 0.32198,Time: 876.32s
2024-11-19 13:16:47,219 - logger.py:50 - Best -- epoch=4, train loss: 1.45941, val loss: 0.30991, test loss: 0.32198

2024-11-19 13:16:47,710 - logger.py:50 - Epoch: [5][0/1000] loss: 0.53878, MAE: 0.28379, time/step=488ms, lr=5.00e-04
2024-11-19 13:17:24,946 - logger.py:50 - Epoch: [5][50/1000] loss: 1.25829, MAE: 0.30184, time/step=740ms, lr=5.00e-04
2024-11-19 13:18:04,443 - logger.py:50 - Epoch: [5][100/1000] loss: 1.40139, MAE: 0.31051, time/step=765ms, lr=5.00e-04
2024-11-19 13:18:45,376 - logger.py:50 - Epoch: [5][150/1000] loss: 1.39389, MAE: 0.30338, time/step=782ms, lr=5.00e-04
2024-11-19 13:19:24,918 - logger.py:50 - Epoch: [5][200/1000] loss: 1.33065, MAE: 0.30058, time/step=785ms, lr=5.00e-04
2024-11-19 13:20:06,115 - logger.py:50 - Epoch: [5][250/1000] loss: 1.33056, MAE: 0.30428, time/step=792ms, lr=5.00e-04
2024-11-19 13:20:47,388 - logger.py:50 - Epoch: [5][300/1000] loss: 1.32047, MAE: 0.30446, time/step=798ms, lr=5.00e-04
2024-11-19 13:21:29,087 - logger.py:50 - Epoch: [5][350/1000] loss: 1.30821, MAE: 0.30496, time/step=803ms, lr=5.00e-04
2024-11-19 13:22:07,100 - logger.py:50 - Epoch: [5][400/1000] loss: 1.31143, MAE: 0.30539, time/step=798ms, lr=5.00e-04
2024-11-19 13:22:47,992 - logger.py:50 - Epoch: [5][450/1000] loss: 1.68454, MAE: 0.31130, time/step=800ms, lr=5.00e-04
2024-11-19 13:23:28,700 - logger.py:50 - Epoch: [5][500/1000] loss: 1.64548, MAE: 0.31235, time/step=801ms, lr=5.00e-04
2024-11-19 13:24:07,373 - logger.py:50 - Epoch: [5][550/1000] loss: 1.61717, MAE: 0.31284, time/step=799ms, lr=5.00e-04
2024-11-19 13:24:45,607 - logger.py:50 - Epoch: [5][600/1000] loss: 1.59664, MAE: 0.31213, time/step=796ms, lr=5.00e-04
2024-11-19 13:25:24,308 - logger.py:50 - Epoch: [5][650/1000] loss: 1.56263, MAE: 0.31040, time/step=794ms, lr=5.00e-04
2024-11-19 13:26:05,570 - logger.py:50 - Epoch: [5][700/1000] loss: 1.53628, MAE: 0.30925, time/step=797ms, lr=5.00e-04
2024-11-19 13:26:44,617 - logger.py:50 - Epoch: [5][750/1000] loss: 1.51385, MAE: 0.30864, time/step=795ms, lr=5.00e-04
2024-11-19 13:27:25,038 - logger.py:50 - Epoch: [5][800/1000] loss: 1.49331, MAE: 0.30862, time/step=796ms, lr=5.00e-04
2024-11-19 13:28:07,515 - logger.py:50 - Epoch: [5][850/1000] loss: 1.48408, MAE: 0.30832, time/step=799ms, lr=5.00e-04
2024-11-19 13:28:48,870 - logger.py:50 - Epoch: [5][900/1000] loss: 1.47876, MAE: 0.30889, time/step=801ms, lr=5.00e-04
2024-11-19 13:29:29,211 - logger.py:50 - Epoch: [5][950/1000] loss: 1.46666, MAE: 0.30839, time/step=801ms, lr=5.00e-04
2024-11-19 13:30:11,018 - logger.py:50 - Epoch: [5][999/1000] loss: 1.45921, MAE: 0.30843, time/step=804ms, lr=5.00e-04
2024-11-19 13:31:21,566 - logger.py:50 - Epoch: [5] train loss: 1.45921, train MAE: 0.30843,val loss: 0.30992, val MAE: 0.30992,test loss: 0.32192, test MAE: 0.32192,Time: 874.35s
2024-11-19 13:31:21,566 - logger.py:50 - Best -- epoch=4, train loss: 1.45941, val loss: 0.30991, test loss: 0.32198

2024-11-19 13:31:21,973 - logger.py:50 - Epoch: [6][0/1000] loss: 0.66222, MAE: 0.20717, time/step=405ms, lr=5.00e-04
2024-11-19 13:31:59,409 - logger.py:50 - Epoch: [6][50/1000] loss: 4.57659, MAE: 0.36824, time/step=742ms, lr=5.00e-04
2024-11-19 13:32:36,041 - logger.py:50 - Epoch: [6][100/1000] loss: 3.01685, MAE: 0.34115, time/step=737ms, lr=5.00e-04
2024-11-19 13:33:14,125 - logger.py:50 - Epoch: [6][150/1000] loss: 2.45255, MAE: 0.33112, time/step=745ms, lr=5.00e-04
2024-11-19 13:33:51,105 - logger.py:50 - Epoch: [6][200/1000] loss: 2.16409, MAE: 0.32424, time/step=744ms, lr=5.00e-04
2024-11-19 13:34:31,384 - logger.py:50 - Epoch: [6][250/1000] loss: 1.98966, MAE: 0.32149, time/step=756ms, lr=5.00e-04
2024-11-19 13:35:11,757 - logger.py:50 - Epoch: [6][300/1000] loss: 1.86074, MAE: 0.31784, time/step=765ms, lr=5.00e-04
2024-11-19 13:35:52,993 - logger.py:50 - Epoch: [6][350/1000] loss: 1.76141, MAE: 0.31431, time/step=773ms, lr=5.00e-04
2024-11-19 13:36:35,128 - logger.py:50 - Epoch: [6][400/1000] loss: 1.73206, MAE: 0.31364, time/step=782ms, lr=5.00e-04
2024-11-19 13:37:18,944 - logger.py:50 - Epoch: [6][450/1000] loss: 1.67739, MAE: 0.31248, time/step=792ms, lr=5.00e-04
2024-11-19 13:38:01,103 - logger.py:50 - Epoch: [6][500/1000] loss: 1.63851, MAE: 0.31291, time/step=797ms, lr=5.00e-04
2024-11-19 13:38:41,988 - logger.py:50 - Epoch: [6][550/1000] loss: 1.61779, MAE: 0.31212, time/step=799ms, lr=5.00e-04
2024-11-19 13:39:21,714 - logger.py:50 - Epoch: [6][600/1000] loss: 1.58718, MAE: 0.31111, time/step=799ms, lr=5.00e-04
2024-11-19 13:40:01,491 - logger.py:50 - Epoch: [6][650/1000] loss: 1.57468, MAE: 0.31165, time/step=799ms, lr=5.00e-04
2024-11-19 13:40:42,063 - logger.py:50 - Epoch: [6][700/1000] loss: 1.54717, MAE: 0.30977, time/step=800ms, lr=5.00e-04
2024-11-19 13:41:20,551 - logger.py:50 - Epoch: [6][750/1000] loss: 1.52710, MAE: 0.30942, time/step=798ms, lr=5.00e-04
2024-11-19 13:41:58,602 - logger.py:50 - Epoch: [6][800/1000] loss: 1.50903, MAE: 0.30923, time/step=795ms, lr=5.00e-04
2024-11-19 13:42:37,629 - logger.py:50 - Epoch: [6][850/1000] loss: 1.49490, MAE: 0.30794, time/step=794ms, lr=5.00e-04
2024-11-19 13:43:18,518 - logger.py:50 - Epoch: [6][900/1000] loss: 1.48552, MAE: 0.30822, time/step=796ms, lr=5.00e-04
2024-11-19 13:44:00,318 - logger.py:50 - Epoch: [6][950/1000] loss: 1.47240, MAE: 0.30820, time/step=798ms, lr=5.00e-04
2024-11-19 13:44:40,990 - logger.py:50 - Epoch: [6][999/1000] loss: 1.45864, MAE: 0.30752, time/step=799ms, lr=5.00e-04
2024-11-19 13:45:58,298 - logger.py:50 - Epoch: [6] train loss: 1.45864, train MAE: 0.30752,val loss: 0.30933, val MAE: 0.30933,test loss: 0.32124, test MAE: 0.32124,Time: 876.73s
2024-11-19 13:45:58,299 - logger.py:50 - Best -- epoch=6, train loss: 1.45864, val loss: 0.30933, test loss: 0.32124

2024-11-19 13:45:58,879 - logger.py:50 - Epoch: [7][0/1000] loss: 0.78226, MAE: 0.31383, time/step=577ms, lr=4.99e-04
2024-11-19 13:46:36,368 - logger.py:50 - Epoch: [7][50/1000] loss: 1.38858, MAE: 0.31194, time/step=746ms, lr=4.99e-04
2024-11-19 13:47:14,783 - logger.py:50 - Epoch: [7][100/1000] loss: 1.30389, MAE: 0.30440, time/step=757ms, lr=4.99e-04
2024-11-19 13:47:52,974 - logger.py:50 - Epoch: [7][150/1000] loss: 1.29350, MAE: 0.30287, time/step=759ms, lr=4.99e-04
2024-11-19 13:48:33,106 - logger.py:50 - Epoch: [7][200/1000] loss: 1.26106, MAE: 0.30223, time/step=770ms, lr=4.99e-04
2024-11-19 13:49:13,490 - logger.py:50 - Epoch: [7][250/1000] loss: 1.26136, MAE: 0.30195, time/step=778ms, lr=4.99e-04
2024-11-19 13:49:56,400 - logger.py:50 - Epoch: [7][300/1000] loss: 1.25240, MAE: 0.30137, time/step=791ms, lr=4.99e-04
2024-11-19 13:50:36,675 - logger.py:50 - Epoch: [7][350/1000] loss: 1.25763, MAE: 0.29993, time/step=793ms, lr=4.99e-04
2024-11-19 13:51:15,066 - logger.py:50 - Epoch: [7][400/1000] loss: 1.27325, MAE: 0.30112, time/step=790ms, lr=4.99e-04
2024-11-19 13:51:52,974 - logger.py:50 - Epoch: [7][450/1000] loss: 1.26975, MAE: 0.30108, time/step=786ms, lr=4.99e-04
2024-11-19 13:52:31,550 - logger.py:50 - Epoch: [7][500/1000] loss: 1.28523, MAE: 0.30385, time/step=785ms, lr=4.99e-04
2024-11-19 13:53:09,945 - logger.py:50 - Epoch: [7][550/1000] loss: 1.27317, MAE: 0.30296, time/step=783ms, lr=4.99e-04
2024-11-19 13:53:47,110 - logger.py:50 - Epoch: [7][600/1000] loss: 1.26804, MAE: 0.30264, time/step=780ms, lr=4.99e-04
2024-11-19 13:54:26,746 - logger.py:50 - Epoch: [7][650/1000] loss: 1.27124, MAE: 0.30290, time/step=781ms, lr=4.99e-04
2024-11-19 13:55:04,826 - logger.py:50 - Epoch: [7][700/1000] loss: 1.26887, MAE: 0.30263, time/step=780ms, lr=4.99e-04
2024-11-19 13:55:43,988 - logger.py:50 - Epoch: [7][750/1000] loss: 1.26020, MAE: 0.30268, time/step=780ms, lr=4.99e-04
2024-11-19 13:56:22,578 - logger.py:50 - Epoch: [7][800/1000] loss: 1.26902, MAE: 0.30219, time/step=779ms, lr=4.99e-04
2024-11-19 13:57:02,872 - logger.py:50 - Epoch: [7][850/1000] loss: 1.27558, MAE: 0.30325, time/step=781ms, lr=4.99e-04
2024-11-19 13:57:42,397 - logger.py:50 - Epoch: [7][900/1000] loss: 1.46406, MAE: 0.30700, time/step=781ms, lr=4.99e-04
2024-11-19 13:58:23,581 - logger.py:50 - Epoch: [7][950/1000] loss: 1.45901, MAE: 0.30626, time/step=784ms, lr=4.99e-04
2024-11-19 13:59:04,334 - logger.py:50 - Epoch: [7][999/1000] loss: 1.45793, MAE: 0.30652, time/step=786ms, lr=4.99e-04
2024-11-19 14:00:17,105 - logger.py:50 - Epoch: [7] train loss: 1.45793, train MAE: 0.30652,val loss: 0.30828, val MAE: 0.30828,test loss: 0.32021, test MAE: 0.32021,Time: 858.81s
2024-11-19 14:00:17,106 - logger.py:50 - Best -- epoch=7, train loss: 1.45793, val loss: 0.30828, test loss: 0.32021

2024-11-19 14:00:17,638 - logger.py:50 - Epoch: [8][0/1000] loss: 1.28463, MAE: 0.24865, time/step=529ms, lr=4.99e-04
2024-11-19 14:00:54,517 - logger.py:50 - Epoch: [8][50/1000] loss: 1.26581, MAE: 0.29217, time/step=734ms, lr=4.99e-04
2024-11-19 14:01:33,311 - logger.py:50 - Epoch: [8][100/1000] loss: 1.29186, MAE: 0.29824, time/step=754ms, lr=4.99e-04
2024-11-19 14:02:14,096 - logger.py:50 - Epoch: [8][150/1000] loss: 1.33668, MAE: 0.30029, time/step=775ms, lr=4.99e-04
2024-11-19 14:02:57,084 - logger.py:50 - Epoch: [8][200/1000] loss: 1.39252, MAE: 0.30441, time/step=796ms, lr=4.99e-04
2024-11-19 14:03:36,753 - logger.py:50 - Epoch: [8][250/1000] loss: 1.38556, MAE: 0.30561, time/step=795ms, lr=4.99e-04
2024-11-19 14:04:17,826 - logger.py:50 - Epoch: [8][300/1000] loss: 1.35308, MAE: 0.30452, time/step=800ms, lr=4.99e-04
2024-11-19 14:04:58,845 - logger.py:50 - Epoch: [8][350/1000] loss: 1.33759, MAE: 0.30170, time/step=803ms, lr=4.99e-04
2024-11-19 14:05:37,790 - logger.py:50 - Epoch: [8][400/1000] loss: 1.33980, MAE: 0.30294, time/step=800ms, lr=4.99e-04
2024-11-19 14:06:15,816 - logger.py:50 - Epoch: [8][450/1000] loss: 1.33729, MAE: 0.30292, time/step=795ms, lr=4.99e-04
2024-11-19 14:06:55,066 - logger.py:50 - Epoch: [8][500/1000] loss: 1.33587, MAE: 0.30348, time/step=794ms, lr=4.99e-04
2024-11-19 14:07:33,205 - logger.py:50 - Epoch: [8][550/1000] loss: 1.32331, MAE: 0.30218, time/step=791ms, lr=4.99e-04
2024-11-19 14:08:13,702 - logger.py:50 - Epoch: [8][600/1000] loss: 1.31373, MAE: 0.30145, time/step=793ms, lr=4.99e-04
2024-11-19 14:08:55,968 - logger.py:50 - Epoch: [8][650/1000] loss: 1.31138, MAE: 0.30195, time/step=797ms, lr=4.99e-04
2024-11-19 14:09:39,488 - logger.py:50 - Epoch: [8][700/1000] loss: 1.54299, MAE: 0.30638, time/step=802ms, lr=4.99e-04
2024-11-19 14:10:19,099 - logger.py:50 - Epoch: [8][750/1000] loss: 1.52493, MAE: 0.30653, time/step=802ms, lr=4.99e-04
2024-11-19 14:11:01,327 - logger.py:50 - Epoch: [8][800/1000] loss: 1.50566, MAE: 0.30695, time/step=804ms, lr=4.99e-04
2024-11-19 14:11:39,299 - logger.py:50 - Epoch: [8][850/1000] loss: 1.49704, MAE: 0.30759, time/step=802ms, lr=4.99e-04
2024-11-19 14:12:19,917 - logger.py:50 - Epoch: [8][900/1000] loss: 1.48756, MAE: 0.30761, time/step=802ms, lr=4.99e-04
2024-11-19 14:12:57,197 - logger.py:50 - Epoch: [8][950/1000] loss: 1.46730, MAE: 0.30602, time/step=799ms, lr=4.99e-04
2024-11-19 14:13:34,142 - logger.py:50 - Epoch: [8][999/1000] loss: 1.45732, MAE: 0.30587, time/step=797ms, lr=4.99e-04
2024-11-19 14:14:43,901 - logger.py:50 - Epoch: [8] train loss: 1.45732, train MAE: 0.30587,val loss: 0.30733, val MAE: 0.30733,test loss: 0.31938, test MAE: 0.31938,Time: 866.80s
2024-11-19 14:14:43,902 - logger.py:50 - Best -- epoch=8, train loss: 1.45732, val loss: 0.30733, test loss: 0.31938

2024-11-19 14:14:44,382 - logger.py:50 - Epoch: [9][0/1000] loss: 2.58615, MAE: 0.37541, time/step=478ms, lr=4.99e-04
2024-11-19 14:15:19,858 - logger.py:50 - Epoch: [9][50/1000] loss: 1.24962, MAE: 0.30310, time/step=705ms, lr=4.99e-04
2024-11-19 14:15:56,651 - logger.py:50 - Epoch: [9][100/1000] loss: 1.27127, MAE: 0.30212, time/step=720ms, lr=4.99e-04
2024-11-19 14:16:33,608 - logger.py:50 - Epoch: [9][150/1000] loss: 1.30290, MAE: 0.30591, time/step=727ms, lr=4.99e-04
2024-11-19 14:17:10,875 - logger.py:50 - Epoch: [9][200/1000] loss: 1.29104, MAE: 0.30391, time/step=731ms, lr=4.99e-04
2024-11-19 14:17:51,107 - logger.py:50 - Epoch: [9][250/1000] loss: 1.30894, MAE: 0.30577, time/step=746ms, lr=4.99e-04
2024-11-19 14:18:31,792 - logger.py:50 - Epoch: [9][300/1000] loss: 1.29071, MAE: 0.30376, time/step=757ms, lr=4.99e-04
2024-11-19 14:19:13,623 - logger.py:50 - Epoch: [9][350/1000] loss: 1.31067, MAE: 0.30472, time/step=768ms, lr=4.99e-04
2024-11-19 14:19:54,428 - logger.py:50 - Epoch: [9][400/1000] loss: 1.30060, MAE: 0.30456, time/step=774ms, lr=4.99e-04
2024-11-19 14:20:34,000 - logger.py:50 - Epoch: [9][450/1000] loss: 1.30254, MAE: 0.30448, time/step=776ms, lr=4.99e-04
2024-11-19 14:21:13,911 - logger.py:50 - Epoch: [9][500/1000] loss: 1.29889, MAE: 0.30540, time/step=778ms, lr=4.99e-04
2024-11-19 14:21:54,836 - logger.py:50 - Epoch: [9][550/1000] loss: 1.28938, MAE: 0.30461, time/step=782ms, lr=4.99e-04
2024-11-19 14:22:34,263 - logger.py:50 - Epoch: [9][600/1000] loss: 1.28640, MAE: 0.30508, time/step=783ms, lr=4.99e-04
2024-11-19 14:23:12,337 - logger.py:50 - Epoch: [9][650/1000] loss: 1.28870, MAE: 0.30521, time/step=781ms, lr=4.99e-04
2024-11-19 14:23:51,487 - logger.py:50 - Epoch: [9][700/1000] loss: 1.29628, MAE: 0.30453, time/step=781ms, lr=4.99e-04
2024-11-19 14:24:29,343 - logger.py:50 - Epoch: [9][750/1000] loss: 1.30378, MAE: 0.30463, time/step=780ms, lr=4.99e-04
2024-11-19 14:25:08,478 - logger.py:50 - Epoch: [9][800/1000] loss: 1.51211, MAE: 0.30846, time/step=780ms, lr=4.99e-04
2024-11-19 14:25:49,889 - logger.py:50 - Epoch: [9][850/1000] loss: 1.49877, MAE: 0.30740, time/step=783ms, lr=4.99e-04
2024-11-19 14:26:30,644 - logger.py:50 - Epoch: [9][900/1000] loss: 1.48873, MAE: 0.30721, time/step=784ms, lr=4.99e-04
2024-11-19 14:27:12,138 - logger.py:50 - Epoch: [9][950/1000] loss: 1.47635, MAE: 0.30696, time/step=787ms, lr=4.99e-04
2024-11-19 14:27:52,821 - logger.py:50 - Epoch: [9][999/1000] loss: 1.45644, MAE: 0.30566, time/step=789ms, lr=4.99e-04
2024-11-19 14:29:04,948 - logger.py:50 - Epoch: [9] train loss: 1.45644, train MAE: 0.30566,val loss: 0.30648, val MAE: 0.30648,test loss: 0.31851, test MAE: 0.31851,Time: 861.05s
2024-11-19 14:29:04,949 - logger.py:50 - Best -- epoch=9, train loss: 1.45644, val loss: 0.30648, test loss: 0.31851

2024-11-19 14:29:05,442 - logger.py:50 - Epoch: [10][0/1000] loss: 1.70746, MAE: 0.33982, time/step=491ms, lr=4.99e-04
2024-11-19 14:29:42,484 - logger.py:50 - Epoch: [10][50/1000] loss: 1.37733, MAE: 0.29678, time/step=736ms, lr=4.99e-04
2024-11-19 14:30:19,179 - logger.py:50 - Epoch: [10][100/1000] loss: 1.32485, MAE: 0.29706, time/step=735ms, lr=4.99e-04
2024-11-19 14:30:57,843 - logger.py:50 - Epoch: [10][150/1000] loss: 1.33580, MAE: 0.30226, time/step=748ms, lr=4.99e-04
2024-11-19 14:31:38,168 - logger.py:50 - Epoch: [10][200/1000] loss: 1.31021, MAE: 0.30111, time/step=762ms, lr=4.99e-04
2024-11-19 14:32:17,817 - logger.py:50 - Epoch: [10][250/1000] loss: 1.96309, MAE: 0.31367, time/step=768ms, lr=4.99e-04
2024-11-19 14:32:56,913 - logger.py:50 - Epoch: [10][300/1000] loss: 1.87283, MAE: 0.31316, time/step=771ms, lr=4.99e-04
2024-11-19 14:33:37,107 - logger.py:50 - Epoch: [10][350/1000] loss: 1.77639, MAE: 0.31175, time/step=775ms, lr=4.99e-04
2024-11-19 14:34:16,140 - logger.py:50 - Epoch: [10][400/1000] loss: 1.71088, MAE: 0.31061, time/step=776ms, lr=4.99e-04
2024-11-19 14:34:58,263 - logger.py:50 - Epoch: [10][450/1000] loss: 1.66267, MAE: 0.31016, time/step=783ms, lr=4.99e-04
2024-11-19 14:35:38,931 - logger.py:50 - Epoch: [10][500/1000] loss: 1.62115, MAE: 0.30942, time/step=786ms, lr=4.99e-04
2024-11-19 14:36:21,858 - logger.py:50 - Epoch: [10][550/1000] loss: 1.58759, MAE: 0.30880, time/step=793ms, lr=4.99e-04
2024-11-19 14:37:03,228 - logger.py:50 - Epoch: [10][600/1000] loss: 1.55706, MAE: 0.30809, time/step=796ms, lr=4.99e-04
2024-11-19 14:37:46,610 - logger.py:50 - Epoch: [10][650/1000] loss: 1.53713, MAE: 0.30746, time/step=801ms, lr=4.99e-04
2024-11-19 14:38:26,406 - logger.py:50 - Epoch: [10][700/1000] loss: 1.51449, MAE: 0.30705, time/step=801ms, lr=4.99e-04
2024-11-19 14:39:09,977 - logger.py:50 - Epoch: [10][750/1000] loss: 1.50596, MAE: 0.30699, time/step=806ms, lr=4.99e-04
2024-11-19 14:39:52,401 - logger.py:50 - Epoch: [10][800/1000] loss: 1.49640, MAE: 0.30695, time/step=808ms, lr=4.99e-04
2024-11-19 14:40:32,714 - logger.py:50 - Epoch: [10][850/1000] loss: 1.48818, MAE: 0.30657, time/step=808ms, lr=4.99e-04
2024-11-19 14:41:13,738 - logger.py:50 - Epoch: [10][900/1000] loss: 1.48095, MAE: 0.30617, time/step=809ms, lr=4.99e-04
2024-11-19 14:41:52,991 - logger.py:50 - Epoch: [10][950/1000] loss: 1.46917, MAE: 0.30619, time/step=808ms, lr=4.99e-04
2024-11-19 14:42:35,972 - logger.py:50 - Epoch: [10][999/1000] loss: 1.45643, MAE: 0.30565, time/step=811ms, lr=4.99e-04
2024-11-19 14:43:50,580 - logger.py:50 - Epoch: [10] train loss: 1.45643, train MAE: 0.30565,val loss: 0.30703, val MAE: 0.30703,test loss: 0.31914, test MAE: 0.31914,Time: 885.63s
2024-11-19 14:43:50,580 - logger.py:50 - Best -- epoch=9, train loss: 1.45644, val loss: 0.30648, test loss: 0.31851

2024-11-19 14:43:51,198 - logger.py:50 - Epoch: [11][0/1000] loss: 0.32508, MAE: 0.21042, time/step=615ms, lr=4.98e-04
2024-11-19 14:44:27,691 - logger.py:50 - Epoch: [11][50/1000] loss: 1.16308, MAE: 0.29577, time/step=728ms, lr=4.98e-04
2024-11-19 14:45:05,502 - logger.py:50 - Epoch: [11][100/1000] loss: 1.19141, MAE: 0.29894, time/step=742ms, lr=4.98e-04
2024-11-19 14:45:42,192 - logger.py:50 - Epoch: [11][150/1000] loss: 1.24102, MAE: 0.29890, time/step=739ms, lr=4.98e-04
2024-11-19 14:46:19,496 - logger.py:50 - Epoch: [11][200/1000] loss: 1.24584, MAE: 0.29927, time/step=741ms, lr=4.98e-04
2024-11-19 14:46:58,579 - logger.py:50 - Epoch: [11][250/1000] loss: 1.24758, MAE: 0.29749, time/step=749ms, lr=4.98e-04
2024-11-19 14:47:35,778 - logger.py:50 - Epoch: [11][300/1000] loss: 1.26673, MAE: 0.30020, time/step=748ms, lr=4.98e-04
2024-11-19 14:48:14,960 - logger.py:50 - Epoch: [11][350/1000] loss: 1.27068, MAE: 0.30054, time/step=753ms, lr=4.98e-04
2024-11-19 14:48:53,433 - logger.py:50 - Epoch: [11][400/1000] loss: 1.25074, MAE: 0.29906, time/step=755ms, lr=4.98e-04
2024-11-19 14:49:32,352 - logger.py:50 - Epoch: [11][450/1000] loss: 1.24839, MAE: 0.29926, time/step=758ms, lr=4.98e-04
2024-11-19 14:50:13,860 - logger.py:50 - Epoch: [11][500/1000] loss: 1.58669, MAE: 0.30650, time/step=765ms, lr=4.98e-04
2024-11-19 14:50:52,893 - logger.py:50 - Epoch: [11][550/1000] loss: 1.55412, MAE: 0.30569, time/step=766ms, lr=4.98e-04
2024-11-19 14:51:30,755 - logger.py:50 - Epoch: [11][600/1000] loss: 1.52989, MAE: 0.30560, time/step=766ms, lr=4.98e-04
2024-11-19 14:52:09,111 - logger.py:50 - Epoch: [11][650/1000] loss: 1.52438, MAE: 0.30606, time/step=766ms, lr=4.98e-04
2024-11-19 14:52:47,110 - logger.py:50 - Epoch: [11][700/1000] loss: 1.51557, MAE: 0.30605, time/step=765ms, lr=4.98e-04
2024-11-19 14:53:25,712 - logger.py:50 - Epoch: [11][750/1000] loss: 1.49507, MAE: 0.30488, time/step=766ms, lr=4.98e-04
2024-11-19 14:54:04,547 - logger.py:50 - Epoch: [11][800/1000] loss: 1.48678, MAE: 0.30472, time/step=766ms, lr=4.98e-04
2024-11-19 14:54:43,546 - logger.py:50 - Epoch: [11][850/1000] loss: 1.48290, MAE: 0.30551, time/step=767ms, lr=4.98e-04
2024-11-19 14:55:21,648 - logger.py:50 - Epoch: [11][900/1000] loss: 1.46911, MAE: 0.30572, time/step=767ms, lr=4.98e-04
2024-11-19 14:56:01,683 - logger.py:50 - Epoch: [11][950/1000] loss: 1.46555, MAE: 0.30581, time/step=769ms, lr=4.98e-04
2024-11-19 14:56:40,910 - logger.py:50 - Epoch: [11][999/1000] loss: 1.45631, MAE: 0.30559, time/step=770ms, lr=4.98e-04
2024-11-19 14:57:53,959 - logger.py:50 - Epoch: [11] train loss: 1.45631, train MAE: 0.30559,val loss: 0.30672, val MAE: 0.30672,test loss: 0.31870, test MAE: 0.31870,Time: 843.38s
2024-11-19 14:57:53,959 - logger.py:50 - Best -- epoch=9, train loss: 1.45644, val loss: 0.30648, test loss: 0.31851

2024-11-19 14:57:55,079 - logger.py:50 - Epoch: [12][0/1000] loss: 2.37974, MAE: 0.40640, time/step=1116ms, lr=4.98e-04
2024-11-19 14:58:33,835 - logger.py:50 - Epoch: [12][50/1000] loss: 1.32973, MAE: 0.30124, time/step=782ms, lr=4.98e-04
2024-11-19 14:59:11,362 - logger.py:50 - Epoch: [12][100/1000] loss: 1.36472, MAE: 0.30496, time/step=766ms, lr=4.98e-04
2024-11-19 14:59:50,266 - logger.py:50 - Epoch: [12][150/1000] loss: 1.42601, MAE: 0.31152, time/step=770ms, lr=4.98e-04
2024-11-19 15:00:28,527 - logger.py:50 - Epoch: [12][200/1000] loss: 1.37438, MAE: 0.30676, time/step=769ms, lr=4.98e-04
2024-11-19 15:01:07,591 - logger.py:50 - Epoch: [12][250/1000] loss: 1.38787, MAE: 0.31049, time/step=771ms, lr=4.98e-04
2024-11-19 15:01:48,828 - logger.py:50 - Epoch: [12][300/1000] loss: 1.36927, MAE: 0.30957, time/step=780ms, lr=4.98e-04
2024-11-19 15:02:27,777 - logger.py:50 - Epoch: [12][350/1000] loss: 1.33681, MAE: 0.30680, time/step=780ms, lr=4.98e-04
2024-11-19 15:03:08,992 - logger.py:50 - Epoch: [12][400/1000] loss: 1.33658, MAE: 0.30668, time/step=786ms, lr=4.98e-04
2024-11-19 15:03:46,138 - logger.py:50 - Epoch: [12][450/1000] loss: 1.31689, MAE: 0.30418, time/step=781ms, lr=4.98e-04
2024-11-19 15:04:25,351 - logger.py:50 - Epoch: [12][500/1000] loss: 1.31696, MAE: 0.30316, time/step=781ms, lr=4.98e-04
2024-11-19 15:05:03,148 - logger.py:50 - Epoch: [12][550/1000] loss: 1.32376, MAE: 0.30355, time/step=779ms, lr=4.98e-04
2024-11-19 15:05:42,876 - logger.py:50 - Epoch: [12][600/1000] loss: 1.32687, MAE: 0.30480, time/step=780ms, lr=4.98e-04
2024-11-19 15:06:24,530 - logger.py:50 - Epoch: [12][650/1000] loss: 1.30808, MAE: 0.30373, time/step=784ms, lr=4.98e-04
2024-11-19 15:07:06,367 - logger.py:50 - Epoch: [12][700/1000] loss: 1.29932, MAE: 0.30345, time/step=788ms, lr=4.98e-04
2024-11-19 15:07:45,632 - logger.py:50 - Epoch: [12][750/1000] loss: 1.29191, MAE: 0.30284, time/step=788ms, lr=4.98e-04
2024-11-19 15:08:25,198 - logger.py:50 - Epoch: [12][800/1000] loss: 1.28909, MAE: 0.30273, time/step=788ms, lr=4.98e-04
2024-11-19 15:09:05,583 - logger.py:50 - Epoch: [12][850/1000] loss: 1.28581, MAE: 0.30284, time/step=789ms, lr=4.98e-04
2024-11-19 15:09:45,221 - logger.py:50 - Epoch: [12][900/1000] loss: 1.27991, MAE: 0.30149, time/step=789ms, lr=4.98e-04
2024-11-19 15:10:25,202 - logger.py:50 - Epoch: [12][950/1000] loss: 1.46657, MAE: 0.30549, time/step=790ms, lr=4.98e-04
2024-11-19 15:11:04,296 - logger.py:50 - Epoch: [12][999/1000] loss: 1.45646, MAE: 0.30563, time/step=790ms, lr=4.98e-04
2024-11-19 15:12:14,441 - logger.py:50 - Epoch: [12] train loss: 1.45646, train MAE: 0.30563,val loss: 0.30629, val MAE: 0.30629,test loss: 0.31849, test MAE: 0.31849,Time: 860.48s
2024-11-19 15:12:14,441 - logger.py:50 - Best -- epoch=12, train loss: 1.45646, val loss: 0.30629, test loss: 0.31849

2024-11-19 15:12:15,056 - logger.py:50 - Epoch: [13][0/1000] loss: 0.57632, MAE: 0.30094, time/step=612ms, lr=4.98e-04
2024-11-19 15:12:52,008 - logger.py:50 - Epoch: [13][50/1000] loss: 1.10240, MAE: 0.29260, time/step=737ms, lr=4.98e-04
2024-11-19 15:13:27,311 - logger.py:50 - Epoch: [13][100/1000] loss: 1.21281, MAE: 0.30054, time/step=721ms, lr=4.98e-04
2024-11-19 15:14:02,523 - logger.py:50 - Epoch: [13][150/1000] loss: 1.27220, MAE: 0.30507, time/step=716ms, lr=4.98e-04
2024-11-19 15:14:40,266 - logger.py:50 - Epoch: [13][200/1000] loss: 1.31252, MAE: 0.30878, time/step=725ms, lr=4.98e-04
2024-11-19 15:15:18,338 - logger.py:50 - Epoch: [13][250/1000] loss: 1.98033, MAE: 0.31914, time/step=733ms, lr=4.98e-04
2024-11-19 15:15:58,450 - logger.py:50 - Epoch: [13][300/1000] loss: 1.85469, MAE: 0.31672, time/step=744ms, lr=4.98e-04
2024-11-19 15:16:38,554 - logger.py:50 - Epoch: [13][350/1000] loss: 1.76888, MAE: 0.31463, time/step=752ms, lr=4.98e-04
2024-11-19 15:17:20,495 - logger.py:50 - Epoch: [13][400/1000] loss: 1.73028, MAE: 0.31405, time/step=763ms, lr=4.98e-04
2024-11-19 15:18:00,610 - logger.py:50 - Epoch: [13][450/1000] loss: 1.69340, MAE: 0.31203, time/step=768ms, lr=4.98e-04
2024-11-19 15:18:43,012 - logger.py:50 - Epoch: [13][500/1000] loss: 1.64149, MAE: 0.30990, time/step=776ms, lr=4.98e-04
2024-11-19 15:19:21,870 - logger.py:50 - Epoch: [13][550/1000] loss: 1.61140, MAE: 0.30990, time/step=776ms, lr=4.98e-04
2024-11-19 15:20:00,771 - logger.py:50 - Epoch: [13][600/1000] loss: 1.58619, MAE: 0.30982, time/step=776ms, lr=4.98e-04
2024-11-19 15:20:40,558 - logger.py:50 - Epoch: [13][650/1000] loss: 1.56272, MAE: 0.31026, time/step=777ms, lr=4.98e-04
2024-11-19 15:21:18,451 - logger.py:50 - Epoch: [13][700/1000] loss: 1.53645, MAE: 0.30902, time/step=776ms, lr=4.98e-04
2024-11-19 15:21:57,378 - logger.py:50 - Epoch: [13][750/1000] loss: 1.52224, MAE: 0.30868, time/step=776ms, lr=4.98e-04
2024-11-19 15:22:35,505 - logger.py:50 - Epoch: [13][800/1000] loss: 1.50050, MAE: 0.30766, time/step=775ms, lr=4.98e-04
2024-11-19 15:23:15,409 - logger.py:50 - Epoch: [13][850/1000] loss: 1.47954, MAE: 0.30658, time/step=777ms, lr=4.98e-04
2024-11-19 15:23:55,594 - logger.py:50 - Epoch: [13][900/1000] loss: 1.47915, MAE: 0.30650, time/step=778ms, lr=4.98e-04
2024-11-19 15:24:39,470 - logger.py:50 - Epoch: [13][950/1000] loss: 1.46528, MAE: 0.30577, time/step=783ms, lr=4.98e-04
2024-11-19 15:25:19,725 - logger.py:50 - Epoch: [13][999/1000] loss: 1.45650, MAE: 0.30570, time/step=785ms, lr=4.98e-04
2024-11-19 15:28:03,973 - logger.py:50 - Epoch: [13] train loss: 1.45650, train MAE: 0.30570,val loss: 0.30689, val MAE: 0.30689,test loss: 0.31892, test MAE: 0.31892,Time: 949.53s
2024-11-19 15:28:03,974 - logger.py:50 - Best -- epoch=12, train loss: 1.45646, val loss: 0.30629, test loss: 0.31849

2024-11-19 15:28:05,585 - logger.py:50 - Epoch: [14][0/1000] loss: 0.51267, MAE: 0.26179, time/step=1609ms, lr=4.97e-04
2024-11-19 15:29:53,035 - logger.py:50 - Epoch: [14][50/1000] loss: 1.38504, MAE: 0.30931, time/step=2138ms, lr=4.97e-04
2024-11-19 15:31:34,765 - logger.py:50 - Epoch: [14][100/1000] loss: 1.28636, MAE: 0.30010, time/step=2087ms, lr=4.97e-04
2024-11-19 15:33:20,536 - logger.py:50 - Epoch: [14][150/1000] loss: 1.27709, MAE: 0.29886, time/step=2096ms, lr=4.97e-04
2024-11-19 15:35:07,692 - logger.py:50 - Epoch: [14][200/1000] loss: 1.25106, MAE: 0.29699, time/step=2108ms, lr=4.97e-04
2024-11-19 15:37:00,087 - logger.py:50 - Epoch: [14][250/1000] loss: 1.26323, MAE: 0.29978, time/step=2136ms, lr=4.97e-04
2024-11-19 15:38:52,556 - logger.py:50 - Epoch: [14][300/1000] loss: 1.22633, MAE: 0.29685, time/step=2155ms, lr=4.97e-04
2024-11-19 15:40:40,331 - logger.py:50 - Epoch: [14][350/1000] loss: 1.22504, MAE: 0.29648, time/step=2155ms, lr=4.97e-04
2024-11-19 15:42:25,579 - logger.py:50 - Epoch: [14][400/1000] loss: 1.22628, MAE: 0.29704, time/step=2149ms, lr=4.97e-04
2024-11-19 15:44:10,998 - logger.py:50 - Epoch: [14][450/1000] loss: 1.22410, MAE: 0.29853, time/step=2144ms, lr=4.97e-04
2024-11-19 15:45:57,439 - logger.py:50 - Epoch: [14][500/1000] loss: 1.25043, MAE: 0.29985, time/step=2143ms, lr=4.97e-04
2024-11-19 15:47:51,594 - logger.py:50 - Epoch: [14][550/1000] loss: 1.26362, MAE: 0.30051, time/step=2155ms, lr=4.97e-04
2024-11-19 15:49:44,613 - logger.py:50 - Epoch: [14][600/1000] loss: 1.26445, MAE: 0.30119, time/step=2164ms, lr=4.97e-04
2024-11-19 15:51:36,844 - logger.py:50 - Epoch: [14][650/1000] loss: 1.27956, MAE: 0.30127, time/step=2170ms, lr=4.97e-04
2024-11-19 15:53:26,797 - logger.py:50 - Epoch: [14][700/1000] loss: 1.28131, MAE: 0.30223, time/step=2172ms, lr=4.97e-04
2024-11-19 15:55:14,935 - logger.py:50 - Epoch: [14][750/1000] loss: 1.27728, MAE: 0.30269, time/step=2172ms, lr=4.97e-04
2024-11-19 15:57:05,912 - logger.py:50 - Epoch: [14][800/1000] loss: 1.49297, MAE: 0.30671, time/step=2175ms, lr=4.97e-04
2024-11-19 15:58:58,760 - logger.py:50 - Epoch: [14][850/1000] loss: 1.48234, MAE: 0.30612, time/step=2180ms, lr=4.97e-04
2024-11-19 16:00:57,142 - logger.py:50 - Epoch: [14][900/1000] loss: 1.46686, MAE: 0.30464, time/step=2190ms, lr=4.97e-04
2024-11-19 16:02:52,891 - logger.py:50 - Epoch: [14][950/1000] loss: 1.45914, MAE: 0.30494, time/step=2197ms, lr=4.97e-04
2024-11-19 16:04:43,018 - logger.py:50 - Epoch: [14][999/1000] loss: 1.45625, MAE: 0.30559, time/step=2199ms, lr=4.97e-04
2024-11-19 16:07:56,338 - logger.py:50 - Epoch: [14] train loss: 1.45625, train MAE: 0.30559,val loss: 0.30783, val MAE: 0.30783,test loss: 0.31981, test MAE: 0.31981,Time: 2392.36s
2024-11-19 16:07:56,338 - logger.py:50 - Best -- epoch=12, train loss: 1.45646, val loss: 0.30629, test loss: 0.31849

2024-11-19 16:07:58,413 - logger.py:50 - Epoch: [15][0/1000] loss: 1.15504, MAE: 0.29015, time/step=2071ms, lr=4.97e-04
2024-11-19 16:09:37,297 - logger.py:50 - Epoch: [15][50/1000] loss: 1.42290, MAE: 0.29848, time/step=1980ms, lr=4.97e-04
2024-11-19 16:11:29,652 - logger.py:50 - Epoch: [15][100/1000] loss: 1.25167, MAE: 0.29640, time/step=2112ms, lr=4.97e-04
2024-11-22 18:23:29,070 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-22 18:23:52,228 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-22 18:23:53,937 - logger.py:50 - Number of params: 2978805
2024-11-22 18:23:58,049 - logger.py:50 - Epoch: [0][0/1000] loss: 4.08479, MAE: 0.73749, time/step=4107ms, lr=1.00e-06
2024-11-22 18:26:14,450 - logger.py:50 - Epoch: [0][50/1000] loss: 2.39461, MAE: 0.54465, time/step=2755ms, lr=1.00e-06
2024-11-22 18:28:21,119 - logger.py:50 - Epoch: [0][100/1000] loss: 4.00998, MAE: 0.56150, time/step=2645ms, lr=1.00e-06
2024-11-22 18:30:22,195 - logger.py:50 - Epoch: [0][150/1000] loss: 3.34495, MAE: 0.53141, time/step=2571ms, lr=1.00e-06
2024-11-22 18:45:06,212 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-22 18:45:30,311 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-22 18:45:31,891 - logger.py:50 - Number of params: 2978805
2024-11-22 18:45:36,020 - logger.py:50 - Epoch: [0][0/1000] loss: 4.08479, MAE: 0.73749, time/step=4124ms, lr=1.00e-06
2024-11-22 18:46:30,615 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-22 18:47:06,556 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-22 18:51:43,257 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-22 18:52:07,321 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-22 18:52:08,353 - logger.py:50 - Number of params: 2978805
2024-11-22 18:52:12,525 - logger.py:50 - Epoch: [0][0/1000] loss: 4.08479, MAE: 0.73749, time/step=4167ms, lr=1.00e-06
2024-11-22 18:54:35,943 - logger.py:50 - Epoch: [0][50/1000] loss: 2.39461, MAE: 0.54465, time/step=2894ms, lr=1.00e-06
2024-11-22 18:56:51,745 - logger.py:50 - Epoch: [0][100/1000] loss: 4.00998, MAE: 0.56150, time/step=2806ms, lr=1.00e-06
2024-11-22 18:58:59,822 - logger.py:50 - Epoch: [0][150/1000] loss: 3.34495, MAE: 0.53141, time/step=2725ms, lr=1.00e-06
2024-11-22 19:25:54,253 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-22 19:26:17,849 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-22 19:26:18,916 - logger.py:50 - Number of params: 2978805
2024-11-22 19:26:24,897 - logger.py:50 - Epoch: [0][0/1000] loss: 4.08479, MAE: 0.73749, time/step=5976ms, lr=1.00e-06
2024-11-22 19:28:44,307 - logger.py:50 - Epoch: [0][50/1000] loss: 2.39461, MAE: 0.54465, time/step=2851ms, lr=1.00e-06
2024-11-22 19:30:49,870 - logger.py:50 - Epoch: [0][100/1000] loss: 4.00998, MAE: 0.56150, time/step=2683ms, lr=1.00e-06
2024-11-22 19:32:51,454 - logger.py:50 - Epoch: [0][150/1000] loss: 3.34495, MAE: 0.53141, time/step=2600ms, lr=1.00e-06
2024-11-22 19:38:40,189 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-22 19:40:14,583 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-22 19:40:37,874 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-22 19:40:38,928 - logger.py:50 - Number of params: 2978805
2024-11-22 19:40:44,252 - logger.py:50 - Epoch: [0][0/1000] loss: 4.08479, MAE: 0.73749, time/step=5320ms, lr=1.00e-06
2024-11-22 19:43:04,167 - logger.py:50 - Epoch: [0][50/1000] loss: 2.39461, MAE: 0.54465, time/step=2848ms, lr=1.00e-06
2024-11-22 19:45:12,207 - logger.py:50 - Epoch: [0][100/1000] loss: 4.00998, MAE: 0.56150, time/step=2706ms, lr=1.00e-06
2024-11-22 19:47:14,840 - logger.py:50 - Epoch: [0][150/1000] loss: 3.34495, MAE: 0.53141, time/step=2622ms, lr=1.00e-06
2024-11-22 19:53:32,902 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm_dx', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-22 19:53:57,255 - logger.py:50 - GraphAttentionTransformer_dx(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-22 19:53:57,750 - logger.py:50 - Number of params: 2978805
2024-11-25 21:37:04,240 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm_dx', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-25 21:37:28,483 - logger.py:50 - GraphAttentionTransformer_dx(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-25 21:37:28,756 - logger.py:50 - Number of params: 2978805
2024-11-25 21:50:14,360 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm_dx', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-25 21:50:57,360 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm_dx', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-25 21:51:25,212 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm_dx', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-25 21:51:48,293 - logger.py:50 - GraphAttentionTransformer_dx(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-25 21:51:49,280 - logger.py:50 - Number of params: 2978805
2024-11-25 21:53:07,193 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm_dx', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-25 21:53:30,146 - logger.py:50 - GraphAttentionTransformer_dx(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-25 21:53:30,517 - logger.py:50 - Number of params: 2978805
2024-11-25 22:10:00,973 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-11-25 22:10:24,497 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-11-25 22:10:25,470 - logger.py:50 - Number of params: 2978805
2024-11-25 22:10:29,589 - logger.py:50 - Epoch: [0][0/1000] loss: 4.08479, MAE: 0.73749, time/step=4114ms, lr=1.00e-06
2024-11-25 22:12:27,142 - logger.py:50 - Epoch: [0][50/1000] loss: 2.39461, MAE: 0.54465, time/step=2386ms, lr=1.00e-06
2024-11-25 22:14:22,513 - logger.py:50 - Epoch: [0][100/1000] loss: 4.00998, MAE: 0.56150, time/step=2347ms, lr=1.00e-06
2024-11-25 22:16:18,395 - logger.py:50 - Epoch: [0][150/1000] loss: 3.34495, MAE: 0.53141, time/step=2337ms, lr=1.00e-06
2024-11-26 21:53:42,145 - logger.py:50 - Namespace(output_dir='../models/Test/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=300, batch_size=8, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='../datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
