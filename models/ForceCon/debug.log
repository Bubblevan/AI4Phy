2024-03-15 01:32:59,163 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=4, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 01:36:42,723 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 01:36:42,739 - logger.py:50 - Number of params: 2978805
2024-03-15 01:40:32,535 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=4, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 01:40:39,842 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 01:40:40,305 - logger.py:50 - Number of params: 2978805
2024-03-15 01:40:42,202 - logger.py:50 - Epoch: [0][0/38] loss: 69.89140, MAE: 0.57683, time/step=1893ms, lr=1.00e-06
2024-03-15 01:40:56,477 - logger.py:50 - Epoch: [0][37/38] loss: 19012.87913, MAE: 0.66039, time/step=425ms, lr=1.00e-06
2024-03-15 01:52:34,571 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=4, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 01:52:41,553 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 01:52:42,172 - logger.py:50 - Number of params: 2978805
2024-03-15 01:54:07,516 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=4, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 01:54:14,561 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 01:54:14,869 - logger.py:50 - Number of params: 2978805
2024-03-15 01:54:16,178 - logger.py:50 - Epoch: [0][0/38] loss: 69.89140, MAE: 0.57683, time/step=1304ms, lr=1.00e-06
2024-03-15 01:54:31,111 - logger.py:50 - Epoch: [0][37/38] loss: 19012.87913, MAE: 0.66039, time/step=427ms, lr=1.00e-06
2024-03-15 01:55:21,361 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=4, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 01:55:28,394 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 01:55:28,935 - logger.py:50 - Number of params: 2978805
2024-03-15 01:55:30,304 - logger.py:50 - Epoch: [0][0/38] loss: 69.89140, MAE: 0.57683, time/step=1365ms, lr=1.00e-06
2024-03-15 01:55:44,706 - logger.py:50 - Epoch: [0][37/38] loss: 19012.87943, MAE: 0.66039, time/step=415ms, lr=1.00e-06
2024-03-15 01:55:46,489 - logger.py:50 - Epoch: [0] train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623, Time: 17.55s
2024-03-15 01:55:46,490 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:55:46,728 - logger.py:50 - Epoch: [1][0/38] loss: 405.99765, MAE: 0.72100, time/step=236ms, lr=1.08e-05
2024-03-15 01:55:59,321 - logger.py:50 - Epoch: [1][37/38] loss: 14742.88109, MAE: 0.73647, time/step=338ms, lr=1.08e-05
2024-03-15 01:56:01,131 - logger.py:50 - Epoch: [1] train MAE: 0.73647, val MAE: 0.82689, test MAE: 0.79669, Time: 14.64s
2024-03-15 01:56:01,131 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:56:01,446 - logger.py:50 - Epoch: [2][0/38] loss: 76.06024, MAE: 0.60232, time/step=313ms, lr=2.06e-05
2024-03-15 01:56:15,815 - logger.py:50 - Epoch: [2][37/38] loss: 15052.69900, MAE: 0.71119, time/step=386ms, lr=2.06e-05
2024-03-15 01:56:17,715 - logger.py:50 - Epoch: [2] train MAE: 0.71119, val MAE: 0.89151, test MAE: 0.84651, Time: 16.58s
2024-03-15 01:56:17,715 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:56:18,000 - logger.py:50 - Epoch: [3][0/38] loss: 1118.20520, MAE: 0.79989, time/step=282ms, lr=3.04e-05
2024-03-15 01:56:28,738 - logger.py:50 - Epoch: [3][37/38] loss: 11920.57569, MAE: 0.71623, time/step=290ms, lr=3.04e-05
2024-03-15 01:56:30,661 - logger.py:50 - Epoch: [3] train MAE: 0.71623, val MAE: 0.83532, test MAE: 0.80415, Time: 12.95s
2024-03-15 01:56:30,661 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:56:30,982 - logger.py:50 - Epoch: [4][0/38] loss: 1265.77905, MAE: 0.54711, time/step=319ms, lr=4.02e-05
2024-03-15 01:56:45,354 - logger.py:50 - Epoch: [4][37/38] loss: 14202.23951, MAE: 0.71088, time/step=387ms, lr=4.02e-05
2024-03-15 01:56:47,214 - logger.py:50 - Epoch: [4] train MAE: 0.71088, val MAE: 0.82103, test MAE: 0.78517, Time: 16.55s
2024-03-15 01:56:47,214 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:56:47,531 - logger.py:50 - Epoch: [5][0/38] loss: 8775.81543, MAE: 0.82982, time/step=315ms, lr=4.99e-05
2024-03-15 01:56:59,379 - logger.py:50 - Epoch: [5][37/38] loss: 16353.16356, MAE: 0.71787, time/step=320ms, lr=4.99e-05
2024-03-15 01:57:00,686 - logger.py:50 - Epoch: [5] train MAE: 0.71787, val MAE: 0.83436, test MAE: 0.78575, Time: 13.47s
2024-03-15 01:57:00,686 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:57:00,884 - logger.py:50 - Epoch: [6][0/38] loss: 3263.67017, MAE: 0.38104, time/step=196ms, lr=4.98e-05
2024-03-15 01:57:14,683 - logger.py:50 - Epoch: [6][37/38] loss: 9975.21117, MAE: 0.69673, time/step=368ms, lr=4.98e-05
2024-03-15 01:57:16,520 - logger.py:50 - Epoch: [6] train MAE: 0.69673, val MAE: 0.80602, test MAE: 0.76664, Time: 15.83s
2024-03-15 01:57:16,520 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:57:16,859 - logger.py:50 - Epoch: [7][0/38] loss: 9171.00781, MAE: 0.37007, time/step=337ms, lr=4.97e-05
2024-03-15 01:57:30,761 - logger.py:50 - Epoch: [7][37/38] loss: 7892.69128, MAE: 0.69183, time/step=375ms, lr=4.97e-05
2024-03-15 01:57:32,062 - logger.py:50 - Epoch: [7] train MAE: 0.69183, val MAE: 0.89782, test MAE: 0.84475, Time: 15.54s
2024-03-15 01:57:32,063 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:57:32,291 - logger.py:50 - Epoch: [8][0/38] loss: 12670.59766, MAE: 0.82141, time/step=226ms, lr=4.97e-05
2024-03-15 01:57:43,834 - logger.py:50 - Epoch: [8][37/38] loss: 12067.22883, MAE: 0.70499, time/step=310ms, lr=4.97e-05
2024-03-15 01:57:45,748 - logger.py:50 - Epoch: [8] train MAE: 0.70499, val MAE: 0.84860, test MAE: 0.79371, Time: 13.69s
2024-03-15 01:57:45,748 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:57:46,041 - logger.py:50 - Epoch: [9][0/38] loss: 841.82324, MAE: 0.95810, time/step=291ms, lr=4.96e-05
2024-03-15 01:58:00,458 - logger.py:50 - Epoch: [9][37/38] loss: 8284.91450, MAE: 0.68168, time/step=387ms, lr=4.96e-05
2024-03-15 01:58:02,347 - logger.py:50 - Epoch: [9] train MAE: 0.68168, val MAE: 0.83653, test MAE: 0.78496, Time: 16.60s
2024-03-15 01:58:02,348 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:58:02,637 - logger.py:50 - Epoch: [10][0/38] loss: 1910.91821, MAE: 0.98579, time/step=288ms, lr=4.95e-05
2024-03-15 01:58:13,673 - logger.py:50 - Epoch: [10][37/38] loss: 8737.34390, MAE: 0.69487, time/step=298ms, lr=4.95e-05
2024-03-15 01:58:14,948 - logger.py:50 - Epoch: [10] train MAE: 0.69487, val MAE: 0.84933, test MAE: 0.80866, Time: 12.60s
2024-03-15 01:58:14,948 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:58:15,352 - logger.py:50 - Epoch: [11][0/38] loss: 4901.93115, MAE: 1.04631, time/step=402ms, lr=4.94e-05
2024-03-15 01:58:29,711 - logger.py:50 - Epoch: [11][37/38] loss: 10825.97701, MAE: 0.70208, time/step=388ms, lr=4.94e-05
2024-03-15 01:58:31,674 - logger.py:50 - Epoch: [11] train MAE: 0.70208, val MAE: 0.86186, test MAE: 0.82144, Time: 16.73s
2024-03-15 01:58:31,674 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:58:32,131 - logger.py:50 - Epoch: [12][0/38] loss: 1408.36792, MAE: 0.51131, time/step=455ms, lr=4.92e-05
2024-03-15 01:58:45,085 - logger.py:50 - Epoch: [12][37/38] loss: 9660.76025, MAE: 0.69492, time/step=353ms, lr=4.92e-05
2024-03-15 01:58:46,298 - logger.py:50 - Epoch: [12] train MAE: 0.69492, val MAE: 0.79038, test MAE: 0.74430, Time: 14.62s
2024-03-15 01:58:46,298 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:58:46,523 - logger.py:50 - Epoch: [13][0/38] loss: 108171.28906, MAE: 0.74319, time/step=222ms, lr=4.91e-05
2024-03-15 01:58:59,016 - logger.py:50 - Epoch: [13][37/38] loss: 7895.44870, MAE: 0.68856, time/step=335ms, lr=4.91e-05
2024-03-15 01:59:00,896 - logger.py:50 - Epoch: [13] train MAE: 0.68856, val MAE: 0.81561, test MAE: 0.75597, Time: 14.60s
2024-03-15 01:59:00,896 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:59:01,302 - logger.py:50 - Epoch: [14][0/38] loss: 2489.20532, MAE: 0.78517, time/step=404ms, lr=4.90e-05
2024-03-15 01:59:15,513 - logger.py:50 - Epoch: [14][37/38] loss: 6791.86695, MAE: 0.67977, time/step=385ms, lr=4.90e-05
2024-03-15 01:59:17,313 - logger.py:50 - Epoch: [14] train MAE: 0.67977, val MAE: 0.83799, test MAE: 0.77825, Time: 16.42s
2024-03-15 01:59:17,313 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:59:17,735 - logger.py:50 - Epoch: [15][0/38] loss: 100.77113, MAE: 0.60219, time/step=420ms, lr=4.88e-05
2024-03-15 01:59:28,216 - logger.py:50 - Epoch: [15][37/38] loss: 3545.63969, MAE: 0.67549, time/step=287ms, lr=4.88e-05
2024-03-15 01:59:30,139 - logger.py:50 - Epoch: [15] train MAE: 0.67549, val MAE: 0.78736, test MAE: 0.72872, Time: 12.83s
2024-03-15 01:59:30,139 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:59:30,468 - logger.py:50 - Epoch: [16][0/38] loss: 2875.24780, MAE: 0.97391, time/step=327ms, lr=4.86e-05
2024-03-15 01:59:44,926 - logger.py:50 - Epoch: [16][37/38] loss: 10025.54673, MAE: 0.67315, time/step=389ms, lr=4.86e-05
2024-03-15 01:59:46,898 - logger.py:50 - Epoch: [16] train MAE: 0.67315, val MAE: 0.83932, test MAE: 0.77622, Time: 16.76s
2024-03-15 01:59:46,898 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 01:59:47,221 - logger.py:50 - Epoch: [17][0/38] loss: 33.66394, MAE: 0.78036, time/step=320ms, lr=4.85e-05
2024-03-15 01:59:59,416 - logger.py:50 - Epoch: [17][37/38] loss: 5520.05448, MAE: 0.67675, time/step=329ms, lr=4.85e-05
2024-03-15 02:00:00,604 - logger.py:50 - Epoch: [17] train MAE: 0.67675, val MAE: 0.86153, test MAE: 0.79669, Time: 13.71s
2024-03-15 02:00:00,605 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:00:00,829 - logger.py:50 - Epoch: [18][0/38] loss: 6912.18604, MAE: 0.60629, time/step=222ms, lr=4.83e-05
2024-03-15 02:00:14,336 - logger.py:50 - Epoch: [18][37/38] loss: 5066.67485, MAE: 0.67645, time/step=361ms, lr=4.83e-05
2024-03-15 02:00:16,243 - logger.py:50 - Epoch: [18] train MAE: 0.67645, val MAE: 0.85507, test MAE: 0.80185, Time: 15.64s
2024-03-15 02:00:16,243 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:00:16,671 - logger.py:50 - Epoch: [19][0/38] loss: 7138.18213, MAE: 0.64671, time/step=426ms, lr=4.81e-05
2024-03-15 02:00:30,855 - logger.py:50 - Epoch: [19][37/38] loss: 5575.03099, MAE: 0.68100, time/step=384ms, lr=4.81e-05
2024-03-15 02:00:32,136 - logger.py:50 - Epoch: [19] train MAE: 0.68100, val MAE: 0.82933, test MAE: 0.77058, Time: 15.89s
2024-03-15 02:00:32,136 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:00:32,379 - logger.py:50 - Epoch: [20][0/38] loss: 7664.08643, MAE: 0.76380, time/step=241ms, lr=4.79e-05
2024-03-15 02:00:43,602 - logger.py:50 - Epoch: [20][37/38] loss: 6032.63811, MAE: 0.67852, time/step=302ms, lr=4.79e-05
2024-03-15 02:00:45,518 - logger.py:50 - Epoch: [20] train MAE: 0.67852, val MAE: 0.82775, test MAE: 0.76827, Time: 13.38s
2024-03-15 02:00:45,518 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:00:45,938 - logger.py:50 - Epoch: [21][0/38] loss: 103.53100, MAE: 0.60770, time/step=417ms, lr=4.77e-05
2024-03-15 02:01:00,231 - logger.py:50 - Epoch: [21][37/38] loss: 3906.01362, MAE: 0.67368, time/step=387ms, lr=4.77e-05
2024-03-15 02:01:02,090 - logger.py:50 - Epoch: [21] train MAE: 0.67368, val MAE: 0.86437, test MAE: 0.80107, Time: 16.57s
2024-03-15 02:01:02,090 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:01:02,447 - logger.py:50 - Epoch: [22][0/38] loss: 2304.05273, MAE: 0.74923, time/step=355ms, lr=4.74e-05
2024-03-15 02:01:13,636 - logger.py:50 - Epoch: [22][37/38] loss: 5440.18640, MAE: 0.68671, time/step=304ms, lr=4.74e-05
2024-03-15 02:01:14,825 - logger.py:50 - Epoch: [22] train MAE: 0.68671, val MAE: 0.82181, test MAE: 0.76685, Time: 12.74s
2024-03-15 02:01:14,826 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:01:15,238 - logger.py:50 - Epoch: [23][0/38] loss: 802.23022, MAE: 0.84884, time/step=410ms, lr=4.72e-05
2024-03-15 02:01:29,385 - logger.py:50 - Epoch: [23][37/38] loss: 3438.41882, MAE: 0.67609, time/step=383ms, lr=4.72e-05
2024-03-15 02:01:31,228 - logger.py:50 - Epoch: [23] train MAE: 0.67609, val MAE: 0.77618, test MAE: 0.74150, Time: 16.40s
2024-03-15 02:01:31,228 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:01:31,576 - logger.py:50 - Epoch: [24][0/38] loss: 533.31140, MAE: 0.45622, time/step=346ms, lr=4.70e-05
2024-03-15 02:01:45,066 - logger.py:50 - Epoch: [24][37/38] loss: 4332.20642, MAE: 0.67236, time/step=364ms, lr=4.70e-05
2024-03-15 02:01:46,269 - logger.py:50 - Epoch: [24] train MAE: 0.67236, val MAE: 0.82789, test MAE: 0.79040, Time: 15.04s
2024-03-15 02:01:46,269 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:01:46,506 - logger.py:50 - Epoch: [25][0/38] loss: 151.62697, MAE: 0.58719, time/step=234ms, lr=4.67e-05
2024-03-15 02:01:58,833 - logger.py:50 - Epoch: [25][37/38] loss: 3771.57087, MAE: 0.68329, time/step=331ms, lr=4.67e-05
2024-03-15 02:02:00,715 - logger.py:50 - Epoch: [25] train MAE: 0.68329, val MAE: 0.83631, test MAE: 0.78725, Time: 14.45s
2024-03-15 02:02:00,716 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:02:01,129 - logger.py:50 - Epoch: [26][0/38] loss: 2133.54443, MAE: 0.70683, time/step=412ms, lr=4.65e-05
2024-03-15 02:02:15,422 - logger.py:50 - Epoch: [26][37/38] loss: 3228.89631, MAE: 0.67162, time/step=387ms, lr=4.65e-05
2024-03-15 02:02:17,283 - logger.py:50 - Epoch: [26] train MAE: 0.67162, val MAE: 0.90769, test MAE: 0.84653, Time: 16.57s
2024-03-15 02:02:17,283 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:02:17,617 - logger.py:50 - Epoch: [27][0/38] loss: 11963.72559, MAE: 0.97699, time/step=332ms, lr=4.62e-05
2024-03-15 02:02:28,193 - logger.py:50 - Epoch: [27][37/38] loss: 4348.45648, MAE: 0.68137, time/step=287ms, lr=4.62e-05
2024-03-15 02:02:30,110 - logger.py:50 - Epoch: [27] train MAE: 0.68137, val MAE: 0.77854, test MAE: 0.74189, Time: 12.83s
2024-03-15 02:02:30,110 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:02:30,380 - logger.py:50 - Epoch: [28][0/38] loss: 149.72400, MAE: 0.46980, time/step=268ms, lr=4.59e-05
2024-03-15 02:02:44,984 - logger.py:50 - Epoch: [28][37/38] loss: 2391.30199, MAE: 0.67528, time/step=391ms, lr=4.59e-05
2024-03-15 02:02:46,809 - logger.py:50 - Epoch: [28] train MAE: 0.67528, val MAE: 0.80492, test MAE: 0.76237, Time: 16.70s
2024-03-15 02:02:46,809 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:02:47,100 - logger.py:50 - Epoch: [29][0/38] loss: 71.57197, MAE: 0.71644, time/step=288ms, lr=4.56e-05
2024-03-15 02:02:59,479 - logger.py:50 - Epoch: [29][37/38] loss: 3002.20777, MAE: 0.67856, time/step=333ms, lr=4.56e-05
2024-03-15 02:03:00,669 - logger.py:50 - Epoch: [29] train MAE: 0.67856, val MAE: 0.76462, test MAE: 0.73635, Time: 13.86s
2024-03-15 02:03:00,669 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:03:01,017 - logger.py:50 - Epoch: [30][0/38] loss: 16707.06836, MAE: 0.82468, time/step=345ms, lr=4.53e-05
2024-03-15 02:03:14,221 - logger.py:50 - Epoch: [30][37/38] loss: 2402.05523, MAE: 0.67739, time/step=357ms, lr=4.53e-05
2024-03-15 02:03:16,073 - logger.py:50 - Epoch: [30] train MAE: 0.67739, val MAE: 0.80200, test MAE: 0.75835, Time: 15.40s
2024-03-15 02:03:16,073 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:03:16,488 - logger.py:50 - Epoch: [31][0/38] loss: 23.38216, MAE: 0.63365, time/step=413ms, lr=4.50e-05
2024-03-15 02:03:30,561 - logger.py:50 - Epoch: [31][37/38] loss: 2906.16312, MAE: 0.67812, time/step=381ms, lr=4.50e-05
2024-03-15 02:03:32,006 - logger.py:50 - Epoch: [31] train MAE: 0.67812, val MAE: 0.79356, test MAE: 0.74623, Time: 15.93s
2024-03-15 02:03:32,006 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:03:32,241 - logger.py:50 - Epoch: [32][0/38] loss: 409.22864, MAE: 0.76002, time/step=233ms, lr=4.47e-05
2024-03-15 02:03:43,288 - logger.py:50 - Epoch: [32][37/38] loss: 1701.59065, MAE: 0.68091, time/step=297ms, lr=4.47e-05
2024-03-15 02:03:45,299 - logger.py:50 - Epoch: [32] train MAE: 0.68091, val MAE: 0.80354, test MAE: 0.77141, Time: 13.29s
2024-03-15 02:03:45,299 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:03:45,657 - logger.py:50 - Epoch: [33][0/38] loss: 2623.71997, MAE: 0.56763, time/step=356ms, lr=4.44e-05
2024-03-15 02:03:59,872 - logger.py:50 - Epoch: [33][37/38] loss: 1130.55601, MAE: 0.67723, time/step=383ms, lr=4.44e-05
2024-03-15 02:04:01,742 - logger.py:50 - Epoch: [33] train MAE: 0.67723, val MAE: 0.80091, test MAE: 0.76112, Time: 16.44s
2024-03-15 02:04:01,742 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:04:02,130 - logger.py:50 - Epoch: [34][0/38] loss: 397.83801, MAE: 0.35164, time/step=385ms, lr=4.40e-05
2024-03-15 02:04:13,554 - logger.py:50 - Epoch: [34][37/38] loss: 1515.27410, MAE: 0.67850, time/step=311ms, lr=4.40e-05
2024-03-15 02:04:14,748 - logger.py:50 - Epoch: [34] train MAE: 0.67850, val MAE: 0.79329, test MAE: 0.75808, Time: 13.01s
2024-03-15 02:04:14,748 - logger.py:50 - Best -- epoch=0, train MAE: 0.66039, val MAE: 0.75941, test MAE: 0.73623

2024-03-15 02:04:15,092 - logger.py:50 - Epoch: [35][0/38] loss: 452.58121, MAE: 0.60811, time/step=342ms, lr=4.37e-05
2024-03-15 02:04:29,156 - logger.py:50 - Epoch: [35][37/38] loss: 1890.34188, MAE: 0.67482, time/step=379ms, lr=4.37e-05
2024-03-15 02:04:31,237 - logger.py:50 - Epoch: [35] train MAE: 0.67482, val MAE: 0.75132, test MAE: 0.71955, Time: 16.49s
2024-03-15 02:04:31,237 - logger.py:50 - Best -- epoch=35, train MAE: 0.67482, val MAE: 0.75132, test MAE: 0.71955

2024-03-15 02:04:31,544 - logger.py:50 - Epoch: [36][0/38] loss: 28.75595, MAE: 0.47998, time/step=305ms, lr=4.34e-05
2024-03-15 02:04:45,098 - logger.py:50 - Epoch: [36][37/38] loss: 2706.36106, MAE: 0.68096, time/step=365ms, lr=4.34e-05
2024-03-15 02:04:46,498 - logger.py:50 - Epoch: [36] train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358, Time: 15.26s
2024-03-15 02:04:46,498 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:04:46,863 - logger.py:50 - Epoch: [37][0/38] loss: 2842.26172, MAE: 0.78717, time/step=362ms, lr=4.30e-05
2024-03-15 02:04:58,979 - logger.py:50 - Epoch: [37][37/38] loss: 1508.53040, MAE: 0.68354, time/step=328ms, lr=4.30e-05
2024-03-15 02:05:00,799 - logger.py:50 - Epoch: [37] train MAE: 0.68354, val MAE: 0.79173, test MAE: 0.75798, Time: 14.30s
2024-03-15 02:05:00,799 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:05:01,124 - logger.py:50 - Epoch: [38][0/38] loss: 54.53431, MAE: 0.72298, time/step=322ms, lr=4.26e-05
2024-03-15 02:05:15,339 - logger.py:50 - Epoch: [38][37/38] loss: 1188.07510, MAE: 0.67471, time/step=383ms, lr=4.26e-05
2024-03-15 02:05:17,206 - logger.py:50 - Epoch: [38] train MAE: 0.67471, val MAE: 0.78615, test MAE: 0.75517, Time: 16.41s
2024-03-15 02:05:17,206 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:05:17,507 - logger.py:50 - Epoch: [39][0/38] loss: 753.00732, MAE: 0.91851, time/step=299ms, lr=4.23e-05
2024-03-15 02:05:27,963 - logger.py:50 - Epoch: [39][37/38] loss: 649.66243, MAE: 0.67424, time/step=283ms, lr=4.23e-05
2024-03-15 02:05:29,872 - logger.py:50 - Epoch: [39] train MAE: 0.67424, val MAE: 0.78795, test MAE: 0.75827, Time: 12.67s
2024-03-15 02:05:29,872 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:05:30,231 - logger.py:50 - Epoch: [40][0/38] loss: 134.83073, MAE: 0.76836, time/step=357ms, lr=4.19e-05
2024-03-15 02:05:44,547 - logger.py:50 - Epoch: [40][37/38] loss: 593.40504, MAE: 0.68057, time/step=386ms, lr=4.19e-05
2024-03-15 02:05:46,413 - logger.py:50 - Epoch: [40] train MAE: 0.68057, val MAE: 0.81105, test MAE: 0.77042, Time: 16.54s
2024-03-15 02:05:46,413 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:05:46,717 - logger.py:50 - Epoch: [41][0/38] loss: 1437.08740, MAE: 0.48106, time/step=301ms, lr=4.15e-05
2024-03-15 02:05:59,238 - logger.py:50 - Epoch: [41][37/38] loss: 794.61543, MAE: 0.67887, time/step=337ms, lr=4.15e-05
2024-03-15 02:06:00,589 - logger.py:50 - Epoch: [41] train MAE: 0.67887, val MAE: 0.80397, test MAE: 0.76662, Time: 14.18s
2024-03-15 02:06:00,589 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:06:00,896 - logger.py:50 - Epoch: [42][0/38] loss: 1483.62732, MAE: 0.82465, time/step=304ms, lr=4.11e-05
2024-03-15 02:06:13,713 - logger.py:50 - Epoch: [42][37/38] loss: 742.66244, MAE: 0.68156, time/step=345ms, lr=4.11e-05
2024-03-15 02:06:15,548 - logger.py:50 - Epoch: [42] train MAE: 0.68156, val MAE: 0.78398, test MAE: 0.74339, Time: 14.96s
2024-03-15 02:06:15,549 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:06:15,878 - logger.py:50 - Epoch: [43][0/38] loss: 1388.97925, MAE: 0.44483, time/step=327ms, lr=4.07e-05
2024-03-15 02:06:30,105 - logger.py:50 - Epoch: [43][37/38] loss: 742.12792, MAE: 0.67762, time/step=383ms, lr=4.07e-05
2024-03-15 02:06:31,887 - logger.py:50 - Epoch: [43] train MAE: 0.67762, val MAE: 0.80363, test MAE: 0.75704, Time: 16.34s
2024-03-15 02:06:31,887 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:06:32,279 - logger.py:50 - Epoch: [44][0/38] loss: 4.37970, MAE: 0.79079, time/step=390ms, lr=4.03e-05
2024-03-15 02:06:42,891 - logger.py:50 - Epoch: [44][37/38] loss: 517.55171, MAE: 0.67741, time/step=290ms, lr=4.03e-05
2024-03-15 02:06:44,799 - logger.py:50 - Epoch: [44] train MAE: 0.67741, val MAE: 0.80183, test MAE: 0.76515, Time: 12.91s
2024-03-15 02:06:44,800 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:06:45,215 - logger.py:50 - Epoch: [45][0/38] loss: 1428.97522, MAE: 0.44864, time/step=414ms, lr=3.99e-05
2024-03-15 02:06:59,493 - logger.py:50 - Epoch: [45][37/38] loss: 484.54475, MAE: 0.68296, time/step=387ms, lr=3.99e-05
2024-03-15 02:07:01,463 - logger.py:50 - Epoch: [45] train MAE: 0.68296, val MAE: 0.78964, test MAE: 0.75249, Time: 16.66s
2024-03-15 02:07:01,463 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:07:01,801 - logger.py:50 - Epoch: [46][0/38] loss: 344.50522, MAE: 0.97871, time/step=336ms, lr=3.95e-05
2024-03-15 02:07:13,672 - logger.py:50 - Epoch: [46][37/38] loss: 935.22704, MAE: 0.67824, time/step=321ms, lr=3.95e-05
2024-03-15 02:07:14,857 - logger.py:50 - Epoch: [46] train MAE: 0.67824, val MAE: 0.77760, test MAE: 0.74701, Time: 13.39s
2024-03-15 02:07:14,857 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:07:15,089 - logger.py:50 - Epoch: [47][0/38] loss: 602.32733, MAE: 0.63838, time/step=229ms, lr=3.91e-05
2024-03-15 02:07:28,801 - logger.py:50 - Epoch: [47][37/38] loss: 526.71693, MAE: 0.67837, time/step=367ms, lr=3.91e-05
2024-03-15 02:07:30,627 - logger.py:50 - Epoch: [47] train MAE: 0.67837, val MAE: 0.79709, test MAE: 0.76047, Time: 15.77s
2024-03-15 02:07:30,627 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:07:30,936 - logger.py:50 - Epoch: [48][0/38] loss: 13.55403, MAE: 0.91787, time/step=306ms, lr=3.86e-05
2024-03-15 02:07:44,961 - logger.py:50 - Epoch: [48][37/38] loss: 466.70267, MAE: 0.67897, time/step=377ms, lr=3.86e-05
2024-03-15 02:07:46,265 - logger.py:50 - Epoch: [48] train MAE: 0.67897, val MAE: 0.76283, test MAE: 0.72897, Time: 15.64s
2024-03-15 02:07:46,266 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:07:46,561 - logger.py:50 - Epoch: [49][0/38] loss: 1274.77637, MAE: 0.71572, time/step=294ms, lr=3.82e-05
2024-03-15 02:07:58,212 - logger.py:50 - Epoch: [49][37/38] loss: 1035.73383, MAE: 0.67613, time/step=314ms, lr=3.82e-05
2024-03-15 02:08:00,125 - logger.py:50 - Epoch: [49] train MAE: 0.67613, val MAE: 0.79043, test MAE: 0.75287, Time: 13.86s
2024-03-15 02:08:00,125 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:08:00,384 - logger.py:50 - Epoch: [50][0/38] loss: 79.08935, MAE: 0.33908, time/step=257ms, lr=3.78e-05
2024-03-15 02:08:14,623 - logger.py:50 - Epoch: [50][37/38] loss: 481.47828, MAE: 0.67480, time/step=381ms, lr=3.78e-05
2024-03-15 02:08:16,564 - logger.py:50 - Epoch: [50] train MAE: 0.67480, val MAE: 0.80816, test MAE: 0.77037, Time: 16.44s
2024-03-15 02:08:16,564 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:08:16,962 - logger.py:50 - Epoch: [51][0/38] loss: 379.84189, MAE: 0.72845, time/step=396ms, lr=3.73e-05
2024-03-15 02:08:27,891 - logger.py:50 - Epoch: [51][37/38] loss: 336.17977, MAE: 0.67920, time/step=298ms, lr=3.73e-05
2024-03-15 02:08:29,343 - logger.py:50 - Epoch: [51] train MAE: 0.67920, val MAE: 0.77940, test MAE: 0.74706, Time: 12.78s
2024-03-15 02:08:29,344 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:08:29,685 - logger.py:50 - Epoch: [52][0/38] loss: 27.32334, MAE: 0.78932, time/step=340ms, lr=3.69e-05
2024-03-15 02:08:44,044 - logger.py:50 - Epoch: [52][37/38] loss: 370.45610, MAE: 0.67587, time/step=387ms, lr=3.69e-05
2024-03-15 02:08:45,864 - logger.py:50 - Epoch: [52] train MAE: 0.67587, val MAE: 0.78020, test MAE: 0.75008, Time: 16.52s
2024-03-15 02:08:45,864 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:08:46,398 - logger.py:50 - Epoch: [53][0/38] loss: 264.63211, MAE: 0.90556, time/step=531ms, lr=3.64e-05
2024-03-15 02:08:59,330 - logger.py:50 - Epoch: [53][37/38] loss: 545.34570, MAE: 0.67676, time/step=354ms, lr=3.64e-05
2024-03-15 02:09:00,532 - logger.py:50 - Epoch: [53] train MAE: 0.67676, val MAE: 0.79734, test MAE: 0.76398, Time: 14.67s
2024-03-15 02:09:00,532 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:09:01,000 - logger.py:50 - Epoch: [54][0/38] loss: 18.59871, MAE: 0.75362, time/step=466ms, lr=3.59e-05
2024-03-15 02:09:13,225 - logger.py:50 - Epoch: [54][37/38] loss: 294.87955, MAE: 0.67557, time/step=334ms, lr=3.59e-05
2024-03-15 02:09:15,119 - logger.py:50 - Epoch: [54] train MAE: 0.67557, val MAE: 0.78898, test MAE: 0.75967, Time: 14.59s
2024-03-15 02:09:15,119 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:09:15,452 - logger.py:50 - Epoch: [55][0/38] loss: 37.57434, MAE: 0.65241, time/step=331ms, lr=3.55e-05
2024-03-15 02:09:29,730 - logger.py:50 - Epoch: [55][37/38] loss: 260.65923, MAE: 0.67660, time/step=384ms, lr=3.55e-05
2024-03-15 02:09:31,558 - logger.py:50 - Epoch: [55] train MAE: 0.67660, val MAE: 0.79168, test MAE: 0.76461, Time: 16.44s
2024-03-15 02:09:31,559 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:09:31,854 - logger.py:50 - Epoch: [56][0/38] loss: 227.88118, MAE: 0.47998, time/step=293ms, lr=3.50e-05
2024-03-15 02:09:42,475 - logger.py:50 - Epoch: [56][37/38] loss: 612.53262, MAE: 0.67555, time/step=287ms, lr=3.50e-05
2024-03-15 02:09:44,393 - logger.py:50 - Epoch: [56] train MAE: 0.67555, val MAE: 0.78118, test MAE: 0.75416, Time: 12.83s
2024-03-15 02:09:44,393 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:09:44,856 - logger.py:50 - Epoch: [57][0/38] loss: 876.13776, MAE: 0.38106, time/step=461ms, lr=3.45e-05
2024-03-15 02:09:59,191 - logger.py:50 - Epoch: [57][37/38] loss: 271.73756, MAE: 0.67779, time/step=389ms, lr=3.45e-05
2024-03-15 02:10:01,029 - logger.py:50 - Epoch: [57] train MAE: 0.67779, val MAE: 0.78953, test MAE: 0.76197, Time: 16.64s
2024-03-15 02:10:01,029 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:10:01,387 - logger.py:50 - Epoch: [58][0/38] loss: 512.15027, MAE: 0.61818, time/step=355ms, lr=3.40e-05
2024-03-15 02:10:13,449 - logger.py:50 - Epoch: [58][37/38] loss: 231.66879, MAE: 0.67754, time/step=327ms, lr=3.40e-05
2024-03-15 02:10:14,637 - logger.py:50 - Epoch: [58] train MAE: 0.67754, val MAE: 0.78425, test MAE: 0.75354, Time: 13.61s
2024-03-15 02:10:14,637 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:10:15,020 - logger.py:50 - Epoch: [59][0/38] loss: 102.70605, MAE: 0.89228, time/step=381ms, lr=3.36e-05
2024-03-15 02:10:28,476 - logger.py:50 - Epoch: [59][37/38] loss: 354.03140, MAE: 0.67876, time/step=364ms, lr=3.36e-05
2024-03-15 02:10:30,297 - logger.py:50 - Epoch: [59] train MAE: 0.67876, val MAE: 0.80336, test MAE: 0.76851, Time: 15.66s
2024-03-15 02:10:30,297 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:10:30,725 - logger.py:50 - Epoch: [60][0/38] loss: 347.21353, MAE: 0.66778, time/step=426ms, lr=3.31e-05
2024-03-15 02:10:44,803 - logger.py:50 - Epoch: [60][37/38] loss: 252.63793, MAE: 0.67841, time/step=382ms, lr=3.31e-05
2024-03-15 02:10:46,081 - logger.py:50 - Epoch: [60] train MAE: 0.67841, val MAE: 0.80434, test MAE: 0.76761, Time: 15.78s
2024-03-15 02:10:46,081 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:10:46,320 - logger.py:50 - Epoch: [61][0/38] loss: 137.06316, MAE: 0.84675, time/step=237ms, lr=3.26e-05
2024-03-15 02:10:57,416 - logger.py:50 - Epoch: [61][37/38] loss: 331.18049, MAE: 0.67570, time/step=298ms, lr=3.26e-05
2024-03-15 02:10:59,422 - logger.py:50 - Epoch: [61] train MAE: 0.67570, val MAE: 0.79263, test MAE: 0.75784, Time: 13.34s
2024-03-15 02:10:59,422 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:10:59,848 - logger.py:50 - Epoch: [62][0/38] loss: 679.76624, MAE: 0.89217, time/step=424ms, lr=3.21e-05
2024-03-15 02:11:14,010 - logger.py:50 - Epoch: [62][37/38] loss: 789.89828, MAE: 0.67762, time/step=384ms, lr=3.21e-05
2024-03-15 02:11:15,838 - logger.py:50 - Epoch: [62] train MAE: 0.67762, val MAE: 0.77042, test MAE: 0.73948, Time: 16.42s
2024-03-15 02:11:15,839 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:11:16,222 - logger.py:50 - Epoch: [63][0/38] loss: 2279.16797, MAE: 0.52310, time/step=382ms, lr=3.16e-05
2024-03-15 02:11:27,539 - logger.py:50 - Epoch: [63][37/38] loss: 393.77080, MAE: 0.67493, time/step=308ms, lr=3.16e-05
2024-03-15 02:11:28,718 - logger.py:50 - Epoch: [63] train MAE: 0.67493, val MAE: 0.80754, test MAE: 0.77289, Time: 12.88s
2024-03-15 02:11:28,718 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:11:29,057 - logger.py:50 - Epoch: [64][0/38] loss: 28.57556, MAE: 0.67108, time/step=336ms, lr=3.11e-05
2024-03-15 02:11:42,894 - logger.py:50 - Epoch: [64][37/38] loss: 254.39331, MAE: 0.67739, time/step=373ms, lr=3.11e-05
2024-03-15 02:11:44,753 - logger.py:50 - Epoch: [64] train MAE: 0.67739, val MAE: 0.78647, test MAE: 0.75252, Time: 16.03s
2024-03-15 02:11:44,754 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:11:45,070 - logger.py:50 - Epoch: [65][0/38] loss: 438.72147, MAE: 0.59404, time/step=314ms, lr=3.06e-05
2024-03-15 02:11:58,696 - logger.py:50 - Epoch: [65][37/38] loss: 313.69492, MAE: 0.67672, time/step=367ms, lr=3.06e-05
2024-03-15 02:11:59,871 - logger.py:50 - Epoch: [65] train MAE: 0.67672, val MAE: 0.79347, test MAE: 0.75950, Time: 15.12s
2024-03-15 02:11:59,871 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:12:00,274 - logger.py:50 - Epoch: [66][0/38] loss: 441.11023, MAE: 0.46299, time/step=401ms, lr=3.01e-05
2024-03-15 02:12:11,988 - logger.py:50 - Epoch: [66][37/38] loss: 369.05209, MAE: 0.67928, time/step=319ms, lr=3.01e-05
2024-03-15 02:12:13,906 - logger.py:50 - Epoch: [66] train MAE: 0.67928, val MAE: 0.80114, test MAE: 0.76610, Time: 14.03s
2024-03-15 02:12:13,906 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:12:14,279 - logger.py:50 - Epoch: [67][0/38] loss: 5.59029, MAE: 0.70749, time/step=372ms, lr=2.96e-05
2024-03-15 02:12:28,366 - logger.py:50 - Epoch: [67][37/38] loss: 234.50542, MAE: 0.67939, time/step=380ms, lr=2.96e-05
2024-03-15 02:12:30,180 - logger.py:50 - Epoch: [67] train MAE: 0.67939, val MAE: 0.78110, test MAE: 0.74780, Time: 16.27s
2024-03-15 02:12:30,180 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:12:30,506 - logger.py:50 - Epoch: [68][0/38] loss: 203.29826, MAE: 0.65201, time/step=323ms, lr=2.91e-05
2024-03-15 02:12:41,241 - logger.py:50 - Epoch: [68][37/38] loss: 189.38963, MAE: 0.67769, time/step=291ms, lr=2.91e-05
2024-03-15 02:12:42,672 - logger.py:50 - Epoch: [68] train MAE: 0.67769, val MAE: 0.78392, test MAE: 0.75026, Time: 12.49s
2024-03-15 02:12:42,672 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:12:43,018 - logger.py:50 - Epoch: [69][0/38] loss: 52.71661, MAE: 0.54507, time/step=345ms, lr=2.86e-05
2024-03-15 02:12:57,244 - logger.py:50 - Epoch: [69][37/38] loss: 225.41841, MAE: 0.67922, time/step=383ms, lr=2.86e-05
2024-03-15 02:12:59,167 - logger.py:50 - Epoch: [69] train MAE: 0.67922, val MAE: 0.78633, test MAE: 0.75436, Time: 16.49s
2024-03-15 02:12:59,167 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:12:59,534 - logger.py:50 - Epoch: [70][0/38] loss: 306.48932, MAE: 0.54394, time/step=365ms, lr=2.81e-05
2024-03-15 02:13:12,503 - logger.py:50 - Epoch: [70][37/38] loss: 330.88724, MAE: 0.67995, time/step=351ms, lr=2.81e-05
2024-03-15 02:13:13,729 - logger.py:50 - Epoch: [70] train MAE: 0.67995, val MAE: 0.79883, test MAE: 0.76524, Time: 14.56s
2024-03-15 02:13:13,730 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:13:13,968 - logger.py:50 - Epoch: [71][0/38] loss: 263.05280, MAE: 0.35256, time/step=235ms, lr=2.76e-05
2024-03-15 02:13:26,348 - logger.py:50 - Epoch: [71][37/38] loss: 318.32248, MAE: 0.68116, time/step=332ms, lr=2.76e-05
2024-03-15 02:13:28,257 - logger.py:50 - Epoch: [71] train MAE: 0.68116, val MAE: 0.77883, test MAE: 0.75131, Time: 14.53s
2024-03-15 02:13:28,257 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:13:28,598 - logger.py:50 - Epoch: [72][0/38] loss: 549.84723, MAE: 0.52816, time/step=339ms, lr=2.70e-05
2024-03-15 02:13:42,737 - logger.py:50 - Epoch: [72][37/38] loss: 348.82163, MAE: 0.67891, time/step=381ms, lr=2.70e-05
2024-03-15 02:13:44,549 - logger.py:50 - Epoch: [72] train MAE: 0.67891, val MAE: 0.77661, test MAE: 0.74897, Time: 16.29s
2024-03-15 02:13:44,549 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:13:44,963 - logger.py:50 - Epoch: [73][0/38] loss: 71.14816, MAE: 0.52903, time/step=412ms, lr=2.65e-05
2024-03-15 02:13:55,388 - logger.py:50 - Epoch: [73][37/38] loss: 239.62809, MAE: 0.67813, time/step=285ms, lr=2.65e-05
2024-03-15 02:13:57,305 - logger.py:50 - Epoch: [73] train MAE: 0.67813, val MAE: 0.78587, test MAE: 0.75483, Time: 12.76s
2024-03-15 02:13:57,305 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:13:57,775 - logger.py:50 - Epoch: [74][0/38] loss: 35.93338, MAE: 0.85905, time/step=468ms, lr=2.60e-05
2024-03-15 02:14:11,951 - logger.py:50 - Epoch: [74][37/38] loss: 183.19124, MAE: 0.67804, time/step=385ms, lr=2.60e-05
2024-03-15 02:14:13,799 - logger.py:50 - Epoch: [74] train MAE: 0.67804, val MAE: 0.80313, test MAE: 0.77121, Time: 16.49s
2024-03-15 02:14:13,799 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:14:14,103 - logger.py:50 - Epoch: [75][0/38] loss: 290.11026, MAE: 0.58624, time/step=302ms, lr=2.55e-05
2024-03-15 02:14:26,413 - logger.py:50 - Epoch: [75][37/38] loss: 231.88413, MAE: 0.68067, time/step=332ms, lr=2.55e-05
2024-03-15 02:14:27,596 - logger.py:50 - Epoch: [75] train MAE: 0.68067, val MAE: 0.78626, test MAE: 0.75525, Time: 13.80s
2024-03-15 02:14:27,597 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:14:27,926 - logger.py:50 - Epoch: [76][0/38] loss: 58.97010, MAE: 0.69542, time/step=327ms, lr=2.50e-05
2024-03-15 02:14:41,137 - logger.py:50 - Epoch: [76][37/38] loss: 297.77573, MAE: 0.67660, time/step=356ms, lr=2.50e-05
2024-03-15 02:14:42,938 - logger.py:50 - Epoch: [76] train MAE: 0.67660, val MAE: 0.80720, test MAE: 0.76946, Time: 15.34s
2024-03-15 02:14:42,938 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:14:43,317 - logger.py:50 - Epoch: [77][0/38] loss: 11.14987, MAE: 0.60468, time/step=376ms, lr=2.45e-05
2024-03-15 02:14:57,455 - logger.py:50 - Epoch: [77][37/38] loss: 324.43664, MAE: 0.68136, time/step=382ms, lr=2.45e-05
2024-03-15 02:14:58,837 - logger.py:50 - Epoch: [77] train MAE: 0.68136, val MAE: 0.80148, test MAE: 0.76766, Time: 15.90s
2024-03-15 02:14:58,837 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:14:59,195 - logger.py:50 - Epoch: [78][0/38] loss: 8.46297, MAE: 0.39911, time/step=356ms, lr=2.40e-05
2024-03-15 02:15:10,092 - logger.py:50 - Epoch: [78][37/38] loss: 302.10048, MAE: 0.67867, time/step=296ms, lr=2.40e-05
2024-03-15 02:15:11,995 - logger.py:50 - Epoch: [78] train MAE: 0.67867, val MAE: 0.80193, test MAE: 0.76518, Time: 13.16s
2024-03-15 02:15:11,995 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:15:12,407 - logger.py:50 - Epoch: [79][0/38] loss: 4.90743, MAE: 0.54505, time/step=409ms, lr=2.34e-05
2024-03-15 02:15:26,487 - logger.py:50 - Epoch: [79][37/38] loss: 167.72691, MAE: 0.67668, time/step=381ms, lr=2.34e-05
2024-03-15 02:15:28,361 - logger.py:50 - Epoch: [79] train MAE: 0.67668, val MAE: 0.78777, test MAE: 0.75642, Time: 16.37s
2024-03-15 02:15:28,362 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:15:28,745 - logger.py:50 - Epoch: [80][0/38] loss: 374.72159, MAE: 0.94815, time/step=381ms, lr=2.29e-05
2024-03-15 02:15:40,229 - logger.py:50 - Epoch: [80][37/38] loss: 198.75880, MAE: 0.67771, time/step=312ms, lr=2.29e-05
2024-03-15 02:15:41,522 - logger.py:50 - Epoch: [80] train MAE: 0.67771, val MAE: 0.79617, test MAE: 0.75963, Time: 13.16s
2024-03-15 02:15:41,522 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:15:41,773 - logger.py:50 - Epoch: [81][0/38] loss: 4.85537, MAE: 0.63084, time/step=249ms, lr=2.24e-05
2024-03-15 02:15:55,486 - logger.py:50 - Epoch: [81][37/38] loss: 171.10612, MAE: 0.67825, time/step=367ms, lr=2.24e-05
2024-03-15 02:15:57,349 - logger.py:50 - Epoch: [81] train MAE: 0.67825, val MAE: 0.79435, test MAE: 0.75797, Time: 15.83s
2024-03-15 02:15:57,349 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:15:57,653 - logger.py:50 - Epoch: [82][0/38] loss: 37.60054, MAE: 0.81138, time/step=302ms, lr=2.19e-05
2024-03-15 02:16:11,539 - logger.py:50 - Epoch: [82][37/38] loss: 232.83269, MAE: 0.67457, time/step=373ms, lr=2.19e-05
2024-03-15 02:16:12,723 - logger.py:50 - Epoch: [82] train MAE: 0.67457, val MAE: 0.78216, test MAE: 0.75329, Time: 15.37s
2024-03-15 02:16:12,723 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:16:13,059 - logger.py:50 - Epoch: [83][0/38] loss: 2.87088, MAE: 0.57560, time/step=334ms, lr=2.14e-05
2024-03-15 02:16:24,617 - logger.py:50 - Epoch: [83][37/38] loss: 274.44316, MAE: 0.68010, time/step=313ms, lr=2.14e-05
2024-03-15 02:16:26,520 - logger.py:50 - Epoch: [83] train MAE: 0.68010, val MAE: 0.77790, test MAE: 0.74873, Time: 13.80s
2024-03-15 02:16:26,520 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:16:26,815 - logger.py:50 - Epoch: [84][0/38] loss: 20.99893, MAE: 0.42399, time/step=293ms, lr=2.09e-05
2024-03-15 02:16:41,072 - logger.py:50 - Epoch: [84][37/38] loss: 210.57772, MAE: 0.67629, time/step=383ms, lr=2.09e-05
2024-03-15 02:16:42,917 - logger.py:50 - Epoch: [84] train MAE: 0.67629, val MAE: 0.80350, test MAE: 0.76754, Time: 16.40s
2024-03-15 02:16:42,917 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:16:43,236 - logger.py:50 - Epoch: [85][0/38] loss: 95.23814, MAE: 0.73627, time/step=316ms, lr=2.04e-05
2024-03-15 02:16:54,232 - logger.py:50 - Epoch: [85][37/38] loss: 152.81920, MAE: 0.67972, time/step=298ms, lr=2.04e-05
2024-03-15 02:16:55,500 - logger.py:50 - Epoch: [85] train MAE: 0.67972, val MAE: 0.79093, test MAE: 0.75898, Time: 12.58s
2024-03-15 02:16:55,500 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:16:55,834 - logger.py:50 - Epoch: [86][0/38] loss: 68.28903, MAE: 0.36917, time/step=332ms, lr=1.99e-05
2024-03-15 02:17:10,256 - logger.py:50 - Epoch: [86][37/38] loss: 146.84613, MAE: 0.67825, time/step=388ms, lr=1.99e-05
2024-03-15 02:17:12,121 - logger.py:50 - Epoch: [86] train MAE: 0.67825, val MAE: 0.79799, test MAE: 0.76224, Time: 16.62s
2024-03-15 02:17:12,121 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:17:12,596 - logger.py:50 - Epoch: [87][0/38] loss: 225.02197, MAE: 1.01103, time/step=473ms, lr=1.94e-05
2024-03-15 02:17:25,464 - logger.py:50 - Epoch: [87][37/38] loss: 248.77256, MAE: 0.67548, time/step=351ms, lr=1.94e-05
2024-03-15 02:17:26,829 - logger.py:50 - Epoch: [87] train MAE: 0.67548, val MAE: 0.78775, test MAE: 0.75541, Time: 14.71s
2024-03-15 02:17:26,830 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:17:27,057 - logger.py:50 - Epoch: [88][0/38] loss: 563.25824, MAE: 0.50843, time/step=225ms, lr=1.89e-05
2024-03-15 02:17:39,292 - logger.py:50 - Epoch: [88][37/38] loss: 167.31562, MAE: 0.68071, time/step=328ms, lr=1.89e-05
2024-03-15 02:17:41,131 - logger.py:50 - Epoch: [88] train MAE: 0.68071, val MAE: 0.78789, test MAE: 0.75697, Time: 14.30s
2024-03-15 02:17:41,131 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:17:41,433 - logger.py:50 - Epoch: [89][0/38] loss: 0.82303, MAE: 0.40236, time/step=300ms, lr=1.84e-05
2024-03-15 02:17:55,645 - logger.py:50 - Epoch: [89][37/38] loss: 138.18949, MAE: 0.68116, time/step=382ms, lr=1.84e-05
2024-03-15 02:17:57,526 - logger.py:50 - Epoch: [89] train MAE: 0.68116, val MAE: 0.78563, test MAE: 0.75432, Time: 16.40s
2024-03-15 02:17:57,526 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:17:57,922 - logger.py:50 - Epoch: [90][0/38] loss: 354.94431, MAE: 0.59952, time/step=393ms, lr=1.79e-05
2024-03-15 02:18:08,433 - logger.py:50 - Epoch: [90][37/38] loss: 192.79089, MAE: 0.68123, time/step=287ms, lr=1.79e-05
2024-03-15 02:18:10,352 - logger.py:50 - Epoch: [90] train MAE: 0.68123, val MAE: 0.79541, test MAE: 0.76096, Time: 12.83s
2024-03-15 02:18:10,352 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:18:10,730 - logger.py:50 - Epoch: [91][0/38] loss: 54.49736, MAE: 0.86025, time/step=376ms, lr=1.74e-05
2024-03-15 02:18:25,058 - logger.py:50 - Epoch: [91][37/38] loss: 222.02440, MAE: 0.67919, time/step=387ms, lr=1.74e-05
2024-03-15 02:18:26,938 - logger.py:50 - Epoch: [91] train MAE: 0.67919, val MAE: 0.81225, test MAE: 0.77358, Time: 16.59s
2024-03-15 02:18:26,938 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:18:27,279 - logger.py:50 - Epoch: [92][0/38] loss: 58.78838, MAE: 0.60833, time/step=339ms, lr=1.70e-05
2024-03-15 02:18:39,470 - logger.py:50 - Epoch: [92][37/38] loss: 250.17181, MAE: 0.67661, time/step=330ms, lr=1.70e-05
2024-03-15 02:18:40,652 - logger.py:50 - Epoch: [92] train MAE: 0.67661, val MAE: 0.77906, test MAE: 0.75147, Time: 13.71s
2024-03-15 02:18:40,652 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:18:41,000 - logger.py:50 - Epoch: [93][0/38] loss: 42.95673, MAE: 0.72692, time/step=346ms, lr=1.65e-05
2024-03-15 02:18:54,231 - logger.py:50 - Epoch: [93][37/38] loss: 165.72191, MAE: 0.67956, time/step=357ms, lr=1.65e-05
2024-03-15 02:18:56,028 - logger.py:50 - Epoch: [93] train MAE: 0.67956, val MAE: 0.79593, test MAE: 0.76525, Time: 15.38s
2024-03-15 02:18:56,028 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:18:56,452 - logger.py:50 - Epoch: [94][0/38] loss: 886.01788, MAE: 0.49297, time/step=422ms, lr=1.60e-05
2024-03-15 02:19:10,538 - logger.py:50 - Epoch: [94][37/38] loss: 165.19673, MAE: 0.67597, time/step=382ms, lr=1.60e-05
2024-03-15 02:19:11,921 - logger.py:50 - Epoch: [94] train MAE: 0.67597, val MAE: 0.78575, test MAE: 0.75698, Time: 15.89s
2024-03-15 02:19:11,921 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:19:12,248 - logger.py:50 - Epoch: [95][0/38] loss: 438.82373, MAE: 0.53929, time/step=325ms, lr=1.55e-05
2024-03-15 02:19:23,271 - logger.py:50 - Epoch: [95][37/38] loss: 122.72441, MAE: 0.67762, time/step=299ms, lr=1.55e-05
2024-03-15 02:19:25,179 - logger.py:50 - Epoch: [95] train MAE: 0.67762, val MAE: 0.79577, test MAE: 0.76380, Time: 13.26s
2024-03-15 02:19:25,179 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:19:25,565 - logger.py:50 - Epoch: [96][0/38] loss: 63.59975, MAE: 0.85392, time/step=384ms, lr=1.51e-05
2024-03-15 02:19:39,814 - logger.py:50 - Epoch: [96][37/38] loss: 162.01376, MAE: 0.67943, time/step=385ms, lr=1.51e-05
2024-03-15 02:19:41,663 - logger.py:50 - Epoch: [96] train MAE: 0.67943, val MAE: 0.79512, test MAE: 0.76018, Time: 16.48s
2024-03-15 02:19:41,664 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:19:42,110 - logger.py:50 - Epoch: [97][0/38] loss: 312.72351, MAE: 0.57921, time/step=445ms, lr=1.46e-05
2024-03-15 02:19:53,625 - logger.py:50 - Epoch: [97][37/38] loss: 209.06435, MAE: 0.67948, time/step=315ms, lr=1.46e-05
2024-03-15 02:19:54,919 - logger.py:50 - Epoch: [97] train MAE: 0.67948, val MAE: 0.79029, test MAE: 0.75514, Time: 13.26s
2024-03-15 02:19:54,920 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:19:55,209 - logger.py:50 - Epoch: [98][0/38] loss: 424.42438, MAE: 0.80508, time/step=287ms, lr=1.41e-05
2024-03-15 02:20:09,067 - logger.py:50 - Epoch: [98][37/38] loss: 119.93136, MAE: 0.67731, time/step=372ms, lr=1.41e-05
2024-03-15 02:20:10,923 - logger.py:50 - Epoch: [98] train MAE: 0.67731, val MAE: 0.79712, test MAE: 0.76426, Time: 16.00s
2024-03-15 02:20:10,924 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:20:11,272 - logger.py:50 - Epoch: [99][0/38] loss: 32.53016, MAE: 0.56278, time/step=346ms, lr=1.37e-05
2024-03-15 02:20:25,038 - logger.py:50 - Epoch: [99][37/38] loss: 130.21637, MAE: 0.67842, time/step=371ms, lr=1.37e-05
2024-03-15 02:20:26,219 - logger.py:50 - Epoch: [99] train MAE: 0.67842, val MAE: 0.79990, test MAE: 0.76570, Time: 15.30s
2024-03-15 02:20:26,220 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:20:26,552 - logger.py:50 - Epoch: [100][0/38] loss: 32.99550, MAE: 0.44692, time/step=329ms, lr=1.32e-05
2024-03-15 02:20:38,255 - logger.py:50 - Epoch: [100][37/38] loss: 115.99274, MAE: 0.67841, time/step=317ms, lr=1.32e-05
2024-03-15 02:20:40,148 - logger.py:50 - Epoch: [100] train MAE: 0.67841, val MAE: 0.79171, test MAE: 0.75947, Time: 13.93s
2024-03-15 02:20:40,148 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:20:40,483 - logger.py:50 - Epoch: [101][0/38] loss: 0.00939, MAE: 0.71053, time/step=333ms, lr=1.28e-05
2024-03-15 02:20:54,837 - logger.py:50 - Epoch: [101][37/38] loss: 156.35748, MAE: 0.67918, time/step=386ms, lr=1.28e-05
2024-03-15 02:20:56,713 - logger.py:50 - Epoch: [101] train MAE: 0.67918, val MAE: 0.80365, test MAE: 0.76847, Time: 16.56s
2024-03-15 02:20:56,713 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:20:57,131 - logger.py:50 - Epoch: [102][0/38] loss: 127.73870, MAE: 0.44522, time/step=416ms, lr=1.24e-05
2024-03-15 02:21:07,866 - logger.py:50 - Epoch: [102][37/38] loss: 75.97793, MAE: 0.67963, time/step=293ms, lr=1.24e-05
2024-03-15 02:21:09,268 - logger.py:50 - Epoch: [102] train MAE: 0.67963, val MAE: 0.78579, test MAE: 0.75473, Time: 12.55s
2024-03-15 02:21:09,268 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:21:09,762 - logger.py:50 - Epoch: [103][0/38] loss: 2.15732, MAE: 0.50542, time/step=492ms, lr=1.19e-05
2024-03-15 02:21:24,030 - logger.py:50 - Epoch: [103][37/38] loss: 128.55905, MAE: 0.67722, time/step=388ms, lr=1.19e-05
2024-03-15 02:21:25,834 - logger.py:50 - Epoch: [103] train MAE: 0.67722, val MAE: 0.79845, test MAE: 0.76550, Time: 16.57s
2024-03-15 02:21:25,834 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:21:26,093 - logger.py:50 - Epoch: [104][0/38] loss: 0.29154, MAE: 0.63487, time/step=256ms, lr=1.15e-05
2024-03-15 02:21:39,040 - logger.py:50 - Epoch: [104][37/38] loss: 183.51126, MAE: 0.67879, time/step=347ms, lr=1.15e-05
2024-03-15 02:21:40,231 - logger.py:50 - Epoch: [104] train MAE: 0.67879, val MAE: 0.79274, test MAE: 0.76093, Time: 14.40s
2024-03-15 02:21:40,232 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:21:40,661 - logger.py:50 - Epoch: [105][0/38] loss: 21.32575, MAE: 0.88348, time/step=426ms, lr=1.11e-05
2024-03-15 02:21:52,969 - logger.py:50 - Epoch: [105][37/38] loss: 141.73301, MAE: 0.67888, time/step=335ms, lr=1.11e-05
2024-03-15 02:21:54,804 - logger.py:50 - Epoch: [105] train MAE: 0.67888, val MAE: 0.79873, test MAE: 0.76592, Time: 14.57s
2024-03-15 02:21:54,805 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:21:55,117 - logger.py:50 - Epoch: [106][0/38] loss: 2.14970, MAE: 0.85770, time/step=310ms, lr=1.07e-05
2024-03-15 02:22:09,385 - logger.py:50 - Epoch: [106][37/38] loss: 202.28473, MAE: 0.67885, time/step=384ms, lr=1.07e-05
2024-03-15 02:22:11,246 - logger.py:50 - Epoch: [106] train MAE: 0.67885, val MAE: 0.79046, test MAE: 0.75864, Time: 16.44s
2024-03-15 02:22:11,246 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:22:11,605 - logger.py:50 - Epoch: [107][0/38] loss: 40.43777, MAE: 0.49406, time/step=357ms, lr=1.03e-05
2024-03-15 02:22:22,027 - logger.py:50 - Epoch: [107][37/38] loss: 113.56001, MAE: 0.67815, time/step=284ms, lr=1.03e-05
2024-03-15 02:22:24,039 - logger.py:50 - Epoch: [107] train MAE: 0.67815, val MAE: 0.79997, test MAE: 0.76638, Time: 12.79s
2024-03-15 02:22:24,040 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:22:24,459 - logger.py:50 - Epoch: [108][0/38] loss: 115.02837, MAE: 0.75329, time/step=417ms, lr=9.88e-06
2024-03-15 02:22:38,646 - logger.py:50 - Epoch: [108][37/38] loss: 133.07980, MAE: 0.67774, time/step=384ms, lr=9.88e-06
2024-03-15 02:22:40,552 - logger.py:50 - Epoch: [108] train MAE: 0.67774, val MAE: 0.80054, test MAE: 0.76511, Time: 16.51s
2024-03-15 02:22:40,552 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:22:40,870 - logger.py:50 - Epoch: [109][0/38] loss: 90.67552, MAE: 0.49544, time/step=316ms, lr=9.49e-06
2024-03-15 02:22:53,259 - logger.py:50 - Epoch: [109][37/38] loss: 97.08752, MAE: 0.67789, time/step=334ms, lr=9.49e-06
2024-03-15 02:22:54,436 - logger.py:50 - Epoch: [109] train MAE: 0.67789, val MAE: 0.80288, test MAE: 0.76835, Time: 13.88s
2024-03-15 02:22:54,436 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:22:54,669 - logger.py:50 - Epoch: [110][0/38] loss: 7.46013, MAE: 0.82769, time/step=230ms, lr=9.11e-06
2024-03-15 02:23:07,831 - logger.py:50 - Epoch: [110][37/38] loss: 108.49464, MAE: 0.67844, time/step=352ms, lr=9.11e-06
2024-03-15 02:23:09,685 - logger.py:50 - Epoch: [110] train MAE: 0.67844, val MAE: 0.79570, test MAE: 0.76193, Time: 15.25s
2024-03-15 02:23:09,685 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:23:10,006 - logger.py:50 - Epoch: [111][0/38] loss: 0.87713, MAE: 0.59840, time/step=319ms, lr=8.73e-06
2024-03-15 02:23:24,080 - logger.py:50 - Epoch: [111][37/38] loss: 125.85357, MAE: 0.67951, time/step=379ms, lr=8.73e-06
2024-03-15 02:23:25,739 - logger.py:50 - Epoch: [111] train MAE: 0.67951, val MAE: 0.79286, test MAE: 0.75859, Time: 16.05s
2024-03-15 02:23:25,739 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:23:25,977 - logger.py:50 - Epoch: [112][0/38] loss: 13.10039, MAE: 0.89581, time/step=236ms, lr=8.36e-06
2024-03-15 02:23:36,767 - logger.py:50 - Epoch: [112][37/38] loss: 127.64824, MAE: 0.67833, time/step=290ms, lr=8.36e-06
2024-03-15 02:23:38,766 - logger.py:50 - Epoch: [112] train MAE: 0.67833, val MAE: 0.79255, test MAE: 0.75751, Time: 13.03s
2024-03-15 02:23:38,766 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:23:39,068 - logger.py:50 - Epoch: [113][0/38] loss: 374.01657, MAE: 0.42516, time/step=300ms, lr=8.00e-06
2024-03-15 02:23:53,324 - logger.py:50 - Epoch: [113][37/38] loss: 101.05228, MAE: 0.67862, time/step=383ms, lr=8.00e-06
2024-03-15 02:23:55,175 - logger.py:50 - Epoch: [113] train MAE: 0.67862, val MAE: 0.80294, test MAE: 0.76637, Time: 16.41s
2024-03-15 02:23:55,175 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:23:55,561 - logger.py:50 - Epoch: [114][0/38] loss: 236.10544, MAE: 0.52142, time/step=384ms, lr=7.64e-06
2024-03-15 02:24:07,240 - logger.py:50 - Epoch: [114][37/38] loss: 110.96266, MAE: 0.67915, time/step=317ms, lr=7.64e-06
2024-03-15 02:24:08,419 - logger.py:50 - Epoch: [114] train MAE: 0.67915, val MAE: 0.79840, test MAE: 0.76362, Time: 13.24s
2024-03-15 02:24:08,419 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:24:08,746 - logger.py:50 - Epoch: [115][0/38] loss: 0.13807, MAE: 0.74694, time/step=324ms, lr=7.29e-06
2024-03-15 02:24:22,420 - logger.py:50 - Epoch: [115][37/38] loss: 102.67864, MAE: 0.67693, time/step=368ms, lr=7.29e-06
2024-03-15 02:24:24,265 - logger.py:50 - Epoch: [115] train MAE: 0.67693, val MAE: 0.80681, test MAE: 0.77081, Time: 15.85s
2024-03-15 02:24:24,266 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:24:24,635 - logger.py:50 - Epoch: [116][0/38] loss: 55.77174, MAE: 0.52650, time/step=367ms, lr=6.95e-06
2024-03-15 02:24:38,659 - logger.py:50 - Epoch: [116][37/38] loss: 151.71705, MAE: 0.67944, time/step=379ms, lr=6.95e-06
2024-03-15 02:24:39,853 - logger.py:50 - Epoch: [116] train MAE: 0.67944, val MAE: 0.78825, test MAE: 0.75900, Time: 15.59s
2024-03-15 02:24:39,853 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:24:40,226 - logger.py:50 - Epoch: [117][0/38] loss: 2.69065, MAE: 0.60900, time/step=371ms, lr=6.62e-06
2024-03-15 02:24:51,763 - logger.py:50 - Epoch: [117][37/38] loss: 99.89348, MAE: 0.67926, time/step=313ms, lr=6.62e-06
2024-03-15 02:24:53,704 - logger.py:50 - Epoch: [117] train MAE: 0.67926, val MAE: 0.79677, test MAE: 0.76475, Time: 13.85s
2024-03-15 02:24:53,704 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:24:54,134 - logger.py:50 - Epoch: [118][0/38] loss: 2.51510, MAE: 0.60721, time/step=428ms, lr=6.30e-06
2024-03-15 02:25:08,239 - logger.py:50 - Epoch: [118][37/38] loss: 95.64221, MAE: 0.67968, time/step=382ms, lr=6.30e-06
2024-03-15 02:25:10,048 - logger.py:50 - Epoch: [118] train MAE: 0.67968, val MAE: 0.80311, test MAE: 0.76818, Time: 16.34s
2024-03-15 02:25:10,048 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:25:10,363 - logger.py:50 - Epoch: [119][0/38] loss: 0.88705, MAE: 0.62108, time/step=313ms, lr=5.99e-06
2024-03-15 02:25:21,390 - logger.py:50 - Epoch: [119][37/38] loss: 114.89708, MAE: 0.67950, time/step=298ms, lr=5.99e-06
2024-03-15 02:25:22,574 - logger.py:50 - Epoch: [119] train MAE: 0.67950, val MAE: 0.79543, test MAE: 0.76196, Time: 12.53s
2024-03-15 02:25:22,575 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:25:23,051 - logger.py:50 - Epoch: [120][0/38] loss: 47.71526, MAE: 0.44222, time/step=474ms, lr=5.68e-06
2024-03-15 02:25:37,369 - logger.py:50 - Epoch: [120][37/38] loss: 101.53361, MAE: 0.67808, time/step=389ms, lr=5.68e-06
2024-03-15 02:25:39,222 - logger.py:50 - Epoch: [120] train MAE: 0.67808, val MAE: 0.79069, test MAE: 0.75871, Time: 16.65s
2024-03-15 02:25:39,222 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:25:39,598 - logger.py:50 - Epoch: [121][0/38] loss: 5.18463, MAE: 0.89946, time/step=374ms, lr=5.38e-06
2024-03-15 02:25:52,929 - logger.py:50 - Epoch: [121][37/38] loss: 65.72174, MAE: 0.67887, time/step=361ms, lr=5.38e-06
2024-03-15 02:25:54,112 - logger.py:50 - Epoch: [121] train MAE: 0.67887, val MAE: 0.79665, test MAE: 0.76336, Time: 14.89s
2024-03-15 02:25:54,112 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:25:54,427 - logger.py:50 - Epoch: [122][0/38] loss: 10.73578, MAE: 0.65355, time/step=313ms, lr=5.09e-06
2024-03-15 02:26:06,618 - logger.py:50 - Epoch: [122][37/38] loss: 65.60855, MAE: 0.67812, time/step=329ms, lr=5.09e-06
2024-03-15 02:26:08,478 - logger.py:50 - Epoch: [122] train MAE: 0.67812, val MAE: 0.79738, test MAE: 0.76419, Time: 14.37s
2024-03-15 02:26:08,479 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:26:08,781 - logger.py:50 - Epoch: [123][0/38] loss: 96.24084, MAE: 0.96066, time/step=300ms, lr=4.81e-06
2024-03-15 02:26:22,918 - logger.py:50 - Epoch: [123][37/38] loss: 95.53304, MAE: 0.67902, time/step=380ms, lr=4.81e-06
2024-03-15 02:26:24,744 - logger.py:50 - Epoch: [123] train MAE: 0.67902, val MAE: 0.79835, test MAE: 0.76442, Time: 16.27s
2024-03-15 02:26:24,744 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:26:25,281 - logger.py:50 - Epoch: [124][0/38] loss: 14.36949, MAE: 0.72579, time/step=535ms, lr=4.54e-06
2024-03-15 02:26:35,662 - logger.py:50 - Epoch: [124][37/38] loss: 73.73999, MAE: 0.67869, time/step=287ms, lr=4.54e-06
2024-03-15 02:26:37,570 - logger.py:50 - Epoch: [124] train MAE: 0.67869, val MAE: 0.79309, test MAE: 0.76031, Time: 12.83s
2024-03-15 02:26:37,570 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:26:37,852 - logger.py:50 - Epoch: [125][0/38] loss: 56.00628, MAE: 0.41287, time/step=280ms, lr=4.28e-06
2024-03-15 02:26:52,211 - logger.py:50 - Epoch: [125][37/38] loss: 68.64806, MAE: 0.67983, time/step=385ms, lr=4.28e-06
2024-03-15 02:26:54,030 - logger.py:50 - Epoch: [125] train MAE: 0.67983, val MAE: 0.79671, test MAE: 0.76320, Time: 16.46s
2024-03-15 02:26:54,030 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:26:54,412 - logger.py:50 - Epoch: [126][0/38] loss: 107.02410, MAE: 0.62088, time/step=380ms, lr=4.03e-06
2024-03-15 02:27:06,836 - logger.py:50 - Epoch: [126][37/38] loss: 74.08530, MAE: 0.67922, time/step=337ms, lr=4.03e-06
2024-03-15 02:27:08,165 - logger.py:50 - Epoch: [126] train MAE: 0.67922, val MAE: 0.79773, test MAE: 0.76384, Time: 14.14s
2024-03-15 02:27:08,166 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:27:08,419 - logger.py:50 - Epoch: [127][0/38] loss: 125.82064, MAE: 0.79758, time/step=251ms, lr=3.79e-06
2024-03-15 02:27:21,199 - logger.py:50 - Epoch: [127][37/38] loss: 70.24573, MAE: 0.67875, time/step=343ms, lr=3.79e-06
2024-03-15 02:27:23,064 - logger.py:50 - Epoch: [127] train MAE: 0.67875, val MAE: 0.79140, test MAE: 0.75887, Time: 14.90s
2024-03-15 02:27:23,064 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:27:23,381 - logger.py:50 - Epoch: [128][0/38] loss: 195.08505, MAE: 1.09108, time/step=315ms, lr=3.56e-06
2024-03-15 02:27:37,578 - logger.py:50 - Epoch: [128][37/38] loss: 88.81846, MAE: 0.67847, time/step=382ms, lr=3.56e-06
2024-03-15 02:27:39,356 - logger.py:50 - Epoch: [128] train MAE: 0.67847, val MAE: 0.79406, test MAE: 0.76150, Time: 16.29s
2024-03-15 02:27:39,356 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:27:39,718 - logger.py:50 - Epoch: [129][0/38] loss: 53.35222, MAE: 0.50445, time/step=359ms, lr=3.33e-06
2024-03-15 02:27:50,529 - logger.py:50 - Epoch: [129][37/38] loss: 95.37063, MAE: 0.67903, time/step=294ms, lr=3.33e-06
2024-03-15 02:27:52,432 - logger.py:50 - Epoch: [129] train MAE: 0.67903, val MAE: 0.79092, test MAE: 0.75871, Time: 13.08s
2024-03-15 02:27:52,432 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:27:52,701 - logger.py:50 - Epoch: [130][0/38] loss: 57.95601, MAE: 0.61277, time/step=267ms, lr=3.12e-06
2024-03-15 02:28:06,933 - logger.py:50 - Epoch: [130][37/38] loss: 63.62117, MAE: 0.67776, time/step=382ms, lr=3.12e-06
2024-03-15 02:28:08,778 - logger.py:50 - Epoch: [130] train MAE: 0.67776, val MAE: 0.79351, test MAE: 0.76050, Time: 16.35s
2024-03-15 02:28:08,778 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:28:09,111 - logger.py:50 - Epoch: [131][0/38] loss: 1.86270, MAE: 0.61053, time/step=330ms, lr=2.91e-06
2024-03-15 02:28:20,828 - logger.py:50 - Epoch: [131][37/38] loss: 89.07709, MAE: 0.67857, time/step=317ms, lr=2.91e-06
2024-03-15 02:28:22,120 - logger.py:50 - Epoch: [131] train MAE: 0.67857, val MAE: 0.79590, test MAE: 0.76303, Time: 13.34s
2024-03-15 02:28:22,120 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:28:22,380 - logger.py:50 - Epoch: [132][0/38] loss: 117.66767, MAE: 0.38637, time/step=257ms, lr=2.72e-06
2024-03-15 02:28:36,041 - logger.py:50 - Epoch: [132][37/38] loss: 81.90431, MAE: 0.67901, time/step=366ms, lr=2.72e-06
2024-03-15 02:28:37,886 - logger.py:50 - Epoch: [132] train MAE: 0.67901, val MAE: 0.80028, test MAE: 0.76650, Time: 15.77s
2024-03-15 02:28:37,886 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:28:38,201 - logger.py:50 - Epoch: [133][0/38] loss: 6.62982, MAE: 0.36889, time/step=312ms, lr=2.54e-06
2024-03-15 02:28:52,152 - logger.py:50 - Epoch: [133][37/38] loss: 111.25487, MAE: 0.67775, time/step=375ms, lr=2.54e-06
2024-03-15 02:28:53,342 - logger.py:50 - Epoch: [133] train MAE: 0.67775, val MAE: 0.79548, test MAE: 0.76309, Time: 15.46s
2024-03-15 02:28:53,342 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:28:53,669 - logger.py:50 - Epoch: [134][0/38] loss: 8.95994, MAE: 0.81411, time/step=324ms, lr=2.36e-06
2024-03-15 02:29:05,103 - logger.py:50 - Epoch: [134][37/38] loss: 69.81697, MAE: 0.67988, time/step=309ms, lr=2.36e-06
2024-03-15 02:29:06,991 - logger.py:50 - Epoch: [134] train MAE: 0.67988, val MAE: 0.79470, test MAE: 0.76237, Time: 13.65s
2024-03-15 02:29:06,991 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:29:07,328 - logger.py:50 - Epoch: [135][0/38] loss: 46.34033, MAE: 0.78470, time/step=335ms, lr=2.20e-06
2024-03-15 02:29:21,507 - logger.py:50 - Epoch: [135][37/38] loss: 86.02148, MAE: 0.67903, time/step=382ms, lr=2.20e-06
2024-03-15 02:29:23,334 - logger.py:50 - Epoch: [135] train MAE: 0.67903, val MAE: 0.79668, test MAE: 0.76350, Time: 16.34s
2024-03-15 02:29:23,335 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:29:23,591 - logger.py:50 - Epoch: [136][0/38] loss: 2.98260, MAE: 0.67938, time/step=254ms, lr=2.05e-06
2024-03-15 02:29:34,929 - logger.py:50 - Epoch: [136][37/38] loss: 89.77120, MAE: 0.67905, time/step=305ms, lr=2.05e-06
2024-03-15 02:29:36,125 - logger.py:50 - Epoch: [136] train MAE: 0.67905, val MAE: 0.79420, test MAE: 0.76169, Time: 12.79s
2024-03-15 02:29:36,125 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:29:36,350 - logger.py:50 - Epoch: [137][0/38] loss: 3.29723, MAE: 0.64534, time/step=223ms, lr=1.90e-06
2024-03-15 02:29:50,619 - logger.py:50 - Epoch: [137][37/38] loss: 78.93946, MAE: 0.68016, time/step=381ms, lr=1.90e-06
2024-03-15 02:29:52,451 - logger.py:50 - Epoch: [137] train MAE: 0.68016, val MAE: 0.79113, test MAE: 0.75953, Time: 16.33s
2024-03-15 02:29:52,451 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:29:52,835 - logger.py:50 - Epoch: [138][0/38] loss: 87.38153, MAE: 0.49277, time/step=382ms, lr=1.77e-06
2024-03-15 02:30:06,068 - logger.py:50 - Epoch: [138][37/38] loss: 116.67921, MAE: 0.67825, time/step=358ms, lr=1.77e-06
2024-03-15 02:30:07,250 - logger.py:50 - Epoch: [138] train MAE: 0.67825, val MAE: 0.79677, test MAE: 0.76362, Time: 14.80s
2024-03-15 02:30:07,250 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:30:07,451 - logger.py:50 - Epoch: [139][0/38] loss: 90.53434, MAE: 0.66648, time/step=198ms, lr=1.65e-06
2024-03-15 02:30:19,686 - logger.py:50 - Epoch: [139][37/38] loss: 78.92540, MAE: 0.67946, time/step=327ms, lr=1.65e-06
2024-03-15 02:30:21,547 - logger.py:50 - Epoch: [139] train MAE: 0.67946, val MAE: 0.79668, test MAE: 0.76344, Time: 14.30s
2024-03-15 02:30:21,547 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:30:21,946 - logger.py:50 - Epoch: [140][0/38] loss: 5.03192, MAE: 0.66378, time/step=397ms, lr=1.54e-06
2024-03-15 02:30:36,100 - logger.py:50 - Epoch: [140][37/38] loss: 55.99038, MAE: 0.67917, time/step=383ms, lr=1.54e-06
2024-03-15 02:30:37,951 - logger.py:50 - Epoch: [140] train MAE: 0.67917, val MAE: 0.79648, test MAE: 0.76321, Time: 16.40s
2024-03-15 02:30:37,951 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:30:38,294 - logger.py:50 - Epoch: [141][0/38] loss: 263.26569, MAE: 0.54790, time/step=341ms, lr=1.43e-06
2024-03-15 02:30:48,750 - logger.py:50 - Epoch: [141][37/38] loss: 76.91222, MAE: 0.67905, time/step=284ms, lr=1.43e-06
2024-03-15 02:30:50,737 - logger.py:50 - Epoch: [141] train MAE: 0.67905, val MAE: 0.79387, test MAE: 0.76108, Time: 12.79s
2024-03-15 02:30:50,738 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:30:51,170 - logger.py:50 - Epoch: [142][0/38] loss: 3.48365, MAE: 0.68976, time/step=430ms, lr=1.34e-06
2024-03-15 02:31:05,530 - logger.py:50 - Epoch: [142][37/38] loss: 70.64434, MAE: 0.67822, time/step=389ms, lr=1.34e-06
2024-03-15 02:31:07,352 - logger.py:50 - Epoch: [142] train MAE: 0.67822, val MAE: 0.79648, test MAE: 0.76287, Time: 16.61s
2024-03-15 02:31:07,352 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:31:07,738 - logger.py:50 - Epoch: [143][0/38] loss: 141.22299, MAE: 0.82874, time/step=384ms, lr=1.26e-06
2024-03-15 02:31:20,234 - logger.py:50 - Epoch: [143][37/38] loss: 100.40360, MAE: 0.67946, time/step=339ms, lr=1.26e-06
2024-03-15 02:31:21,540 - logger.py:50 - Epoch: [143] train MAE: 0.67946, val MAE: 0.79745, test MAE: 0.76361, Time: 14.19s
2024-03-15 02:31:21,540 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:31:21,748 - logger.py:50 - Epoch: [144][0/38] loss: 71.12241, MAE: 0.84310, time/step=206ms, lr=1.19e-06
2024-03-15 02:31:34,648 - logger.py:50 - Epoch: [144][37/38] loss: 71.87448, MAE: 0.67863, time/step=345ms, lr=1.19e-06
2024-03-15 02:31:36,520 - logger.py:50 - Epoch: [144] train MAE: 0.67863, val MAE: 0.79754, test MAE: 0.76374, Time: 14.98s
2024-03-15 02:31:36,520 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:31:36,885 - logger.py:50 - Epoch: [145][0/38] loss: 26.80988, MAE: 0.62555, time/step=363ms, lr=1.13e-06
2024-03-15 02:31:51,000 - logger.py:50 - Epoch: [145][37/38] loss: 71.16830, MAE: 0.67921, time/step=381ms, lr=1.13e-06
2024-03-15 02:31:52,737 - logger.py:50 - Epoch: [145] train MAE: 0.67921, val MAE: 0.79425, test MAE: 0.76106, Time: 16.22s
2024-03-15 02:31:52,738 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:31:53,101 - logger.py:50 - Epoch: [146][0/38] loss: 220.46739, MAE: 0.48085, time/step=361ms, lr=1.09e-06
2024-03-15 02:32:03,684 - logger.py:50 - Epoch: [146][37/38] loss: 98.16118, MAE: 0.67844, time/step=288ms, lr=1.09e-06
2024-03-15 02:32:05,581 - logger.py:50 - Epoch: [146] train MAE: 0.67844, val MAE: 0.79837, test MAE: 0.76427, Time: 12.84s
2024-03-15 02:32:05,581 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:32:05,890 - logger.py:50 - Epoch: [147][0/38] loss: 0.05202, MAE: 0.74877, time/step=307ms, lr=1.05e-06
2024-03-15 02:32:20,293 - logger.py:50 - Epoch: [147][37/38] loss: 80.64684, MAE: 0.67950, time/step=387ms, lr=1.05e-06
2024-03-15 02:32:22,132 - logger.py:50 - Epoch: [147] train MAE: 0.67950, val MAE: 0.79706, test MAE: 0.76311, Time: 16.55s
2024-03-15 02:32:22,132 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:32:22,549 - logger.py:50 - Epoch: [148][0/38] loss: 55.99486, MAE: 0.64639, time/step=414ms, lr=1.02e-06
2024-03-15 02:32:34,308 - logger.py:50 - Epoch: [148][37/38] loss: 79.63292, MAE: 0.67831, time/step=320ms, lr=1.02e-06
2024-03-15 02:32:35,484 - logger.py:50 - Epoch: [148] train MAE: 0.67831, val MAE: 0.79783, test MAE: 0.76364, Time: 13.35s
2024-03-15 02:32:35,485 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:32:35,688 - logger.py:50 - Epoch: [149][0/38] loss: 63.12605, MAE: 0.44125, time/step=201ms, lr=1.01e-06
2024-03-15 02:32:49,313 - logger.py:50 - Epoch: [149][37/38] loss: 77.53382, MAE: 0.67966, time/step=364ms, lr=1.01e-06
2024-03-15 02:32:51,148 - logger.py:50 - Epoch: [149] train MAE: 0.67966, val MAE: 0.79551, test MAE: 0.76162, Time: 15.66s
2024-03-15 02:32:51,148 - logger.py:50 - Best -- epoch=36, train MAE: 0.68096, val MAE: 0.72589, test MAE: 0.70358

2024-03-15 02:32:51,148 - logger.py:50 - fold_1 test MAE:0.70358
2024-03-15 02:36:46,388 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 02:36:53,409 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 02:36:54,456 - logger.py:50 - Number of params: 2978805
2024-03-15 02:38:56,408 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 02:39:03,952 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 02:39:04,305 - logger.py:50 - Number of params: 2978805
2024-03-15 02:41:18,358 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 02:41:27,161 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 02:41:28,006 - logger.py:50 - Number of params: 2978805
2024-03-15 02:42:08,815 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=48, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 02:42:16,077 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 02:42:16,617 - logger.py:50 - Number of params: 2978805
2024-03-15 02:44:32,167 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 02:44:41,135 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 02:44:41,391 - logger.py:50 - Number of params: 2978805
2024-03-15 18:55:55,708 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 18:56:03,848 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 18:56:03,860 - logger.py:50 - Number of params: 2978805
2024-03-15 19:17:55,435 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 19:18:02,736 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 19:18:03,633 - logger.py:50 - Number of params: 2978805
2024-03-15 19:18:37,021 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 19:18:44,231 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 19:18:45,288 - logger.py:50 - Number of params: 2978805
2024-03-15 19:21:43,727 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 19:21:52,656 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 19:21:52,672 - logger.py:50 - Number of params: 2978805
2024-03-15 20:06:30,990 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 20:06:37,845 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 20:06:37,857 - logger.py:50 - Number of params: 2978805
2024-03-15 20:22:03,285 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-15 20:22:09,967 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-15 20:22:09,979 - logger.py:50 - Number of params: 2978805
2024-03-16 14:41:11,425 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-16 14:41:18,549 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-16 14:41:18,563 - logger.py:50 - Number of params: 2978805
2024-03-16 14:47:48,461 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-16 14:47:55,799 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-16 14:47:56,131 - logger.py:50 - Number of params: 2978805
2024-03-16 14:48:00,407 - logger.py:50 - Epoch: [0][0/2] loss: 38829.82812, MAE: 0.62381, time/step=4272ms, lr=1.00e-06
2024-03-16 14:48:04,238 - logger.py:50 - Epoch: [0][1/2] loss: 137149.53451, MAE: 0.64645, time/step=4052ms, lr=1.00e-06
2024-03-16 14:48:06,007 - logger.py:50 - Epoch: [0] train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756, Time: 9.87s
2024-03-16 14:48:06,007 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:48:09,169 - logger.py:50 - Epoch: [1][0/2] loss: 221357.04688, MAE: 0.66487, time/step=3159ms, lr=1.08e-05
2024-03-16 14:48:12,420 - logger.py:50 - Epoch: [1][1/2] loss: 150236.39800, MAE: 0.67469, time/step=3205ms, lr=1.08e-05
2024-03-16 14:48:13,607 - logger.py:50 - Epoch: [1] train MAE: 0.67469, val MAE: 0.76765, test MAE: 0.74457, Time: 7.60s
2024-03-16 14:48:13,607 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:48:16,788 - logger.py:50 - Epoch: [2][0/2] loss: 35973.89062, MAE: 0.68376, time/step=3179ms, lr=2.06e-05
2024-03-16 14:48:19,841 - logger.py:50 - Epoch: [2][1/2] loss: 65783.82832, MAE: 0.68584, time/step=3116ms, lr=2.06e-05
2024-03-16 14:48:20,807 - logger.py:50 - Epoch: [2] train MAE: 0.68584, val MAE: 0.82141, test MAE: 0.79456, Time: 7.20s
2024-03-16 14:48:20,807 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:48:23,893 - logger.py:50 - Epoch: [3][0/2] loss: 26144.07227, MAE: 0.70520, time/step=3084ms, lr=3.04e-05
2024-03-16 14:48:26,879 - logger.py:50 - Epoch: [3][1/2] loss: 20962.23122, MAE: 0.72886, time/step=3035ms, lr=3.04e-05
2024-03-16 14:48:27,858 - logger.py:50 - Epoch: [3] train MAE: 0.72886, val MAE: 0.88960, test MAE: 0.85829, Time: 7.05s
2024-03-16 14:48:27,859 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:48:30,904 - logger.py:50 - Epoch: [4][0/2] loss: 345.47791, MAE: 0.78608, time/step=3043ms, lr=4.02e-05
2024-03-16 14:48:33,955 - logger.py:50 - Epoch: [4][1/2] loss: 115622.96739, MAE: 0.77295, time/step=3047ms, lr=4.02e-05
2024-03-16 14:48:34,937 - logger.py:50 - Epoch: [4] train MAE: 0.77295, val MAE: 0.93848, test MAE: 0.90439, Time: 7.08s
2024-03-16 14:48:34,938 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:48:38,116 - logger.py:50 - Epoch: [5][0/2] loss: 37778.93750, MAE: 0.79128, time/step=3176ms, lr=4.99e-05
2024-03-16 14:48:40,889 - logger.py:50 - Epoch: [5][1/2] loss: 157985.11500, MAE: 0.81164, time/step=2975ms, lr=4.99e-05
2024-03-16 14:48:41,948 - logger.py:50 - Epoch: [5] train MAE: 0.81164, val MAE: 0.93389, test MAE: 0.90129, Time: 7.01s
2024-03-16 14:48:41,948 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:48:44,824 - logger.py:50 - Epoch: [6][0/2] loss: 42734.66016, MAE: 0.77426, time/step=2874ms, lr=4.98e-05
2024-03-16 14:48:47,769 - logger.py:50 - Epoch: [6][1/2] loss: 61458.30918, MAE: 0.80808, time/step=2909ms, lr=4.98e-05
2024-03-16 14:48:48,873 - logger.py:50 - Epoch: [6] train MAE: 0.80808, val MAE: 0.89511, test MAE: 0.86656, Time: 6.92s
2024-03-16 14:48:48,873 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:48:51,755 - logger.py:50 - Epoch: [7][0/2] loss: 108537.35156, MAE: 0.73008, time/step=2879ms, lr=4.97e-05
2024-03-16 14:48:55,003 - logger.py:50 - Epoch: [7][1/2] loss: 52751.04352, MAE: 0.75410, time/step=3064ms, lr=4.97e-05
2024-03-16 14:48:55,975 - logger.py:50 - Epoch: [7] train MAE: 0.75410, val MAE: 0.84031, test MAE: 0.81652, Time: 7.10s
2024-03-16 14:48:55,976 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:48:58,907 - logger.py:50 - Epoch: [8][0/2] loss: 14214.21680, MAE: 0.74070, time/step=2929ms, lr=4.97e-05
2024-03-16 14:49:01,892 - logger.py:50 - Epoch: [8][1/2] loss: 35635.45574, MAE: 0.72603, time/step=2957ms, lr=4.97e-05
2024-03-16 14:49:02,878 - logger.py:50 - Epoch: [8] train MAE: 0.72603, val MAE: 0.79532, test MAE: 0.77532, Time: 6.90s
2024-03-16 14:49:02,878 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:49:05,837 - logger.py:50 - Epoch: [9][0/2] loss: 39239.53906, MAE: 0.76847, time/step=2956ms, lr=4.96e-05
2024-03-16 14:49:08,922 - logger.py:50 - Epoch: [9][1/2] loss: 19624.35091, MAE: 0.71959, time/step=3021ms, lr=4.96e-05
2024-03-16 14:49:09,887 - logger.py:50 - Epoch: [9] train MAE: 0.71959, val MAE: 0.77659, test MAE: 0.75826, Time: 7.01s
2024-03-16 14:49:09,887 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:49:12,686 - logger.py:50 - Epoch: [10][0/2] loss: 129659.77344, MAE: 0.71959, time/step=2797ms, lr=4.95e-05
2024-03-16 14:49:15,849 - logger.py:50 - Epoch: [10][1/2] loss: 60154.04020, MAE: 0.69544, time/step=2980ms, lr=4.95e-05
2024-03-16 14:49:16,902 - logger.py:50 - Epoch: [10] train MAE: 0.69544, val MAE: 0.78025, test MAE: 0.76207, Time: 7.01s
2024-03-16 14:49:16,902 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:49:20,085 - logger.py:50 - Epoch: [11][0/2] loss: 71.51518, MAE: 0.67642, time/step=3181ms, lr=4.94e-05
2024-03-16 14:49:22,922 - logger.py:50 - Epoch: [11][1/2] loss: 52713.89841, MAE: 0.69353, time/step=3009ms, lr=4.94e-05
2024-03-16 14:49:23,879 - logger.py:50 - Epoch: [11] train MAE: 0.69353, val MAE: 0.79293, test MAE: 0.77416, Time: 6.98s
2024-03-16 14:49:23,879 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:49:27,088 - logger.py:50 - Epoch: [12][0/2] loss: 3403.22412, MAE: 0.70446, time/step=3206ms, lr=4.92e-05
2024-03-16 14:49:29,974 - logger.py:50 - Epoch: [12][1/2] loss: 11120.45936, MAE: 0.70714, time/step=3046ms, lr=4.92e-05
2024-03-16 14:49:30,940 - logger.py:50 - Epoch: [12] train MAE: 0.70714, val MAE: 0.81733, test MAE: 0.79720, Time: 7.06s
2024-03-16 14:49:30,940 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:49:33,927 - logger.py:50 - Epoch: [13][0/2] loss: 24664.52539, MAE: 0.73360, time/step=2984ms, lr=4.91e-05
2024-03-16 14:49:36,867 - logger.py:50 - Epoch: [13][1/2] loss: 12494.15586, MAE: 0.74432, time/step=2962ms, lr=4.91e-05
2024-03-16 14:49:37,845 - logger.py:50 - Epoch: [13] train MAE: 0.74432, val MAE: 0.84785, test MAE: 0.82593, Time: 6.90s
2024-03-16 14:49:37,845 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:49:41,013 - logger.py:50 - Epoch: [14][0/2] loss: 1499.34961, MAE: 0.75764, time/step=3166ms, lr=4.90e-05
2024-03-16 14:49:43,864 - logger.py:50 - Epoch: [14][1/2] loss: 788.72656, MAE: 0.75692, time/step=3009ms, lr=4.90e-05
2024-03-16 14:49:44,820 - logger.py:50 - Epoch: [14] train MAE: 0.75692, val MAE: 0.87079, test MAE: 0.84747, Time: 6.97s
2024-03-16 14:49:44,820 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:49:47,819 - logger.py:50 - Epoch: [15][0/2] loss: 20091.29688, MAE: 0.78932, time/step=2997ms, lr=4.88e-05
2024-03-16 14:49:50,769 - logger.py:50 - Epoch: [15][1/2] loss: 19483.05408, MAE: 0.78851, time/step=2973ms, lr=4.88e-05
2024-03-16 14:49:51,733 - logger.py:50 - Epoch: [15] train MAE: 0.78851, val MAE: 0.87790, test MAE: 0.85420, Time: 6.91s
2024-03-16 14:49:51,733 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:49:54,830 - logger.py:50 - Epoch: [16][0/2] loss: 36086.17969, MAE: 0.82967, time/step=3094ms, lr=4.86e-05
2024-03-16 14:49:58,077 - logger.py:50 - Epoch: [16][1/2] loss: 19731.16270, MAE: 0.78084, time/step=3171ms, lr=4.86e-05
2024-03-16 14:49:59,044 - logger.py:50 - Epoch: [16] train MAE: 0.78084, val MAE: 0.86762, test MAE: 0.84473, Time: 7.31s
2024-03-16 14:49:59,044 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:50:01,861 - logger.py:50 - Epoch: [17][0/2] loss: 57162.84375, MAE: 0.73245, time/step=2815ms, lr=4.85e-05
2024-03-16 14:50:04,927 - logger.py:50 - Epoch: [17][1/2] loss: 26906.56918, MAE: 0.75326, time/step=2941ms, lr=4.85e-05
2024-03-16 14:50:05,888 - logger.py:50 - Epoch: [17] train MAE: 0.75326, val MAE: 0.84667, test MAE: 0.82487, Time: 6.84s
2024-03-16 14:50:05,888 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:50:08,764 - logger.py:50 - Epoch: [18][0/2] loss: 170.49818, MAE: 0.77225, time/step=2875ms, lr=4.83e-05
2024-03-16 14:50:11,932 - logger.py:50 - Epoch: [18][1/2] loss: 440.75551, MAE: 0.75629, time/step=3021ms, lr=4.83e-05
2024-03-16 14:50:12,907 - logger.py:50 - Epoch: [18] train MAE: 0.75629, val MAE: 0.82790, test MAE: 0.80707, Time: 7.02s
2024-03-16 14:50:12,907 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:50:16,061 - logger.py:50 - Epoch: [19][0/2] loss: 4817.04102, MAE: 0.77059, time/step=3152ms, lr=4.81e-05
2024-03-16 14:50:19,208 - logger.py:50 - Epoch: [19][1/2] loss: 13450.94895, MAE: 0.72184, time/step=3149ms, lr=4.81e-05
2024-03-16 14:50:20,079 - logger.py:50 - Epoch: [19] train MAE: 0.72184, val MAE: 0.81142, test MAE: 0.79160, Time: 7.17s
2024-03-16 14:50:20,079 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:50:23,061 - logger.py:50 - Epoch: [20][0/2] loss: 39259.80469, MAE: 0.73082, time/step=2980ms, lr=4.79e-05
2024-03-16 14:50:26,119 - logger.py:50 - Epoch: [20][1/2] loss: 21917.09855, MAE: 0.72583, time/step=3019ms, lr=4.79e-05
2024-03-16 14:50:27,081 - logger.py:50 - Epoch: [20] train MAE: 0.72583, val MAE: 0.81362, test MAE: 0.79373, Time: 7.00s
2024-03-16 14:50:27,081 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:50:30,146 - logger.py:50 - Epoch: [21][0/2] loss: 3782.31006, MAE: 0.72244, time/step=3063ms, lr=4.77e-05
2024-03-16 14:50:33,390 - logger.py:50 - Epoch: [21][1/2] loss: 1970.56846, MAE: 0.72772, time/step=3153ms, lr=4.77e-05
2024-03-16 14:50:34,372 - logger.py:50 - Epoch: [21] train MAE: 0.72772, val MAE: 0.82018, test MAE: 0.79994, Time: 7.29s
2024-03-16 14:50:34,373 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:50:37,114 - logger.py:50 - Epoch: [22][0/2] loss: 9022.54199, MAE: 0.73144, time/step=2739ms, lr=4.74e-05
2024-03-16 14:50:40,298 - logger.py:50 - Epoch: [22][1/2] loss: 5967.55295, MAE: 0.71508, time/step=2962ms, lr=4.74e-05
2024-03-16 14:50:41,268 - logger.py:50 - Epoch: [22] train MAE: 0.71508, val MAE: 0.82908, test MAE: 0.80815, Time: 6.90s
2024-03-16 14:50:41,268 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:50:44,196 - logger.py:50 - Epoch: [23][0/2] loss: 10224.68555, MAE: 0.76388, time/step=2925ms, lr=4.72e-05
2024-03-16 14:50:47,289 - logger.py:50 - Epoch: [23][1/2] loss: 10484.13644, MAE: 0.73120, time/step=3009ms, lr=4.72e-05
2024-03-16 14:50:48,260 - logger.py:50 - Epoch: [23] train MAE: 0.73120, val MAE: 0.83732, test MAE: 0.81579, Time: 6.99s
2024-03-16 14:50:48,260 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:50:51,178 - logger.py:50 - Epoch: [24][0/2] loss: 8016.32568, MAE: 0.74987, time/step=2916ms, lr=4.70e-05
2024-03-16 14:50:54,279 - logger.py:50 - Epoch: [24][1/2] loss: 5775.97172, MAE: 0.74497, time/step=3009ms, lr=4.70e-05
2024-03-16 14:50:55,244 - logger.py:50 - Epoch: [24] train MAE: 0.74497, val MAE: 0.83431, test MAE: 0.81297, Time: 6.98s
2024-03-16 14:50:55,244 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:50:58,083 - logger.py:50 - Epoch: [25][0/2] loss: 8926.14355, MAE: 0.68968, time/step=2836ms, lr=4.67e-05
2024-03-16 14:51:01,172 - logger.py:50 - Epoch: [25][1/2] loss: 5043.72274, MAE: 0.73235, time/step=2963ms, lr=4.67e-05
2024-03-16 14:51:02,346 - logger.py:50 - Epoch: [25] train MAE: 0.73235, val MAE: 0.82742, test MAE: 0.80612, Time: 7.10s
2024-03-16 14:51:02,346 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:51:05,529 - logger.py:50 - Epoch: [26][0/2] loss: 1044.92615, MAE: 0.73545, time/step=3180ms, lr=4.65e-05
2024-03-16 14:51:08,811 - logger.py:50 - Epoch: [26][1/2] loss: 2533.99013, MAE: 0.74209, time/step=3232ms, lr=4.65e-05
2024-03-16 14:51:09,772 - logger.py:50 - Epoch: [26] train MAE: 0.74209, val MAE: 0.81926, test MAE: 0.79808, Time: 7.43s
2024-03-16 14:51:09,772 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:51:12,742 - logger.py:50 - Epoch: [27][0/2] loss: 3393.95850, MAE: 0.75076, time/step=2968ms, lr=4.62e-05
2024-03-16 14:51:15,598 - logger.py:50 - Epoch: [27][1/2] loss: 6057.54386, MAE: 0.74469, time/step=2912ms, lr=4.62e-05
2024-03-16 14:51:16,565 - logger.py:50 - Epoch: [27] train MAE: 0.74469, val MAE: 0.80996, test MAE: 0.78913, Time: 6.79s
2024-03-16 14:51:16,565 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:51:19,534 - logger.py:50 - Epoch: [28][0/2] loss: 465.34683, MAE: 0.73913, time/step=2967ms, lr=4.59e-05
2024-03-16 14:51:22,694 - logger.py:50 - Epoch: [28][1/2] loss: 12722.90424, MAE: 0.74057, time/step=3063ms, lr=4.59e-05
2024-03-16 14:51:23,564 - logger.py:50 - Epoch: [28] train MAE: 0.74057, val MAE: 0.81085, test MAE: 0.78989, Time: 7.00s
2024-03-16 14:51:23,564 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:51:26,621 - logger.py:50 - Epoch: [29][0/2] loss: 49805.19531, MAE: 0.70023, time/step=3055ms, lr=4.56e-05
2024-03-16 14:51:29,614 - logger.py:50 - Epoch: [29][1/2] loss: 24434.65731, MAE: 0.72402, time/step=3024ms, lr=4.56e-05
2024-03-16 14:51:30,581 - logger.py:50 - Epoch: [29] train MAE: 0.72402, val MAE: 0.82672, test MAE: 0.80514, Time: 7.02s
2024-03-16 14:51:30,581 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:51:33,722 - logger.py:50 - Epoch: [30][0/2] loss: 30876.13477, MAE: 0.74123, time/step=3138ms, lr=4.53e-05
2024-03-16 14:51:36,594 - logger.py:50 - Epoch: [30][1/2] loss: 29543.72429, MAE: 0.73101, time/step=3006ms, lr=4.53e-05
2024-03-16 14:51:37,565 - logger.py:50 - Epoch: [30] train MAE: 0.73101, val MAE: 0.84507, test MAE: 0.82233, Time: 6.98s
2024-03-16 14:51:37,565 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:51:40,511 - logger.py:50 - Epoch: [31][0/2] loss: 901.68536, MAE: 0.76972, time/step=2944ms, lr=4.50e-05
2024-03-16 14:51:43,535 - logger.py:50 - Epoch: [31][1/2] loss: 6312.07135, MAE: 0.76233, time/step=2984ms, lr=4.50e-05
2024-03-16 14:51:44,521 - logger.py:50 - Epoch: [31] train MAE: 0.76233, val MAE: 0.85075, test MAE: 0.82737, Time: 6.96s
2024-03-16 14:51:44,521 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:51:47,653 - logger.py:50 - Epoch: [32][0/2] loss: 229.93768, MAE: 0.75559, time/step=3130ms, lr=4.47e-05
2024-03-16 14:51:50,669 - logger.py:50 - Epoch: [32][1/2] loss: 3982.81835, MAE: 0.76470, time/step=3073ms, lr=4.47e-05
2024-03-16 14:51:51,812 - logger.py:50 - Epoch: [32] train MAE: 0.76470, val MAE: 0.84865, test MAE: 0.82516, Time: 7.29s
2024-03-16 14:51:51,813 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:51:54,682 - logger.py:50 - Epoch: [33][0/2] loss: 30408.51367, MAE: 0.73743, time/step=2868ms, lr=4.44e-05
2024-03-16 14:51:57,874 - logger.py:50 - Epoch: [33][1/2] loss: 16618.12193, MAE: 0.76599, time/step=3030ms, lr=4.44e-05
2024-03-16 14:51:58,842 - logger.py:50 - Epoch: [33] train MAE: 0.76599, val MAE: 0.83728, test MAE: 0.81401, Time: 7.03s
2024-03-16 14:51:58,843 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:52:01,851 - logger.py:50 - Epoch: [34][0/2] loss: 1172.81165, MAE: 0.73363, time/step=3007ms, lr=4.40e-05
2024-03-16 14:52:04,847 - logger.py:50 - Epoch: [34][1/2] loss: 2426.48485, MAE: 0.75703, time/step=3001ms, lr=4.40e-05
2024-03-16 14:52:05,821 - logger.py:50 - Epoch: [34] train MAE: 0.75703, val MAE: 0.83028, test MAE: 0.80695, Time: 6.98s
2024-03-16 14:52:05,821 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:52:08,807 - logger.py:50 - Epoch: [35][0/2] loss: 95.74689, MAE: 0.73527, time/step=2983ms, lr=4.37e-05
2024-03-16 14:52:11,705 - logger.py:50 - Epoch: [35][1/2] loss: 49.08270, MAE: 0.73081, time/step=2941ms, lr=4.37e-05
2024-03-16 14:52:12,668 - logger.py:50 - Epoch: [35] train MAE: 0.73081, val MAE: 0.82585, test MAE: 0.80236, Time: 6.85s
2024-03-16 14:52:12,668 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:52:15,610 - logger.py:50 - Epoch: [36][0/2] loss: 100.32253, MAE: 0.71406, time/step=2940ms, lr=4.34e-05
2024-03-16 14:52:18,819 - logger.py:50 - Epoch: [36][1/2] loss: 116.65540, MAE: 0.73255, time/step=3074ms, lr=4.34e-05
2024-03-16 14:52:19,803 - logger.py:50 - Epoch: [36] train MAE: 0.73255, val MAE: 0.82121, test MAE: 0.79765, Time: 7.13s
2024-03-16 14:52:19,803 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:52:22,876 - logger.py:50 - Epoch: [37][0/2] loss: 10528.18262, MAE: 0.74210, time/step=3070ms, lr=4.30e-05
2024-03-16 14:52:25,849 - logger.py:50 - Epoch: [37][1/2] loss: 5301.94441, MAE: 0.72892, time/step=3022ms, lr=4.30e-05
2024-03-16 14:52:26,818 - logger.py:50 - Epoch: [37] train MAE: 0.72892, val MAE: 0.82311, test MAE: 0.79932, Time: 7.02s
2024-03-16 14:52:26,818 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:52:29,733 - logger.py:50 - Epoch: [38][0/2] loss: 16533.96680, MAE: 0.72400, time/step=2913ms, lr=4.26e-05
2024-03-16 14:52:32,833 - logger.py:50 - Epoch: [38][1/2] loss: 33408.95151, MAE: 0.72986, time/step=3006ms, lr=4.26e-05
2024-03-16 14:52:33,798 - logger.py:50 - Epoch: [38] train MAE: 0.72986, val MAE: 0.82327, test MAE: 0.79949, Time: 6.98s
2024-03-16 14:52:33,798 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:52:36,936 - logger.py:50 - Epoch: [39][0/2] loss: 0.01029, MAE: 0.72202, time/step=3135ms, lr=4.23e-05
2024-03-16 14:52:39,807 - logger.py:50 - Epoch: [39][1/2] loss: 545.45209, MAE: 0.73360, time/step=3003ms, lr=4.23e-05
2024-03-16 14:52:40,865 - logger.py:50 - Epoch: [39] train MAE: 0.73360, val MAE: 0.83037, test MAE: 0.80633, Time: 7.07s
2024-03-16 14:52:40,865 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:52:43,803 - logger.py:50 - Epoch: [40][0/2] loss: 227.83235, MAE: 0.75872, time/step=2935ms, lr=4.19e-05
2024-03-16 14:52:46,934 - logger.py:50 - Epoch: [40][1/2] loss: 174.55871, MAE: 0.74946, time/step=3033ms, lr=4.19e-05
2024-03-16 14:52:47,904 - logger.py:50 - Epoch: [40] train MAE: 0.74946, val MAE: 0.83650, test MAE: 0.81224, Time: 7.04s
2024-03-16 14:52:47,904 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:52:50,964 - logger.py:50 - Epoch: [41][0/2] loss: 19830.01758, MAE: 0.78421, time/step=3058ms, lr=4.15e-05
2024-03-16 14:52:53,832 - logger.py:50 - Epoch: [41][1/2] loss: 36159.35330, MAE: 0.75616, time/step=2963ms, lr=4.15e-05
2024-03-16 14:52:54,797 - logger.py:50 - Epoch: [41] train MAE: 0.75616, val MAE: 0.84446, test MAE: 0.81954, Time: 6.89s
2024-03-16 14:52:54,797 - logger.py:50 - Best -- epoch=0, train MAE: 0.64645, val MAE: 0.73860, test MAE: 0.71756

2024-03-16 14:52:57,836 - logger.py:50 - Epoch: [42][0/2] loss: 59032.86328, MAE: 0.74343, time/step=3036ms, lr=4.11e-05
2024-03-16 14:53:29,753 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-16 19:34:36,505 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-16 19:43:41,313 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=8, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-16 19:56:11,384 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=8, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-16 22:50:19,649 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-16 22:50:19,985 - logger.py:50 - Number of params: 2978805
2024-03-16 23:09:28,719 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=8, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-16 23:09:44,681 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-16 23:09:45,049 - logger.py:50 - Number of params: 2978805
2024-03-16 23:11:05,474 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=8, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-16 23:11:23,393 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-16 23:11:23,820 - logger.py:50 - Number of params: 2978805
2024-03-16 23:13:35,968 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=8, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-16 23:13:53,238 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-16 23:13:53,539 - logger.py:50 - Number of params: 2978805
2024-03-17 12:12:32,233 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 12:12:50,591 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 12:12:51,029 - logger.py:50 - Number of params: 2978805
2024-03-17 12:13:42,104 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 12:13:59,651 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 12:13:59,963 - logger.py:50 - Number of params: 2978805
2024-03-17 12:14:05,253 - logger.py:50 - Epoch: [0][0/125] loss: 100678.85938, MAE: 0.52315, time/step=5287ms, lr=1.00e-06
2024-03-17 12:20:24,963 - logger.py:50 - Epoch: [0][100/125] loss: 372894.36703, MAE: 0.62112, time/step=3812ms, lr=1.00e-06
2024-03-17 12:21:54,762 - logger.py:50 - Epoch: [0][124/125] loss: 307047.74272, MAE: 0.62843, time/step=3798ms, lr=1.00e-06
2024-03-17 12:22:49,996 - logger.py:50 - Epoch: [0] train MAE: 0.62843, val MAE: 0.65710, test MAE: 0.63990, Time: 530.03s
2024-03-17 12:22:49,997 - logger.py:50 - Best -- epoch=0, train MAE: 0.62843, val MAE: 0.65710, test MAE: 0.63990

2024-03-17 12:22:53,678 - logger.py:50 - Epoch: [1][0/125] loss: 60366.30469, MAE: 0.63979, time/step=3680ms, lr=1.08e-05
2024-03-17 12:29:07,746 - logger.py:50 - Epoch: [1][100/125] loss: 374250.43948, MAE: 0.66466, time/step=3740ms, lr=1.08e-05
2024-03-17 12:30:37,151 - logger.py:50 - Epoch: [1][124/125] loss: 306127.00583, MAE: 0.66237, time/step=3737ms, lr=1.08e-05
2024-03-17 12:31:31,812 - logger.py:50 - Epoch: [1] train MAE: 0.66237, val MAE: 0.64250, test MAE: 0.62566, Time: 521.82s
2024-03-17 12:31:31,813 - logger.py:50 - Best -- epoch=1, train MAE: 0.66237, val MAE: 0.64250, test MAE: 0.62566

2024-03-17 12:31:35,445 - logger.py:50 - Epoch: [2][0/125] loss: 849.21869, MAE: 0.67358, time/step=3630ms, lr=2.06e-05
2024-03-17 12:37:47,081 - logger.py:50 - Epoch: [2][100/125] loss: 346862.06153, MAE: 0.66209, time/step=3716ms, lr=2.06e-05
2024-03-17 12:39:17,737 - logger.py:50 - Epoch: [2][124/125] loss: 281946.87751, MAE: 0.65585, time/step=3727ms, lr=2.06e-05
2024-03-17 12:40:11,673 - logger.py:50 - Epoch: [2] train MAE: 0.65585, val MAE: 0.64555, test MAE: 0.62912, Time: 519.86s
2024-03-17 12:40:11,674 - logger.py:50 - Best -- epoch=1, train MAE: 0.66237, val MAE: 0.64250, test MAE: 0.62566

2024-03-17 12:40:15,437 - logger.py:50 - Epoch: [3][0/125] loss: 31792.64844, MAE: 0.63000, time/step=3761ms, lr=3.04e-05
2024-03-17 12:46:28,558 - logger.py:50 - Epoch: [3][100/125] loss: 142152.38142, MAE: 0.64369, time/step=3732ms, lr=3.04e-05
2024-03-17 12:47:58,353 - logger.py:50 - Epoch: [3][124/125] loss: 331054.69850, MAE: 0.65325, time/step=3733ms, lr=3.04e-05
2024-03-17 12:48:52,775 - logger.py:50 - Epoch: [3] train MAE: 0.65325, val MAE: 0.70969, test MAE: 0.69456, Time: 521.10s
2024-03-17 12:48:52,775 - logger.py:50 - Best -- epoch=1, train MAE: 0.66237, val MAE: 0.64250, test MAE: 0.62566

2024-03-17 12:48:56,551 - logger.py:50 - Epoch: [4][0/125] loss: 52886.52344, MAE: 0.74880, time/step=3773ms, lr=4.02e-05
2024-03-17 12:55:09,153 - logger.py:50 - Epoch: [4][100/125] loss: 422520.03972, MAE: 0.65016, time/step=3726ms, lr=4.02e-05
2024-03-17 12:56:38,522 - logger.py:50 - Epoch: [4][124/125] loss: 345181.01973, MAE: 0.64251, time/step=3726ms, lr=4.02e-05
2024-03-17 12:57:32,983 - logger.py:50 - Epoch: [4] train MAE: 0.64251, val MAE: 0.62053, test MAE: 0.60879, Time: 520.21s
2024-03-17 12:57:32,984 - logger.py:50 - Best -- epoch=4, train MAE: 0.64251, val MAE: 0.62053, test MAE: 0.60879

2024-03-17 12:57:37,167 - logger.py:50 - Epoch: [5][0/125] loss: 10540.16016, MAE: 0.60462, time/step=4181ms, lr=4.99e-05
2024-03-17 13:03:48,906 - logger.py:50 - Epoch: [5][100/125] loss: 400474.24772, MAE: 0.63622, time/step=3722ms, lr=4.99e-05
2024-03-17 13:05:18,735 - logger.py:50 - Epoch: [5][124/125] loss: 329565.23632, MAE: 0.63363, time/step=3726ms, lr=4.99e-05
2024-03-17 13:06:12,706 - logger.py:50 - Epoch: [5] train MAE: 0.63363, val MAE: 0.62197, test MAE: 0.61094, Time: 519.72s
2024-03-17 13:06:12,707 - logger.py:50 - Best -- epoch=4, train MAE: 0.64251, val MAE: 0.62053, test MAE: 0.60879

2024-03-17 13:06:16,866 - logger.py:50 - Epoch: [6][0/125] loss: 744.81287, MAE: 0.59609, time/step=4157ms, lr=4.98e-05
2024-03-17 13:12:29,068 - logger.py:50 - Epoch: [6][100/125] loss: 393627.11238, MAE: 0.63668, time/step=3726ms, lr=4.98e-05
2024-03-17 13:13:58,262 - logger.py:50 - Epoch: [6][124/125] loss: 322219.16045, MAE: 0.63488, time/step=3724ms, lr=4.98e-05
2024-03-17 13:14:51,381 - logger.py:50 - Epoch: [6] train MAE: 0.63488, val MAE: 0.62405, test MAE: 0.61229, Time: 518.67s
2024-03-17 13:14:51,381 - logger.py:50 - Best -- epoch=4, train MAE: 0.64251, val MAE: 0.62053, test MAE: 0.60879

2024-03-17 13:14:55,060 - logger.py:50 - Epoch: [7][0/125] loss: 1565.49084, MAE: 0.63995, time/step=3676ms, lr=4.97e-05
2024-03-17 13:21:07,139 - logger.py:50 - Epoch: [7][100/125] loss: 397711.16558, MAE: 0.64230, time/step=3720ms, lr=4.97e-05
2024-03-17 13:22:36,227 - logger.py:50 - Epoch: [7][124/125] loss: 327262.12130, MAE: 0.63114, time/step=3719ms, lr=4.97e-05
2024-03-17 13:23:31,297 - logger.py:50 - Epoch: [7] train MAE: 0.63114, val MAE: 0.59909, test MAE: 0.59063, Time: 519.92s
2024-03-17 13:23:31,298 - logger.py:50 - Best -- epoch=7, train MAE: 0.63114, val MAE: 0.59909, test MAE: 0.59063

2024-03-17 13:23:35,106 - logger.py:50 - Epoch: [8][0/125] loss: 59051.19531, MAE: 0.60435, time/step=3806ms, lr=4.97e-05
2024-03-17 13:31:33,884 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=100, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', rank=0, local_rank=0, distributed=True, dist_backend='nccl')
2024-03-17 17:24:41,778 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 17:24:41,877 - logger.py:50 - Number of params: 2978805
2024-03-17 17:24:47,398 - logger.py:50 - Epoch: [0][0/125] loss: 470.97266, MAE: 0.52321, time/step=5518ms, lr=1.00e-06
2024-03-17 18:02:03,739 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 18:02:20,968 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 18:02:21,289 - logger.py:50 - Number of params: 2978805
2024-03-17 18:02:26,187 - logger.py:50 - Epoch: [0][0/125] loss: 335629.00000, MAE: 0.63892, time/step=4894ms, lr=1.00e-06
2024-03-17 18:05:38,491 - logger.py:50 - Epoch: [0][50/125] loss: 56065.65143, MAE: 0.60261, time/step=3867ms, lr=1.00e-06
2024-03-17 18:08:44,709 - logger.py:50 - Epoch: [0][100/125] loss: 438403.24416, MAE: 0.62010, time/step=3796ms, lr=1.00e-06
2024-03-17 18:10:15,508 - logger.py:50 - Epoch: [0][124/125] loss: 357338.41028, MAE: 0.62540, time/step=3794ms, lr=1.00e-06
2024-03-17 18:11:12,010 - logger.py:50 - Epoch: [0] train MAE: 0.62540, val MAE: 0.65029, test MAE: 0.63324, Time: 530.72s
2024-03-17 18:11:12,010 - logger.py:50 - Best -- epoch=0, train MAE: 0.62540, val MAE: 0.65029, test MAE: 0.63324

2024-03-17 18:11:15,739 - logger.py:50 - Epoch: [1][0/125] loss: 4433.11816, MAE: 0.69195, time/step=3727ms, lr=1.08e-05
2024-03-17 18:14:23,929 - logger.py:50 - Epoch: [1][50/125] loss: 28785.54270, MAE: 0.63261, time/step=3763ms, lr=1.08e-05
2024-03-17 18:17:31,857 - logger.py:50 - Epoch: [1][100/125] loss: 269610.08182, MAE: 0.64630, time/step=3761ms, lr=1.08e-05
2024-03-17 18:19:00,920 - logger.py:50 - Epoch: [1][124/125] loss: 307464.86567, MAE: 0.65787, time/step=3751ms, lr=1.08e-05
2024-03-17 18:19:56,693 - logger.py:50 - Epoch: [1] train MAE: 0.65787, val MAE: 0.69357, test MAE: 0.67564, Time: 524.68s
2024-03-17 18:19:56,693 - logger.py:50 - Best -- epoch=0, train MAE: 0.62540, val MAE: 0.65029, test MAE: 0.63324

2024-03-17 18:20:00,331 - logger.py:50 - Epoch: [2][0/125] loss: 38723.72656, MAE: 0.65909, time/step=3636ms, lr=2.06e-05
2024-03-17 18:23:07,550 - logger.py:50 - Epoch: [2][50/125] loss: 724682.25844, MAE: 0.70843, time/step=3742ms, lr=2.06e-05
2024-03-17 18:26:15,201 - logger.py:50 - Epoch: [2][100/125] loss: 381061.43886, MAE: 0.66898, time/step=3748ms, lr=2.06e-05
2024-03-17 18:27:46,083 - logger.py:50 - Epoch: [2][124/125] loss: 311730.22616, MAE: 0.66131, time/step=3755ms, lr=2.06e-05
2024-03-17 18:28:40,451 - logger.py:50 - Epoch: [2] train MAE: 0.66131, val MAE: 0.66049, test MAE: 0.64273, Time: 523.76s
2024-03-17 18:28:40,451 - logger.py:50 - Best -- epoch=0, train MAE: 0.62540, val MAE: 0.65029, test MAE: 0.63324

2024-03-17 18:28:44,092 - logger.py:50 - Epoch: [3][0/125] loss: 311.91562, MAE: 0.66994, time/step=3639ms, lr=3.04e-05
2024-03-17 18:31:50,120 - logger.py:50 - Epoch: [3][50/125] loss: 216551.37503, MAE: 0.65384, time/step=3719ms, lr=3.04e-05
2024-03-17 18:34:56,381 - logger.py:50 - Epoch: [3][100/125] loss: 357947.74268, MAE: 0.66197, time/step=3722ms, lr=3.04e-05
2024-03-17 18:36:27,164 - logger.py:50 - Epoch: [3][124/125] loss: 291210.40501, MAE: 0.65783, time/step=3734ms, lr=3.04e-05
2024-03-17 18:37:22,644 - logger.py:50 - Epoch: [3] train MAE: 0.65783, val MAE: 0.64625, test MAE: 0.62728, Time: 522.19s
2024-03-17 18:37:22,644 - logger.py:50 - Best -- epoch=3, train MAE: 0.65783, val MAE: 0.64625, test MAE: 0.62728

2024-03-17 18:37:26,986 - logger.py:50 - Epoch: [4][0/125] loss: 2570.73267, MAE: 0.65020, time/step=4340ms, lr=4.02e-05
2024-03-17 18:40:35,047 - logger.py:50 - Epoch: [4][50/125] loss: 675200.64064, MAE: 0.66007, time/step=3773ms, lr=4.02e-05
2024-03-17 18:43:42,549 - logger.py:50 - Epoch: [4][100/125] loss: 391013.69901, MAE: 0.65751, time/step=3761ms, lr=4.02e-05
2024-03-17 18:45:11,464 - logger.py:50 - Epoch: [4][124/125] loss: 321395.52193, MAE: 0.65259, time/step=3751ms, lr=4.02e-05
2024-03-17 18:46:06,844 - logger.py:50 - Epoch: [4] train MAE: 0.65259, val MAE: 0.63308, test MAE: 0.61322, Time: 524.20s
2024-03-17 18:46:06,844 - logger.py:50 - Best -- epoch=4, train MAE: 0.65259, val MAE: 0.63308, test MAE: 0.61322

2024-03-17 18:46:10,646 - logger.py:50 - Epoch: [5][0/125] loss: 1492.70166, MAE: 0.62049, time/step=3800ms, lr=4.99e-05
2024-03-17 18:49:18,143 - logger.py:50 - Epoch: [5][50/125] loss: 29650.15567, MAE: 0.63087, time/step=3751ms, lr=4.99e-05
2024-03-17 18:52:25,473 - logger.py:50 - Epoch: [5][100/125] loss: 25588.74313, MAE: 0.63231, time/step=3749ms, lr=4.99e-05
2024-03-17 18:53:55,207 - logger.py:50 - Epoch: [5][124/125] loss: 350336.68678, MAE: 0.65260, time/step=3747ms, lr=4.99e-05
2024-03-17 18:54:51,066 - logger.py:50 - Epoch: [5] train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128, Time: 524.22s
2024-03-17 18:54:51,066 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 18:54:55,219 - logger.py:50 - Epoch: [6][0/125] loss: 214457.40625, MAE: 0.54247, time/step=4151ms, lr=4.98e-05
2024-03-17 18:58:02,374 - logger.py:50 - Epoch: [6][50/125] loss: 628569.94848, MAE: 0.61795, time/step=3751ms, lr=4.98e-05
2024-03-17 19:01:09,443 - logger.py:50 - Epoch: [6][100/125] loss: 331396.10819, MAE: 0.61117, time/step=3746ms, lr=4.98e-05
2024-03-17 19:02:40,448 - logger.py:50 - Epoch: [6][124/125] loss: 363082.51473, MAE: 0.61469, time/step=3755ms, lr=4.98e-05
2024-03-17 19:03:35,225 - logger.py:50 - Epoch: [6] train MAE: 0.61469, val MAE: 0.61936, test MAE: 0.60570, Time: 524.16s
2024-03-17 19:03:35,226 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 19:03:38,882 - logger.py:50 - Epoch: [7][0/125] loss: 1298.67322, MAE: 0.57392, time/step=3654ms, lr=4.97e-05
2024-03-17 19:06:45,569 - logger.py:50 - Epoch: [7][50/125] loss: 675389.08277, MAE: 0.64699, time/step=3732ms, lr=4.97e-05
2024-03-17 19:09:52,745 - logger.py:50 - Epoch: [7][100/125] loss: 365057.80532, MAE: 0.62933, time/step=3738ms, lr=4.97e-05
2024-03-17 19:11:21,524 - logger.py:50 - Epoch: [7][124/125] loss: 300567.02067, MAE: 0.62523, time/step=3730ms, lr=4.97e-05
2024-03-17 19:12:16,074 - logger.py:50 - Epoch: [7] train MAE: 0.62523, val MAE: 0.60525, test MAE: 0.59611, Time: 520.85s
2024-03-17 19:12:16,074 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 19:12:20,244 - logger.py:50 - Epoch: [8][0/125] loss: 33584.00781, MAE: 0.59630, time/step=4168ms, lr=4.97e-05
2024-03-17 19:15:26,390 - logger.py:50 - Epoch: [8][50/125] loss: 748159.89794, MAE: 0.64069, time/step=3732ms, lr=4.97e-05
2024-03-17 19:18:33,256 - logger.py:50 - Epoch: [8][100/125] loss: 388789.02056, MAE: 0.61096, time/step=3734ms, lr=4.97e-05
2024-03-17 19:20:03,091 - logger.py:50 - Epoch: [8][124/125] loss: 320052.44448, MAE: 0.60804, time/step=3736ms, lr=4.97e-05
2024-03-17 19:20:58,402 - logger.py:50 - Epoch: [8] train MAE: 0.60804, val MAE: 0.60185, test MAE: 0.59562, Time: 522.33s
2024-03-17 19:20:58,402 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 19:21:02,155 - logger.py:50 - Epoch: [9][0/125] loss: 8690002.00000, MAE: 0.91326, time/step=3751ms, lr=4.96e-05
2024-03-17 19:24:07,288 - logger.py:50 - Epoch: [9][50/125] loss: 198343.49538, MAE: 0.61460, time/step=3704ms, lr=4.96e-05
2024-03-17 19:27:15,202 - logger.py:50 - Epoch: [9][100/125] loss: 114054.03640, MAE: 0.59686, time/step=3731ms, lr=4.96e-05
2024-03-17 19:28:45,284 - logger.py:50 - Epoch: [9][124/125] loss: 303771.59993, MAE: 0.60336, time/step=3735ms, lr=4.96e-05
2024-03-17 19:29:41,058 - logger.py:50 - Epoch: [9] train MAE: 0.60336, val MAE: 0.65940, test MAE: 0.65138, Time: 522.66s
2024-03-17 19:29:41,058 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 19:29:44,727 - logger.py:50 - Epoch: [10][0/125] loss: 82263.36719, MAE: 0.73916, time/step=3667ms, lr=4.95e-05
2024-03-17 19:32:51,356 - logger.py:50 - Epoch: [10][50/125] loss: 26818.43298, MAE: 0.59821, time/step=3731ms, lr=4.95e-05
2024-03-17 19:35:58,528 - logger.py:50 - Epoch: [10][100/125] loss: 121447.94945, MAE: 0.60770, time/step=3737ms, lr=4.95e-05
2024-03-17 19:37:29,141 - logger.py:50 - Epoch: [10][124/125] loss: 302732.97937, MAE: 0.60624, time/step=3745ms, lr=4.95e-05
2024-03-17 19:38:24,893 - logger.py:50 - Epoch: [10] train MAE: 0.60624, val MAE: 0.61585, test MAE: 0.60728, Time: 523.83s
2024-03-17 19:38:24,893 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 19:38:28,459 - logger.py:50 - Epoch: [11][0/125] loss: 7603.32031, MAE: 0.59013, time/step=3564ms, lr=4.94e-05
2024-03-17 19:41:34,748 - logger.py:50 - Epoch: [11][50/125] loss: 473676.19240, MAE: 0.63495, time/step=3723ms, lr=4.94e-05
2024-03-17 19:44:43,750 - logger.py:50 - Epoch: [11][100/125] loss: 252374.87221, MAE: 0.61585, time/step=3751ms, lr=4.94e-05
2024-03-17 19:46:13,540 - logger.py:50 - Epoch: [11][124/125] loss: 282168.40713, MAE: 0.61628, time/step=3749ms, lr=4.94e-05
2024-03-17 19:47:08,775 - logger.py:50 - Epoch: [11] train MAE: 0.61628, val MAE: 0.62647, test MAE: 0.61801, Time: 523.88s
2024-03-17 19:47:08,776 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 19:47:12,531 - logger.py:50 - Epoch: [12][0/125] loss: 39199.84375, MAE: 0.61093, time/step=3753ms, lr=4.92e-05
2024-03-17 19:50:19,462 - logger.py:50 - Epoch: [12][50/125] loss: 26162.98130, MAE: 0.59205, time/step=3739ms, lr=4.92e-05
2024-03-17 19:53:27,172 - logger.py:50 - Epoch: [12][100/125] loss: 373280.67865, MAE: 0.61640, time/step=3746ms, lr=4.92e-05
2024-03-17 19:54:58,224 - logger.py:50 - Epoch: [12][124/125] loss: 307381.21514, MAE: 0.60807, time/step=3756ms, lr=4.92e-05
2024-03-17 19:55:52,899 - logger.py:50 - Epoch: [12] train MAE: 0.60807, val MAE: 0.58522, test MAE: 0.57684, Time: 524.12s
2024-03-17 19:55:52,899 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 19:55:56,535 - logger.py:50 - Epoch: [13][0/125] loss: 5154.12500, MAE: 0.60151, time/step=3633ms, lr=4.91e-05
2024-03-17 19:59:05,384 - logger.py:50 - Epoch: [13][50/125] loss: 229010.35350, MAE: 0.60377, time/step=3774ms, lr=4.91e-05
2024-03-17 20:02:11,929 - logger.py:50 - Epoch: [13][100/125] loss: 371894.34088, MAE: 0.60469, time/step=3753ms, lr=4.91e-05
2024-03-17 20:03:42,407 - logger.py:50 - Epoch: [13][124/125] loss: 306392.88046, MAE: 0.60631, time/step=3756ms, lr=4.91e-05
2024-03-17 20:04:37,020 - logger.py:50 - Epoch: [13] train MAE: 0.60631, val MAE: 0.60478, test MAE: 0.59675, Time: 524.12s
2024-03-17 20:04:37,020 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 20:04:40,835 - logger.py:50 - Epoch: [14][0/125] loss: 13939.90723, MAE: 0.56931, time/step=3812ms, lr=4.90e-05
2024-03-17 20:07:48,053 - logger.py:50 - Epoch: [14][50/125] loss: 499789.37534, MAE: 0.61056, time/step=3746ms, lr=4.90e-05
2024-03-17 20:10:55,110 - logger.py:50 - Epoch: [14][100/125] loss: 363353.24483, MAE: 0.61238, time/step=3743ms, lr=4.90e-05
2024-03-17 20:12:24,339 - logger.py:50 - Epoch: [14][124/125] loss: 300071.24623, MAE: 0.60661, time/step=3739ms, lr=4.90e-05
2024-03-17 20:13:19,356 - logger.py:50 - Epoch: [14] train MAE: 0.60661, val MAE: 0.59490, test MAE: 0.58767, Time: 522.34s
2024-03-17 20:13:19,358 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 20:13:23,650 - logger.py:50 - Epoch: [15][0/125] loss: 5772.75342, MAE: 0.61303, time/step=4289ms, lr=4.88e-05
2024-03-17 20:16:29,690 - logger.py:50 - Epoch: [15][50/125] loss: 494619.30846, MAE: 0.60532, time/step=3732ms, lr=4.88e-05
2024-03-17 20:19:36,082 - logger.py:50 - Epoch: [15][100/125] loss: 268853.78117, MAE: 0.60066, time/step=3730ms, lr=4.88e-05
2024-03-17 20:21:06,993 - logger.py:50 - Epoch: [15][124/125] loss: 303995.33581, MAE: 0.60093, time/step=3741ms, lr=4.88e-05
2024-03-17 20:22:01,880 - logger.py:50 - Epoch: [15] train MAE: 0.60093, val MAE: 0.62523, test MAE: 0.61619, Time: 522.52s
2024-03-17 20:22:01,880 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 20:22:06,007 - logger.py:50 - Epoch: [16][0/125] loss: 110362.48438, MAE: 0.62609, time/step=4125ms, lr=4.86e-05
2024-03-17 20:25:14,095 - logger.py:50 - Epoch: [16][50/125] loss: 212410.37087, MAE: 0.61682, time/step=3769ms, lr=4.86e-05
2024-03-17 20:28:19,215 - logger.py:50 - Epoch: [16][100/125] loss: 366559.69181, MAE: 0.61179, time/step=3736ms, lr=4.86e-05
2024-03-17 20:29:49,908 - logger.py:50 - Epoch: [16][124/125] loss: 299212.60454, MAE: 0.60409, time/step=3744ms, lr=4.86e-05
2024-03-17 20:30:44,275 - logger.py:50 - Epoch: [16] train MAE: 0.60409, val MAE: 0.59555, test MAE: 0.58762, Time: 522.39s
2024-03-17 20:30:44,275 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 20:30:48,576 - logger.py:50 - Epoch: [17][0/125] loss: 128.80255, MAE: 0.53086, time/step=4299ms, lr=4.85e-05
2024-03-17 20:33:55,017 - logger.py:50 - Epoch: [17][50/125] loss: 499362.78876, MAE: 0.60633, time/step=3740ms, lr=4.85e-05
2024-03-17 20:37:02,259 - logger.py:50 - Epoch: [17][100/125] loss: 364616.23481, MAE: 0.60885, time/step=3742ms, lr=4.85e-05
2024-03-17 20:38:32,121 - logger.py:50 - Epoch: [17][124/125] loss: 296486.25913, MAE: 0.60489, time/step=3743ms, lr=4.85e-05
2024-03-17 20:39:27,002 - logger.py:50 - Epoch: [17] train MAE: 0.60489, val MAE: 0.59830, test MAE: 0.58809, Time: 522.73s
2024-03-17 20:39:27,002 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 20:39:30,697 - logger.py:50 - Epoch: [18][0/125] loss: 41.73740, MAE: 0.61062, time/step=3693ms, lr=4.83e-05
2024-03-17 20:42:38,439 - logger.py:50 - Epoch: [18][50/125] loss: 482397.58177, MAE: 0.61516, time/step=3754ms, lr=4.83e-05
2024-03-17 20:45:45,939 - logger.py:50 - Epoch: [18][100/125] loss: 351138.93700, MAE: 0.60926, time/step=3752ms, lr=4.83e-05
2024-03-17 20:47:15,056 - logger.py:50 - Epoch: [18][124/125] loss: 286612.73707, MAE: 0.60482, time/step=3744ms, lr=4.83e-05
2024-03-17 20:48:10,005 - logger.py:50 - Epoch: [18] train MAE: 0.60482, val MAE: 0.59508, test MAE: 0.58486, Time: 523.00s
2024-03-17 20:48:10,005 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 20:48:13,707 - logger.py:50 - Epoch: [19][0/125] loss: 218.51422, MAE: 0.59618, time/step=3700ms, lr=4.81e-05
2024-03-17 20:51:19,885 - logger.py:50 - Epoch: [19][50/125] loss: 20005.99989, MAE: 0.59022, time/step=3723ms, lr=4.81e-05
2024-03-17 20:54:27,206 - logger.py:50 - Epoch: [19][100/125] loss: 117636.42298, MAE: 0.59617, time/step=3735ms, lr=4.81e-05
2024-03-17 20:55:57,155 - logger.py:50 - Epoch: [19][124/125] loss: 277736.57210, MAE: 0.60430, time/step=3737ms, lr=4.81e-05
2024-03-17 20:56:52,507 - logger.py:50 - Epoch: [19] train MAE: 0.60430, val MAE: 0.61338, test MAE: 0.60559, Time: 522.50s
2024-03-17 20:56:52,507 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 20:56:56,144 - logger.py:50 - Epoch: [20][0/125] loss: 140548.65625, MAE: 0.59468, time/step=3635ms, lr=4.79e-05
2024-03-17 21:00:03,920 - logger.py:50 - Epoch: [20][50/125] loss: 19703.86166, MAE: 0.57907, time/step=3753ms, lr=4.79e-05
2024-03-17 21:03:10,995 - logger.py:50 - Epoch: [20][100/125] loss: 117097.51149, MAE: 0.58723, time/step=3747ms, lr=4.79e-05
2024-03-17 21:04:40,057 - logger.py:50 - Epoch: [20][124/125] loss: 282536.42327, MAE: 0.59422, time/step=3740ms, lr=4.79e-05
2024-03-17 21:05:34,430 - logger.py:50 - Epoch: [20] train MAE: 0.59422, val MAE: 0.62447, test MAE: 0.61631, Time: 521.92s
2024-03-17 21:05:34,431 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 21:05:38,259 - logger.py:50 - Epoch: [21][0/125] loss: 10475.64258, MAE: 0.62384, time/step=3826ms, lr=4.77e-05
2024-03-17 21:08:43,980 - logger.py:50 - Epoch: [21][50/125] loss: 236574.69053, MAE: 0.61618, time/step=3717ms, lr=4.77e-05
2024-03-17 21:11:50,808 - logger.py:50 - Epoch: [21][100/125] loss: 355582.27887, MAE: 0.61949, time/step=3726ms, lr=4.77e-05
2024-03-17 21:13:20,834 - logger.py:50 - Epoch: [21][124/125] loss: 290611.74279, MAE: 0.61100, time/step=3731ms, lr=4.77e-05
2024-03-17 21:14:15,701 - logger.py:50 - Epoch: [21] train MAE: 0.61100, val MAE: 0.58013, test MAE: 0.57310, Time: 521.27s
2024-03-17 21:14:15,701 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 21:14:19,804 - logger.py:50 - Epoch: [22][0/125] loss: 128799.50000, MAE: 0.59793, time/step=4101ms, lr=4.74e-05
2024-03-17 21:17:26,579 - logger.py:50 - Epoch: [22][50/125] loss: 22511.34525, MAE: 0.57600, time/step=3743ms, lr=4.74e-05
2024-03-17 21:20:33,904 - logger.py:50 - Epoch: [22][100/125] loss: 277196.40162, MAE: 0.59429, time/step=3745ms, lr=4.74e-05
2024-03-17 21:22:03,500 - logger.py:50 - Epoch: [22][124/125] loss: 306861.09973, MAE: 0.59596, time/step=3742ms, lr=4.74e-05
2024-03-17 21:22:58,804 - logger.py:50 - Epoch: [22] train MAE: 0.59596, val MAE: 0.62255, test MAE: 0.61561, Time: 523.10s
2024-03-17 21:22:58,804 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 21:23:02,610 - logger.py:50 - Epoch: [23][0/125] loss: 8807189.00000, MAE: 0.82213, time/step=3804ms, lr=4.72e-05
2024-03-17 21:26:09,740 - logger.py:50 - Epoch: [23][50/125] loss: 222711.01787, MAE: 0.60863, time/step=3744ms, lr=4.72e-05
2024-03-17 21:29:16,634 - logger.py:50 - Epoch: [23][100/125] loss: 120773.85420, MAE: 0.59874, time/step=3741ms, lr=4.72e-05
2024-03-17 21:30:45,843 - logger.py:50 - Epoch: [23][124/125] loss: 285229.11794, MAE: 0.60340, time/step=3736ms, lr=4.72e-05
2024-03-17 21:31:41,134 - logger.py:50 - Epoch: [23] train MAE: 0.60340, val MAE: 0.67127, test MAE: 0.65740, Time: 522.33s
2024-03-17 21:31:41,135 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 21:31:45,469 - logger.py:50 - Epoch: [24][0/125] loss: 262819.06250, MAE: 0.57652, time/step=4332ms, lr=4.70e-05
2024-03-17 21:34:52,016 - logger.py:50 - Epoch: [24][50/125] loss: 253324.56843, MAE: 0.61963, time/step=3743ms, lr=4.70e-05
2024-03-17 21:37:59,352 - logger.py:50 - Epoch: [24][100/125] loss: 381546.11140, MAE: 0.60966, time/step=3745ms, lr=4.70e-05
2024-03-17 21:39:28,647 - logger.py:50 - Epoch: [24][124/125] loss: 318590.41138, MAE: 0.60923, time/step=3740ms, lr=4.70e-05
2024-03-17 21:40:23,591 - logger.py:50 - Epoch: [24] train MAE: 0.60923, val MAE: 0.59027, test MAE: 0.58109, Time: 522.46s
2024-03-17 21:40:23,591 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 21:40:27,991 - logger.py:50 - Epoch: [25][0/125] loss: 27658.71094, MAE: 0.50205, time/step=4397ms, lr=4.67e-05
2024-03-17 21:43:34,270 - logger.py:50 - Epoch: [25][50/125] loss: 683488.61618, MAE: 0.61717, time/step=3739ms, lr=4.67e-05
2024-03-17 21:46:41,949 - logger.py:50 - Epoch: [25][100/125] loss: 354759.79626, MAE: 0.60183, time/step=3746ms, lr=4.67e-05
2024-03-17 21:48:11,613 - logger.py:50 - Epoch: [25][124/125] loss: 292177.31841, MAE: 0.59909, time/step=3744ms, lr=4.67e-05
2024-03-17 21:49:06,040 - logger.py:50 - Epoch: [25] train MAE: 0.59909, val MAE: 0.59671, test MAE: 0.58731, Time: 522.45s
2024-03-17 21:49:06,040 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 21:49:10,182 - logger.py:50 - Epoch: [26][0/125] loss: 9185.18164, MAE: 0.56194, time/step=4140ms, lr=4.65e-05
2024-03-17 21:52:16,245 - logger.py:50 - Epoch: [26][50/125] loss: 16536.98086, MAE: 0.58751, time/step=3729ms, lr=4.65e-05
2024-03-17 21:55:23,795 - logger.py:50 - Epoch: [26][100/125] loss: 16090.34533, MAE: 0.58237, time/step=3740ms, lr=4.65e-05
2024-03-17 21:56:54,992 - logger.py:50 - Epoch: [26][124/125] loss: 294099.39428, MAE: 0.59744, time/step=3752ms, lr=4.65e-05
2024-03-17 21:57:50,684 - logger.py:50 - Epoch: [26] train MAE: 0.59744, val MAE: 0.63885, test MAE: 0.62917, Time: 524.64s
2024-03-17 21:57:50,684 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 21:57:54,366 - logger.py:50 - Epoch: [27][0/125] loss: 27447.93945, MAE: 0.62514, time/step=3680ms, lr=4.62e-05
2024-03-17 22:01:02,639 - logger.py:50 - Epoch: [27][50/125] loss: 211261.25998, MAE: 0.61704, time/step=3764ms, lr=4.62e-05
2024-03-17 22:04:09,789 - logger.py:50 - Epoch: [27][100/125] loss: 340237.49951, MAE: 0.60014, time/step=3753ms, lr=4.62e-05
2024-03-17 22:05:39,720 - logger.py:50 - Epoch: [27][124/125] loss: 285085.73208, MAE: 0.60482, time/step=3752ms, lr=4.62e-05
2024-03-17 22:06:35,436 - logger.py:50 - Epoch: [27] train MAE: 0.60482, val MAE: 0.60433, test MAE: 0.59556, Time: 524.75s
2024-03-17 22:06:35,436 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 22:06:39,006 - logger.py:50 - Epoch: [28][0/125] loss: 2494.83911, MAE: 0.59666, time/step=3568ms, lr=4.59e-05
2024-03-17 22:09:46,299 - logger.py:50 - Epoch: [28][50/125] loss: 699261.88555, MAE: 0.61148, time/step=3742ms, lr=4.59e-05
2024-03-17 22:12:54,916 - logger.py:50 - Epoch: [28][100/125] loss: 360506.40519, MAE: 0.60821, time/step=3757ms, lr=4.59e-05
2024-03-17 22:14:24,466 - logger.py:50 - Epoch: [28][124/125] loss: 295917.68949, MAE: 0.60036, time/step=3752ms, lr=4.59e-05
2024-03-17 22:15:20,161 - logger.py:50 - Epoch: [28] train MAE: 0.60036, val MAE: 0.58441, test MAE: 0.57384, Time: 524.72s
2024-03-17 22:15:20,162 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 22:15:23,695 - logger.py:50 - Epoch: [29][0/125] loss: 10.66670, MAE: 0.57960, time/step=3531ms, lr=4.56e-05
2024-03-17 22:18:31,113 - logger.py:50 - Epoch: [29][50/125] loss: 17756.80149, MAE: 0.57396, time/step=3744ms, lr=4.56e-05
2024-03-17 22:21:38,526 - logger.py:50 - Epoch: [29][100/125] loss: 248652.26358, MAE: 0.58698, time/step=3746ms, lr=4.56e-05
2024-03-17 22:23:09,262 - logger.py:50 - Epoch: [29][124/125] loss: 291520.81108, MAE: 0.59927, time/step=3753ms, lr=4.56e-05
2024-03-17 22:24:04,991 - logger.py:50 - Epoch: [29] train MAE: 0.59927, val MAE: 0.62800, test MAE: 0.61611, Time: 524.83s
2024-03-17 22:24:04,992 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 22:24:08,852 - logger.py:50 - Epoch: [30][0/125] loss: 110376.35156, MAE: 0.62814, time/step=3858ms, lr=4.53e-05
2024-03-17 22:27:17,370 - logger.py:50 - Epoch: [30][50/125] loss: 236178.96845, MAE: 0.58476, time/step=3772ms, lr=4.53e-05
2024-03-17 22:30:24,250 - logger.py:50 - Epoch: [30][100/125] loss: 373111.05718, MAE: 0.59605, time/step=3755ms, lr=4.53e-05
2024-03-17 22:31:53,785 - logger.py:50 - Epoch: [30][124/125] loss: 312324.14613, MAE: 0.60188, time/step=3750ms, lr=4.53e-05
2024-03-17 22:32:49,348 - logger.py:50 - Epoch: [30] train MAE: 0.60188, val MAE: 0.60222, test MAE: 0.59103, Time: 524.36s
2024-03-17 22:32:49,348 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 22:32:53,609 - logger.py:50 - Epoch: [31][0/125] loss: 45086.91406, MAE: 0.57530, time/step=4258ms, lr=4.50e-05
2024-03-17 22:36:00,266 - logger.py:50 - Epoch: [31][50/125] loss: 23081.30771, MAE: 0.58277, time/step=3743ms, lr=4.50e-05
2024-03-17 22:39:06,926 - logger.py:50 - Epoch: [31][100/125] loss: 340969.34776, MAE: 0.59177, time/step=3738ms, lr=4.50e-05
2024-03-17 22:40:36,135 - logger.py:50 - Epoch: [31][124/125] loss: 286812.73209, MAE: 0.60000, time/step=3734ms, lr=4.50e-05
2024-03-17 22:41:30,742 - logger.py:50 - Epoch: [31] train MAE: 0.60000, val MAE: 0.60659, test MAE: 0.59585, Time: 521.39s
2024-03-17 22:41:30,742 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 22:41:34,933 - logger.py:50 - Epoch: [32][0/125] loss: 1981.82568, MAE: 0.62246, time/step=4189ms, lr=4.47e-05
2024-03-17 22:44:40,672 - logger.py:50 - Epoch: [32][50/125] loss: 235212.65061, MAE: 0.58125, time/step=3724ms, lr=4.47e-05
2024-03-17 22:47:47,587 - logger.py:50 - Epoch: [32][100/125] loss: 346660.41160, MAE: 0.59700, time/step=3731ms, lr=4.47e-05
2024-03-17 22:49:16,558 - logger.py:50 - Epoch: [32][124/125] loss: 283797.81381, MAE: 0.59755, time/step=3727ms, lr=4.47e-05
2024-03-17 22:50:11,711 - logger.py:50 - Epoch: [32] train MAE: 0.59755, val MAE: 0.58689, test MAE: 0.57484, Time: 520.97s
2024-03-17 22:50:11,711 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 22:50:15,584 - logger.py:50 - Epoch: [33][0/125] loss: 30950.69727, MAE: 0.58819, time/step=3871ms, lr=4.44e-05
2024-03-17 22:53:21,529 - logger.py:50 - Epoch: [33][50/125] loss: 230430.31998, MAE: 0.57746, time/step=3722ms, lr=4.44e-05
2024-03-17 22:56:27,953 - logger.py:50 - Epoch: [33][100/125] loss: 360516.49568, MAE: 0.60461, time/step=3725ms, lr=4.44e-05
2024-03-17 22:57:57,748 - logger.py:50 - Epoch: [33][124/125] loss: 294047.84407, MAE: 0.60076, time/step=3728ms, lr=4.44e-05
2024-03-17 22:58:52,564 - logger.py:50 - Epoch: [33] train MAE: 0.60076, val MAE: 0.59431, test MAE: 0.58135, Time: 520.85s
2024-03-17 22:58:52,564 - logger.py:50 - Best -- epoch=5, train MAE: 0.65260, val MAE: 0.55415, test MAE: 0.54128

2024-03-17 22:58:55,990 - logger.py:50 - Epoch: [34][0/125] loss: 24234910.00000, MAE: 1.01353, time/step=3424ms, lr=4.40e-05
2024-03-17 23:02:01,466 - logger.py:50 - Epoch: [34][50/125] loss: 653121.12322, MAE: 0.61488, time/step=3704ms, lr=4.40e-05
2024-03-17 23:05:08,371 - logger.py:50 - Epoch: [34][100/125] loss: 338140.61672, MAE: 0.60395, time/step=3721ms, lr=4.40e-05
2024-03-17 23:06:38,493 - logger.py:50 - Epoch: [34][124/125] loss: 275952.61420, MAE: 0.60000, time/step=3727ms, lr=4.40e-05
2024-03-17 23:07:20,268 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:07:37,478 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:07:37,789 - logger.py:50 - Number of params: 2978805
2024-03-17 23:07:43,088 - logger.py:50 - Epoch: [0][0/125] loss: 24.18565, MAE: 0.63892, time/step=5296ms, lr=1.00e-06
2024-03-17 23:10:56,566 - logger.py:50 - Epoch: [0][50/125] loss: 17.13965, MAE: 0.55890, time/step=3898ms, lr=1.00e-06
2024-03-17 23:14:05,412 - logger.py:50 - Epoch: [0][100/125] loss: 19.11626, MAE: 0.54121, time/step=3838ms, lr=1.00e-06
2024-03-17 23:15:36,881 - logger.py:50 - Epoch: [0][124/125] loss: 18.32129, MAE: 0.53212, time/step=3833ms, lr=1.00e-06
2024-03-17 23:16:34,659 - logger.py:50 - Epoch: [0] train MAE: 0.53212, val MAE: 0.49227, test MAE: 0.47892, Time: 536.87s
2024-03-17 23:16:34,660 - logger.py:50 - Best -- epoch=0, train MAE: 0.53212, val MAE: 0.49227, test MAE: 0.47892

2024-03-17 23:16:38,411 - logger.py:50 - Epoch: [1][0/125] loss: 14.48835, MAE: 0.52804, time/step=3750ms, lr=1.08e-05
2024-03-17 23:17:14,427 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,427 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,427 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,427 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,427 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,427 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,427 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,427 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,659 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,659 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,659 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,659 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,659 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,659 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,659 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:14,659 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:17:40,836 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:41,292 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:41,379 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:41,644 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:42,097 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:42,225 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:42,249 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:42,283 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:42,544 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:42,663 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:42,696 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:42,781 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:42,786 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:42,808 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:43,143 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:43,168 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:43,381 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:43,490 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:43,490 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:43,500 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:43,596 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:43,632 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:43,691 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:43,749 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:17:44,083 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:44,122 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:44,127 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:44,129 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:44,297 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:44,430 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:44,762 - logger.py:50 - Number of params: 2978805
2024-03-17 23:17:44,762 - logger.py:50 - Number of params: 2978805
2024-03-17 23:19:51,156 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:51,160 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:51,336 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:51,349 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:51,371 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:51,374 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:51,386 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:51,406 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:57,705 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:57,705 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:57,705 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:57,705 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:57,705 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:57,705 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:57,705 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:19:57,705 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:20:15,271 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:15,571 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:15,623 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:15,890 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:16,924 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:17,010 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:17,454 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:17,479 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:18,125 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:18,257 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:18,446 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:18,496 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:18,545 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:18,923 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:19,076 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:19,184 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:24,274 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:24,337 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:25,136 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:25,138 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:25,136 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:25,146 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:25,801 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:25,814 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:26,316 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:26,318 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:26,334 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:26,346 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:20:27,316 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:27,680 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:27,683 - logger.py:50 - Number of params: 2978805
2024-03-17 23:20:27,686 - logger.py:50 - Number of params: 2978805
2024-03-17 23:22:21,752 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-17 23:22:37,582 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-17 23:22:37,842 - logger.py:50 - Number of params: 2978805
2024-03-17 23:22:42,895 - logger.py:50 - Epoch: [0][0/125] loss: 24.18565, MAE: 0.63892, time/step=5049ms, lr=1.00e-06
2024-03-17 23:25:54,315 - logger.py:50 - Epoch: [0][50/125] loss: 17.13965, MAE: 0.55890, time/step=3852ms, lr=1.00e-06
2024-03-17 23:29:00,365 - logger.py:50 - Epoch: [0][100/125] loss: 19.11626, MAE: 0.54121, time/step=3787ms, lr=1.00e-06
2024-03-17 23:30:30,699 - logger.py:50 - Epoch: [0][124/125] loss: 18.32129, MAE: 0.53212, time/step=3783ms, lr=1.00e-06
2024-03-17 23:31:26,923 - logger.py:50 - Epoch: [0] train MAE: 0.53212, val MAE: 0.49227, test MAE: 0.47892, Time: 529.08s
2024-03-17 23:31:26,923 - logger.py:50 - Best -- epoch=0, train MAE: 0.53212, val MAE: 0.49227, test MAE: 0.47892

2024-03-17 23:31:30,615 - logger.py:50 - Epoch: [1][0/125] loss: 14.48835, MAE: 0.52804, time/step=3689ms, lr=1.08e-05
2024-03-17 23:34:38,395 - logger.py:50 - Epoch: [1][50/125] loss: 12.37470, MAE: 0.42934, time/step=3754ms, lr=1.08e-05
2024-03-17 23:37:45,155 - logger.py:50 - Epoch: [1][100/125] loss: 13.52205, MAE: 0.43504, time/step=3745ms, lr=1.08e-05
2024-03-17 23:39:13,671 - logger.py:50 - Epoch: [1][124/125] loss: 13.71086, MAE: 0.44031, time/step=3734ms, lr=1.08e-05
2024-03-17 23:40:09,422 - logger.py:50 - Epoch: [1] train MAE: 0.44031, val MAE: 0.45417, test MAE: 0.44008, Time: 522.50s
2024-03-17 23:40:09,422 - logger.py:50 - Best -- epoch=1, train MAE: 0.44031, val MAE: 0.45417, test MAE: 0.44008

2024-03-17 23:40:13,106 - logger.py:50 - Epoch: [2][0/125] loss: 8.05556, MAE: 0.42754, time/step=3682ms, lr=2.06e-05
2024-03-17 23:43:20,126 - logger.py:50 - Epoch: [2][50/125] loss: 13.94810, MAE: 0.46858, time/step=3739ms, lr=2.06e-05
2024-03-17 23:46:27,392 - logger.py:50 - Epoch: [2][100/125] loss: 10.31819, MAE: 0.45693, time/step=3742ms, lr=2.06e-05
2024-03-17 23:47:58,407 - logger.py:50 - Epoch: [2][124/125] loss: 9.60397, MAE: 0.45485, time/step=3752ms, lr=2.06e-05
2024-03-17 23:48:52,909 - logger.py:50 - Epoch: [2] train MAE: 0.45485, val MAE: 0.45668, test MAE: 0.44213, Time: 523.49s
2024-03-17 23:48:52,909 - logger.py:50 - Best -- epoch=1, train MAE: 0.44031, val MAE: 0.45417, test MAE: 0.44008

2024-03-17 23:48:56,613 - logger.py:50 - Epoch: [3][0/125] loss: 7.37924, MAE: 0.45933, time/step=3702ms, lr=3.04e-05
2024-03-17 23:52:02,741 - logger.py:50 - Epoch: [3][50/125] loss: 7.53270, MAE: 0.45593, time/step=3722ms, lr=3.04e-05
2024-03-17 23:55:08,788 - logger.py:50 - Epoch: [3][100/125] loss: 8.05784, MAE: 0.45830, time/step=3722ms, lr=3.04e-05
2024-03-17 23:56:39,758 - logger.py:50 - Epoch: [3][124/125] loss: 7.34128, MAE: 0.45686, time/step=3735ms, lr=3.04e-05
2024-03-17 23:57:35,353 - logger.py:50 - Epoch: [3] train MAE: 0.45686, val MAE: 0.45746, test MAE: 0.44137, Time: 522.44s
2024-03-17 23:57:35,353 - logger.py:50 - Best -- epoch=1, train MAE: 0.44031, val MAE: 0.45417, test MAE: 0.44008

2024-03-17 23:57:39,717 - logger.py:50 - Epoch: [4][0/125] loss: 3.02024, MAE: 0.45557, time/step=4362ms, lr=4.02e-05
2024-03-18 00:00:47,382 - logger.py:50 - Epoch: [4][50/125] loss: 9.57987, MAE: 0.46264, time/step=3765ms, lr=4.02e-05
2024-03-18 00:03:54,723 - logger.py:50 - Epoch: [4][100/125] loss: 6.48149, MAE: 0.45806, time/step=3756ms, lr=4.02e-05
2024-03-18 00:05:23,460 - logger.py:50 - Epoch: [4][124/125] loss: 5.81777, MAE: 0.45728, time/step=3745ms, lr=4.02e-05
2024-03-18 00:06:18,507 - logger.py:50 - Epoch: [4] train MAE: 0.45728, val MAE: 0.45627, test MAE: 0.44001, Time: 523.15s
2024-03-18 00:06:18,507 - logger.py:50 - Best -- epoch=1, train MAE: 0.44031, val MAE: 0.45417, test MAE: 0.44008

2024-03-18 00:06:22,273 - logger.py:50 - Epoch: [5][0/125] loss: 2.14890, MAE: 0.45610, time/step=3764ms, lr=4.99e-05
2024-03-18 00:09:28,931 - logger.py:50 - Epoch: [5][50/125] loss: 2.84998, MAE: 0.44853, time/step=3734ms, lr=4.99e-05
2024-03-18 00:12:35,349 - logger.py:50 - Epoch: [5][100/125] loss: 2.61515, MAE: 0.44828, time/step=3731ms, lr=4.99e-05
2024-03-18 00:14:04,599 - logger.py:50 - Epoch: [5][124/125] loss: 4.83313, MAE: 0.45328, time/step=3729ms, lr=4.99e-05
2024-03-18 00:14:59,343 - logger.py:50 - Epoch: [5] train MAE: 0.45328, val MAE: 0.45555, test MAE: 0.43927, Time: 520.84s
2024-03-18 00:14:59,343 - logger.py:50 - Best -- epoch=1, train MAE: 0.44031, val MAE: 0.45417, test MAE: 0.44008

2024-03-18 00:15:03,488 - logger.py:50 - Epoch: [6][0/125] loss: 2.47355, MAE: 0.44779, time/step=4143ms, lr=4.98e-05
2024-03-18 00:18:10,390 - logger.py:50 - Epoch: [6][50/125] loss: 5.89969, MAE: 0.45710, time/step=3746ms, lr=4.98e-05
2024-03-18 00:21:17,083 - logger.py:50 - Epoch: [6][100/125] loss: 3.89418, MAE: 0.45123, time/step=3740ms, lr=4.98e-05
2024-03-18 00:22:48,428 - logger.py:50 - Epoch: [6][124/125] loss: 4.25057, MAE: 0.44923, time/step=3753ms, lr=4.98e-05
2024-03-18 00:23:43,369 - logger.py:50 - Epoch: [6] train MAE: 0.44923, val MAE: 0.44772, test MAE: 0.43204, Time: 524.03s
2024-03-18 00:23:43,369 - logger.py:50 - Best -- epoch=6, train MAE: 0.44923, val MAE: 0.44772, test MAE: 0.43204

2024-03-18 00:23:47,024 - logger.py:50 - Epoch: [7][0/125] loss: 1.04359, MAE: 0.41145, time/step=3653ms, lr=4.97e-05
2024-03-18 00:26:53,624 - logger.py:50 - Epoch: [7][50/125] loss: 7.50866, MAE: 0.45356, time/step=3730ms, lr=4.97e-05
2024-03-18 00:30:00,494 - logger.py:50 - Epoch: [7][100/125] loss: 4.53829, MAE: 0.44870, time/step=3734ms, lr=4.97e-05
2024-03-18 00:31:28,620 - logger.py:50 - Epoch: [7][124/125] loss: 3.93469, MAE: 0.44709, time/step=3722ms, lr=4.97e-05
2024-03-18 00:32:23,295 - logger.py:50 - Epoch: [7] train MAE: 0.44709, val MAE: 0.44618, test MAE: 0.43057, Time: 519.93s
2024-03-18 00:32:23,296 - logger.py:50 - Best -- epoch=7, train MAE: 0.44709, val MAE: 0.44618, test MAE: 0.43057

2024-03-18 00:32:26,976 - logger.py:50 - Epoch: [8][0/125] loss: 2.06960, MAE: 0.43440, time/step=3678ms, lr=4.97e-05
2024-03-18 00:35:34,043 - logger.py:50 - Epoch: [8][50/125] loss: 7.17341, MAE: 0.45516, time/step=3740ms, lr=4.97e-05
2024-03-18 00:38:41,335 - logger.py:50 - Epoch: [8][100/125] loss: 4.28047, MAE: 0.44747, time/step=3743ms, lr=4.97e-05
2024-03-18 00:40:11,780 - logger.py:50 - Epoch: [8][124/125] loss: 3.75380, MAE: 0.44665, time/step=3748ms, lr=4.97e-05
2024-03-18 00:41:06,386 - logger.py:50 - Epoch: [8] train MAE: 0.44665, val MAE: 0.45291, test MAE: 0.43798, Time: 523.09s
2024-03-18 00:41:06,386 - logger.py:50 - Best -- epoch=7, train MAE: 0.44709, val MAE: 0.44618, test MAE: 0.43057

2024-03-18 00:41:10,120 - logger.py:50 - Epoch: [9][0/125] loss: 100.06287, MAE: 0.72775, time/step=3732ms, lr=4.96e-05
2024-03-18 00:44:15,911 - logger.py:50 - Epoch: [9][50/125] loss: 3.43751, MAE: 0.45378, time/step=3716ms, lr=4.96e-05
2024-03-18 00:47:24,640 - logger.py:50 - Epoch: [9][100/125] loss: 2.32905, MAE: 0.44397, time/step=3745ms, lr=4.96e-05
2024-03-18 00:48:54,479 - logger.py:50 - Epoch: [9][124/125] loss: 3.62391, MAE: 0.44599, time/step=3745ms, lr=4.96e-05
2024-03-18 00:49:50,110 - logger.py:50 - Epoch: [9] train MAE: 0.44599, val MAE: 0.45319, test MAE: 0.43766, Time: 523.72s
2024-03-18 00:49:50,111 - logger.py:50 - Best -- epoch=7, train MAE: 0.44709, val MAE: 0.44618, test MAE: 0.43057

2024-03-18 00:49:53,834 - logger.py:50 - Epoch: [10][0/125] loss: 1.48610, MAE: 0.52044, time/step=3721ms, lr=4.95e-05
2024-03-18 00:53:00,611 - logger.py:50 - Epoch: [10][50/125] loss: 1.15727, MAE: 0.44375, time/step=3735ms, lr=4.95e-05
2024-03-18 00:56:07,856 - logger.py:50 - Epoch: [10][100/125] loss: 2.15198, MAE: 0.44499, time/step=3740ms, lr=4.95e-05
2024-03-18 00:57:38,973 - logger.py:50 - Epoch: [10][124/125] loss: 3.52710, MAE: 0.44547, time/step=3751ms, lr=4.95e-05
2024-03-18 00:58:33,494 - logger.py:50 - Epoch: [10] train MAE: 0.44547, val MAE: 0.44913, test MAE: 0.43407, Time: 523.38s
2024-03-18 00:58:33,494 - logger.py:50 - Best -- epoch=7, train MAE: 0.44709, val MAE: 0.44618, test MAE: 0.43057

2024-03-18 00:58:37,607 - logger.py:50 - Epoch: [11][0/125] loss: 1.11231, MAE: 0.41636, time/step=4111ms, lr=4.94e-05
2024-03-18 01:01:43,836 - logger.py:50 - Epoch: [11][50/125] loss: 4.93553, MAE: 0.45364, time/step=3732ms, lr=4.94e-05
2024-03-18 01:04:52,483 - logger.py:50 - Epoch: [11][100/125] loss: 3.01973, MAE: 0.44550, time/step=3752ms, lr=4.94e-05
2024-03-18 01:06:22,222 - logger.py:50 - Epoch: [11][124/125] loss: 3.45498, MAE: 0.44679, time/step=3750ms, lr=4.94e-05
2024-03-18 01:07:17,999 - logger.py:50 - Epoch: [11] train MAE: 0.44679, val MAE: 0.44522, test MAE: 0.42973, Time: 524.50s
2024-03-18 01:07:17,999 - logger.py:50 - Best -- epoch=11, train MAE: 0.44679, val MAE: 0.44522, test MAE: 0.42973

2024-03-18 01:07:21,774 - logger.py:50 - Epoch: [12][0/125] loss: 0.89059, MAE: 0.43228, time/step=3773ms, lr=4.92e-05
2024-03-18 01:10:26,991 - logger.py:50 - Epoch: [12][50/125] loss: 1.07243, MAE: 0.43768, time/step=3706ms, lr=4.92e-05
2024-03-18 01:13:34,156 - logger.py:50 - Epoch: [12][100/125] loss: 3.94358, MAE: 0.44641, time/step=3724ms, lr=4.92e-05
2024-03-18 01:15:04,054 - logger.py:50 - Epoch: [12][124/125] loss: 3.37980, MAE: 0.44569, time/step=3728ms, lr=4.92e-05
2024-03-18 01:15:59,495 - logger.py:50 - Epoch: [12] train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868, Time: 521.50s
2024-03-18 01:15:59,495 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 01:16:03,077 - logger.py:50 - Epoch: [13][0/125] loss: 0.92230, MAE: 0.45189, time/step=3580ms, lr=4.91e-05
2024-03-18 01:19:10,098 - logger.py:50 - Epoch: [13][50/125] loss: 2.95264, MAE: 0.44649, time/step=3737ms, lr=4.91e-05
2024-03-18 01:22:16,618 - logger.py:50 - Epoch: [13][100/125] loss: 3.87698, MAE: 0.44503, time/step=3734ms, lr=4.91e-05
2024-03-18 01:23:46,000 - logger.py:50 - Epoch: [13][124/125] loss: 3.32388, MAE: 0.44509, time/step=3732ms, lr=4.91e-05
2024-03-18 01:24:40,351 - logger.py:50 - Epoch: [13] train MAE: 0.44509, val MAE: 0.45522, test MAE: 0.43987, Time: 520.86s
2024-03-18 01:24:40,351 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 01:24:44,628 - logger.py:50 - Epoch: [14][0/125] loss: 0.80475, MAE: 0.41337, time/step=4275ms, lr=4.90e-05
2024-03-18 01:27:51,297 - logger.py:50 - Epoch: [14][50/125] loss: 4.64932, MAE: 0.44263, time/step=3744ms, lr=4.90e-05
2024-03-18 01:30:58,693 - logger.py:50 - Epoch: [14][100/125] loss: 3.81765, MAE: 0.44559, time/step=3746ms, lr=4.90e-05
2024-03-18 01:32:27,529 - logger.py:50 - Epoch: [14][124/125] loss: 3.27657, MAE: 0.44467, time/step=3737ms, lr=4.90e-05
2024-03-18 01:33:21,993 - logger.py:50 - Epoch: [14] train MAE: 0.44467, val MAE: 0.44496, test MAE: 0.42981, Time: 521.64s
2024-03-18 01:33:21,995 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 01:33:25,727 - logger.py:50 - Epoch: [15][0/125] loss: 0.64512, MAE: 0.47882, time/step=3730ms, lr=4.88e-05
2024-03-18 01:36:31,631 - logger.py:50 - Epoch: [15][50/125] loss: 4.68009, MAE: 0.44662, time/step=3718ms, lr=4.88e-05
2024-03-18 01:39:37,624 - logger.py:50 - Epoch: [15][100/125] loss: 2.81562, MAE: 0.44243, time/step=3719ms, lr=4.88e-05
2024-03-18 01:41:08,182 - logger.py:50 - Epoch: [15][124/125] loss: 3.22985, MAE: 0.44420, time/step=3729ms, lr=4.88e-05
2024-03-18 01:42:03,498 - logger.py:50 - Epoch: [15] train MAE: 0.44420, val MAE: 0.45366, test MAE: 0.43822, Time: 521.50s
2024-03-18 01:42:03,498 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 01:42:07,094 - logger.py:50 - Epoch: [16][0/125] loss: 0.90062, MAE: 0.43155, time/step=3594ms, lr=4.86e-05
2024-03-18 01:45:14,794 - logger.py:50 - Epoch: [16][50/125] loss: 2.84322, MAE: 0.44738, time/step=3751ms, lr=4.86e-05
2024-03-18 01:48:19,335 - logger.py:50 - Epoch: [16][100/125] loss: 3.75988, MAE: 0.44848, time/step=3721ms, lr=4.86e-05
2024-03-18 01:49:49,357 - logger.py:50 - Epoch: [16][124/125] loss: 3.19170, MAE: 0.44509, time/step=3727ms, lr=4.86e-05
2024-03-18 01:50:44,561 - logger.py:50 - Epoch: [16] train MAE: 0.44509, val MAE: 0.44928, test MAE: 0.43401, Time: 521.06s
2024-03-18 01:50:44,561 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 01:50:48,366 - logger.py:50 - Epoch: [17][0/125] loss: 0.76312, MAE: 0.37311, time/step=3803ms, lr=4.85e-05
2024-03-18 01:53:54,078 - logger.py:50 - Epoch: [17][50/125] loss: 4.57307, MAE: 0.44657, time/step=3716ms, lr=4.85e-05
2024-03-18 01:57:01,721 - logger.py:50 - Epoch: [17][100/125] loss: 3.71182, MAE: 0.44716, time/step=3734ms, lr=4.85e-05
2024-03-18 01:58:30,492 - logger.py:50 - Epoch: [17][124/125] loss: 3.16125, MAE: 0.44442, time/step=3727ms, lr=4.85e-05
2024-03-18 01:59:25,310 - logger.py:50 - Epoch: [17] train MAE: 0.44442, val MAE: 0.44443, test MAE: 0.42934, Time: 520.75s
2024-03-18 01:59:25,310 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 01:59:29,024 - logger.py:50 - Epoch: [18][0/125] loss: 0.71326, MAE: 0.47002, time/step=3712ms, lr=4.83e-05
2024-03-18 02:02:36,421 - logger.py:50 - Epoch: [18][50/125] loss: 4.57272, MAE: 0.45083, time/step=3747ms, lr=4.83e-05
2024-03-18 02:05:42,113 - logger.py:50 - Epoch: [18][100/125] loss: 3.69554, MAE: 0.44597, time/step=3731ms, lr=4.83e-05
2024-03-18 02:07:11,218 - logger.py:50 - Epoch: [18][124/125] loss: 3.13888, MAE: 0.44466, time/step=3727ms, lr=4.83e-05
2024-03-18 02:08:05,914 - logger.py:50 - Epoch: [18] train MAE: 0.44466, val MAE: 0.44830, test MAE: 0.43324, Time: 520.60s
2024-03-18 02:08:05,914 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 02:08:10,119 - logger.py:50 - Epoch: [19][0/125] loss: 0.77860, MAE: 0.43596, time/step=4202ms, lr=4.81e-05
2024-03-18 02:11:16,140 - logger.py:50 - Epoch: [19][50/125] loss: 0.82181, MAE: 0.43847, time/step=3730ms, lr=4.81e-05
2024-03-18 02:14:22,913 - logger.py:50 - Epoch: [19][100/125] loss: 1.79146, MAE: 0.44038, time/step=3733ms, lr=4.81e-05
2024-03-18 02:15:52,248 - logger.py:50 - Epoch: [19][124/125] loss: 3.11408, MAE: 0.44419, time/step=3731ms, lr=4.81e-05
2024-03-18 02:16:47,055 - logger.py:50 - Epoch: [19] train MAE: 0.44419, val MAE: 0.44749, test MAE: 0.43228, Time: 521.14s
2024-03-18 02:16:47,056 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 02:16:51,236 - logger.py:50 - Epoch: [20][0/125] loss: 0.88159, MAE: 0.42302, time/step=4178ms, lr=4.79e-05
2024-03-18 02:19:58,697 - logger.py:50 - Epoch: [20][50/125] loss: 0.72926, MAE: 0.43616, time/step=3758ms, lr=4.79e-05
2024-03-18 02:23:04,940 - logger.py:50 - Epoch: [20][100/125] loss: 1.77736, MAE: 0.44037, time/step=3741ms, lr=4.79e-05
2024-03-18 02:24:33,898 - logger.py:50 - Epoch: [20][124/125] loss: 3.08484, MAE: 0.44383, time/step=3735ms, lr=4.79e-05
2024-03-18 02:25:28,114 - logger.py:50 - Epoch: [20] train MAE: 0.44383, val MAE: 0.45156, test MAE: 0.43600, Time: 521.06s
2024-03-18 02:25:28,115 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 02:25:32,436 - logger.py:50 - Epoch: [21][0/125] loss: 0.74370, MAE: 0.47081, time/step=4319ms, lr=4.77e-05
2024-03-18 02:28:38,170 - logger.py:50 - Epoch: [21][50/125] loss: 2.75905, MAE: 0.45210, time/step=3727ms, lr=4.77e-05
2024-03-18 02:31:45,414 - logger.py:50 - Epoch: [21][100/125] loss: 3.65231, MAE: 0.44889, time/step=3736ms, lr=4.77e-05
2024-03-18 02:33:14,876 - logger.py:50 - Epoch: [21][124/125] loss: 3.09233, MAE: 0.44592, time/step=3734ms, lr=4.77e-05
2024-03-18 02:34:10,051 - logger.py:50 - Epoch: [21] train MAE: 0.44592, val MAE: 0.44410, test MAE: 0.42928, Time: 521.94s
2024-03-18 02:34:10,051 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 02:34:13,707 - logger.py:50 - Epoch: [22][0/125] loss: 1.27660, MAE: 0.48252, time/step=3653ms, lr=4.74e-05
2024-03-18 02:37:20,014 - logger.py:50 - Epoch: [22][50/125] loss: 0.67519, MAE: 0.43571, time/step=3725ms, lr=4.74e-05
2024-03-18 02:40:27,554 - logger.py:50 - Epoch: [22][100/125] loss: 2.61014, MAE: 0.44209, time/step=3738ms, lr=4.74e-05
2024-03-18 02:41:57,422 - logger.py:50 - Epoch: [22][124/125] loss: 3.05734, MAE: 0.44380, time/step=3739ms, lr=4.74e-05
2024-03-18 02:42:51,754 - logger.py:50 - Epoch: [22] train MAE: 0.44380, val MAE: 0.45288, test MAE: 0.43766, Time: 521.70s
2024-03-18 02:42:51,754 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 02:42:55,544 - logger.py:50 - Epoch: [23][0/125] loss: 96.26887, MAE: 0.65640, time/step=3787ms, lr=4.72e-05
2024-03-18 02:46:02,674 - logger.py:50 - Epoch: [23][50/125] loss: 2.61369, MAE: 0.44337, time/step=3743ms, lr=4.72e-05
2024-03-18 02:49:08,742 - logger.py:50 - Epoch: [23][100/125] loss: 1.68103, MAE: 0.44042, time/step=3733ms, lr=4.72e-05
2024-03-18 02:50:37,707 - logger.py:50 - Epoch: [23][124/125] loss: 3.03552, MAE: 0.44416, time/step=3728ms, lr=4.72e-05
2024-03-18 02:51:32,502 - logger.py:50 - Epoch: [23] train MAE: 0.44416, val MAE: 0.45251, test MAE: 0.43712, Time: 520.75s
2024-03-18 02:51:32,502 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 02:51:36,750 - logger.py:50 - Epoch: [24][0/125] loss: 0.49764, MAE: 0.37087, time/step=4246ms, lr=4.70e-05
2024-03-18 02:54:43,827 - logger.py:50 - Epoch: [24][50/125] loss: 2.67212, MAE: 0.44731, time/step=3751ms, lr=4.70e-05
2024-03-18 02:57:51,559 - logger.py:50 - Epoch: [24][100/125] loss: 3.57144, MAE: 0.44722, time/step=3753ms, lr=4.70e-05
2024-03-18 02:59:20,796 - logger.py:50 - Epoch: [24][124/125] loss: 3.04208, MAE: 0.44566, time/step=3746ms, lr=4.70e-05
2024-03-18 03:00:15,946 - logger.py:50 - Epoch: [24] train MAE: 0.44566, val MAE: 0.44802, test MAE: 0.43338, Time: 523.44s
2024-03-18 03:00:15,946 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 03:00:19,797 - logger.py:50 - Epoch: [25][0/125] loss: 0.47995, MAE: 0.36843, time/step=3849ms, lr=4.67e-05
2024-03-18 03:03:26,514 - logger.py:50 - Epoch: [25][50/125] loss: 6.33310, MAE: 0.44914, time/step=3737ms, lr=4.67e-05
2024-03-18 03:06:34,202 - logger.py:50 - Epoch: [25][100/125] loss: 3.55980, MAE: 0.44549, time/step=3745ms, lr=4.67e-05
2024-03-18 03:08:04,062 - logger.py:50 - Epoch: [25][124/125] loss: 3.01500, MAE: 0.44461, time/step=3745ms, lr=4.67e-05
2024-03-18 03:08:59,721 - logger.py:50 - Epoch: [25] train MAE: 0.44461, val MAE: 0.44971, test MAE: 0.43472, Time: 523.78s
2024-03-18 03:08:59,721 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 03:09:03,414 - logger.py:50 - Epoch: [26][0/125] loss: 0.54778, MAE: 0.42335, time/step=3690ms, lr=4.65e-05
2024-03-18 03:12:10,113 - logger.py:50 - Epoch: [26][50/125] loss: 0.70247, MAE: 0.43747, time/step=3733ms, lr=4.65e-05
2024-03-18 03:15:17,240 - logger.py:50 - Epoch: [26][100/125] loss: 0.69810, MAE: 0.43658, time/step=3738ms, lr=4.65e-05
2024-03-18 03:16:47,731 - logger.py:50 - Epoch: [26][124/125] loss: 2.99533, MAE: 0.44394, time/step=3744ms, lr=4.65e-05
2024-03-18 03:17:42,858 - logger.py:50 - Epoch: [26] train MAE: 0.44394, val MAE: 0.45483, test MAE: 0.43941, Time: 523.14s
2024-03-18 03:17:42,858 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 03:17:47,074 - logger.py:50 - Epoch: [27][0/125] loss: 0.57035, MAE: 0.46626, time/step=4214ms, lr=4.62e-05
2024-03-18 03:20:54,806 - logger.py:50 - Epoch: [27][50/125] loss: 2.64267, MAE: 0.45446, time/step=3764ms, lr=4.62e-05
2024-03-18 03:24:00,603 - logger.py:50 - Epoch: [27][100/125] loss: 3.51980, MAE: 0.44562, time/step=3740ms, lr=4.62e-05
2024-03-18 03:25:30,115 - logger.py:50 - Epoch: [27][124/125] loss: 2.99343, MAE: 0.44486, time/step=3738ms, lr=4.62e-05
2024-03-18 03:26:25,321 - logger.py:50 - Epoch: [27] train MAE: 0.44486, val MAE: 0.45154, test MAE: 0.43639, Time: 522.46s
2024-03-18 03:26:25,321 - logger.py:50 - Best -- epoch=12, train MAE: 0.44569, val MAE: 0.44385, test MAE: 0.42868

2024-03-18 03:26:28,831 - logger.py:50 - Epoch: [28][0/125] loss: 0.68741, MAE: 0.42639, time/step=3508ms, lr=4.59e-05
2024-03-18 03:29:35,096 - logger.py:50 - Epoch: [28][50/125] loss: 6.30170, MAE: 0.45149, time/step=3721ms, lr=4.59e-05
2024-03-18 03:32:42,017 - logger.py:50 - Epoch: [28][100/125] loss: 3.52306, MAE: 0.44876, time/step=3730ms, lr=4.59e-05
2024-03-18 03:34:11,443 - logger.py:50 - Epoch: [28][124/125] loss: 2.97043, MAE: 0.44481, time/step=3729ms, lr=4.59e-05
2024-03-18 03:35:06,442 - logger.py:50 - Epoch: [28] train MAE: 0.44481, val MAE: 0.44328, test MAE: 0.42851, Time: 521.12s
2024-03-18 03:35:06,442 - logger.py:50 - Best -- epoch=28, train MAE: 0.44481, val MAE: 0.44328, test MAE: 0.42851

2024-03-18 03:35:09,959 - logger.py:50 - Epoch: [29][0/125] loss: 0.82832, MAE: 0.44635, time/step=3514ms, lr=4.56e-05
2024-03-18 03:38:16,822 - logger.py:50 - Epoch: [29][50/125] loss: 0.64237, MAE: 0.43409, time/step=3733ms, lr=4.56e-05
2024-03-18 03:41:23,787 - logger.py:50 - Epoch: [29][100/125] loss: 2.51300, MAE: 0.44239, time/step=3736ms, lr=4.56e-05
2024-03-18 03:42:53,908 - logger.py:50 - Epoch: [29][124/125] loss: 2.94349, MAE: 0.44406, time/step=3740ms, lr=4.56e-05
2024-03-18 03:43:48,556 - logger.py:50 - Epoch: [29] train MAE: 0.44406, val MAE: 0.44855, test MAE: 0.43350, Time: 522.11s
2024-03-18 03:43:48,556 - logger.py:50 - Best -- epoch=28, train MAE: 0.44481, val MAE: 0.44328, test MAE: 0.42851

2024-03-18 03:43:52,420 - logger.py:50 - Epoch: [30][0/125] loss: 0.60315, MAE: 0.43965, time/step=3861ms, lr=4.53e-05
2024-03-18 03:47:00,282 - logger.py:50 - Epoch: [30][50/125] loss: 2.51898, MAE: 0.44092, time/step=3759ms, lr=4.53e-05
2024-03-18 03:50:06,194 - logger.py:50 - Epoch: [30][100/125] loss: 3.44127, MAE: 0.44504, time/step=3739ms, lr=4.53e-05
2024-03-18 03:51:35,292 - logger.py:50 - Epoch: [30][124/125] loss: 2.92775, MAE: 0.44487, time/step=3734ms, lr=4.53e-05
2024-03-18 03:52:30,263 - logger.py:50 - Epoch: [30] train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147, Time: 521.71s
2024-03-18 03:52:30,263 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 03:52:34,062 - logger.py:50 - Epoch: [31][0/125] loss: 0.63976, MAE: 0.39813, time/step=3797ms, lr=4.50e-05
2024-03-18 03:55:40,926 - logger.py:50 - Epoch: [31][50/125] loss: 0.65735, MAE: 0.44279, time/step=3738ms, lr=4.50e-05
2024-03-18 03:58:47,907 - logger.py:50 - Epoch: [31][100/125] loss: 3.39536, MAE: 0.44343, time/step=3739ms, lr=4.50e-05
2024-03-18 04:00:17,099 - logger.py:50 - Epoch: [31][124/125] loss: 2.89046, MAE: 0.44461, time/step=3735ms, lr=4.50e-05
2024-03-18 04:01:12,407 - logger.py:50 - Epoch: [31] train MAE: 0.44461, val MAE: 0.43983, test MAE: 0.42493, Time: 522.14s
2024-03-18 04:01:12,407 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 04:01:16,096 - logger.py:50 - Epoch: [32][0/125] loss: 0.81692, MAE: 0.45790, time/step=3687ms, lr=4.47e-05
2024-03-18 04:04:21,693 - logger.py:50 - Epoch: [32][50/125] loss: 2.45836, MAE: 0.44139, time/step=3711ms, lr=4.47e-05
2024-03-18 04:07:29,116 - logger.py:50 - Epoch: [32][100/125] loss: 3.38022, MAE: 0.44513, time/step=3730ms, lr=4.47e-05
2024-03-18 04:08:58,653 - logger.py:50 - Epoch: [32][124/125] loss: 2.86134, MAE: 0.44575, time/step=3730ms, lr=4.47e-05
2024-03-18 04:09:53,488 - logger.py:50 - Epoch: [32] train MAE: 0.44575, val MAE: 0.45057, test MAE: 0.43525, Time: 521.08s
2024-03-18 04:09:53,488 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 04:09:57,859 - logger.py:50 - Epoch: [33][0/125] loss: 0.84694, MAE: 0.46800, time/step=4369ms, lr=4.44e-05
2024-03-18 04:13:03,520 - logger.py:50 - Epoch: [33][50/125] loss: 2.42732, MAE: 0.43933, time/step=3726ms, lr=4.44e-05
2024-03-18 04:16:10,201 - logger.py:50 - Epoch: [33][100/125] loss: 3.32645, MAE: 0.44617, time/step=3730ms, lr=4.44e-05
2024-03-18 04:17:40,111 - logger.py:50 - Epoch: [33][124/125] loss: 2.81365, MAE: 0.44530, time/step=3733ms, lr=4.44e-05
2024-03-18 04:18:34,957 - logger.py:50 - Epoch: [33] train MAE: 0.44530, val MAE: 0.44676, test MAE: 0.43184, Time: 521.47s
2024-03-18 04:18:34,957 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 04:18:38,897 - logger.py:50 - Epoch: [34][0/125] loss: 192.07634, MAE: 0.88341, time/step=3937ms, lr=4.40e-05
2024-03-18 04:21:44,217 - logger.py:50 - Epoch: [34][50/125] loss: 5.83182, MAE: 0.45419, time/step=3711ms, lr=4.40e-05
2024-03-18 04:24:51,325 - logger.py:50 - Epoch: [34][100/125] loss: 3.25795, MAE: 0.44667, time/step=3726ms, lr=4.40e-05
2024-03-18 04:26:21,728 - logger.py:50 - Epoch: [34][124/125] loss: 2.76650, MAE: 0.44629, time/step=3734ms, lr=4.40e-05
2024-03-18 04:27:16,975 - logger.py:50 - Epoch: [34] train MAE: 0.44629, val MAE: 0.44185, test MAE: 0.42653, Time: 522.02s
2024-03-18 04:27:16,975 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 04:27:20,610 - logger.py:50 - Epoch: [35][0/125] loss: 0.78211, MAE: 0.43651, time/step=3633ms, lr=4.37e-05
2024-03-18 04:30:29,636 - logger.py:50 - Epoch: [35][50/125] loss: 0.66476, MAE: 0.43910, time/step=3778ms, lr=4.37e-05
2024-03-18 04:33:35,242 - logger.py:50 - Epoch: [35][100/125] loss: 3.17063, MAE: 0.44839, time/step=3745ms, lr=4.37e-05
2024-03-18 04:35:03,677 - logger.py:50 - Epoch: [35][124/125] loss: 2.70799, MAE: 0.44544, time/step=3734ms, lr=4.37e-05
2024-03-18 04:35:58,964 - logger.py:50 - Epoch: [35] train MAE: 0.44544, val MAE: 0.44692, test MAE: 0.43209, Time: 521.99s
2024-03-18 04:35:58,964 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 04:36:03,038 - logger.py:50 - Epoch: [36][0/125] loss: 0.70829, MAE: 0.43834, time/step=4072ms, lr=4.34e-05
2024-03-18 04:39:08,935 - logger.py:50 - Epoch: [36][50/125] loss: 5.44363, MAE: 0.44829, time/step=3725ms, lr=4.34e-05
2024-03-18 04:42:18,205 - logger.py:50 - Epoch: [36][100/125] loss: 3.15248, MAE: 0.44552, time/step=3755ms, lr=4.34e-05
2024-03-18 04:43:47,568 - logger.py:50 - Epoch: [36][124/125] loss: 2.67445, MAE: 0.44602, time/step=3749ms, lr=4.34e-05
2024-03-18 04:44:42,301 - logger.py:50 - Epoch: [36] train MAE: 0.44602, val MAE: 0.43982, test MAE: 0.42471, Time: 523.34s
2024-03-18 04:44:42,301 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 04:44:46,871 - logger.py:50 - Epoch: [37][0/125] loss: 0.51314, MAE: 0.43647, time/step=4567ms, lr=4.30e-05
2024-03-18 04:47:53,601 - logger.py:50 - Epoch: [37][50/125] loss: 3.97807, MAE: 0.45473, time/step=3751ms, lr=4.30e-05
2024-03-18 04:50:59,712 - logger.py:50 - Epoch: [37][100/125] loss: 3.10122, MAE: 0.44779, time/step=3737ms, lr=4.30e-05
2024-03-18 04:52:28,619 - logger.py:50 - Epoch: [37][124/125] loss: 2.64246, MAE: 0.44573, time/step=3731ms, lr=4.30e-05
2024-03-18 04:53:23,821 - logger.py:50 - Epoch: [37] train MAE: 0.44573, val MAE: 0.44716, test MAE: 0.43198, Time: 521.52s
2024-03-18 04:53:23,821 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 04:53:28,292 - logger.py:50 - Epoch: [38][0/125] loss: 0.66832, MAE: 0.43344, time/step=4469ms, lr=4.26e-05
2024-03-18 04:56:34,249 - logger.py:50 - Epoch: [38][50/125] loss: 3.79445, MAE: 0.44450, time/step=3734ms, lr=4.26e-05
2024-03-18 04:59:41,190 - logger.py:50 - Epoch: [38][100/125] loss: 2.94468, MAE: 0.44413, time/step=3736ms, lr=4.26e-05
2024-03-18 05:01:10,608 - logger.py:50 - Epoch: [38][124/125] loss: 2.51726, MAE: 0.44523, time/step=3734ms, lr=4.26e-05
2024-03-18 05:02:04,711 - logger.py:50 - Epoch: [38] train MAE: 0.44523, val MAE: 0.44205, test MAE: 0.42731, Time: 520.89s
2024-03-18 05:02:04,711 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 05:02:08,594 - logger.py:50 - Epoch: [39][0/125] loss: 1.98816, MAE: 0.42797, time/step=3881ms, lr=4.23e-05
2024-03-18 05:05:15,192 - logger.py:50 - Epoch: [39][50/125] loss: 0.68390, MAE: 0.44048, time/step=3735ms, lr=4.23e-05
2024-03-18 05:08:22,325 - logger.py:50 - Epoch: [39][100/125] loss: 2.17058, MAE: 0.44309, time/step=3739ms, lr=4.23e-05
2024-03-18 05:09:51,101 - logger.py:50 - Epoch: [39][124/125] loss: 2.36865, MAE: 0.44520, time/step=3731ms, lr=4.23e-05
2024-03-18 05:10:46,158 - logger.py:50 - Epoch: [39] train MAE: 0.44520, val MAE: 0.44376, test MAE: 0.42885, Time: 521.45s
2024-03-18 05:10:46,159 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 05:10:49,903 - logger.py:50 - Epoch: [40][0/125] loss: 0.57086, MAE: 0.42762, time/step=3743ms, lr=4.19e-05
2024-03-18 05:13:56,715 - logger.py:50 - Epoch: [40][50/125] loss: 4.04059, MAE: 0.45503, time/step=3736ms, lr=4.19e-05
2024-03-18 05:17:02,694 - logger.py:50 - Epoch: [40][100/125] loss: 2.42344, MAE: 0.44954, time/step=3728ms, lr=4.19e-05
2024-03-18 05:18:32,462 - logger.py:50 - Epoch: [40][124/125] loss: 2.09085, MAE: 0.44672, time/step=3730ms, lr=4.19e-05
2024-03-18 05:19:27,650 - logger.py:50 - Epoch: [40] train MAE: 0.44672, val MAE: 0.45065, test MAE: 0.43505, Time: 521.49s
2024-03-18 05:19:27,650 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 05:19:31,850 - logger.py:50 - Epoch: [41][0/125] loss: 0.57348, MAE: 0.49133, time/step=4198ms, lr=4.15e-05
2024-03-18 05:22:38,458 - logger.py:50 - Epoch: [41][50/125] loss: 1.50492, MAE: 0.44419, time/step=3741ms, lr=4.15e-05
2024-03-18 05:25:45,382 - logger.py:50 - Epoch: [41][100/125] loss: 1.12860, MAE: 0.44368, time/step=3740ms, lr=4.15e-05
2024-03-18 05:27:14,343 - logger.py:50 - Epoch: [41][124/125] loss: 1.80747, MAE: 0.44468, time/step=3734ms, lr=4.15e-05
2024-03-18 05:28:09,622 - logger.py:50 - Epoch: [41] train MAE: 0.44468, val MAE: 0.44843, test MAE: 0.43265, Time: 521.97s
2024-03-18 05:28:09,622 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 05:28:13,269 - logger.py:50 - Epoch: [42][0/125] loss: 0.60748, MAE: 0.39076, time/step=3645ms, lr=4.11e-05
2024-03-18 05:31:19,804 - logger.py:50 - Epoch: [42][50/125] loss: 1.32238, MAE: 0.44564, time/step=3729ms, lr=4.11e-05
2024-03-18 05:34:27,205 - logger.py:50 - Epoch: [42][100/125] loss: 1.03617, MAE: 0.44295, time/step=3738ms, lr=4.11e-05
2024-03-18 05:35:57,244 - logger.py:50 - Epoch: [42][124/125] loss: 1.62190, MAE: 0.44565, time/step=3741ms, lr=4.11e-05
2024-03-18 05:36:52,812 - logger.py:50 - Epoch: [42] train MAE: 0.44565, val MAE: 0.45545, test MAE: 0.44122, Time: 523.19s
2024-03-18 05:36:52,812 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 05:36:56,455 - logger.py:50 - Epoch: [43][0/125] loss: 0.51463, MAE: 0.43804, time/step=3641ms, lr=4.07e-05
2024-03-18 05:40:02,314 - logger.py:50 - Epoch: [43][50/125] loss: 2.53389, MAE: 0.45643, time/step=3716ms, lr=4.07e-05
2024-03-18 05:43:09,543 - logger.py:50 - Epoch: [43][100/125] loss: 1.61414, MAE: 0.44718, time/step=3730ms, lr=4.07e-05
2024-03-18 05:44:39,888 - logger.py:50 - Epoch: [43][124/125] loss: 1.43628, MAE: 0.44567, time/step=3737ms, lr=4.07e-05
2024-03-18 05:45:34,480 - logger.py:50 - Epoch: [43] train MAE: 0.44567, val MAE: 0.45003, test MAE: 0.43542, Time: 521.67s
2024-03-18 05:45:34,480 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 05:45:38,641 - logger.py:50 - Epoch: [44][0/125] loss: 1.28277, MAE: 0.48631, time/step=4157ms, lr=4.03e-05
2024-03-18 05:48:45,112 - logger.py:50 - Epoch: [44][50/125] loss: 1.93994, MAE: 0.45035, time/step=3738ms, lr=4.03e-05
2024-03-18 05:51:52,432 - logger.py:50 - Epoch: [44][100/125] loss: 1.51786, MAE: 0.44648, time/step=3742ms, lr=4.03e-05
2024-03-18 05:53:21,500 - logger.py:50 - Epoch: [44][124/125] loss: 1.35226, MAE: 0.44519, time/step=3736ms, lr=4.03e-05
2024-03-18 05:54:16,778 - logger.py:50 - Epoch: [44] train MAE: 0.44519, val MAE: 0.44717, test MAE: 0.43224, Time: 522.30s
2024-03-18 05:54:16,778 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 05:54:20,294 - logger.py:50 - Epoch: [45][0/125] loss: 0.87181, MAE: 0.48129, time/step=3514ms, lr=3.99e-05
2024-03-18 05:57:26,450 - logger.py:50 - Epoch: [45][50/125] loss: 1.06181, MAE: 0.44836, time/step=3719ms, lr=3.99e-05
2024-03-18 06:00:33,961 - logger.py:50 - Epoch: [45][100/125] loss: 1.39161, MAE: 0.44642, time/step=3734ms, lr=3.99e-05
2024-03-18 06:02:03,649 - logger.py:50 - Epoch: [45][124/125] loss: 1.24208, MAE: 0.44506, time/step=3735ms, lr=3.99e-05
2024-03-18 06:02:57,998 - logger.py:50 - Epoch: [45] train MAE: 0.44506, val MAE: 0.44639, test MAE: 0.43153, Time: 521.22s
2024-03-18 06:02:57,998 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 06:03:02,081 - logger.py:50 - Epoch: [46][0/125] loss: 0.55831, MAE: 0.37766, time/step=4081ms, lr=3.95e-05
2024-03-18 06:06:08,600 - logger.py:50 - Epoch: [46][50/125] loss: 1.91216, MAE: 0.45186, time/step=3737ms, lr=3.95e-05
2024-03-18 06:09:14,924 - logger.py:50 - Epoch: [46][100/125] loss: 1.30761, MAE: 0.44505, time/step=3732ms, lr=3.95e-05
2024-03-18 06:10:44,774 - logger.py:50 - Epoch: [46][124/125] loss: 1.17721, MAE: 0.44493, time/step=3734ms, lr=3.95e-05
2024-03-18 06:11:40,070 - logger.py:50 - Epoch: [46] train MAE: 0.44493, val MAE: 0.44791, test MAE: 0.43306, Time: 522.07s
2024-03-18 06:11:40,070 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 06:11:44,450 - logger.py:50 - Epoch: [47][0/125] loss: 0.96524, MAE: 0.45051, time/step=4378ms, lr=3.91e-05
2024-03-18 06:14:50,362 - logger.py:50 - Epoch: [47][50/125] loss: 1.51144, MAE: 0.44741, time/step=3731ms, lr=3.91e-05
2024-03-18 06:17:57,803 - logger.py:50 - Epoch: [47][100/125] loss: 1.23722, MAE: 0.44447, time/step=3740ms, lr=3.91e-05
2024-03-18 06:19:26,990 - logger.py:50 - Epoch: [47][124/125] loss: 1.13658, MAE: 0.44481, time/step=3735ms, lr=3.91e-05
2024-03-18 06:20:21,769 - logger.py:50 - Epoch: [47] train MAE: 0.44481, val MAE: 0.44072, test MAE: 0.42626, Time: 521.70s
2024-03-18 06:20:21,769 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 06:20:25,328 - logger.py:50 - Epoch: [48][0/125] loss: 0.81244, MAE: 0.44479, time/step=3557ms, lr=3.86e-05
2024-03-18 06:23:33,141 - logger.py:50 - Epoch: [48][50/125] loss: 0.94958, MAE: 0.44288, time/step=3752ms, lr=3.86e-05
2024-03-18 06:26:38,741 - logger.py:50 - Epoch: [48][100/125] loss: 1.21440, MAE: 0.44326, time/step=3732ms, lr=3.86e-05
2024-03-18 06:28:08,668 - logger.py:50 - Epoch: [48][124/125] loss: 1.10899, MAE: 0.44464, time/step=3735ms, lr=3.86e-05
2024-03-18 06:29:03,410 - logger.py:50 - Epoch: [48] train MAE: 0.44464, val MAE: 0.44335, test MAE: 0.42857, Time: 521.64s
2024-03-18 06:29:03,410 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 06:29:07,635 - logger.py:50 - Epoch: [49][0/125] loss: 0.53823, MAE: 0.40333, time/step=4222ms, lr=3.82e-05
2024-03-18 06:32:14,694 - logger.py:50 - Epoch: [49][50/125] loss: 1.36463, MAE: 0.44616, time/step=3751ms, lr=3.82e-05
2024-03-18 06:35:19,853 - logger.py:50 - Epoch: [49][100/125] loss: 1.01730, MAE: 0.44196, time/step=3727ms, lr=3.82e-05
2024-03-18 06:36:50,730 - logger.py:50 - Epoch: [49][124/125] loss: 1.07427, MAE: 0.44471, time/step=3739ms, lr=3.82e-05
2024-03-18 06:37:44,939 - logger.py:50 - Epoch: [49] train MAE: 0.44471, val MAE: 0.44093, test MAE: 0.42622, Time: 521.53s
2024-03-18 06:37:44,939 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 06:37:48,767 - logger.py:50 - Epoch: [50][0/125] loss: 0.57016, MAE: 0.41003, time/step=3825ms, lr=3.78e-05
2024-03-18 06:40:55,859 - logger.py:50 - Epoch: [50][50/125] loss: 0.95691, MAE: 0.44492, time/step=3743ms, lr=3.78e-05
2024-03-18 06:44:02,730 - logger.py:50 - Epoch: [50][100/125] loss: 1.18391, MAE: 0.44599, time/step=3740ms, lr=3.78e-05
2024-03-18 06:45:31,414 - logger.py:50 - Epoch: [50][124/125] loss: 1.07475, MAE: 0.44454, time/step=3732ms, lr=3.78e-05
2024-03-18 06:46:26,206 - logger.py:50 - Epoch: [50] train MAE: 0.44454, val MAE: 0.44588, test MAE: 0.43083, Time: 521.27s
2024-03-18 06:46:26,207 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 06:46:30,192 - logger.py:50 - Epoch: [51][0/125] loss: 0.74188, MAE: 0.47078, time/step=3983ms, lr=3.73e-05
2024-03-18 06:49:36,633 - logger.py:50 - Epoch: [51][50/125] loss: 0.93719, MAE: 0.45009, time/step=3734ms, lr=3.73e-05
2024-03-18 06:52:43,705 - logger.py:50 - Epoch: [51][100/125] loss: 1.14155, MAE: 0.44812, time/step=3738ms, lr=3.73e-05
2024-03-18 06:54:13,304 - logger.py:50 - Epoch: [51][124/125] loss: 1.05744, MAE: 0.44456, time/step=3737ms, lr=3.73e-05
2024-03-18 06:55:08,404 - logger.py:50 - Epoch: [51] train MAE: 0.44456, val MAE: 0.44439, test MAE: 0.42901, Time: 522.20s
2024-03-18 06:55:08,404 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 06:55:12,120 - logger.py:50 - Epoch: [52][0/125] loss: 0.54556, MAE: 0.49310, time/step=3714ms, lr=3.69e-05
2024-03-18 06:58:18,861 - logger.py:50 - Epoch: [52][50/125] loss: 1.31144, MAE: 0.44214, time/step=3734ms, lr=3.69e-05
2024-03-18 07:01:26,940 - logger.py:50 - Epoch: [52][100/125] loss: 1.14903, MAE: 0.44700, time/step=3748ms, lr=3.69e-05
2024-03-18 07:02:56,719 - logger.py:50 - Epoch: [52][124/125] loss: 1.04830, MAE: 0.44473, time/step=3747ms, lr=3.69e-05
2024-03-18 07:03:52,248 - logger.py:50 - Epoch: [52] train MAE: 0.44473, val MAE: 0.44386, test MAE: 0.42904, Time: 523.84s
2024-03-18 07:03:52,248 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 07:03:56,036 - logger.py:50 - Epoch: [53][0/125] loss: 0.61848, MAE: 0.46911, time/step=3786ms, lr=3.64e-05
2024-03-18 07:07:04,018 - logger.py:50 - Epoch: [53][50/125] loss: 0.61234, MAE: 0.44286, time/step=3760ms, lr=3.64e-05
2024-03-18 07:10:10,680 - logger.py:50 - Epoch: [53][100/125] loss: 1.14269, MAE: 0.44562, time/step=3747ms, lr=3.64e-05
2024-03-18 07:11:40,141 - logger.py:50 - Epoch: [53][124/125] loss: 1.03394, MAE: 0.44454, time/step=3743ms, lr=3.64e-05
2024-03-18 07:12:35,678 - logger.py:50 - Epoch: [53] train MAE: 0.44454, val MAE: 0.44480, test MAE: 0.42982, Time: 523.43s
2024-03-18 07:12:35,679 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 07:12:39,437 - logger.py:50 - Epoch: [54][0/125] loss: 0.66231, MAE: 0.43519, time/step=3756ms, lr=3.59e-05
2024-03-18 07:15:47,825 - logger.py:50 - Epoch: [54][50/125] loss: 0.95051, MAE: 0.45615, time/step=3768ms, lr=3.59e-05
2024-03-18 07:18:54,107 - logger.py:50 - Epoch: [54][100/125] loss: 0.77738, MAE: 0.44261, time/step=3747ms, lr=3.59e-05
2024-03-18 07:20:23,917 - logger.py:50 - Epoch: [54][124/125] loss: 1.03154, MAE: 0.44436, time/step=3746ms, lr=3.59e-05
2024-03-18 07:21:19,475 - logger.py:50 - Epoch: [54] train MAE: 0.44436, val MAE: 0.44795, test MAE: 0.43301, Time: 523.80s
2024-03-18 07:21:19,475 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 07:21:23,056 - logger.py:50 - Epoch: [55][0/125] loss: 0.60989, MAE: 0.43738, time/step=3579ms, lr=3.55e-05
2024-03-18 07:24:29,022 - logger.py:50 - Epoch: [55][50/125] loss: 0.58452, MAE: 0.44228, time/step=3717ms, lr=3.55e-05
2024-03-18 07:27:36,317 - logger.py:50 - Epoch: [55][100/125] loss: 0.94087, MAE: 0.44675, time/step=3731ms, lr=3.55e-05
2024-03-18 07:29:06,469 - logger.py:50 - Epoch: [55][124/125] loss: 1.02421, MAE: 0.44468, time/step=3736ms, lr=3.55e-05
2024-03-18 07:30:00,782 - logger.py:50 - Epoch: [55] train MAE: 0.44468, val MAE: 0.45053, test MAE: 0.43510, Time: 521.31s
2024-03-18 07:30:00,782 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 07:30:04,456 - logger.py:50 - Epoch: [56][0/125] loss: 0.65732, MAE: 0.40197, time/step=3672ms, lr=3.50e-05
2024-03-18 07:33:10,908 - logger.py:50 - Epoch: [56][50/125] loss: 0.91821, MAE: 0.44247, time/step=3728ms, lr=3.50e-05
2024-03-18 07:36:19,249 - logger.py:50 - Epoch: [56][100/125] loss: 1.16418, MAE: 0.44727, time/step=3747ms, lr=3.50e-05
2024-03-18 07:37:48,154 - logger.py:50 - Epoch: [56][124/125] loss: 1.05384, MAE: 0.44456, time/step=3739ms, lr=3.50e-05
2024-03-18 07:38:42,371 - logger.py:50 - Epoch: [56] train MAE: 0.44456, val MAE: 0.44094, test MAE: 0.42595, Time: 521.59s
2024-03-18 07:38:42,371 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 07:38:46,041 - logger.py:50 - Epoch: [57][0/125] loss: 0.60895, MAE: 0.45238, time/step=3667ms, lr=3.45e-05
2024-03-18 07:41:52,925 - logger.py:50 - Epoch: [57][50/125] loss: 0.98835, MAE: 0.44714, time/step=3736ms, lr=3.45e-05
2024-03-18 07:44:59,352 - logger.py:50 - Epoch: [57][100/125] loss: 0.78590, MAE: 0.44112, time/step=3732ms, lr=3.45e-05
2024-03-18 07:46:29,328 - logger.py:50 - Epoch: [57][124/125] loss: 1.02901, MAE: 0.44443, time/step=3736ms, lr=3.45e-05
2024-03-18 07:47:24,552 - logger.py:50 - Epoch: [57] train MAE: 0.44443, val MAE: 0.44552, test MAE: 0.43074, Time: 522.18s
2024-03-18 07:47:24,552 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 07:47:29,023 - logger.py:50 - Epoch: [58][0/125] loss: 0.48465, MAE: 0.36836, time/step=4469ms, lr=3.40e-05
2024-03-18 07:50:35,413 - logger.py:50 - Epoch: [58][50/125] loss: 0.60325, MAE: 0.44187, time/step=3742ms, lr=3.40e-05
2024-03-18 07:53:42,404 - logger.py:50 - Epoch: [58][100/125] loss: 1.11628, MAE: 0.44747, time/step=3741ms, lr=3.40e-05
2024-03-18 07:55:11,794 - logger.py:50 - Epoch: [58][124/125] loss: 1.01171, MAE: 0.44457, time/step=3738ms, lr=3.40e-05
2024-03-18 07:56:06,348 - logger.py:50 - Epoch: [58] train MAE: 0.44457, val MAE: 0.44732, test MAE: 0.43247, Time: 521.80s
2024-03-18 07:56:06,348 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 07:56:10,295 - logger.py:50 - Epoch: [59][0/125] loss: 0.48638, MAE: 0.44528, time/step=3945ms, lr=3.36e-05
2024-03-18 07:59:16,515 - logger.py:50 - Epoch: [59][50/125] loss: 1.23409, MAE: 0.44728, time/step=3729ms, lr=3.36e-05
2024-03-18 08:02:23,186 - logger.py:50 - Epoch: [59][100/125] loss: 0.89891, MAE: 0.44093, time/step=3731ms, lr=3.36e-05
2024-03-18 08:03:52,740 - logger.py:50 - Epoch: [59][124/125] loss: 1.00146, MAE: 0.44443, time/step=3731ms, lr=3.36e-05
2024-03-18 08:04:47,633 - logger.py:50 - Epoch: [59] train MAE: 0.44443, val MAE: 0.44270, test MAE: 0.42713, Time: 521.28s
2024-03-18 08:04:47,633 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 08:04:51,243 - logger.py:50 - Epoch: [60][0/125] loss: 0.46005, MAE: 0.42749, time/step=3608ms, lr=3.31e-05
2024-03-18 08:07:58,334 - logger.py:50 - Epoch: [60][50/125] loss: 0.57136, MAE: 0.43465, time/step=3739ms, lr=3.31e-05
2024-03-18 08:11:06,873 - logger.py:50 - Epoch: [60][100/125] loss: 1.05895, MAE: 0.44764, time/step=3755ms, lr=3.31e-05
2024-03-18 08:12:35,841 - logger.py:50 - Epoch: [60][124/125] loss: 0.97752, MAE: 0.44418, time/step=3746ms, lr=3.31e-05
2024-03-18 08:13:30,912 - logger.py:50 - Epoch: [60] train MAE: 0.44418, val MAE: 0.44511, test MAE: 0.43027, Time: 523.28s
2024-03-18 08:13:30,912 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 08:13:34,684 - logger.py:50 - Epoch: [61][0/125] loss: 0.67943, MAE: 0.47516, time/step=3770ms, lr=3.26e-05
2024-03-18 08:16:42,032 - logger.py:50 - Epoch: [61][50/125] loss: 0.58379, MAE: 0.44389, time/step=3747ms, lr=3.26e-05
2024-03-18 08:19:49,077 - logger.py:50 - Epoch: [61][100/125] loss: 1.06993, MAE: 0.44461, time/step=3744ms, lr=3.26e-05
2024-03-18 08:21:19,038 - logger.py:50 - Epoch: [61][124/125] loss: 0.98402, MAE: 0.44443, time/step=3745ms, lr=3.26e-05
2024-03-18 08:22:14,100 - logger.py:50 - Epoch: [61] train MAE: 0.44443, val MAE: 0.44034, test MAE: 0.42576, Time: 523.19s
2024-03-18 08:22:14,100 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 08:22:18,563 - logger.py:50 - Epoch: [62][0/125] loss: 0.77188, MAE: 0.47081, time/step=4460ms, lr=3.21e-05
2024-03-18 08:25:25,411 - logger.py:50 - Epoch: [62][50/125] loss: 0.89328, MAE: 0.45296, time/step=3751ms, lr=3.21e-05
2024-03-18 08:28:33,261 - logger.py:50 - Epoch: [62][100/125] loss: 1.07423, MAE: 0.44857, time/step=3754ms, lr=3.21e-05
2024-03-18 08:30:02,825 - logger.py:50 - Epoch: [62][124/125] loss: 0.97122, MAE: 0.44434, time/step=3750ms, lr=3.21e-05
2024-03-18 08:30:57,929 - logger.py:50 - Epoch: [62] train MAE: 0.44434, val MAE: 0.44463, test MAE: 0.42966, Time: 523.83s
2024-03-18 08:30:57,929 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 08:31:01,722 - logger.py:50 - Epoch: [63][0/125] loss: 0.51543, MAE: 0.40965, time/step=3790ms, lr=3.16e-05
2024-03-18 08:34:09,605 - logger.py:50 - Epoch: [63][50/125] loss: 1.21525, MAE: 0.45181, time/step=3758ms, lr=3.16e-05
2024-03-18 08:37:16,232 - logger.py:50 - Epoch: [63][100/125] loss: 1.05825, MAE: 0.44716, time/step=3746ms, lr=3.16e-05
2024-03-18 08:38:46,680 - logger.py:50 - Epoch: [63][124/125] loss: 0.96130, MAE: 0.44441, time/step=3750ms, lr=3.16e-05
2024-03-18 08:39:41,834 - logger.py:50 - Epoch: [63] train MAE: 0.44441, val MAE: 0.44609, test MAE: 0.43098, Time: 523.90s
2024-03-18 08:39:41,834 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 08:39:45,549 - logger.py:50 - Epoch: [64][0/125] loss: 0.74354, MAE: 0.39358, time/step=3712ms, lr=3.11e-05
2024-03-18 08:42:53,818 - logger.py:50 - Epoch: [64][50/125] loss: 0.55837, MAE: 0.43739, time/step=3764ms, lr=3.11e-05
2024-03-18 08:46:00,605 - logger.py:50 - Epoch: [64][100/125] loss: 0.55561, MAE: 0.43659, time/step=3750ms, lr=3.11e-05
2024-03-18 08:47:30,810 - logger.py:50 - Epoch: [64][124/125] loss: 1.18263, MAE: 0.44463, time/step=3752ms, lr=3.11e-05
2024-03-18 08:48:25,781 - logger.py:50 - Epoch: [64] train MAE: 0.44463, val MAE: 0.45882, test MAE: 0.44040, Time: 523.95s
2024-03-18 08:48:25,781 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 08:48:29,997 - logger.py:50 - Epoch: [65][0/125] loss: 0.45312, MAE: 0.41060, time/step=4214ms, lr=3.06e-05
2024-03-18 08:51:37,529 - logger.py:50 - Epoch: [65][50/125] loss: 1.68771, MAE: 0.45865, time/step=3760ms, lr=3.06e-05
2024-03-18 08:54:44,913 - logger.py:50 - Epoch: [65][100/125] loss: 1.15437, MAE: 0.44540, time/step=3754ms, lr=3.06e-05
2024-03-18 08:56:14,505 - logger.py:50 - Epoch: [65][124/125] loss: 1.05597, MAE: 0.44530, time/step=3750ms, lr=3.06e-05
2024-03-18 08:57:10,035 - logger.py:50 - Epoch: [65] train MAE: 0.44530, val MAE: 0.44968, test MAE: 0.43480, Time: 524.25s
2024-03-18 08:57:10,035 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 08:57:14,443 - logger.py:50 - Epoch: [66][0/125] loss: 0.49722, MAE: 0.41230, time/step=4406ms, lr=3.01e-05
2024-03-18 09:00:21,511 - logger.py:50 - Epoch: [66][50/125] loss: 1.58883, MAE: 0.45823, time/step=3754ms, lr=3.01e-05
2024-03-18 09:03:28,838 - logger.py:50 - Epoch: [66][100/125] loss: 1.10168, MAE: 0.44989, time/step=3750ms, lr=3.01e-05
2024-03-18 09:04:58,872 - logger.py:50 - Epoch: [66][124/125] loss: 0.98848, MAE: 0.44447, time/step=3751ms, lr=3.01e-05
2024-03-18 09:05:54,464 - logger.py:50 - Epoch: [66] train MAE: 0.44447, val MAE: 0.44724, test MAE: 0.43228, Time: 524.43s
2024-03-18 09:05:54,464 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 09:05:58,317 - logger.py:50 - Epoch: [67][0/125] loss: 0.56743, MAE: 0.43561, time/step=3850ms, lr=2.96e-05
2024-03-18 09:09:03,556 - logger.py:50 - Epoch: [67][50/125] loss: 0.57552, MAE: 0.43452, time/step=3708ms, lr=2.96e-05
2024-03-18 09:12:11,023 - logger.py:50 - Epoch: [67][100/125] loss: 1.07695, MAE: 0.44487, time/step=3728ms, lr=2.96e-05
2024-03-18 09:13:40,970 - logger.py:50 - Epoch: [67][124/125] loss: 0.97202, MAE: 0.44432, time/step=3732ms, lr=2.96e-05
2024-03-18 09:14:35,315 - logger.py:50 - Epoch: [67] train MAE: 0.44432, val MAE: 0.44531, test MAE: 0.43034, Time: 520.85s
2024-03-18 09:14:35,316 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 09:14:39,640 - logger.py:50 - Epoch: [68][0/125] loss: 0.43181, MAE: 0.42589, time/step=4323ms, lr=2.91e-05
2024-03-18 09:17:47,013 - logger.py:50 - Epoch: [68][50/125] loss: 1.53506, MAE: 0.45559, time/step=3759ms, lr=2.91e-05
2024-03-18 09:20:53,237 - logger.py:50 - Epoch: [68][100/125] loss: 1.06663, MAE: 0.44703, time/step=3742ms, lr=2.91e-05
2024-03-18 09:22:21,132 - logger.py:50 - Epoch: [68][124/125] loss: 0.97230, MAE: 0.44421, time/step=3727ms, lr=2.91e-05
2024-03-18 09:23:15,781 - logger.py:50 - Epoch: [68] train MAE: 0.44421, val MAE: 0.44404, test MAE: 0.42925, Time: 520.47s
2024-03-18 09:23:15,781 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 09:23:19,603 - logger.py:50 - Epoch: [69][0/125] loss: 0.57222, MAE: 0.47393, time/step=3820ms, lr=2.86e-05
2024-03-18 09:26:25,694 - logger.py:50 - Epoch: [69][50/125] loss: 1.17008, MAE: 0.44853, time/step=3724ms, lr=2.86e-05
2024-03-18 09:29:34,473 - logger.py:50 - Epoch: [69][100/125] loss: 1.04856, MAE: 0.44756, time/step=3749ms, lr=2.86e-05
2024-03-18 09:31:03,490 - logger.py:50 - Epoch: [69][124/125] loss: 0.96037, MAE: 0.44435, time/step=3742ms, lr=2.86e-05
2024-03-18 09:31:58,486 - logger.py:50 - Epoch: [69] train MAE: 0.44435, val MAE: 0.44336, test MAE: 0.42839, Time: 522.70s
2024-03-18 09:31:58,486 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 09:32:02,287 - logger.py:50 - Epoch: [70][0/125] loss: 0.40699, MAE: 0.42825, time/step=3798ms, lr=2.81e-05
2024-03-18 09:35:09,862 - logger.py:50 - Epoch: [70][50/125] loss: 0.56161, MAE: 0.44327, time/step=3752ms, lr=2.81e-05
2024-03-18 09:38:16,695 - logger.py:50 - Epoch: [70][100/125] loss: 0.70799, MAE: 0.44275, time/step=3745ms, lr=2.81e-05
2024-03-18 09:39:47,072 - logger.py:50 - Epoch: [70][124/125] loss: 0.95084, MAE: 0.44400, time/step=3749ms, lr=2.81e-05
2024-03-18 09:40:42,112 - logger.py:50 - Epoch: [70] train MAE: 0.44400, val MAE: 0.44597, test MAE: 0.43087, Time: 523.63s
2024-03-18 09:40:42,113 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 09:40:46,251 - logger.py:50 - Epoch: [71][0/125] loss: 0.46387, MAE: 0.43614, time/step=4136ms, lr=2.76e-05
2024-03-18 09:43:54,571 - logger.py:50 - Epoch: [71][50/125] loss: 0.88361, MAE: 0.45310, time/step=3774ms, lr=2.76e-05
2024-03-18 09:47:01,484 - logger.py:50 - Epoch: [71][100/125] loss: 1.04607, MAE: 0.44893, time/step=3756ms, lr=2.76e-05
2024-03-18 09:48:31,243 - logger.py:50 - Epoch: [71][124/125] loss: 0.94550, MAE: 0.44431, time/step=3753ms, lr=2.76e-05
2024-03-18 09:49:25,817 - logger.py:50 - Epoch: [71] train MAE: 0.44431, val MAE: 0.44495, test MAE: 0.42987, Time: 523.70s
2024-03-18 09:49:25,817 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 09:49:30,091 - logger.py:50 - Epoch: [72][0/125] loss: 0.34529, MAE: 0.42886, time/step=4272ms, lr=2.70e-05
2024-03-18 09:52:35,442 - logger.py:50 - Epoch: [72][50/125] loss: 0.58945, MAE: 0.43848, time/step=3718ms, lr=2.70e-05
2024-03-18 09:55:42,880 - logger.py:50 - Epoch: [72][100/125] loss: 0.87910, MAE: 0.44216, time/step=3733ms, lr=2.70e-05
2024-03-18 09:57:12,510 - logger.py:50 - Epoch: [72][124/125] loss: 0.94575, MAE: 0.44423, time/step=3734ms, lr=2.70e-05
2024-03-18 09:58:07,726 - logger.py:50 - Epoch: [72] train MAE: 0.44423, val MAE: 0.44548, test MAE: 0.43070, Time: 521.91s
2024-03-18 09:58:07,726 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 09:58:11,271 - logger.py:50 - Epoch: [73][0/125] loss: 0.55229, MAE: 0.41407, time/step=3543ms, lr=2.65e-05
2024-03-18 10:01:18,145 - logger.py:50 - Epoch: [73][50/125] loss: 0.53191, MAE: 0.43400, time/step=3734ms, lr=2.65e-05
2024-03-18 10:04:25,201 - logger.py:50 - Epoch: [73][100/125] loss: 0.87677, MAE: 0.44290, time/step=3737ms, lr=2.65e-05
2024-03-18 10:05:54,770 - logger.py:50 - Epoch: [73][124/125] loss: 0.93515, MAE: 0.44417, time/step=3736ms, lr=2.65e-05
2024-03-18 10:06:50,006 - logger.py:50 - Epoch: [73] train MAE: 0.44417, val MAE: 0.44466, test MAE: 0.42950, Time: 522.28s
2024-03-18 10:06:50,006 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 10:06:54,231 - logger.py:50 - Epoch: [74][0/125] loss: 0.67915, MAE: 0.46556, time/step=4222ms, lr=2.60e-05
2024-03-18 10:10:03,004 - logger.py:50 - Epoch: [74][50/125] loss: 1.43841, MAE: 0.45710, time/step=3784ms, lr=2.60e-05
2024-03-18 10:13:09,745 - logger.py:50 - Epoch: [74][100/125] loss: 1.00692, MAE: 0.44487, time/step=3760ms, lr=2.60e-05
2024-03-18 10:14:38,783 - logger.py:50 - Epoch: [74][124/125] loss: 0.92401, MAE: 0.44425, time/step=3750ms, lr=2.60e-05
2024-03-18 10:15:34,364 - logger.py:50 - Epoch: [74] train MAE: 0.44425, val MAE: 0.44612, test MAE: 0.43108, Time: 524.36s
2024-03-18 10:15:34,364 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 10:15:38,234 - logger.py:50 - Epoch: [75][0/125] loss: 0.63798, MAE: 0.44286, time/step=3868ms, lr=2.55e-05
2024-03-18 10:18:45,703 - logger.py:50 - Epoch: [75][50/125] loss: 1.17562, MAE: 0.44302, time/step=3752ms, lr=2.55e-05
2024-03-18 10:21:51,994 - logger.py:50 - Epoch: [75][100/125] loss: 1.01391, MAE: 0.44654, time/step=3739ms, lr=2.55e-05
2024-03-18 10:23:22,923 - logger.py:50 - Epoch: [75][124/125] loss: 0.92456, MAE: 0.44422, time/step=3748ms, lr=2.55e-05
2024-03-18 10:24:17,998 - logger.py:50 - Epoch: [75] train MAE: 0.44422, val MAE: 0.44605, test MAE: 0.43075, Time: 523.63s
2024-03-18 10:24:17,999 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 10:24:22,114 - logger.py:50 - Epoch: [76][0/125] loss: 0.87944, MAE: 0.48790, time/step=4113ms, lr=2.50e-05
2024-03-18 10:27:27,888 - logger.py:50 - Epoch: [76][50/125] loss: 0.88162, MAE: 0.44420, time/step=3723ms, lr=2.50e-05
2024-03-18 10:30:35,127 - logger.py:50 - Epoch: [76][100/125] loss: 0.71268, MAE: 0.44227, time/step=3734ms, lr=2.50e-05
2024-03-18 10:32:04,881 - logger.py:50 - Epoch: [76][124/125] loss: 0.91865, MAE: 0.44421, time/step=3735ms, lr=2.50e-05
2024-03-18 10:33:00,092 - logger.py:50 - Epoch: [76] train MAE: 0.44421, val MAE: 0.44646, test MAE: 0.43137, Time: 522.09s
2024-03-18 10:33:00,092 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 10:33:03,764 - logger.py:50 - Epoch: [77][0/125] loss: 0.62922, MAE: 0.41555, time/step=3669ms, lr=2.45e-05
2024-03-18 10:36:10,301 - logger.py:50 - Epoch: [77][50/125] loss: 1.12160, MAE: 0.44190, time/step=3730ms, lr=2.45e-05
2024-03-18 10:39:17,047 - logger.py:50 - Epoch: [77][100/125] loss: 0.86060, MAE: 0.44070, time/step=3732ms, lr=2.45e-05
2024-03-18 10:40:46,039 - logger.py:50 - Epoch: [77][124/125] loss: 0.92020, MAE: 0.44440, time/step=3728ms, lr=2.45e-05
2024-03-18 10:41:41,263 - logger.py:50 - Epoch: [77] train MAE: 0.44440, val MAE: 0.44177, test MAE: 0.42662, Time: 521.17s
2024-03-18 10:41:41,263 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 10:41:45,064 - logger.py:50 - Epoch: [78][0/125] loss: 0.52568, MAE: 0.42934, time/step=3799ms, lr=2.40e-05
2024-03-18 10:44:52,772 - logger.py:50 - Epoch: [78][50/125] loss: 0.55270, MAE: 0.43944, time/step=3755ms, lr=2.40e-05
2024-03-18 10:47:57,702 - logger.py:50 - Epoch: [78][100/125] loss: 0.85870, MAE: 0.44263, time/step=3727ms, lr=2.40e-05
2024-03-18 10:49:28,166 - logger.py:50 - Epoch: [78][124/125] loss: 0.91881, MAE: 0.44411, time/step=3735ms, lr=2.40e-05
2024-03-18 10:50:22,433 - logger.py:50 - Epoch: [78] train MAE: 0.44411, val MAE: 0.43963, test MAE: 0.42447, Time: 521.17s
2024-03-18 10:50:22,433 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 10:50:26,464 - logger.py:50 - Epoch: [79][0/125] loss: 0.54588, MAE: 0.46250, time/step=4029ms, lr=2.34e-05
2024-03-18 10:53:31,993 - logger.py:50 - Epoch: [79][50/125] loss: 0.88612, MAE: 0.45014, time/step=3717ms, lr=2.34e-05
2024-03-18 10:56:39,896 - logger.py:50 - Epoch: [79][100/125] loss: 0.71457, MAE: 0.44280, time/step=3737ms, lr=2.34e-05
2024-03-18 10:58:09,359 - logger.py:50 - Epoch: [79][124/125] loss: 0.92104, MAE: 0.44427, time/step=3735ms, lr=2.34e-05
2024-03-18 10:59:04,162 - logger.py:50 - Epoch: [79] train MAE: 0.44427, val MAE: 0.44484, test MAE: 0.42980, Time: 521.73s
2024-03-18 10:59:04,162 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 10:59:08,365 - logger.py:50 - Epoch: [80][0/125] loss: 0.59332, MAE: 0.42893, time/step=4200ms, lr=2.29e-05
2024-03-18 11:02:15,819 - logger.py:50 - Epoch: [80][50/125] loss: 0.53120, MAE: 0.43185, time/step=3758ms, lr=2.29e-05
2024-03-18 11:05:22,851 - logger.py:50 - Epoch: [80][100/125] loss: 0.70925, MAE: 0.44074, time/step=3749ms, lr=2.29e-05
2024-03-18 11:06:52,079 - logger.py:50 - Epoch: [80][124/125] loss: 0.92091, MAE: 0.44418, time/step=3743ms, lr=2.29e-05
2024-03-18 11:07:47,553 - logger.py:50 - Epoch: [80] train MAE: 0.44418, val MAE: 0.44858, test MAE: 0.43355, Time: 523.39s
2024-03-18 11:07:47,553 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 11:07:51,216 - logger.py:50 - Epoch: [81][0/125] loss: 0.59427, MAE: 0.45601, time/step=3660ms, lr=2.24e-05
2024-03-18 11:10:58,871 - logger.py:50 - Epoch: [81][50/125] loss: 0.52902, MAE: 0.43753, time/step=3751ms, lr=2.24e-05
2024-03-18 11:14:06,535 - logger.py:50 - Epoch: [81][100/125] loss: 1.03272, MAE: 0.44537, time/step=3752ms, lr=2.24e-05
2024-03-18 11:15:36,201 - logger.py:50 - Epoch: [81][124/125] loss: 0.94234, MAE: 0.44449, time/step=3749ms, lr=2.24e-05
2024-03-18 11:16:31,247 - logger.py:50 - Epoch: [81] train MAE: 0.44449, val MAE: 0.44469, test MAE: 0.42977, Time: 523.69s
2024-03-18 11:16:31,247 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 11:16:35,367 - logger.py:50 - Epoch: [82][0/125] loss: 0.55533, MAE: 0.45847, time/step=4117ms, lr=2.19e-05
2024-03-18 11:19:41,687 - logger.py:50 - Epoch: [82][50/125] loss: 0.87122, MAE: 0.43972, time/step=3734ms, lr=2.19e-05
2024-03-18 11:22:49,494 - logger.py:50 - Epoch: [82][100/125] loss: 1.00910, MAE: 0.44327, time/step=3745ms, lr=2.19e-05
2024-03-18 11:24:19,928 - logger.py:50 - Epoch: [82][124/125] loss: 0.91979, MAE: 0.44403, time/step=3749ms, lr=2.19e-05
2024-03-18 11:25:15,419 - logger.py:50 - Epoch: [82] train MAE: 0.44403, val MAE: 0.44758, test MAE: 0.43267, Time: 524.17s
2024-03-18 11:25:15,420 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 11:25:19,642 - logger.py:50 - Epoch: [83][0/125] loss: 0.52748, MAE: 0.44239, time/step=4220ms, lr=2.14e-05
2024-03-18 11:28:25,334 - logger.py:50 - Epoch: [83][50/125] loss: 0.87687, MAE: 0.44280, time/step=3724ms, lr=2.14e-05
2024-03-18 11:31:34,855 - logger.py:50 - Epoch: [83][100/125] loss: 1.01757, MAE: 0.44495, time/step=3757ms, lr=2.14e-05
2024-03-18 11:33:04,010 - logger.py:50 - Epoch: [83][124/125] loss: 0.92456, MAE: 0.44437, time/step=3749ms, lr=2.14e-05
2024-03-18 11:33:59,115 - logger.py:50 - Epoch: [83] train MAE: 0.44437, val MAE: 0.44556, test MAE: 0.43057, Time: 523.70s
2024-03-18 11:33:59,115 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 11:34:03,261 - logger.py:50 - Epoch: [84][0/125] loss: 0.40644, MAE: 0.44457, time/step=4143ms, lr=2.09e-05
2024-03-18 11:37:09,680 - logger.py:50 - Epoch: [84][50/125] loss: 1.46470, MAE: 0.45752, time/step=3737ms, lr=2.09e-05
2024-03-18 11:40:16,877 - logger.py:50 - Epoch: [84][100/125] loss: 1.00537, MAE: 0.44703, time/step=3740ms, lr=2.09e-05
2024-03-18 11:41:48,012 - logger.py:50 - Epoch: [84][124/125] loss: 0.90588, MAE: 0.44421, time/step=3751ms, lr=2.09e-05
2024-03-18 11:42:42,596 - logger.py:50 - Epoch: [84] train MAE: 0.44421, val MAE: 0.44056, test MAE: 0.42549, Time: 523.48s
2024-03-18 11:42:42,597 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 11:42:46,224 - logger.py:50 - Epoch: [85][0/125] loss: 0.51157, MAE: 0.41861, time/step=3625ms, lr=2.04e-05
2024-03-18 11:45:54,279 - logger.py:50 - Epoch: [85][50/125] loss: 1.16199, MAE: 0.44832, time/step=3758ms, lr=2.04e-05
2024-03-18 11:49:01,795 - logger.py:50 - Epoch: [85][100/125] loss: 0.98561, MAE: 0.44518, time/step=3754ms, lr=2.04e-05
2024-03-18 11:50:31,169 - logger.py:50 - Epoch: [85][124/125] loss: 0.90435, MAE: 0.44413, time/step=3749ms, lr=2.04e-05
2024-03-18 11:51:26,680 - logger.py:50 - Epoch: [85] train MAE: 0.44413, val MAE: 0.45093, test MAE: 0.43599, Time: 524.08s
2024-03-18 11:51:26,680 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 11:51:30,401 - logger.py:50 - Epoch: [86][0/125] loss: 0.47716, MAE: 0.42097, time/step=3719ms, lr=1.99e-05
2024-03-18 11:54:38,385 - logger.py:50 - Epoch: [86][50/125] loss: 0.55976, MAE: 0.43908, time/step=3759ms, lr=1.99e-05
2024-03-18 11:57:45,100 - logger.py:50 - Epoch: [86][100/125] loss: 0.99611, MAE: 0.44523, time/step=3747ms, lr=1.99e-05
2024-03-18 11:59:14,781 - logger.py:50 - Epoch: [86][124/125] loss: 0.90479, MAE: 0.44426, time/step=3745ms, lr=1.99e-05
2024-03-18 12:00:09,839 - logger.py:50 - Epoch: [86] train MAE: 0.44426, val MAE: 0.44398, test MAE: 0.42893, Time: 523.16s
2024-03-18 12:00:09,839 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 12:00:13,517 - logger.py:50 - Epoch: [87][0/125] loss: 0.54673, MAE: 0.41959, time/step=3676ms, lr=1.94e-05
2024-03-18 12:03:21,550 - logger.py:50 - Epoch: [87][50/125] loss: 0.58452, MAE: 0.44407, time/step=3759ms, lr=1.94e-05
2024-03-18 12:06:29,221 - logger.py:50 - Epoch: [87][100/125] loss: 1.00212, MAE: 0.44997, time/step=3756ms, lr=1.94e-05
2024-03-18 12:07:57,152 - logger.py:50 - Epoch: [87][124/125] loss: 0.90788, MAE: 0.44415, time/step=3738ms, lr=1.94e-05
2024-03-18 12:08:51,935 - logger.py:50 - Epoch: [87] train MAE: 0.44415, val MAE: 0.44391, test MAE: 0.42904, Time: 522.10s
2024-03-18 12:08:51,935 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 12:08:55,546 - logger.py:50 - Epoch: [88][0/125] loss: 0.51179, MAE: 0.48277, time/step=3609ms, lr=1.89e-05
2024-03-18 12:12:02,981 - logger.py:50 - Epoch: [88][50/125] loss: 0.57629, MAE: 0.43974, time/step=3746ms, lr=1.89e-05
2024-03-18 12:15:09,891 - logger.py:50 - Epoch: [88][100/125] loss: 1.00449, MAE: 0.44443, time/step=3742ms, lr=1.89e-05
2024-03-18 12:16:38,780 - logger.py:50 - Epoch: [88][124/125] loss: 0.91231, MAE: 0.44432, time/step=3735ms, lr=1.89e-05
2024-03-18 12:17:33,503 - logger.py:50 - Epoch: [88] train MAE: 0.44432, val MAE: 0.44751, test MAE: 0.43233, Time: 521.57s
2024-03-18 12:17:33,503 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 12:17:37,825 - logger.py:50 - Epoch: [89][0/125] loss: 0.44510, MAE: 0.46198, time/step=4319ms, lr=1.84e-05
2024-03-18 12:20:44,794 - logger.py:50 - Epoch: [89][50/125] loss: 1.12622, MAE: 0.44777, time/step=3751ms, lr=1.84e-05
2024-03-18 12:23:51,672 - logger.py:50 - Epoch: [89][100/125] loss: 0.84274, MAE: 0.44163, time/step=3744ms, lr=1.84e-05
2024-03-18 12:25:22,620 - logger.py:50 - Epoch: [89][124/125] loss: 0.90862, MAE: 0.44425, time/step=3753ms, lr=1.84e-05
2024-03-18 12:26:17,136 - logger.py:50 - Epoch: [89] train MAE: 0.44425, val MAE: 0.44773, test MAE: 0.43249, Time: 523.63s
2024-03-18 12:26:17,136 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 12:26:20,835 - logger.py:50 - Epoch: [90][0/125] loss: 0.65615, MAE: 0.48098, time/step=3697ms, lr=1.79e-05
2024-03-18 12:29:27,814 - logger.py:50 - Epoch: [90][50/125] loss: 0.86172, MAE: 0.45544, time/step=3739ms, lr=1.79e-05
2024-03-18 12:32:35,137 - logger.py:50 - Epoch: [90][100/125] loss: 0.98989, MAE: 0.44696, time/step=3743ms, lr=1.79e-05
2024-03-18 12:34:05,296 - logger.py:50 - Epoch: [90][124/125] loss: 0.90188, MAE: 0.44431, time/step=3745ms, lr=1.79e-05
2024-03-18 12:34:59,852 - logger.py:50 - Epoch: [90] train MAE: 0.44431, val MAE: 0.44548, test MAE: 0.43016, Time: 522.72s
2024-03-18 12:34:59,852 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 12:35:03,563 - logger.py:50 - Epoch: [91][0/125] loss: 0.37530, MAE: 0.43768, time/step=3708ms, lr=1.74e-05
2024-03-18 12:38:12,312 - logger.py:50 - Epoch: [91][50/125] loss: 0.82189, MAE: 0.44230, time/step=3774ms, lr=1.74e-05
2024-03-18 12:41:19,263 - logger.py:50 - Epoch: [91][100/125] loss: 0.98440, MAE: 0.44611, time/step=3757ms, lr=1.74e-05
2024-03-18 12:42:48,284 - logger.py:50 - Epoch: [91][124/125] loss: 0.90453, MAE: 0.44418, time/step=3747ms, lr=1.74e-05
2024-03-18 12:43:43,859 - logger.py:50 - Epoch: [91] train MAE: 0.44418, val MAE: 0.44360, test MAE: 0.42846, Time: 524.01s
2024-03-18 12:43:43,859 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 12:43:47,450 - logger.py:50 - Epoch: [92][0/125] loss: 0.44637, MAE: 0.44036, time/step=3589ms, lr=1.70e-05
2024-03-18 12:46:54,025 - logger.py:50 - Epoch: [92][50/125] loss: 0.53448, MAE: 0.44123, time/step=3729ms, lr=1.70e-05
2024-03-18 12:50:01,224 - logger.py:50 - Epoch: [92][100/125] loss: 1.01237, MAE: 0.44679, time/step=3736ms, lr=1.70e-05
2024-03-18 12:51:30,996 - logger.py:50 - Epoch: [92][124/125] loss: 0.91801, MAE: 0.44436, time/step=3737ms, lr=1.70e-05
2024-03-18 12:52:25,311 - logger.py:50 - Epoch: [92] train MAE: 0.44436, val MAE: 0.44450, test MAE: 0.42937, Time: 521.45s
2024-03-18 12:52:25,311 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 12:52:28,934 - logger.py:50 - Epoch: [93][0/125] loss: 0.48596, MAE: 0.46394, time/step=3621ms, lr=1.65e-05
2024-03-18 12:55:36,344 - logger.py:50 - Epoch: [93][50/125] loss: 0.54487, MAE: 0.43902, time/step=3746ms, lr=1.65e-05
2024-03-18 12:58:43,362 - logger.py:50 - Epoch: [93][100/125] loss: 0.84262, MAE: 0.44246, time/step=3743ms, lr=1.65e-05
2024-03-18 13:00:11,999 - logger.py:50 - Epoch: [93][124/125] loss: 0.90055, MAE: 0.44406, time/step=3733ms, lr=1.65e-05
2024-03-18 13:01:07,239 - logger.py:50 - Epoch: [93] train MAE: 0.44406, val MAE: 0.44326, test MAE: 0.42833, Time: 521.93s
2024-03-18 13:01:07,239 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 13:01:10,874 - logger.py:50 - Epoch: [94][0/125] loss: 0.63252, MAE: 0.47590, time/step=3632ms, lr=1.60e-05
2024-03-18 13:04:16,637 - logger.py:50 - Epoch: [94][50/125] loss: 0.84325, MAE: 0.43919, time/step=3714ms, lr=1.60e-05
2024-03-18 13:07:23,994 - logger.py:50 - Epoch: [94][100/125] loss: 0.98708, MAE: 0.44291, time/step=3730ms, lr=1.60e-05
2024-03-18 13:08:53,762 - logger.py:50 - Epoch: [94][124/125] loss: 0.90250, MAE: 0.44428, time/step=3732ms, lr=1.60e-05
2024-03-18 13:09:48,587 - logger.py:50 - Epoch: [94] train MAE: 0.44428, val MAE: 0.44476, test MAE: 0.42959, Time: 521.35s
2024-03-18 13:09:48,587 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 13:09:52,241 - logger.py:50 - Epoch: [95][0/125] loss: 0.42497, MAE: 0.43895, time/step=3651ms, lr=1.55e-05
2024-03-18 13:12:58,598 - logger.py:50 - Epoch: [95][50/125] loss: 1.12288, MAE: 0.44533, time/step=3726ms, lr=1.55e-05
2024-03-18 13:16:07,301 - logger.py:50 - Epoch: [95][100/125] loss: 0.97323, MAE: 0.44575, time/step=3750ms, lr=1.55e-05
2024-03-18 13:17:36,650 - logger.py:50 - Epoch: [95][124/125] loss: 0.89988, MAE: 0.44421, time/step=3744ms, lr=1.55e-05
2024-03-18 13:18:31,788 - logger.py:50 - Epoch: [95] train MAE: 0.44421, val MAE: 0.44525, test MAE: 0.43021, Time: 523.20s
2024-03-18 13:18:31,788 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 13:18:35,389 - logger.py:50 - Epoch: [96][0/125] loss: 0.53434, MAE: 0.41729, time/step=3599ms, lr=1.51e-05
2024-03-18 13:21:42,633 - logger.py:50 - Epoch: [96][50/125] loss: 0.84471, MAE: 0.44240, time/step=3742ms, lr=1.51e-05
2024-03-18 13:24:48,888 - logger.py:50 - Epoch: [96][100/125] loss: 0.68575, MAE: 0.43905, time/step=3734ms, lr=1.51e-05
2024-03-18 13:26:18,801 - logger.py:50 - Epoch: [96][124/125] loss: 0.90649, MAE: 0.44429, time/step=3736ms, lr=1.51e-05
2024-03-18 13:27:14,026 - logger.py:50 - Epoch: [96] train MAE: 0.44429, val MAE: 0.44396, test MAE: 0.42889, Time: 522.24s
2024-03-18 13:27:14,027 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 13:27:17,558 - logger.py:50 - Epoch: [97][0/125] loss: 0.47987, MAE: 0.45316, time/step=3530ms, lr=1.46e-05
2024-03-18 13:30:24,593 - logger.py:50 - Epoch: [97][50/125] loss: 1.13522, MAE: 0.44631, time/step=3737ms, lr=1.46e-05
2024-03-18 13:33:32,139 - logger.py:50 - Epoch: [97][100/125] loss: 0.98520, MAE: 0.44508, time/step=3744ms, lr=1.46e-05
2024-03-18 13:35:00,988 - logger.py:50 - Epoch: [97][124/125] loss: 0.90078, MAE: 0.44420, time/step=3736ms, lr=1.46e-05
2024-03-18 13:35:56,264 - logger.py:50 - Epoch: [97] train MAE: 0.44420, val MAE: 0.44809, test MAE: 0.43298, Time: 522.24s
2024-03-18 13:35:56,264 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 13:35:59,919 - logger.py:50 - Epoch: [98][0/125] loss: 0.34205, MAE: 0.40822, time/step=3652ms, lr=1.41e-05
2024-03-18 13:39:06,811 - logger.py:50 - Epoch: [98][50/125] loss: 1.45101, MAE: 0.45747, time/step=3736ms, lr=1.41e-05
2024-03-18 13:42:12,906 - logger.py:50 - Epoch: [98][100/125] loss: 0.99235, MAE: 0.44716, time/step=3729ms, lr=1.41e-05
2024-03-18 13:43:43,956 - logger.py:50 - Epoch: [98][124/125] loss: 0.89831, MAE: 0.44431, time/step=3742ms, lr=1.41e-05
2024-03-18 13:44:38,220 - logger.py:50 - Epoch: [98] train MAE: 0.44431, val MAE: 0.44147, test MAE: 0.42633, Time: 521.96s
2024-03-18 13:44:38,220 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 13:44:42,122 - logger.py:50 - Epoch: [99][0/125] loss: 0.37866, MAE: 0.42293, time/step=3900ms, lr=1.37e-05
2024-03-18 13:47:48,149 - logger.py:50 - Epoch: [99][50/125] loss: 1.40236, MAE: 0.44994, time/step=3724ms, lr=1.37e-05
2024-03-18 13:50:54,726 - logger.py:50 - Epoch: [99][100/125] loss: 0.99358, MAE: 0.44702, time/step=3728ms, lr=1.37e-05
2024-03-18 13:52:25,546 - logger.py:50 - Epoch: [99][124/125] loss: 0.89914, MAE: 0.44413, time/step=3739ms, lr=1.37e-05
2024-03-18 13:53:20,127 - logger.py:50 - Epoch: [99] train MAE: 0.44413, val MAE: 0.44509, test MAE: 0.42996, Time: 521.91s
2024-03-18 13:53:20,127 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 13:53:23,666 - logger.py:50 - Epoch: [100][0/125] loss: 0.52351, MAE: 0.50077, time/step=3536ms, lr=1.32e-05
2024-03-18 13:56:31,697 - logger.py:50 - Epoch: [100][50/125] loss: 1.10566, MAE: 0.45150, time/step=3756ms, lr=1.32e-05
2024-03-18 13:59:38,959 - logger.py:50 - Epoch: [100][100/125] loss: 0.82904, MAE: 0.44216, time/step=3751ms, lr=1.32e-05
2024-03-18 14:01:08,395 - logger.py:50 - Epoch: [100][124/125] loss: 0.89692, MAE: 0.44429, time/step=3746ms, lr=1.32e-05
2024-03-18 14:02:03,713 - logger.py:50 - Epoch: [100] train MAE: 0.44429, val MAE: 0.44479, test MAE: 0.42976, Time: 523.59s
2024-03-18 14:02:03,713 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 14:02:07,498 - logger.py:50 - Epoch: [101][0/125] loss: 0.36429, MAE: 0.45721, time/step=3783ms, lr=1.28e-05
2024-03-18 14:05:14,139 - logger.py:50 - Epoch: [101][50/125] loss: 0.80744, MAE: 0.44141, time/step=3734ms, lr=1.28e-05
2024-03-18 14:08:21,533 - logger.py:50 - Epoch: [101][100/125] loss: 0.98462, MAE: 0.44645, time/step=3741ms, lr=1.28e-05
2024-03-18 14:09:50,677 - logger.py:50 - Epoch: [101][124/125] loss: 0.89579, MAE: 0.44423, time/step=3736ms, lr=1.28e-05
2024-03-18 14:10:45,487 - logger.py:50 - Epoch: [101] train MAE: 0.44423, val MAE: 0.44344, test MAE: 0.42834, Time: 521.77s
2024-03-18 14:10:45,487 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 14:10:48,966 - logger.py:50 - Epoch: [102][0/125] loss: 0.82818, MAE: 0.44063, time/step=3476ms, lr=1.24e-05
2024-03-18 14:13:56,322 - logger.py:50 - Epoch: [102][50/125] loss: 1.40885, MAE: 0.46046, time/step=3742ms, lr=1.24e-05
2024-03-18 14:17:03,275 - logger.py:50 - Epoch: [102][100/125] loss: 0.98463, MAE: 0.44685, time/step=3740ms, lr=1.24e-05
2024-03-18 14:18:33,317 - logger.py:50 - Epoch: [102][124/125] loss: 0.89351, MAE: 0.44425, time/step=3743ms, lr=1.24e-05
2024-03-18 14:19:27,609 - logger.py:50 - Epoch: [102] train MAE: 0.44425, val MAE: 0.44764, test MAE: 0.43250, Time: 522.12s
2024-03-18 14:19:27,609 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 14:19:31,948 - logger.py:50 - Epoch: [103][0/125] loss: 0.33926, MAE: 0.40346, time/step=4336ms, lr=1.19e-05
2024-03-18 14:22:37,383 - logger.py:50 - Epoch: [103][50/125] loss: 0.85546, MAE: 0.44720, time/step=3721ms, lr=1.19e-05
2024-03-18 14:25:43,675 - logger.py:50 - Epoch: [103][100/125] loss: 0.98503, MAE: 0.44549, time/step=3723ms, lr=1.19e-05
2024-03-18 14:27:15,266 - logger.py:50 - Epoch: [103][124/125] loss: 0.89296, MAE: 0.44415, time/step=3741ms, lr=1.19e-05
2024-03-18 14:28:09,529 - logger.py:50 - Epoch: [103] train MAE: 0.44415, val MAE: 0.44589, test MAE: 0.43078, Time: 521.92s
2024-03-18 14:28:09,529 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 14:28:13,228 - logger.py:50 - Epoch: [104][0/125] loss: 0.56541, MAE: 0.47920, time/step=3697ms, lr=1.15e-05
2024-03-18 14:31:21,263 - logger.py:50 - Epoch: [104][50/125] loss: 0.84133, MAE: 0.44644, time/step=3759ms, lr=1.15e-05
2024-03-18 14:34:27,463 - logger.py:50 - Epoch: [104][100/125] loss: 0.98611, MAE: 0.44861, time/step=3742ms, lr=1.15e-05
2024-03-18 14:35:58,215 - logger.py:50 - Epoch: [104][124/125] loss: 0.89348, MAE: 0.44430, time/step=3749ms, lr=1.15e-05
2024-03-18 14:36:53,808 - logger.py:50 - Epoch: [104] train MAE: 0.44430, val MAE: 0.44555, test MAE: 0.43036, Time: 524.28s
2024-03-18 14:36:53,808 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 14:36:57,517 - logger.py:50 - Epoch: [105][0/125] loss: 0.39849, MAE: 0.38989, time/step=3707ms, lr=1.11e-05
2024-03-18 14:40:04,198 - logger.py:50 - Epoch: [105][50/125] loss: 0.54697, MAE: 0.43864, time/step=3733ms, lr=1.11e-05
2024-03-18 14:43:11,732 - logger.py:50 - Epoch: [105][100/125] loss: 0.54837, MAE: 0.43904, time/step=3742ms, lr=1.11e-05
2024-03-18 14:44:42,243 - logger.py:50 - Epoch: [105][124/125] loss: 0.88840, MAE: 0.44414, time/step=3747ms, lr=1.11e-05
2024-03-18 14:45:37,255 - logger.py:50 - Epoch: [105] train MAE: 0.44414, val MAE: 0.44161, test MAE: 0.42649, Time: 523.45s
2024-03-18 14:45:37,255 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 14:45:41,664 - logger.py:50 - Epoch: [106][0/125] loss: 0.37548, MAE: 0.44954, time/step=4406ms, lr=1.07e-05
2024-03-18 14:48:48,347 - logger.py:50 - Epoch: [106][50/125] loss: 0.82321, MAE: 0.44243, time/step=3747ms, lr=1.07e-05
2024-03-18 14:51:55,933 - logger.py:50 - Epoch: [106][100/125] loss: 0.98294, MAE: 0.44753, time/step=3749ms, lr=1.07e-05
2024-03-18 14:53:26,096 - logger.py:50 - Epoch: [106][124/125] loss: 0.89106, MAE: 0.44417, time/step=3751ms, lr=1.07e-05
2024-03-18 14:54:20,340 - logger.py:50 - Epoch: [106] train MAE: 0.44417, val MAE: 0.44543, test MAE: 0.43029, Time: 523.09s
2024-03-18 14:54:20,341 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 14:54:23,987 - logger.py:50 - Epoch: [107][0/125] loss: 0.53210, MAE: 0.44482, time/step=3644ms, lr=1.03e-05
2024-03-18 14:57:32,725 - logger.py:50 - Epoch: [107][50/125] loss: 1.13247, MAE: 0.44648, time/step=3772ms, lr=1.03e-05
2024-03-18 15:00:40,047 - logger.py:50 - Epoch: [107][100/125] loss: 0.97741, MAE: 0.44543, time/step=3759ms, lr=1.03e-05
2024-03-18 15:02:09,649 - logger.py:50 - Epoch: [107][124/125] loss: 0.88865, MAE: 0.44426, time/step=3754ms, lr=1.03e-05
2024-03-18 15:03:05,257 - logger.py:50 - Epoch: [107] train MAE: 0.44426, val MAE: 0.44424, test MAE: 0.42901, Time: 524.92s
2024-03-18 15:03:05,257 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 15:03:08,995 - logger.py:50 - Epoch: [108][0/125] loss: 0.48338, MAE: 0.47823, time/step=3736ms, lr=9.88e-06
2024-03-18 15:06:15,832 - logger.py:50 - Epoch: [108][50/125] loss: 1.12017, MAE: 0.44778, time/step=3737ms, lr=9.88e-06
2024-03-18 15:09:23,652 - logger.py:50 - Epoch: [108][100/125] loss: 0.82220, MAE: 0.44381, time/step=3746ms, lr=9.88e-06
2024-03-18 15:10:53,623 - logger.py:50 - Epoch: [108][124/125] loss: 0.88673, MAE: 0.44419, time/step=3747ms, lr=9.88e-06
2024-03-18 15:11:48,757 - logger.py:50 - Epoch: [108] train MAE: 0.44419, val MAE: 0.44434, test MAE: 0.42928, Time: 523.50s
2024-03-18 15:11:48,757 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 15:11:52,484 - logger.py:50 - Epoch: [109][0/125] loss: 0.41977, MAE: 0.37993, time/step=3724ms, lr=9.49e-06
2024-03-18 15:15:00,339 - logger.py:50 - Epoch: [109][50/125] loss: 0.80397, MAE: 0.44839, time/step=3756ms, lr=9.49e-06
2024-03-18 15:18:08,524 - logger.py:50 - Epoch: [109][100/125] loss: 0.97919, MAE: 0.44546, time/step=3760ms, lr=9.49e-06
2024-03-18 15:19:37,628 - logger.py:50 - Epoch: [109][124/125] loss: 0.88548, MAE: 0.44427, time/step=3751ms, lr=9.49e-06
2024-03-18 15:20:33,273 - logger.py:50 - Epoch: [109] train MAE: 0.44427, val MAE: 0.44368, test MAE: 0.42842, Time: 524.52s
2024-03-18 15:20:33,273 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 15:20:36,896 - logger.py:50 - Epoch: [110][0/125] loss: 0.45602, MAE: 0.43315, time/step=3621ms, lr=9.11e-06
2024-03-18 15:23:44,925 - logger.py:50 - Epoch: [110][50/125] loss: 1.42077, MAE: 0.45594, time/step=3758ms, lr=9.11e-06
2024-03-18 15:26:51,671 - logger.py:50 - Epoch: [110][100/125] loss: 0.98177, MAE: 0.44536, time/step=3746ms, lr=9.11e-06
2024-03-18 15:28:21,853 - logger.py:50 - Epoch: [110][124/125] loss: 0.88745, MAE: 0.44420, time/step=3749ms, lr=9.11e-06
2024-03-18 15:29:16,966 - logger.py:50 - Epoch: [110] train MAE: 0.44420, val MAE: 0.44448, test MAE: 0.42936, Time: 523.69s
2024-03-18 15:29:16,966 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 15:29:21,073 - logger.py:50 - Epoch: [111][0/125] loss: 0.41953, MAE: 0.37573, time/step=4105ms, lr=8.73e-06
2024-03-18 15:32:28,883 - logger.py:50 - Epoch: [111][50/125] loss: 0.55022, MAE: 0.44463, time/step=3763ms, lr=8.73e-06
2024-03-18 15:35:36,439 - logger.py:50 - Epoch: [111][100/125] loss: 0.97063, MAE: 0.44763, time/step=3757ms, lr=8.73e-06
2024-03-18 15:37:05,878 - logger.py:50 - Epoch: [111][124/125] loss: 0.88745, MAE: 0.44425, time/step=3751ms, lr=8.73e-06
2024-03-18 15:38:01,080 - logger.py:50 - Epoch: [111] train MAE: 0.44425, val MAE: 0.44604, test MAE: 0.43076, Time: 524.11s
2024-03-18 15:38:01,081 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 15:38:04,730 - logger.py:50 - Epoch: [112][0/125] loss: 0.56393, MAE: 0.38289, time/step=3647ms, lr=8.36e-06
2024-03-18 15:41:12,767 - logger.py:50 - Epoch: [112][50/125] loss: 0.54675, MAE: 0.44260, time/step=3759ms, lr=8.36e-06
2024-03-18 15:44:20,655 - logger.py:50 - Epoch: [112][100/125] loss: 0.66838, MAE: 0.44212, time/step=3758ms, lr=8.36e-06
2024-03-18 15:45:50,348 - logger.py:50 - Epoch: [112][124/125] loss: 0.88370, MAE: 0.44424, time/step=3754ms, lr=8.36e-06
2024-03-18 15:46:44,888 - logger.py:50 - Epoch: [112] train MAE: 0.44424, val MAE: 0.44365, test MAE: 0.42840, Time: 523.81s
2024-03-18 15:46:44,888 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 15:46:48,653 - logger.py:50 - Epoch: [113][0/125] loss: 0.38476, MAE: 0.42973, time/step=3763ms, lr=8.00e-06
2024-03-18 15:49:57,152 - logger.py:50 - Epoch: [113][50/125] loss: 0.51003, MAE: 0.44141, time/step=3770ms, lr=8.00e-06
2024-03-18 15:53:03,781 - logger.py:50 - Epoch: [113][100/125] loss: 0.52833, MAE: 0.43807, time/step=3751ms, lr=8.00e-06
2024-03-18 15:54:34,303 - logger.py:50 - Epoch: [113][124/125] loss: 0.88307, MAE: 0.44425, time/step=3755ms, lr=8.00e-06
2024-03-18 15:55:28,898 - logger.py:50 - Epoch: [113] train MAE: 0.44425, val MAE: 0.44434, test MAE: 0.42919, Time: 524.01s
2024-03-18 15:55:28,898 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 15:55:32,548 - logger.py:50 - Epoch: [114][0/125] loss: 0.52542, MAE: 0.41879, time/step=3648ms, lr=7.64e-06
2024-03-18 15:58:40,903 - logger.py:50 - Epoch: [114][50/125] loss: 1.36613, MAE: 0.45044, time/step=3765ms, lr=7.64e-06
2024-03-18 16:01:47,179 - logger.py:50 - Epoch: [114][100/125] loss: 0.95270, MAE: 0.44369, time/step=3745ms, lr=7.64e-06
2024-03-18 16:03:17,825 - logger.py:50 - Epoch: [114][124/125] loss: 0.88386, MAE: 0.44424, time/step=3751ms, lr=7.64e-06
2024-03-18 16:04:12,070 - logger.py:50 - Epoch: [114] train MAE: 0.44424, val MAE: 0.44469, test MAE: 0.42927, Time: 523.17s
2024-03-18 16:04:12,070 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 16:04:16,403 - logger.py:50 - Epoch: [115][0/125] loss: 0.52540, MAE: 0.42934, time/step=4331ms, lr=7.29e-06
2024-03-18 16:07:23,026 - logger.py:50 - Epoch: [115][50/125] loss: 0.82107, MAE: 0.44440, time/step=3744ms, lr=7.29e-06
2024-03-18 16:10:30,398 - logger.py:50 - Epoch: [115][100/125] loss: 0.67768, MAE: 0.44250, time/step=3746ms, lr=7.29e-06
2024-03-18 16:11:59,229 - logger.py:50 - Epoch: [115][124/125] loss: 0.89329, MAE: 0.44423, time/step=3737ms, lr=7.29e-06
2024-03-18 16:12:54,542 - logger.py:50 - Epoch: [115] train MAE: 0.44423, val MAE: 0.44103, test MAE: 0.42556, Time: 522.47s
2024-03-18 16:12:54,542 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 16:12:58,290 - logger.py:50 - Epoch: [116][0/125] loss: 0.65257, MAE: 0.45564, time/step=3746ms, lr=6.95e-06
2024-03-18 16:16:03,715 - logger.py:50 - Epoch: [116][50/125] loss: 0.51630, MAE: 0.43778, time/step=3709ms, lr=6.95e-06
2024-03-18 16:19:11,722 - logger.py:50 - Epoch: [116][100/125] loss: 0.83607, MAE: 0.44426, time/step=3734ms, lr=6.95e-06
2024-03-18 16:20:41,477 - logger.py:50 - Epoch: [116][124/125] loss: 0.88619, MAE: 0.44431, time/step=3735ms, lr=6.95e-06
2024-03-18 16:21:35,793 - logger.py:50 - Epoch: [116] train MAE: 0.44431, val MAE: 0.44376, test MAE: 0.42878, Time: 521.25s
2024-03-18 16:21:35,793 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 16:21:39,468 - logger.py:50 - Epoch: [117][0/125] loss: 0.31449, MAE: 0.38732, time/step=3673ms, lr=6.62e-06
2024-03-18 16:24:46,118 - logger.py:50 - Epoch: [117][50/125] loss: 0.85544, MAE: 0.44299, time/step=3732ms, lr=6.62e-06
2024-03-18 16:27:54,146 - logger.py:50 - Epoch: [117][100/125] loss: 0.67946, MAE: 0.44202, time/step=3746ms, lr=6.62e-06
2024-03-18 16:29:22,567 - logger.py:50 - Epoch: [117][124/125] loss: 0.88391, MAE: 0.44414, time/step=3734ms, lr=6.62e-06
2024-03-18 16:30:17,435 - logger.py:50 - Epoch: [117] train MAE: 0.44414, val MAE: 0.44462, test MAE: 0.42945, Time: 521.64s
2024-03-18 16:30:17,435 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 16:30:21,030 - logger.py:50 - Epoch: [118][0/125] loss: 0.36256, MAE: 0.42406, time/step=3593ms, lr=6.30e-06
2024-03-18 16:33:28,315 - logger.py:50 - Epoch: [118][50/125] loss: 1.35789, MAE: 0.45066, time/step=3743ms, lr=6.30e-06
2024-03-18 16:36:34,406 - logger.py:50 - Epoch: [118][100/125] loss: 0.95575, MAE: 0.44606, time/step=3732ms, lr=6.30e-06
2024-03-18 16:38:04,286 - logger.py:50 - Epoch: [118][124/125] loss: 0.88292, MAE: 0.44424, time/step=3735ms, lr=6.30e-06
2024-03-18 16:38:59,130 - logger.py:50 - Epoch: [118] train MAE: 0.44424, val MAE: 0.44476, test MAE: 0.42965, Time: 521.69s
2024-03-18 16:38:59,130 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 16:39:03,461 - logger.py:50 - Epoch: [119][0/125] loss: 0.33733, MAE: 0.41662, time/step=4329ms, lr=5.99e-06
2024-03-18 16:42:08,420 - logger.py:50 - Epoch: [119][50/125] loss: 0.83610, MAE: 0.44874, time/step=3712ms, lr=5.99e-06
2024-03-18 16:45:16,134 - logger.py:50 - Epoch: [119][100/125] loss: 0.67439, MAE: 0.44016, time/step=3733ms, lr=5.99e-06
2024-03-18 16:46:45,494 - logger.py:50 - Epoch: [119][124/125] loss: 0.88084, MAE: 0.44411, time/step=3731ms, lr=5.99e-06
2024-03-18 16:47:40,212 - logger.py:50 - Epoch: [119] train MAE: 0.44411, val MAE: 0.44671, test MAE: 0.43152, Time: 521.08s
2024-03-18 16:47:40,212 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 16:47:44,720 - logger.py:50 - Epoch: [120][0/125] loss: 0.35297, MAE: 0.44242, time/step=4506ms, lr=5.68e-06
2024-03-18 16:50:51,095 - logger.py:50 - Epoch: [120][50/125] loss: 1.08403, MAE: 0.44611, time/step=3743ms, lr=5.68e-06
2024-03-18 16:53:57,540 - logger.py:50 - Epoch: [120][100/125] loss: 0.96878, MAE: 0.44457, time/step=3736ms, lr=5.68e-06
2024-03-18 16:55:27,514 - logger.py:50 - Epoch: [120][124/125] loss: 0.88115, MAE: 0.44430, time/step=3738ms, lr=5.68e-06
2024-03-18 16:56:21,804 - logger.py:50 - Epoch: [120] train MAE: 0.44430, val MAE: 0.44616, test MAE: 0.43103, Time: 521.59s
2024-03-18 16:56:21,804 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 16:56:25,619 - logger.py:50 - Epoch: [121][0/125] loss: 0.59112, MAE: 0.46638, time/step=3812ms, lr=5.38e-06
2024-03-18 16:59:32,087 - logger.py:50 - Epoch: [121][50/125] loss: 0.54848, MAE: 0.44091, time/step=3731ms, lr=5.38e-06
2024-03-18 17:02:39,039 - logger.py:50 - Epoch: [121][100/125] loss: 0.81974, MAE: 0.44496, time/step=3735ms, lr=5.38e-06
2024-03-18 17:04:08,327 - logger.py:50 - Epoch: [121][124/125] loss: 0.88285, MAE: 0.44421, time/step=3732ms, lr=5.38e-06
2024-03-18 17:05:03,187 - logger.py:50 - Epoch: [121] train MAE: 0.44421, val MAE: 0.44548, test MAE: 0.43029, Time: 521.38s
2024-03-18 17:05:03,187 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 17:05:06,807 - logger.py:50 - Epoch: [122][0/125] loss: 0.31768, MAE: 0.39588, time/step=3618ms, lr=5.09e-06
2024-03-18 17:08:12,867 - logger.py:50 - Epoch: [122][50/125] loss: 0.52867, MAE: 0.44227, time/step=3719ms, lr=5.09e-06
2024-03-18 17:11:19,858 - logger.py:50 - Epoch: [122][100/125] loss: 0.96904, MAE: 0.44644, time/step=3729ms, lr=5.09e-06
2024-03-18 17:12:50,307 - logger.py:50 - Epoch: [122][124/125] loss: 0.88069, MAE: 0.44420, time/step=3737ms, lr=5.09e-06
2024-03-18 17:13:44,606 - logger.py:50 - Epoch: [122] train MAE: 0.44420, val MAE: 0.44745, test MAE: 0.43215, Time: 521.42s
2024-03-18 17:13:44,606 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 17:13:48,866 - logger.py:50 - Epoch: [123][0/125] loss: 0.78211, MAE: 0.50215, time/step=4258ms, lr=4.81e-06
2024-03-18 17:16:56,421 - logger.py:50 - Epoch: [123][50/125] loss: 0.53733, MAE: 0.43359, time/step=3761ms, lr=4.81e-06
2024-03-18 17:20:03,889 - logger.py:50 - Epoch: [123][100/125] loss: 0.52766, MAE: 0.43821, time/step=3755ms, lr=4.81e-06
2024-03-18 17:21:34,020 - logger.py:50 - Epoch: [123][124/125] loss: 0.88152, MAE: 0.44425, time/step=3755ms, lr=4.81e-06
2024-03-18 17:22:29,126 - logger.py:50 - Epoch: [123] train MAE: 0.44425, val MAE: 0.44197, test MAE: 0.42687, Time: 524.52s
2024-03-18 17:22:29,126 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 17:22:32,960 - logger.py:50 - Epoch: [124][0/125] loss: 0.51777, MAE: 0.49842, time/step=3831ms, lr=4.54e-06
2024-03-18 17:25:39,815 - logger.py:50 - Epoch: [124][50/125] loss: 0.49899, MAE: 0.43517, time/step=3739ms, lr=4.54e-06
2024-03-18 17:28:47,093 - logger.py:50 - Epoch: [124][100/125] loss: 0.82260, MAE: 0.44276, time/step=3742ms, lr=4.54e-06
2024-03-18 17:30:17,949 - logger.py:50 - Epoch: [124][124/125] loss: 0.88054, MAE: 0.44420, time/step=3751ms, lr=4.54e-06
2024-03-18 17:31:12,552 - logger.py:50 - Epoch: [124] train MAE: 0.44420, val MAE: 0.44348, test MAE: 0.42832, Time: 523.43s
2024-03-18 17:31:12,553 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 17:31:16,214 - logger.py:50 - Epoch: [125][0/125] loss: 0.75528, MAE: 0.43390, time/step=3659ms, lr=4.28e-06
2024-03-18 17:34:24,437 - logger.py:50 - Epoch: [125][50/125] loss: 0.82538, MAE: 0.44356, time/step=3762ms, lr=4.28e-06
2024-03-18 17:37:31,810 - logger.py:50 - Epoch: [125][100/125] loss: 0.97736, MAE: 0.44550, time/step=3755ms, lr=4.28e-06
2024-03-18 17:39:01,139 - logger.py:50 - Epoch: [125][124/125] loss: 0.88068, MAE: 0.44423, time/step=3749ms, lr=4.28e-06
2024-03-18 17:39:55,970 - logger.py:50 - Epoch: [125] train MAE: 0.44423, val MAE: 0.44308, test MAE: 0.42788, Time: 523.42s
2024-03-18 17:39:55,970 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 17:39:59,919 - logger.py:50 - Epoch: [126][0/125] loss: 0.45917, MAE: 0.38258, time/step=3947ms, lr=4.03e-06
2024-03-18 17:43:06,387 - logger.py:50 - Epoch: [126][50/125] loss: 0.51221, MAE: 0.43713, time/step=3734ms, lr=4.03e-06
2024-03-18 17:46:14,844 - logger.py:50 - Epoch: [126][100/125] loss: 0.95496, MAE: 0.44529, time/step=3751ms, lr=4.03e-06
2024-03-18 17:47:43,492 - logger.py:50 - Epoch: [126][124/125] loss: 0.88018, MAE: 0.44419, time/step=3740ms, lr=4.03e-06
2024-03-18 17:48:38,273 - logger.py:50 - Epoch: [126] train MAE: 0.44419, val MAE: 0.44412, test MAE: 0.42889, Time: 522.30s
2024-03-18 17:48:38,273 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 17:48:42,034 - logger.py:50 - Epoch: [127][0/125] loss: 0.58408, MAE: 0.41570, time/step=3758ms, lr=3.79e-06
2024-03-18 17:51:47,866 - logger.py:50 - Epoch: [127][50/125] loss: 0.51395, MAE: 0.43356, time/step=3717ms, lr=3.79e-06
2024-03-18 17:54:53,639 - logger.py:50 - Epoch: [127][100/125] loss: 0.96494, MAE: 0.44505, time/step=3716ms, lr=3.79e-06
2024-03-18 17:56:24,602 - logger.py:50 - Epoch: [127][124/125] loss: 0.87914, MAE: 0.44424, time/step=3731ms, lr=3.79e-06
2024-03-18 17:57:19,909 - logger.py:50 - Epoch: [127] train MAE: 0.44424, val MAE: 0.44473, test MAE: 0.42961, Time: 521.64s
2024-03-18 17:57:19,910 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 17:57:23,365 - logger.py:50 - Epoch: [128][0/125] loss: 0.38451, MAE: 0.40513, time/step=3453ms, lr=3.56e-06
2024-03-18 18:00:30,054 - logger.py:50 - Epoch: [128][50/125] loss: 0.54148, MAE: 0.44881, time/step=3728ms, lr=3.56e-06
2024-03-18 18:03:36,784 - logger.py:50 - Epoch: [128][100/125] loss: 0.97522, MAE: 0.44851, time/step=3731ms, lr=3.56e-06
2024-03-18 18:05:07,269 - logger.py:50 - Epoch: [128][124/125] loss: 0.87875, MAE: 0.44423, time/step=3739ms, lr=3.56e-06
2024-03-18 18:06:01,614 - logger.py:50 - Epoch: [128] train MAE: 0.44423, val MAE: 0.44523, test MAE: 0.43003, Time: 521.70s
2024-03-18 18:06:01,615 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 18:06:05,810 - logger.py:50 - Epoch: [129][0/125] loss: 0.39566, MAE: 0.42665, time/step=4193ms, lr=3.33e-06
2024-03-18 18:09:12,961 - logger.py:50 - Epoch: [129][50/125] loss: 1.09398, MAE: 0.45112, time/step=3752ms, lr=3.33e-06
2024-03-18 18:12:18,870 - logger.py:50 - Epoch: [129][100/125] loss: 0.96533, MAE: 0.44560, time/step=3735ms, lr=3.33e-06
2024-03-18 18:13:48,515 - logger.py:50 - Epoch: [129][124/125] loss: 0.87892, MAE: 0.44423, time/step=3735ms, lr=3.33e-06
2024-03-18 18:14:43,325 - logger.py:50 - Epoch: [129] train MAE: 0.44423, val MAE: 0.44333, test MAE: 0.42818, Time: 521.71s
2024-03-18 18:14:43,325 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 18:14:47,530 - logger.py:50 - Epoch: [130][0/125] loss: 0.45396, MAE: 0.43193, time/step=4202ms, lr=3.12e-06
2024-03-18 18:17:54,718 - logger.py:50 - Epoch: [130][50/125] loss: 1.39171, MAE: 0.45521, time/step=3753ms, lr=3.12e-06
2024-03-18 18:21:01,705 - logger.py:50 - Epoch: [130][100/125] loss: 0.96133, MAE: 0.44605, time/step=3746ms, lr=3.12e-06
2024-03-18 18:22:30,887 - logger.py:50 - Epoch: [130][124/125] loss: 0.87823, MAE: 0.44421, time/step=3740ms, lr=3.12e-06
2024-03-18 18:23:25,553 - logger.py:50 - Epoch: [130] train MAE: 0.44421, val MAE: 0.44464, test MAE: 0.42928, Time: 522.23s
2024-03-18 18:23:25,553 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 18:23:29,788 - logger.py:50 - Epoch: [131][0/125] loss: 0.30789, MAE: 0.46017, time/step=4232ms, lr=2.91e-06
2024-03-18 18:26:36,277 - logger.py:50 - Epoch: [131][50/125] loss: 1.11273, MAE: 0.44543, time/step=3740ms, lr=2.91e-06
2024-03-18 18:29:43,344 - logger.py:50 - Epoch: [131][100/125] loss: 0.81778, MAE: 0.44161, time/step=3740ms, lr=2.91e-06
2024-03-18 18:31:13,068 - logger.py:50 - Epoch: [131][124/125] loss: 0.87906, MAE: 0.44422, time/step=3740ms, lr=2.91e-06
2024-03-18 18:32:07,723 - logger.py:50 - Epoch: [131] train MAE: 0.44422, val MAE: 0.44617, test MAE: 0.43095, Time: 522.17s
2024-03-18 18:32:07,723 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 18:32:11,627 - logger.py:50 - Epoch: [132][0/125] loss: 0.30356, MAE: 0.39203, time/step=3902ms, lr=2.72e-06
2024-03-18 18:35:17,620 - logger.py:50 - Epoch: [132][50/125] loss: 0.51564, MAE: 0.43989, time/step=3723ms, lr=2.72e-06
2024-03-18 18:38:24,444 - logger.py:50 - Epoch: [132][100/125] loss: 0.82134, MAE: 0.44227, time/step=3730ms, lr=2.72e-06
2024-03-18 18:39:54,008 - logger.py:50 - Epoch: [132][124/125] loss: 0.87759, MAE: 0.44424, time/step=3730ms, lr=2.72e-06
2024-03-18 18:40:49,066 - logger.py:50 - Epoch: [132] train MAE: 0.44424, val MAE: 0.44553, test MAE: 0.43032, Time: 521.34s
2024-03-18 18:40:49,066 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 18:40:53,327 - logger.py:50 - Epoch: [133][0/125] loss: 30.22144, MAE: 0.97626, time/step=4259ms, lr=2.54e-06
2024-03-18 18:43:59,557 - logger.py:50 - Epoch: [133][50/125] loss: 1.10908, MAE: 0.44944, time/step=3735ms, lr=2.54e-06
2024-03-18 18:47:06,702 - logger.py:50 - Epoch: [133][100/125] loss: 0.81249, MAE: 0.44377, time/step=3739ms, lr=2.54e-06
2024-03-18 18:48:36,002 - logger.py:50 - Epoch: [133][124/125] loss: 0.87659, MAE: 0.44422, time/step=3735ms, lr=2.54e-06
2024-03-18 18:49:31,307 - logger.py:50 - Epoch: [133] train MAE: 0.44422, val MAE: 0.44525, test MAE: 0.42998, Time: 522.24s
2024-03-18 18:49:31,307 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 18:49:34,827 - logger.py:50 - Epoch: [134][0/125] loss: 0.62342, MAE: 0.44258, time/step=3518ms, lr=2.36e-06
2024-03-18 18:52:41,024 - logger.py:50 - Epoch: [134][50/125] loss: 0.53634, MAE: 0.44002, time/step=3720ms, lr=2.36e-06
2024-03-18 18:55:48,619 - logger.py:50 - Epoch: [134][100/125] loss: 0.66863, MAE: 0.44295, time/step=3736ms, lr=2.36e-06
2024-03-18 18:57:18,023 - logger.py:50 - Epoch: [134][124/125] loss: 0.87699, MAE: 0.44422, time/step=3734ms, lr=2.36e-06
2024-03-18 18:58:13,621 - logger.py:50 - Epoch: [134] train MAE: 0.44422, val MAE: 0.44484, test MAE: 0.42955, Time: 522.31s
2024-03-18 18:58:13,621 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 18:58:17,340 - logger.py:50 - Epoch: [135][0/125] loss: 0.50986, MAE: 0.41406, time/step=3716ms, lr=2.20e-06
2024-03-18 19:01:24,816 - logger.py:50 - Epoch: [135][50/125] loss: 1.09662, MAE: 0.44168, time/step=3749ms, lr=2.20e-06
2024-03-18 19:04:32,919 - logger.py:50 - Epoch: [135][100/125] loss: 0.80421, MAE: 0.44189, time/step=3755ms, lr=2.20e-06
2024-03-18 19:06:02,181 - logger.py:50 - Epoch: [135][124/125] loss: 0.87748, MAE: 0.44429, time/step=3748ms, lr=2.20e-06
2024-03-18 19:06:57,265 - logger.py:50 - Epoch: [135] train MAE: 0.44429, val MAE: 0.44467, test MAE: 0.42945, Time: 523.64s
2024-03-18 19:06:57,265 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 19:07:01,527 - logger.py:50 - Epoch: [136][0/125] loss: 0.42081, MAE: 0.42863, time/step=4259ms, lr=2.05e-06
2024-03-18 19:10:09,870 - logger.py:50 - Epoch: [136][50/125] loss: 0.82094, MAE: 0.44821, time/step=3776ms, lr=2.05e-06
2024-03-18 19:13:16,667 - logger.py:50 - Epoch: [136][100/125] loss: 0.67529, MAE: 0.44229, time/step=3756ms, lr=2.05e-06
2024-03-18 19:14:46,794 - logger.py:50 - Epoch: [136][124/125] loss: 0.87888, MAE: 0.44418, time/step=3756ms, lr=2.05e-06
2024-03-18 19:15:41,847 - logger.py:50 - Epoch: [136] train MAE: 0.44418, val MAE: 0.44350, test MAE: 0.42823, Time: 524.58s
2024-03-18 19:15:41,848 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 19:15:45,403 - logger.py:50 - Epoch: [137][0/125] loss: 0.44285, MAE: 0.41605, time/step=3553ms, lr=1.90e-06
2024-03-18 19:18:53,435 - logger.py:50 - Epoch: [137][50/125] loss: 1.41492, MAE: 0.46047, time/step=3757ms, lr=1.90e-06
2024-03-18 19:22:00,653 - logger.py:50 - Epoch: [137][100/125] loss: 0.96607, MAE: 0.44742, time/step=3751ms, lr=1.90e-06
2024-03-18 19:23:29,847 - logger.py:50 - Epoch: [137][124/125] loss: 0.87702, MAE: 0.44421, time/step=3744ms, lr=1.90e-06
2024-03-18 19:24:25,526 - logger.py:50 - Epoch: [137] train MAE: 0.44421, val MAE: 0.44538, test MAE: 0.43014, Time: 523.68s
2024-03-18 19:24:25,526 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 19:24:29,158 - logger.py:50 - Epoch: [138][0/125] loss: 0.38665, MAE: 0.43475, time/step=3629ms, lr=1.77e-06
2024-03-18 19:27:38,251 - logger.py:50 - Epoch: [138][50/125] loss: 0.79508, MAE: 0.44501, time/step=3779ms, lr=1.77e-06
2024-03-18 19:30:44,600 - logger.py:50 - Epoch: [138][100/125] loss: 0.96210, MAE: 0.44647, time/step=3753ms, lr=1.77e-06
2024-03-18 19:32:14,952 - logger.py:50 - Epoch: [138][124/125] loss: 0.87664, MAE: 0.44423, time/step=3755ms, lr=1.77e-06
2024-03-18 19:33:09,875 - logger.py:50 - Epoch: [138] train MAE: 0.44423, val MAE: 0.44559, test MAE: 0.43033, Time: 524.35s
2024-03-18 19:33:09,876 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 19:33:13,698 - logger.py:50 - Epoch: [139][0/125] loss: 0.62851, MAE: 0.45889, time/step=3820ms, lr=1.65e-06
2024-03-18 19:36:20,700 - logger.py:50 - Epoch: [139][50/125] loss: 0.84188, MAE: 0.45119, time/step=3742ms, lr=1.65e-06
2024-03-18 19:39:28,542 - logger.py:50 - Epoch: [139][100/125] loss: 0.96211, MAE: 0.44559, time/step=3749ms, lr=1.65e-06
2024-03-18 19:40:58,519 - logger.py:50 - Epoch: [139][124/125] loss: 0.87723, MAE: 0.44427, time/step=3749ms, lr=1.65e-06
2024-03-18 19:41:53,556 - logger.py:50 - Epoch: [139] train MAE: 0.44427, val MAE: 0.44396, test MAE: 0.42870, Time: 523.68s
2024-03-18 19:41:53,557 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 19:41:57,840 - logger.py:50 - Epoch: [140][0/125] loss: 0.56044, MAE: 0.46637, time/step=4281ms, lr=1.54e-06
2024-03-18 19:45:04,208 - logger.py:50 - Epoch: [140][50/125] loss: 0.54371, MAE: 0.43519, time/step=3738ms, lr=1.54e-06
2024-03-18 19:48:10,944 - logger.py:50 - Epoch: [140][100/125] loss: 0.53548, MAE: 0.43745, time/step=3736ms, lr=1.54e-06
2024-03-18 19:49:41,151 - logger.py:50 - Epoch: [140][124/125] loss: 0.87522, MAE: 0.44423, time/step=3741ms, lr=1.54e-06
2024-03-18 19:50:36,492 - logger.py:50 - Epoch: [140] train MAE: 0.44423, val MAE: 0.44399, test MAE: 0.42880, Time: 522.94s
2024-03-18 19:50:36,492 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 19:50:40,647 - logger.py:50 - Epoch: [141][0/125] loss: 0.47810, MAE: 0.48925, time/step=4152ms, lr=1.43e-06
2024-03-18 19:53:47,531 - logger.py:50 - Epoch: [141][50/125] loss: 0.50078, MAE: 0.44563, time/step=3746ms, lr=1.43e-06
2024-03-18 19:56:53,858 - logger.py:50 - Epoch: [141][100/125] loss: 0.66992, MAE: 0.44138, time/step=3736ms, lr=1.43e-06
2024-03-18 19:58:23,577 - logger.py:50 - Epoch: [141][124/125] loss: 0.87662, MAE: 0.44418, time/step=3737ms, lr=1.43e-06
2024-03-18 19:59:17,907 - logger.py:50 - Epoch: [141] train MAE: 0.44418, val MAE: 0.44416, test MAE: 0.42893, Time: 521.41s
2024-03-18 19:59:17,908 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 19:59:22,004 - logger.py:50 - Epoch: [142][0/125] loss: 0.40210, MAE: 0.42342, time/step=4095ms, lr=1.34e-06
2024-03-18 20:02:27,942 - logger.py:50 - Epoch: [142][50/125] loss: 0.50520, MAE: 0.43494, time/step=3726ms, lr=1.34e-06
2024-03-18 20:05:35,020 - logger.py:50 - Epoch: [142][100/125] loss: 0.95356, MAE: 0.44346, time/step=3734ms, lr=1.34e-06
2024-03-18 20:07:04,674 - logger.py:50 - Epoch: [142][124/125] loss: 0.87537, MAE: 0.44426, time/step=3734ms, lr=1.34e-06
2024-03-18 20:07:59,951 - logger.py:50 - Epoch: [142] train MAE: 0.44426, val MAE: 0.44429, test MAE: 0.42901, Time: 522.04s
2024-03-18 20:07:59,951 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 20:08:03,822 - logger.py:50 - Epoch: [143][0/125] loss: 0.23670, MAE: 0.43071, time/step=3868ms, lr=1.26e-06
2024-03-18 20:11:10,588 - logger.py:50 - Epoch: [143][50/125] loss: 0.79783, MAE: 0.44363, time/step=3738ms, lr=1.26e-06
2024-03-18 20:14:17,756 - logger.py:50 - Epoch: [143][100/125] loss: 0.96194, MAE: 0.44590, time/step=3741ms, lr=1.26e-06
2024-03-18 20:15:48,070 - logger.py:50 - Epoch: [143][124/125] loss: 0.87839, MAE: 0.44424, time/step=3745ms, lr=1.26e-06
2024-03-18 20:16:43,696 - logger.py:50 - Epoch: [143] train MAE: 0.44424, val MAE: 0.44361, test MAE: 0.42827, Time: 523.74s
2024-03-18 20:16:43,696 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 20:16:47,461 - logger.py:50 - Epoch: [144][0/125] loss: 0.39673, MAE: 0.44139, time/step=3762ms, lr=1.19e-06
2024-03-18 20:19:55,535 - logger.py:50 - Epoch: [144][50/125] loss: 1.10443, MAE: 0.45285, time/step=3761ms, lr=1.19e-06
2024-03-18 20:23:02,194 - logger.py:50 - Epoch: [144][100/125] loss: 0.81506, MAE: 0.44090, time/step=3747ms, lr=1.19e-06
2024-03-18 20:24:32,273 - logger.py:50 - Epoch: [144][124/125] loss: 0.87444, MAE: 0.44419, time/step=3749ms, lr=1.19e-06
2024-03-18 20:25:27,804 - logger.py:50 - Epoch: [144] train MAE: 0.44419, val MAE: 0.44458, test MAE: 0.42936, Time: 524.11s
2024-03-18 20:25:27,804 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 20:25:31,566 - logger.py:50 - Epoch: [145][0/125] loss: 0.44596, MAE: 0.40469, time/step=3760ms, lr=1.13e-06
2024-03-18 20:28:38,779 - logger.py:50 - Epoch: [145][50/125] loss: 0.79512, MAE: 0.44519, time/step=3745ms, lr=1.13e-06
2024-03-18 20:31:46,403 - logger.py:50 - Epoch: [145][100/125] loss: 0.65819, MAE: 0.44115, time/step=3748ms, lr=1.13e-06
2024-03-18 20:33:15,994 - logger.py:50 - Epoch: [145][124/125] loss: 0.87599, MAE: 0.44424, time/step=3746ms, lr=1.13e-06
2024-03-18 20:34:11,149 - logger.py:50 - Epoch: [145] train MAE: 0.44424, val MAE: 0.44448, test MAE: 0.42924, Time: 523.34s
2024-03-18 20:34:11,149 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 20:34:15,477 - logger.py:50 - Epoch: [146][0/125] loss: 0.73345, MAE: 0.43663, time/step=4326ms, lr=1.09e-06
2024-03-18 20:37:23,675 - logger.py:50 - Epoch: [146][50/125] loss: 1.10879, MAE: 0.44741, time/step=3775ms, lr=1.09e-06
2024-03-18 20:40:29,958 - logger.py:50 - Epoch: [146][100/125] loss: 0.95603, MAE: 0.44459, time/step=3751ms, lr=1.09e-06
2024-03-18 20:41:59,969 - logger.py:50 - Epoch: [146][124/125] loss: 0.87541, MAE: 0.44425, time/step=3751ms, lr=1.09e-06
2024-03-18 20:42:55,035 - logger.py:50 - Epoch: [146] train MAE: 0.44425, val MAE: 0.44466, test MAE: 0.42945, Time: 523.89s
2024-03-18 20:42:55,035 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 20:42:58,757 - logger.py:50 - Epoch: [147][0/125] loss: 0.64676, MAE: 0.45234, time/step=3720ms, lr=1.05e-06
2024-03-18 20:46:05,330 - logger.py:50 - Epoch: [147][50/125] loss: 1.11149, MAE: 0.44945, time/step=3731ms, lr=1.05e-06
2024-03-18 20:49:13,377 - logger.py:50 - Epoch: [147][100/125] loss: 0.96103, MAE: 0.44380, time/step=3746ms, lr=1.05e-06
2024-03-18 20:50:43,377 - logger.py:50 - Epoch: [147][124/125] loss: 0.87584, MAE: 0.44426, time/step=3747ms, lr=1.05e-06
2024-03-18 20:51:38,400 - logger.py:50 - Epoch: [147] train MAE: 0.44426, val MAE: 0.44418, test MAE: 0.42896, Time: 523.37s
2024-03-18 20:51:38,401 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 20:51:42,126 - logger.py:50 - Epoch: [148][0/125] loss: 0.52850, MAE: 0.44648, time/step=3723ms, lr=1.02e-06
2024-03-18 20:54:49,579 - logger.py:50 - Epoch: [148][50/125] loss: 0.79780, MAE: 0.44536, time/step=3749ms, lr=1.02e-06
2024-03-18 20:57:57,048 - logger.py:50 - Epoch: [148][100/125] loss: 0.96069, MAE: 0.44644, time/step=3749ms, lr=1.02e-06
2024-03-18 20:59:27,281 - logger.py:50 - Epoch: [148][124/125] loss: 0.87669, MAE: 0.44415, time/step=3751ms, lr=1.02e-06
2024-03-18 21:00:21,865 - logger.py:50 - Epoch: [148] train MAE: 0.44415, val MAE: 0.44457, test MAE: 0.42934, Time: 523.46s
2024-03-18 21:00:21,865 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 21:00:26,069 - logger.py:50 - Epoch: [149][0/125] loss: 0.49982, MAE: 0.43018, time/step=4201ms, lr=1.01e-06
2024-03-18 21:03:34,287 - logger.py:50 - Epoch: [149][50/125] loss: 1.37440, MAE: 0.45573, time/step=3773ms, lr=1.01e-06
2024-03-18 21:06:41,101 - logger.py:50 - Epoch: [149][100/125] loss: 0.95046, MAE: 0.44676, time/step=3755ms, lr=1.01e-06
2024-03-18 21:08:10,588 - logger.py:50 - Epoch: [149][124/125] loss: 0.87631, MAE: 0.44416, time/step=3750ms, lr=1.01e-06
2024-03-18 21:09:05,772 - logger.py:50 - Epoch: [149] train MAE: 0.44416, val MAE: 0.44559, test MAE: 0.43036, Time: 523.91s
2024-03-18 21:09:05,772 - logger.py:50 - Best -- epoch=30, train MAE: 0.44487, val MAE: 0.43603, test MAE: 0.42147

2024-03-18 21:09:05,772 - logger.py:50 - fold_10 test MAE:0.42147
2024-03-18 23:24:35,722 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-18 23:24:53,210 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-18 23:24:53,633 - logger.py:50 - Number of params: 2978805
2024-03-18 23:24:56,210 - logger.py:50 - Epoch: [0][0/500] loss: 33.93241, MAE: 0.66744, time/step=2573ms, lr=1.00e-06
2024-03-18 23:26:00,335 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-18 23:26:16,174 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-18 23:26:16,550 - logger.py:50 - Number of params: 2978805
2024-03-18 23:26:18,700 - logger.py:50 - Epoch: [0][0/500] loss: 33.93241, MAE: 0.66744, time/step=2146ms, lr=1.00e-06
2024-03-18 23:27:00,327 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-18 23:29:30,375 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-18 23:29:40,113 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1 (cuda:0)])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
  )
)
2024-03-18 23:29:40,126 - logger.py:50 - Number of params: 2978805
2024-03-18 23:29:42,216 - logger.py:50 - Epoch: [0][0/500] loss: 0.69403, MAE: 0.45693, time/step=2086ms, lr=1.00e-06
2024-03-18 23:30:40,514 - logger.py:50 - Epoch: [0][50/500] loss: 15.09054, MAE: 0.46684, time/step=1184ms, lr=1.00e-06
2024-03-18 23:31:37,908 - logger.py:50 - Epoch: [0][100/500] loss: 11.66398, MAE: 0.46458, time/step=1166ms, lr=1.00e-06
2024-03-18 23:32:34,351 - logger.py:50 - Epoch: [0][150/500] loss: 8.01682, MAE: 0.46119, time/step=1154ms, lr=1.00e-06
2024-03-18 23:33:30,329 - logger.py:50 - Epoch: [0][200/500] loss: 6.18116, MAE: 0.45462, time/step=1145ms, lr=1.00e-06
2024-03-18 23:34:26,616 - logger.py:50 - Epoch: [0][250/500] loss: 5.06713, MAE: 0.45322, time/step=1141ms, lr=1.00e-06
2024-03-18 23:35:21,841 - logger.py:50 - Epoch: [0][300/500] loss: 4.32441, MAE: 0.45119, time/step=1135ms, lr=1.00e-06
2024-03-18 23:36:16,081 - logger.py:50 - Epoch: [0][350/500] loss: 3.80175, MAE: 0.44683, time/step=1128ms, lr=1.00e-06
2024-03-18 23:37:11,008 - logger.py:50 - Epoch: [0][400/500] loss: 3.39439, MAE: 0.44590, time/step=1124ms, lr=1.00e-06
2024-03-18 23:38:04,295 - logger.py:50 - Epoch: [0][450/500] loss: 3.10094, MAE: 0.44505, time/step=1118ms, lr=1.00e-06
2024-03-18 23:38:56,188 - logger.py:50 - Epoch: [0][499/500] loss: 2.86162, MAE: 0.44377, time/step=1112ms, lr=1.00e-06
2024-03-18 23:39:55,891 - logger.py:50 - Epoch: [0] train LOSS: 2.86162, val LOSS: 0.44538, test LOSS: 0.43057, Time: 615.76s
2024-03-18 23:39:55,891 - logger.py:50 - Best -- epoch=0, train LOSS: 2.86162, val LOSS: 0.44538, test LOSS: 0.43057

2024-03-18 23:39:57,016 - logger.py:50 - Epoch: [1][0/500] loss: 0.67743, MAE: 0.46461, time/step=1124ms, lr=1.08e-05
2024-03-18 23:40:50,940 - logger.py:50 - Epoch: [1][50/500] loss: 0.64888, MAE: 0.44573, time/step=1079ms, lr=1.08e-05
2024-03-18 23:41:43,131 - logger.py:50 - Epoch: [1][100/500] loss: 0.62861, MAE: 0.44455, time/step=1062ms, lr=1.08e-05
2024-03-18 23:42:36,154 - logger.py:50 - Epoch: [1][150/500] loss: 0.66854, MAE: 0.44599, time/step=1061ms, lr=1.08e-05
2024-03-18 23:43:27,665 - logger.py:50 - Epoch: [1][200/500] loss: 0.66298, MAE: 0.44413, time/step=1054ms, lr=1.08e-05
2024-03-18 23:44:19,408 - logger.py:50 - Epoch: [1][250/500] loss: 0.66480, MAE: 0.44171, time/step=1050ms, lr=1.08e-05
2024-03-18 23:45:12,577 - logger.py:50 - Epoch: [1][300/500] loss: 4.29768, MAE: 0.45031, time/step=1052ms, lr=1.08e-05
2024-03-18 23:46:04,503 - logger.py:50 - Epoch: [1][350/500] loss: 3.79472, MAE: 0.44842, time/step=1050ms, lr=1.08e-05
2024-03-18 23:46:56,853 - logger.py:50 - Epoch: [1][400/500] loss: 3.40100, MAE: 0.44780, time/step=1050ms, lr=1.08e-05
2024-03-18 23:47:48,905 - logger.py:50 - Epoch: [1][450/500] loss: 3.10514, MAE: 0.44580, time/step=1049ms, lr=1.08e-05
2024-03-18 23:48:39,338 - logger.py:50 - Epoch: [1][499/500] loss: 2.87042, MAE: 0.44479, time/step=1047ms, lr=1.08e-05
2024-03-18 23:49:38,159 - logger.py:50 - Epoch: [1] train LOSS: 2.87042, val LOSS: 0.44603, test LOSS: 0.43114, Time: 582.27s
2024-03-18 23:49:38,159 - logger.py:50 - Best -- epoch=0, train LOSS: 2.86162, val LOSS: 0.44538, test LOSS: 0.43057

2024-03-18 23:49:38,795 - logger.py:50 - Epoch: [2][0/500] loss: 0.81698, MAE: 0.40818, time/step=634ms, lr=2.06e-05
2024-03-18 23:50:30,784 - logger.py:50 - Epoch: [2][50/500] loss: 0.67314, MAE: 0.44453, time/step=1032ms, lr=2.06e-05
2024-03-18 23:51:22,757 - logger.py:50 - Epoch: [2][100/500] loss: 7.94159, MAE: 0.45954, time/step=1036ms, lr=2.06e-05
2024-03-18 23:52:15,446 - logger.py:50 - Epoch: [2][150/500] loss: 5.48814, MAE: 0.45310, time/step=1042ms, lr=2.06e-05
2024-03-18 23:53:07,442 - logger.py:50 - Epoch: [2][200/500] loss: 4.31325, MAE: 0.45027, time/step=1041ms, lr=2.06e-05
2024-03-18 23:53:59,669 - logger.py:50 - Epoch: [2][250/500] loss: 3.60486, MAE: 0.44664, time/step=1042ms, lr=2.06e-05
2024-03-18 23:54:52,567 - logger.py:50 - Epoch: [2][300/500] loss: 3.09969, MAE: 0.44377, time/step=1045ms, lr=2.06e-05
2024-03-18 23:55:44,629 - logger.py:50 - Epoch: [2][350/500] loss: 2.75124, MAE: 0.44316, time/step=1044ms, lr=2.06e-05
2024-03-18 23:56:37,875 - logger.py:50 - Epoch: [2][400/500] loss: 2.48853, MAE: 0.44358, time/step=1047ms, lr=2.06e-05
2024-03-18 23:57:29,027 - logger.py:50 - Epoch: [2][450/500] loss: 2.29552, MAE: 0.44316, time/step=1044ms, lr=2.06e-05
2024-03-18 23:58:21,321 - logger.py:50 - Epoch: [2][499/500] loss: 2.86596, MAE: 0.44485, time/step=1046ms, lr=2.06e-05
2024-03-18 23:59:18,486 - logger.py:50 - Epoch: [2] train LOSS: 2.86596, val LOSS: 0.46657, test LOSS: 0.45105, Time: 580.33s
2024-03-18 23:59:18,486 - logger.py:50 - Best -- epoch=0, train LOSS: 2.86162, val LOSS: 0.44538, test LOSS: 0.43057

2024-03-18 23:59:19,751 - logger.py:50 - Epoch: [3][0/500] loss: 1.07335, MAE: 0.55894, time/step=1263ms, lr=3.04e-05
2024-03-19 00:00:12,289 - logger.py:50 - Epoch: [3][50/500] loss: 0.67156, MAE: 0.45087, time/step=1055ms, lr=3.04e-05
2024-03-19 00:01:04,399 - logger.py:50 - Epoch: [3][100/500] loss: 7.79181, MAE: 0.46462, time/step=1049ms, lr=3.04e-05
2024-03-19 00:01:56,023 - logger.py:50 - Epoch: [3][150/500] loss: 5.48498, MAE: 0.45889, time/step=1043ms, lr=3.04e-05
2024-03-19 00:02:47,553 - logger.py:50 - Epoch: [3][200/500] loss: 4.29270, MAE: 0.45058, time/step=1040ms, lr=3.04e-05
2024-03-19 00:03:40,183 - logger.py:50 - Epoch: [3][250/500] loss: 3.57748, MAE: 0.44978, time/step=1043ms, lr=3.04e-05
2024-03-19 00:04:32,310 - logger.py:50 - Epoch: [3][300/500] loss: 4.27477, MAE: 0.45037, time/step=1043ms, lr=3.04e-05
2024-03-19 00:05:24,704 - logger.py:50 - Epoch: [3][350/500] loss: 3.76575, MAE: 0.44962, time/step=1043ms, lr=3.04e-05
2024-03-19 00:06:17,725 - logger.py:50 - Epoch: [3][400/500] loss: 3.38221, MAE: 0.44734, time/step=1045ms, lr=3.04e-05
2024-03-19 00:07:10,102 - logger.py:50 - Epoch: [3][450/500] loss: 3.08013, MAE: 0.44670, time/step=1046ms, lr=3.04e-05
2024-03-19 00:08:01,649 - logger.py:50 - Epoch: [3][499/500] loss: 2.84493, MAE: 0.44625, time/step=1046ms, lr=3.04e-05
2024-03-19 00:09:00,342 - logger.py:50 - Epoch: [3] train LOSS: 2.84493, val LOSS: 0.44253, test LOSS: 0.42759, Time: 581.86s
2024-03-19 00:09:00,342 - logger.py:50 - Best -- epoch=3, train LOSS: 2.84493, val LOSS: 0.44253, test LOSS: 0.42759

2024-03-19 00:09:01,618 - logger.py:50 - Epoch: [4][0/500] loss: 0.91589, MAE: 0.53231, time/step=1274ms, lr=4.02e-05
2024-03-19 00:09:53,711 - logger.py:50 - Epoch: [4][50/500] loss: 0.63873, MAE: 0.43696, time/step=1046ms, lr=4.02e-05
2024-03-19 00:10:47,517 - logger.py:50 - Epoch: [4][100/500] loss: 0.64049, MAE: 0.43760, time/step=1061ms, lr=4.02e-05
2024-03-19 00:11:39,276 - logger.py:50 - Epoch: [4][150/500] loss: 2.94839, MAE: 0.44155, time/step=1053ms, lr=4.02e-05
2024-03-19 00:12:32,315 - logger.py:50 - Epoch: [4][200/500] loss: 2.40168, MAE: 0.44209, time/step=1055ms, lr=4.02e-05
2024-03-19 00:13:23,776 - logger.py:50 - Epoch: [4][250/500] loss: 2.05699, MAE: 0.44126, time/step=1050ms, lr=4.02e-05
2024-03-19 00:14:15,338 - logger.py:50 - Epoch: [4][300/500] loss: 4.11749, MAE: 0.44655, time/step=1046ms, lr=4.02e-05
2024-03-19 00:15:07,175 - logger.py:50 - Epoch: [4][350/500] loss: 3.66539, MAE: 0.44681, time/step=1045ms, lr=4.02e-05
2024-03-19 00:15:59,480 - logger.py:50 - Epoch: [4][400/500] loss: 3.29822, MAE: 0.44570, time/step=1045ms, lr=4.02e-05
2024-03-19 00:16:50,286 - logger.py:50 - Epoch: [4][450/500] loss: 3.02673, MAE: 0.44517, time/step=1042ms, lr=4.02e-05
2024-03-19 00:17:41,807 - logger.py:50 - Epoch: [4][499/500] loss: 2.79379, MAE: 0.44588, time/step=1043ms, lr=4.02e-05
2024-03-19 00:18:39,807 - logger.py:50 - Epoch: [4] train LOSS: 2.79379, val LOSS: 0.44189, test LOSS: 0.42663, Time: 579.46s
2024-03-19 00:18:39,807 - logger.py:50 - Best -- epoch=4, train LOSS: 2.79379, val LOSS: 0.44189, test LOSS: 0.42663

2024-03-19 00:18:40,428 - logger.py:50 - Epoch: [5][0/500] loss: 0.96843, MAE: 0.45542, time/step=619ms, lr=4.99e-05
2024-03-19 00:19:31,952 - logger.py:50 - Epoch: [5][50/500] loss: 0.69404, MAE: 0.43858, time/step=1022ms, lr=4.99e-05
2024-03-19 00:20:23,644 - logger.py:50 - Epoch: [5][100/500] loss: 0.63351, MAE: 0.43006, time/step=1028ms, lr=4.99e-05
2024-03-19 00:21:15,452 - logger.py:50 - Epoch: [5][150/500] loss: 3.08486, MAE: 0.44759, time/step=1031ms, lr=4.99e-05
2024-03-19 00:22:06,692 - logger.py:50 - Epoch: [5][200/500] loss: 2.49649, MAE: 0.44518, time/step=1029ms, lr=4.99e-05
2024-03-19 00:22:58,366 - logger.py:50 - Epoch: [5][250/500] loss: 2.15210, MAE: 0.44406, time/step=1030ms, lr=4.99e-05
2024-03-19 00:23:49,545 - logger.py:50 - Epoch: [5][300/500] loss: 1.91791, MAE: 0.44455, time/step=1029ms, lr=4.99e-05
2024-03-19 00:24:41,461 - logger.py:50 - Epoch: [5][350/500] loss: 3.67858, MAE: 0.45061, time/step=1030ms, lr=4.99e-05
2024-03-19 00:25:33,336 - logger.py:50 - Epoch: [5][400/500] loss: 3.33120, MAE: 0.44986, time/step=1031ms, lr=4.99e-05
2024-03-19 00:26:24,475 - logger.py:50 - Epoch: [5][450/500] loss: 3.03624, MAE: 0.44869, time/step=1030ms, lr=4.99e-05
2024-03-19 00:27:14,977 - logger.py:50 - Epoch: [5][499/500] loss: 2.80315, MAE: 0.44607, time/step=1030ms, lr=4.99e-05
2024-03-19 00:28:12,335 - logger.py:50 - Epoch: [5] train LOSS: 2.80315, val LOSS: 0.44741, test LOSS: 0.43219, Time: 572.53s
2024-03-19 00:28:12,336 - logger.py:50 - Best -- epoch=4, train LOSS: 2.79379, val LOSS: 0.44189, test LOSS: 0.42663

2024-03-19 00:28:13,344 - logger.py:50 - Epoch: [6][0/500] loss: 1.15098, MAE: 0.53206, time/step=1007ms, lr=4.98e-05
2024-03-19 00:29:05,151 - logger.py:50 - Epoch: [6][50/500] loss: 0.69631, MAE: 0.43402, time/step=1036ms, lr=4.98e-05
2024-03-19 00:29:57,206 - logger.py:50 - Epoch: [6][100/500] loss: 0.67646, MAE: 0.45055, time/step=1038ms, lr=4.98e-05
2024-03-19 00:30:48,128 - logger.py:50 - Epoch: [6][150/500] loss: 0.66234, MAE: 0.44228, time/step=1032ms, lr=4.98e-05
2024-03-19 00:31:39,836 - logger.py:50 - Epoch: [6][200/500] loss: 0.65704, MAE: 0.44193, time/step=1032ms, lr=4.98e-05
2024-03-19 00:32:30,540 - logger.py:50 - Epoch: [6][250/500] loss: 0.68333, MAE: 0.44328, time/step=1029ms, lr=4.98e-05
2024-03-19 00:33:22,003 - logger.py:50 - Epoch: [6][300/500] loss: 0.67266, MAE: 0.44009, time/step=1029ms, lr=4.98e-05
2024-03-19 00:34:13,989 - logger.py:50 - Epoch: [6][350/500] loss: 0.68070, MAE: 0.44098, time/step=1030ms, lr=4.98e-05
2024-03-19 00:35:06,311 - logger.py:50 - Epoch: [6][400/500] loss: 0.67175, MAE: 0.44034, time/step=1032ms, lr=4.98e-05
2024-03-19 00:35:57,476 - logger.py:50 - Epoch: [6][450/500] loss: 1.41035, MAE: 0.44078, time/step=1031ms, lr=4.98e-05
2024-03-19 00:36:48,115 - logger.py:50 - Epoch: [6][499/500] loss: 2.60409, MAE: 0.44416, time/step=1032ms, lr=4.98e-05
2024-03-19 00:37:45,038 - logger.py:50 - Epoch: [6] train LOSS: 2.60409, val LOSS: 0.48310, test LOSS: 0.46662, Time: 572.70s
2024-03-19 00:37:45,038 - logger.py:50 - Best -- epoch=4, train LOSS: 2.79379, val LOSS: 0.44189, test LOSS: 0.42663

2024-03-19 00:37:45,629 - logger.py:50 - Epoch: [7][0/500] loss: 1.64230, MAE: 0.54950, time/step=589ms, lr=4.97e-05
2024-03-19 00:38:37,453 - logger.py:50 - Epoch: [7][50/500] loss: 1.02679, MAE: 0.44283, time/step=1028ms, lr=4.97e-05
2024-03-19 00:39:28,109 - logger.py:50 - Epoch: [7][100/500] loss: 0.85982, MAE: 0.44307, time/step=1020ms, lr=4.97e-05
2024-03-19 00:40:19,782 - logger.py:50 - Epoch: [7][150/500] loss: 0.80901, MAE: 0.44312, time/step=1025ms, lr=4.97e-05
2024-03-19 00:41:11,823 - logger.py:50 - Epoch: [7][200/500] loss: 0.80201, MAE: 0.44620, time/step=1029ms, lr=4.97e-05
2024-03-19 00:42:02,873 - logger.py:50 - Epoch: [7][250/500] loss: 3.37208, MAE: 0.45473, time/step=1027ms, lr=4.97e-05
2024-03-19 00:42:54,867 - logger.py:50 - Epoch: [7][300/500] loss: 3.68821, MAE: 0.45363, time/step=1029ms, lr=4.97e-05
2024-03-19 00:43:47,525 - logger.py:50 - Epoch: [7][350/500] loss: 3.26040, MAE: 0.45067, time/step=1033ms, lr=4.97e-05
2024-03-19 00:44:38,217 - logger.py:50 - Epoch: [7][400/500] loss: 2.94162, MAE: 0.44922, time/step=1030ms, lr=4.97e-05
2024-03-19 00:45:29,960 - logger.py:50 - Epoch: [7][450/500] loss: 2.77705, MAE: 0.44846, time/step=1031ms, lr=4.97e-05
2024-03-19 00:46:20,062 - logger.py:50 - Epoch: [7][499/500] loss: 2.57163, MAE: 0.44809, time/step=1030ms, lr=4.97e-05
2024-03-19 00:47:16,937 - logger.py:50 - Epoch: [7] train LOSS: 2.57163, val LOSS: 0.44788, test LOSS: 0.43296, Time: 571.90s
2024-03-19 00:47:16,938 - logger.py:50 - Best -- epoch=4, train LOSS: 2.79379, val LOSS: 0.44189, test LOSS: 0.42663

2024-03-19 00:47:18,137 - logger.py:50 - Epoch: [8][0/500] loss: 0.61367, MAE: 0.41924, time/step=1198ms, lr=4.97e-05
2024-03-19 00:48:08,924 - logger.py:50 - Epoch: [8][50/500] loss: 11.23560, MAE: 0.48021, time/step=1019ms, lr=4.97e-05
2024-03-19 00:49:02,119 - logger.py:50 - Epoch: [8][100/500] loss: 6.20246, MAE: 0.46110, time/step=1041ms, lr=4.97e-05
2024-03-19 00:49:52,904 - logger.py:50 - Epoch: [8][150/500] loss: 4.41962, MAE: 0.45318, time/step=1033ms, lr=4.97e-05
2024-03-19 00:50:43,371 - logger.py:50 - Epoch: [8][200/500] loss: 3.54161, MAE: 0.45045, time/step=1027ms, lr=4.97e-05
2024-03-19 00:51:34,991 - logger.py:50 - Epoch: [8][250/500] loss: 2.95869, MAE: 0.44690, time/step=1028ms, lr=4.97e-05
2024-03-19 00:52:25,670 - logger.py:50 - Epoch: [8][300/500] loss: 2.58828, MAE: 0.44518, time/step=1026ms, lr=4.97e-05
2024-03-19 00:53:16,804 - logger.py:50 - Epoch: [8][350/500] loss: 2.30782, MAE: 0.44342, time/step=1025ms, lr=4.97e-05
2024-03-19 00:54:07,284 - logger.py:50 - Epoch: [8][400/500] loss: 2.11571, MAE: 0.44487, time/step=1023ms, lr=4.97e-05
2024-03-19 00:54:58,998 - logger.py:50 - Epoch: [8][450/500] loss: 1.94835, MAE: 0.44406, time/step=1025ms, lr=4.97e-05
2024-03-19 00:55:49,253 - logger.py:50 - Epoch: [8][499/500] loss: 2.22262, MAE: 0.44521, time/step=1025ms, lr=4.97e-05
2024-03-19 00:56:46,172 - logger.py:50 - Epoch: [8] train LOSS: 2.22262, val LOSS: 0.44696, test LOSS: 0.43260, Time: 569.23s
2024-03-19 00:56:46,172 - logger.py:50 - Best -- epoch=4, train LOSS: 2.79379, val LOSS: 0.44189, test LOSS: 0.42663

2024-03-19 00:56:47,357 - logger.py:50 - Epoch: [9][0/500] loss: 0.25533, MAE: 0.42632, time/step=1183ms, lr=4.96e-05
2024-03-19 00:57:38,960 - logger.py:50 - Epoch: [9][50/500] loss: 0.63276, MAE: 0.44771, time/step=1035ms, lr=4.96e-05
2024-03-19 00:58:29,288 - logger.py:50 - Epoch: [9][100/500] loss: 0.62801, MAE: 0.43189, time/step=1021ms, lr=4.96e-05
2024-03-19 00:59:20,596 - logger.py:50 - Epoch: [9][150/500] loss: 0.63310, MAE: 0.43860, time/step=1023ms, lr=4.96e-05
2024-03-19 01:00:11,443 - logger.py:50 - Epoch: [9][200/500] loss: 1.42798, MAE: 0.43841, time/step=1021ms, lr=4.96e-05
2024-03-19 01:01:01,774 - logger.py:50 - Epoch: [9][250/500] loss: 1.31332, MAE: 0.44049, time/step=1018ms, lr=4.96e-05
2024-03-19 01:01:53,369 - logger.py:50 - Epoch: [9][300/500] loss: 1.24970, MAE: 0.44028, time/step=1021ms, lr=4.96e-05
2024-03-19 01:02:44,642 - logger.py:50 - Epoch: [9][350/500] loss: 1.16393, MAE: 0.44007, time/step=1021ms, lr=4.96e-05
2024-03-19 01:03:35,578 - logger.py:50 - Epoch: [9][400/500] loss: 1.09893, MAE: 0.44002, time/step=1021ms, lr=4.96e-05
2024-03-19 01:04:26,258 - logger.py:50 - Epoch: [9][450/500] loss: 1.05052, MAE: 0.44103, time/step=1020ms, lr=4.96e-05
2024-03-19 01:05:17,652 - logger.py:50 - Epoch: [9][499/500] loss: 1.75532, MAE: 0.44495, time/step=1023ms, lr=4.96e-05
2024-03-19 01:06:14,160 - logger.py:50 - Epoch: [9] train LOSS: 1.75532, val LOSS: 0.46775, test LOSS: 0.45168, Time: 567.99s
2024-03-19 01:06:14,160 - logger.py:50 - Best -- epoch=4, train LOSS: 2.79379, val LOSS: 0.44189, test LOSS: 0.42663

2024-03-19 01:06:15,291 - logger.py:50 - Epoch: [10][0/500] loss: 0.95295, MAE: 0.50681, time/step=1129ms, lr=4.95e-05
2024-03-19 01:07:05,953 - logger.py:50 - Epoch: [10][50/500] loss: 0.69784, MAE: 0.44527, time/step=1015ms, lr=4.95e-05
2024-03-19 01:07:56,375 - logger.py:50 - Epoch: [10][100/500] loss: 0.71770, MAE: 0.44071, time/step=1012ms, lr=4.95e-05
2024-03-19 01:08:47,682 - logger.py:50 - Epoch: [10][150/500] loss: 0.73787, MAE: 0.43724, time/step=1017ms, lr=4.95e-05
2024-03-19 01:09:38,926 - logger.py:50 - Epoch: [10][200/500] loss: 0.73462, MAE: 0.43786, time/step=1019ms, lr=4.95e-05
2024-03-19 01:10:30,385 - logger.py:50 - Epoch: [10][250/500] loss: 2.06448, MAE: 0.44147, time/step=1021ms, lr=4.95e-05
2024-03-19 01:11:21,931 - logger.py:50 - Epoch: [10][300/500] loss: 1.86639, MAE: 0.44134, time/step=1022ms, lr=4.95e-05
2024-03-19 01:12:12,965 - logger.py:50 - Epoch: [10][350/500] loss: 1.99486, MAE: 0.44719, time/step=1022ms, lr=4.95e-05
2024-03-19 01:13:04,514 - logger.py:50 - Epoch: [10][400/500] loss: 1.85075, MAE: 0.44868, time/step=1023ms, lr=4.95e-05
2024-03-19 01:13:55,222 - logger.py:50 - Epoch: [10][450/500] loss: 1.75251, MAE: 0.44854, time/step=1022ms, lr=4.95e-05
2024-03-19 01:14:45,798 - logger.py:50 - Epoch: [10][499/500] loss: 1.63664, MAE: 0.44627, time/step=1023ms, lr=4.95e-05
2024-03-19 01:15:43,464 - logger.py:50 - Epoch: [10] train LOSS: 1.63664, val LOSS: 0.44081, test LOSS: 0.42615, Time: 569.30s
2024-03-19 01:15:43,464 - logger.py:50 - Best -- epoch=10, train LOSS: 1.63664, val LOSS: 0.44081, test LOSS: 0.42615

2024-03-19 01:15:44,686 - logger.py:50 - Epoch: [11][0/500] loss: 0.34017, MAE: 0.41643, time/step=1220ms, lr=4.94e-05
2024-03-19 01:16:35,704 - logger.py:50 - Epoch: [11][50/500] loss: 3.14029, MAE: 0.45468, time/step=1024ms, lr=4.94e-05
2024-03-19 01:17:27,571 - logger.py:50 - Epoch: [11][100/500] loss: 2.07800, MAE: 0.45120, time/step=1031ms, lr=4.94e-05
2024-03-19 01:18:18,556 - logger.py:50 - Epoch: [11][150/500] loss: 1.61800, MAE: 0.44155, time/step=1027ms, lr=4.94e-05
2024-03-19 01:19:09,582 - logger.py:50 - Epoch: [11][200/500] loss: 1.37288, MAE: 0.43987, time/step=1025ms, lr=4.94e-05
2024-03-19 01:20:01,692 - logger.py:50 - Epoch: [11][250/500] loss: 1.22500, MAE: 0.44076, time/step=1029ms, lr=4.94e-05
2024-03-19 01:20:53,392 - logger.py:50 - Epoch: [11][300/500] loss: 1.86366, MAE: 0.44456, time/step=1030ms, lr=4.94e-05
2024-03-19 01:21:44,790 - logger.py:50 - Epoch: [11][350/500] loss: 1.70781, MAE: 0.44605, time/step=1029ms, lr=4.94e-05
2024-03-19 01:22:35,920 - logger.py:50 - Epoch: [11][400/500] loss: 1.61655, MAE: 0.44609, time/step=1029ms, lr=4.94e-05
2024-03-19 01:23:27,849 - logger.py:50 - Epoch: [11][450/500] loss: 1.50822, MAE: 0.44566, time/step=1030ms, lr=4.94e-05
2024-03-19 01:24:18,558 - logger.py:50 - Epoch: [11][499/500] loss: 1.42302, MAE: 0.44577, time/step=1030ms, lr=4.94e-05
2024-03-19 01:25:16,297 - logger.py:50 - Epoch: [11] train LOSS: 1.42302, val LOSS: 0.44065, test LOSS: 0.42478, Time: 572.83s
2024-03-19 01:25:16,297 - logger.py:50 - Best -- epoch=11, train LOSS: 1.42302, val LOSS: 0.44065, test LOSS: 0.42478

2024-03-19 01:25:17,453 - logger.py:50 - Epoch: [12][0/500] loss: 0.35084, MAE: 0.51310, time/step=1154ms, lr=4.92e-05
2024-03-19 01:26:07,825 - logger.py:50 - Epoch: [12][50/500] loss: 0.68283, MAE: 0.44484, time/step=1010ms, lr=4.92e-05
2024-03-19 01:26:59,486 - logger.py:50 - Epoch: [12][100/500] loss: 0.87833, MAE: 0.44237, time/step=1022ms, lr=4.92e-05
2024-03-19 01:27:50,467 - logger.py:50 - Epoch: [12][150/500] loss: 2.05381, MAE: 0.45066, time/step=1021ms, lr=4.92e-05
2024-03-19 01:28:42,475 - logger.py:50 - Epoch: [12][200/500] loss: 1.71133, MAE: 0.44824, time/step=1026ms, lr=4.92e-05
2024-03-19 01:29:34,120 - logger.py:50 - Epoch: [12][250/500] loss: 1.49275, MAE: 0.44448, time/step=1027ms, lr=4.92e-05
2024-03-19 01:30:26,433 - logger.py:50 - Epoch: [12][300/500] loss: 1.34856, MAE: 0.44334, time/step=1030ms, lr=4.92e-05
2024-03-19 01:31:16,643 - logger.py:50 - Epoch: [12][350/500] loss: 1.25190, MAE: 0.44262, time/step=1027ms, lr=4.92e-05
2024-03-19 01:32:07,812 - logger.py:50 - Epoch: [12][400/500] loss: 1.36377, MAE: 0.44703, time/step=1026ms, lr=4.92e-05
2024-03-19 01:32:58,950 - logger.py:50 - Epoch: [12][450/500] loss: 1.27799, MAE: 0.44542, time/step=1026ms, lr=4.92e-05
2024-03-19 01:33:48,990 - logger.py:50 - Epoch: [12][499/500] loss: 1.21527, MAE: 0.44519, time/step=1025ms, lr=4.92e-05
2024-03-19 01:34:45,983 - logger.py:50 - Epoch: [12] train LOSS: 1.21527, val LOSS: 0.44145, test LOSS: 0.42671, Time: 569.69s
2024-03-19 01:34:45,984 - logger.py:50 - Best -- epoch=11, train LOSS: 1.42302, val LOSS: 0.44065, test LOSS: 0.42478

2024-03-19 01:34:47,058 - logger.py:50 - Epoch: [13][0/500] loss: 1.30679, MAE: 0.39723, time/step=1073ms, lr=4.91e-05
2024-03-19 01:35:37,547 - logger.py:50 - Epoch: [13][50/500] loss: 0.61700, MAE: 0.44138, time/step=1011ms, lr=4.91e-05
2024-03-19 01:36:29,595 - logger.py:50 - Epoch: [13][100/500] loss: 0.59514, MAE: 0.44209, time/step=1026ms, lr=4.91e-05
2024-03-19 01:37:20,510 - logger.py:50 - Epoch: [13][150/500] loss: 1.05895, MAE: 0.45054, time/step=1023ms, lr=4.91e-05
2024-03-19 01:38:12,431 - logger.py:50 - Epoch: [13][200/500] loss: 0.95917, MAE: 0.44591, time/step=1027ms, lr=4.91e-05
2024-03-19 01:39:02,944 - logger.py:50 - Epoch: [13][250/500] loss: 1.57540, MAE: 0.45215, time/step=1024ms, lr=4.91e-05
2024-03-19 01:39:52,905 - logger.py:50 - Epoch: [13][300/500] loss: 1.41375, MAE: 0.44742, time/step=1020ms, lr=4.91e-05
2024-03-19 01:40:44,027 - logger.py:50 - Epoch: [13][350/500] loss: 1.31494, MAE: 0.44871, time/step=1020ms, lr=4.91e-05
2024-03-19 01:41:35,433 - logger.py:50 - Epoch: [13][400/500] loss: 1.23706, MAE: 0.44709, time/step=1021ms, lr=4.91e-05
2024-03-19 01:42:27,241 - logger.py:50 - Epoch: [13][450/500] loss: 1.17145, MAE: 0.44619, time/step=1023ms, lr=4.91e-05
2024-03-19 01:43:18,033 - logger.py:50 - Epoch: [13][499/500] loss: 1.11847, MAE: 0.44448, time/step=1024ms, lr=4.91e-05
2024-03-19 01:44:15,720 - logger.py:50 - Epoch: [13] train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187, Time: 569.74s
2024-03-19 01:44:15,720 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 01:44:16,834 - logger.py:50 - Epoch: [14][0/500] loss: 0.93490, MAE: 0.42584, time/step=1111ms, lr=4.90e-05
2024-03-19 01:45:08,481 - logger.py:50 - Epoch: [14][50/500] loss: 0.66228, MAE: 0.43804, time/step=1034ms, lr=4.90e-05
2024-03-19 01:45:59,437 - logger.py:50 - Epoch: [14][100/500] loss: 2.06149, MAE: 0.45796, time/step=1027ms, lr=4.90e-05
2024-03-19 01:46:50,764 - logger.py:50 - Epoch: [14][150/500] loss: 1.66167, MAE: 0.44979, time/step=1027ms, lr=4.90e-05
2024-03-19 01:47:42,026 - logger.py:50 - Epoch: [14][200/500] loss: 1.40065, MAE: 0.44827, time/step=1026ms, lr=4.90e-05
2024-03-19 01:48:33,989 - logger.py:50 - Epoch: [14][250/500] loss: 1.24720, MAE: 0.44600, time/step=1029ms, lr=4.90e-05
2024-03-19 01:49:26,262 - logger.py:50 - Epoch: [14][300/500] loss: 1.13316, MAE: 0.44358, time/step=1032ms, lr=4.90e-05
2024-03-19 01:50:16,918 - logger.py:50 - Epoch: [14][350/500] loss: 1.05046, MAE: 0.43969, time/step=1029ms, lr=4.90e-05
2024-03-19 01:51:08,864 - logger.py:50 - Epoch: [14][400/500] loss: 1.20407, MAE: 0.44303, time/step=1030ms, lr=4.90e-05
2024-03-19 01:52:00,785 - logger.py:50 - Epoch: [14][450/500] loss: 1.13406, MAE: 0.44427, time/step=1031ms, lr=4.90e-05
2024-03-19 01:52:50,609 - logger.py:50 - Epoch: [14][499/500] loss: 1.08600, MAE: 0.44470, time/step=1030ms, lr=4.90e-05
2024-03-19 01:53:48,048 - logger.py:50 - Epoch: [14] train LOSS: 1.08600, val LOSS: 0.44143, test LOSS: 0.42678, Time: 572.33s
2024-03-19 01:53:48,048 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 01:53:49,248 - logger.py:50 - Epoch: [15][0/500] loss: 0.46742, MAE: 0.37280, time/step=1198ms, lr=4.88e-05
2024-03-19 01:54:41,867 - logger.py:50 - Epoch: [15][50/500] loss: 0.58343, MAE: 0.43613, time/step=1055ms, lr=4.88e-05
2024-03-19 01:55:33,113 - logger.py:50 - Epoch: [15][100/500] loss: 0.64553, MAE: 0.44020, time/step=1040ms, lr=4.88e-05
2024-03-19 01:56:24,071 - logger.py:50 - Epoch: [15][150/500] loss: 0.65433, MAE: 0.43784, time/step=1033ms, lr=4.88e-05
2024-03-19 01:57:15,186 - logger.py:50 - Epoch: [15][200/500] loss: 0.63978, MAE: 0.43660, time/step=1031ms, lr=4.88e-05
2024-03-19 01:58:05,969 - logger.py:50 - Epoch: [15][250/500] loss: 0.65681, MAE: 0.43731, time/step=1028ms, lr=4.88e-05
2024-03-19 01:58:56,782 - logger.py:50 - Epoch: [15][300/500] loss: 0.65323, MAE: 0.43600, time/step=1026ms, lr=4.88e-05
2024-03-19 01:59:49,155 - logger.py:50 - Epoch: [15][350/500] loss: 0.64538, MAE: 0.43760, time/step=1029ms, lr=4.88e-05
2024-03-19 02:00:40,440 - logger.py:50 - Epoch: [15][400/500] loss: 0.80940, MAE: 0.44161, time/step=1028ms, lr=4.88e-05
2024-03-19 02:01:32,403 - logger.py:50 - Epoch: [15][450/500] loss: 0.78093, MAE: 0.44119, time/step=1030ms, lr=4.88e-05
2024-03-19 02:02:22,491 - logger.py:50 - Epoch: [15][499/500] loss: 1.07965, MAE: 0.44410, time/step=1029ms, lr=4.88e-05
2024-03-19 02:03:19,449 - logger.py:50 - Epoch: [15] train LOSS: 1.07965, val LOSS: 0.44429, test LOSS: 0.42864, Time: 571.40s
2024-03-19 02:03:19,449 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 02:03:20,522 - logger.py:50 - Epoch: [16][0/500] loss: 0.56568, MAE: 0.38847, time/step=1070ms, lr=4.86e-05
2024-03-19 02:04:11,986 - logger.py:50 - Epoch: [16][50/500] loss: 0.58036, MAE: 0.44039, time/step=1030ms, lr=4.86e-05
2024-03-19 02:05:03,468 - logger.py:50 - Epoch: [16][100/500] loss: 0.57428, MAE: 0.43898, time/step=1030ms, lr=4.86e-05
2024-03-19 02:05:54,496 - logger.py:50 - Epoch: [16][150/500] loss: 0.57600, MAE: 0.43891, time/step=1027ms, lr=4.86e-05
2024-03-19 02:06:45,983 - logger.py:50 - Epoch: [16][200/500] loss: 0.57266, MAE: 0.43823, time/step=1028ms, lr=4.86e-05
2024-03-19 02:07:37,915 - logger.py:50 - Epoch: [16][250/500] loss: 0.57572, MAE: 0.44131, time/step=1030ms, lr=4.86e-05
2024-03-19 02:08:29,000 - logger.py:50 - Epoch: [16][300/500] loss: 0.58645, MAE: 0.44042, time/step=1028ms, lr=4.86e-05
2024-03-19 02:09:19,668 - logger.py:50 - Epoch: [16][350/500] loss: 0.58708, MAE: 0.43875, time/step=1026ms, lr=4.86e-05
2024-03-19 02:10:10,112 - logger.py:50 - Epoch: [16][400/500] loss: 0.77575, MAE: 0.44140, time/step=1024ms, lr=4.86e-05
2024-03-19 02:11:00,446 - logger.py:50 - Epoch: [16][450/500] loss: 0.76218, MAE: 0.44177, time/step=1022ms, lr=4.86e-05
2024-03-19 02:11:50,686 - logger.py:50 - Epoch: [16][499/500] loss: 1.08215, MAE: 0.44464, time/step=1022ms, lr=4.86e-05
2024-03-19 02:12:47,143 - logger.py:50 - Epoch: [16] train LOSS: 1.08215, val LOSS: 0.45034, test LOSS: 0.43665, Time: 567.69s
2024-03-19 02:12:47,143 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 02:12:48,304 - logger.py:50 - Epoch: [17][0/500] loss: 0.30520, MAE: 0.34016, time/step=1158ms, lr=4.85e-05
2024-03-19 02:13:38,956 - logger.py:50 - Epoch: [17][50/500] loss: 0.60275, MAE: 0.43357, time/step=1016ms, lr=4.85e-05
2024-03-19 02:14:29,170 - logger.py:50 - Epoch: [17][100/500] loss: 1.96393, MAE: 0.44537, time/step=1010ms, lr=4.85e-05
2024-03-19 02:15:19,717 - logger.py:50 - Epoch: [17][150/500] loss: 1.53525, MAE: 0.44583, time/step=1010ms, lr=4.85e-05
2024-03-19 02:16:11,227 - logger.py:50 - Epoch: [17][200/500] loss: 1.28578, MAE: 0.44233, time/step=1015ms, lr=4.85e-05
2024-03-19 02:17:01,655 - logger.py:50 - Epoch: [17][250/500] loss: 1.15083, MAE: 0.44240, time/step=1014ms, lr=4.85e-05
2024-03-19 02:17:53,156 - logger.py:50 - Epoch: [17][300/500] loss: 1.04968, MAE: 0.44140, time/step=1017ms, lr=4.85e-05
2024-03-19 02:18:44,213 - logger.py:50 - Epoch: [17][350/500] loss: 1.00336, MAE: 0.44179, time/step=1017ms, lr=4.85e-05
2024-03-19 02:19:35,211 - logger.py:50 - Epoch: [17][400/500] loss: 0.95447, MAE: 0.44237, time/step=1018ms, lr=4.85e-05
2024-03-19 02:20:27,686 - logger.py:50 - Epoch: [17][450/500] loss: 0.92181, MAE: 0.44322, time/step=1021ms, lr=4.85e-05
2024-03-19 02:21:18,263 - logger.py:50 - Epoch: [17][499/500] loss: 1.06178, MAE: 0.44482, time/step=1022ms, lr=4.85e-05
2024-03-19 02:22:15,196 - logger.py:50 - Epoch: [17] train LOSS: 1.06178, val LOSS: 0.44683, test LOSS: 0.43187, Time: 568.05s
2024-03-19 02:22:15,197 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 02:22:16,429 - logger.py:50 - Epoch: [18][0/500] loss: 0.44888, MAE: 0.44119, time/step=1231ms, lr=4.83e-05
2024-03-19 02:23:07,558 - logger.py:50 - Epoch: [18][50/500] loss: 0.70659, MAE: 0.44084, time/step=1027ms, lr=4.83e-05
2024-03-19 02:23:59,607 - logger.py:50 - Epoch: [18][100/500] loss: 0.66106, MAE: 0.43452, time/step=1034ms, lr=4.83e-05
2024-03-19 02:24:50,454 - logger.py:50 - Epoch: [18][150/500] loss: 1.06143, MAE: 0.44628, time/step=1028ms, lr=4.83e-05
2024-03-19 02:25:41,903 - logger.py:50 - Epoch: [18][200/500] loss: 1.82723, MAE: 0.45095, time/step=1028ms, lr=4.83e-05
2024-03-19 02:26:33,582 - logger.py:50 - Epoch: [18][250/500] loss: 1.59917, MAE: 0.44716, time/step=1029ms, lr=4.83e-05
2024-03-19 02:27:24,155 - logger.py:50 - Epoch: [18][300/500] loss: 1.50461, MAE: 0.44752, time/step=1026ms, lr=4.83e-05
2024-03-19 02:28:15,528 - logger.py:50 - Epoch: [18][350/500] loss: 1.38352, MAE: 0.44540, time/step=1027ms, lr=4.83e-05
2024-03-19 02:29:05,708 - logger.py:50 - Epoch: [18][400/500] loss: 1.29205, MAE: 0.44592, time/step=1024ms, lr=4.83e-05
2024-03-19 02:29:56,773 - logger.py:50 - Epoch: [18][450/500] loss: 1.21237, MAE: 0.44518, time/step=1023ms, lr=4.83e-05
2024-03-19 02:30:47,086 - logger.py:50 - Epoch: [18][499/500] loss: 1.14876, MAE: 0.44461, time/step=1024ms, lr=4.83e-05
2024-03-19 02:31:43,607 - logger.py:50 - Epoch: [18] train LOSS: 1.14876, val LOSS: 0.44572, test LOSS: 0.43092, Time: 568.41s
2024-03-19 02:31:43,608 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 02:31:44,355 - logger.py:50 - Epoch: [19][0/500] loss: 0.81409, MAE: 0.39111, time/step=745ms, lr=4.81e-05
2024-03-19 02:32:34,969 - logger.py:50 - Epoch: [19][50/500] loss: 0.55392, MAE: 0.42142, time/step=1007ms, lr=4.81e-05
2024-03-19 02:33:26,278 - logger.py:50 - Epoch: [19][100/500] loss: 1.93844, MAE: 0.45095, time/step=1017ms, lr=4.81e-05
2024-03-19 02:34:17,072 - logger.py:50 - Epoch: [19][150/500] loss: 2.03240, MAE: 0.46005, time/step=1016ms, lr=4.81e-05
2024-03-19 02:35:08,349 - logger.py:50 - Epoch: [19][200/500] loss: 1.66680, MAE: 0.45338, time/step=1019ms, lr=4.81e-05
2024-03-19 02:35:59,700 - logger.py:50 - Epoch: [19][250/500] loss: 1.47469, MAE: 0.44865, time/step=1020ms, lr=4.81e-05
2024-03-19 02:36:51,266 - logger.py:50 - Epoch: [19][300/500] loss: 1.32936, MAE: 0.44627, time/step=1022ms, lr=4.81e-05
2024-03-19 02:37:42,021 - logger.py:50 - Epoch: [19][350/500] loss: 1.23522, MAE: 0.44644, time/step=1021ms, lr=4.81e-05
2024-03-19 02:38:32,593 - logger.py:50 - Epoch: [19][400/500] loss: 1.15249, MAE: 0.44549, time/step=1020ms, lr=4.81e-05
2024-03-19 02:39:23,835 - logger.py:50 - Epoch: [19][450/500] loss: 1.08588, MAE: 0.44589, time/step=1020ms, lr=4.81e-05
2024-03-19 02:40:14,407 - logger.py:50 - Epoch: [19][499/500] loss: 1.03897, MAE: 0.44442, time/step=1022ms, lr=4.81e-05
2024-03-19 02:41:11,386 - logger.py:50 - Epoch: [19] train LOSS: 1.03897, val LOSS: 0.44487, test LOSS: 0.43011, Time: 567.78s
2024-03-19 02:41:11,387 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 02:41:12,121 - logger.py:50 - Epoch: [20][0/500] loss: 1.01543, MAE: 0.43234, time/step=732ms, lr=4.79e-05
2024-03-19 02:42:03,338 - logger.py:50 - Epoch: [20][50/500] loss: 6.82617, MAE: 0.47497, time/step=1019ms, lr=4.79e-05
2024-03-19 02:42:54,648 - logger.py:50 - Epoch: [20][100/500] loss: 3.80510, MAE: 0.45869, time/step=1022ms, lr=4.79e-05
2024-03-19 02:43:45,432 - logger.py:50 - Epoch: [20][150/500] loss: 2.80694, MAE: 0.45651, time/step=1020ms, lr=4.79e-05
2024-03-19 02:44:35,904 - logger.py:50 - Epoch: [20][200/500] loss: 2.30774, MAE: 0.45338, time/step=1017ms, lr=4.79e-05
2024-03-19 02:45:27,524 - logger.py:50 - Epoch: [20][250/500] loss: 1.97346, MAE: 0.45183, time/step=1020ms, lr=4.79e-05
2024-03-19 02:46:19,173 - logger.py:50 - Epoch: [20][300/500] loss: 1.72730, MAE: 0.44818, time/step=1023ms, lr=4.79e-05
2024-03-19 02:47:10,845 - logger.py:50 - Epoch: [20][350/500] loss: 1.92503, MAE: 0.45108, time/step=1024ms, lr=4.79e-05
2024-03-19 02:48:02,216 - logger.py:50 - Epoch: [20][400/500] loss: 1.78027, MAE: 0.45009, time/step=1025ms, lr=4.79e-05
2024-03-19 02:48:52,570 - logger.py:50 - Epoch: [20][450/500] loss: 1.64192, MAE: 0.44729, time/step=1023ms, lr=4.79e-05
2024-03-19 02:49:42,705 - logger.py:50 - Epoch: [20][499/500] loss: 1.54543, MAE: 0.44538, time/step=1023ms, lr=4.79e-05
2024-03-19 02:50:39,170 - logger.py:50 - Epoch: [20] train LOSS: 1.54543, val LOSS: 0.44815, test LOSS: 0.43299, Time: 567.78s
2024-03-19 02:50:39,170 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 02:50:40,251 - logger.py:50 - Epoch: [21][0/500] loss: 0.33857, MAE: 0.40422, time/step=1079ms, lr=4.77e-05
2024-03-19 02:51:31,750 - logger.py:50 - Epoch: [21][50/500] loss: 0.51357, MAE: 0.43195, time/step=1031ms, lr=4.77e-05
2024-03-19 02:52:23,185 - logger.py:50 - Epoch: [21][100/500] loss: 0.54679, MAE: 0.43014, time/step=1030ms, lr=4.77e-05
2024-03-19 02:53:13,326 - logger.py:50 - Epoch: [21][150/500] loss: 2.06676, MAE: 0.45650, time/step=1021ms, lr=4.77e-05
2024-03-19 02:54:04,147 - logger.py:50 - Epoch: [21][200/500] loss: 1.72515, MAE: 0.45235, time/step=1020ms, lr=4.77e-05
2024-03-19 02:54:55,560 - logger.py:50 - Epoch: [21][250/500] loss: 1.50444, MAE: 0.44983, time/step=1021ms, lr=4.77e-05
2024-03-19 02:55:45,994 - logger.py:50 - Epoch: [21][300/500] loss: 1.34819, MAE: 0.44859, time/step=1019ms, lr=4.77e-05
2024-03-19 02:56:37,873 - logger.py:50 - Epoch: [21][350/500] loss: 1.23356, MAE: 0.44644, time/step=1022ms, lr=4.77e-05
2024-03-19 02:57:28,657 - logger.py:50 - Epoch: [21][400/500] loss: 1.16571, MAE: 0.44559, time/step=1021ms, lr=4.77e-05
2024-03-19 02:58:20,489 - logger.py:50 - Epoch: [21][450/500] loss: 1.09471, MAE: 0.44499, time/step=1023ms, lr=4.77e-05
2024-03-19 02:59:10,622 - logger.py:50 - Epoch: [21][499/500] loss: 1.04069, MAE: 0.44449, time/step=1023ms, lr=4.77e-05
2024-03-19 03:00:07,197 - logger.py:50 - Epoch: [21] train LOSS: 1.04069, val LOSS: 0.44272, test LOSS: 0.42786, Time: 568.03s
2024-03-19 03:00:07,197 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 03:00:08,269 - logger.py:50 - Epoch: [22][0/500] loss: 0.80816, MAE: 0.47495, time/step=1070ms, lr=4.74e-05
2024-03-19 03:00:58,875 - logger.py:50 - Epoch: [22][50/500] loss: 0.56275, MAE: 0.44713, time/step=1013ms, lr=4.74e-05
2024-03-19 03:01:48,794 - logger.py:50 - Epoch: [22][100/500] loss: 0.57872, MAE: 0.44145, time/step=1006ms, lr=4.74e-05
2024-03-19 03:02:40,159 - logger.py:50 - Epoch: [22][150/500] loss: 1.07177, MAE: 0.45022, time/step=1013ms, lr=4.74e-05
2024-03-19 03:03:31,017 - logger.py:50 - Epoch: [22][200/500] loss: 0.94636, MAE: 0.44706, time/step=1014ms, lr=4.74e-05
2024-03-19 03:04:22,747 - logger.py:50 - Epoch: [22][250/500] loss: 0.87963, MAE: 0.44343, time/step=1018ms, lr=4.74e-05
2024-03-19 03:05:14,585 - logger.py:50 - Epoch: [22][300/500] loss: 1.35341, MAE: 0.44881, time/step=1021ms, lr=4.74e-05
2024-03-19 03:06:05,855 - logger.py:50 - Epoch: [22][350/500] loss: 1.24430, MAE: 0.44634, time/step=1022ms, lr=4.74e-05
2024-03-19 03:06:57,758 - logger.py:50 - Epoch: [22][400/500] loss: 1.15359, MAE: 0.44473, time/step=1024ms, lr=4.74e-05
2024-03-19 03:07:48,600 - logger.py:50 - Epoch: [22][450/500] loss: 1.09896, MAE: 0.44487, time/step=1023ms, lr=4.74e-05
2024-03-19 03:08:38,678 - logger.py:50 - Epoch: [22][499/500] loss: 1.04387, MAE: 0.44426, time/step=1023ms, lr=4.74e-05
2024-03-19 03:09:34,818 - logger.py:50 - Epoch: [22] train LOSS: 1.04387, val LOSS: 0.44209, test LOSS: 0.42716, Time: 567.62s
2024-03-19 03:09:34,818 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 03:09:35,912 - logger.py:50 - Epoch: [23][0/500] loss: 0.76269, MAE: 0.41131, time/step=1092ms, lr=4.72e-05
2024-03-19 03:10:27,334 - logger.py:50 - Epoch: [23][50/500] loss: 3.07246, MAE: 0.46983, time/step=1030ms, lr=4.72e-05
2024-03-19 03:11:18,279 - logger.py:50 - Epoch: [23][100/500] loss: 1.89274, MAE: 0.45183, time/step=1024ms, lr=4.72e-05
2024-03-19 03:12:08,666 - logger.py:50 - Epoch: [23][150/500] loss: 1.44470, MAE: 0.44626, time/step=1019ms, lr=4.72e-05
2024-03-19 03:13:00,231 - logger.py:50 - Epoch: [23][200/500] loss: 1.22214, MAE: 0.44494, time/step=1022ms, lr=4.72e-05
2024-03-19 03:13:52,057 - logger.py:50 - Epoch: [23][250/500] loss: 1.07793, MAE: 0.44300, time/step=1025ms, lr=4.72e-05
2024-03-19 03:14:43,402 - logger.py:50 - Epoch: [23][300/500] loss: 0.99618, MAE: 0.44053, time/step=1025ms, lr=4.72e-05
2024-03-19 03:15:35,078 - logger.py:50 - Epoch: [23][350/500] loss: 1.20065, MAE: 0.44324, time/step=1026ms, lr=4.72e-05
2024-03-19 03:16:25,993 - logger.py:50 - Epoch: [23][400/500] loss: 1.13339, MAE: 0.44408, time/step=1025ms, lr=4.72e-05
2024-03-19 03:17:17,384 - logger.py:50 - Epoch: [23][450/500] loss: 1.06991, MAE: 0.44449, time/step=1026ms, lr=4.72e-05
2024-03-19 03:18:06,653 - logger.py:50 - Epoch: [23][499/500] loss: 1.02556, MAE: 0.44457, time/step=1024ms, lr=4.72e-05
2024-03-19 03:19:03,698 - logger.py:50 - Epoch: [23] train LOSS: 1.02556, val LOSS: 0.44326, test LOSS: 0.42862, Time: 568.88s
2024-03-19 03:19:03,698 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 03:19:04,434 - logger.py:50 - Epoch: [24][0/500] loss: 1.05458, MAE: 0.40916, time/step=733ms, lr=4.70e-05
2024-03-19 03:19:56,330 - logger.py:50 - Epoch: [24][50/500] loss: 0.55153, MAE: 0.43752, time/step=1032ms, lr=4.70e-05
2024-03-19 03:20:46,855 - logger.py:50 - Epoch: [24][100/500] loss: 0.56372, MAE: 0.43394, time/step=1021ms, lr=4.70e-05
2024-03-19 03:21:37,810 - logger.py:50 - Epoch: [24][150/500] loss: 1.01156, MAE: 0.44194, time/step=1021ms, lr=4.70e-05
2024-03-19 03:22:29,496 - logger.py:50 - Epoch: [24][200/500] loss: 0.89383, MAE: 0.44062, time/step=1024ms, lr=4.70e-05
2024-03-19 03:23:20,630 - logger.py:50 - Epoch: [24][250/500] loss: 1.45117, MAE: 0.44731, time/step=1024ms, lr=4.70e-05
2024-03-19 03:24:12,380 - logger.py:50 - Epoch: [24][300/500] loss: 1.29749, MAE: 0.44578, time/step=1026ms, lr=4.70e-05
2024-03-19 03:25:03,894 - logger.py:50 - Epoch: [24][350/500] loss: 1.19238, MAE: 0.44674, time/step=1026ms, lr=4.70e-05
2024-03-19 03:25:56,056 - logger.py:50 - Epoch: [24][400/500] loss: 1.13561, MAE: 0.44670, time/step=1028ms, lr=4.70e-05
2024-03-19 03:26:47,259 - logger.py:50 - Epoch: [24][450/500] loss: 1.07383, MAE: 0.44497, time/step=1028ms, lr=4.70e-05
2024-03-19 03:27:37,629 - logger.py:50 - Epoch: [24][499/500] loss: 1.02169, MAE: 0.44419, time/step=1028ms, lr=4.70e-05
2024-03-19 03:28:34,185 - logger.py:50 - Epoch: [24] train LOSS: 1.02169, val LOSS: 0.44530, test LOSS: 0.42981, Time: 570.49s
2024-03-19 03:28:34,186 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 03:28:35,335 - logger.py:50 - Epoch: [25][0/500] loss: 0.77572, MAE: 0.42093, time/step=1147ms, lr=4.67e-05
2024-03-19 03:29:26,426 - logger.py:50 - Epoch: [25][50/500] loss: 0.56237, MAE: 0.43584, time/step=1024ms, lr=4.67e-05
2024-03-19 03:30:16,624 - logger.py:50 - Epoch: [25][100/500] loss: 1.83896, MAE: 0.45448, time/step=1014ms, lr=4.67e-05
2024-03-19 03:31:07,683 - logger.py:50 - Epoch: [25][150/500] loss: 1.45616, MAE: 0.45371, time/step=1017ms, lr=4.67e-05
2024-03-19 03:31:58,389 - logger.py:50 - Epoch: [25][200/500] loss: 1.24132, MAE: 0.44903, time/step=1016ms, lr=4.67e-05
2024-03-19 03:32:49,960 - logger.py:50 - Epoch: [25][250/500] loss: 1.09580, MAE: 0.44669, time/step=1019ms, lr=4.67e-05
2024-03-19 03:33:41,521 - logger.py:50 - Epoch: [25][300/500] loss: 0.99933, MAE: 0.44226, time/step=1021ms, lr=4.67e-05
2024-03-19 03:34:32,830 - logger.py:50 - Epoch: [25][350/500] loss: 0.92813, MAE: 0.44142, time/step=1022ms, lr=4.67e-05
2024-03-19 03:35:24,224 - logger.py:50 - Epoch: [25][400/500] loss: 0.88484, MAE: 0.43999, time/step=1023ms, lr=4.67e-05
2024-03-19 03:36:15,963 - logger.py:50 - Epoch: [25][450/500] loss: 1.04404, MAE: 0.44466, time/step=1024ms, lr=4.67e-05
2024-03-19 03:37:05,410 - logger.py:50 - Epoch: [25][499/500] loss: 1.00656, MAE: 0.44466, time/step=1022ms, lr=4.67e-05
2024-03-19 03:38:02,363 - logger.py:50 - Epoch: [25] train LOSS: 1.00656, val LOSS: 0.44260, test LOSS: 0.42753, Time: 568.18s
2024-03-19 03:38:02,363 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 03:38:03,481 - logger.py:50 - Epoch: [26][0/500] loss: 0.57338, MAE: 0.45331, time/step=1116ms, lr=4.65e-05
2024-03-19 03:38:54,511 - logger.py:50 - Epoch: [26][50/500] loss: 0.54538, MAE: 0.43283, time/step=1022ms, lr=4.65e-05
2024-03-19 03:39:45,804 - logger.py:50 - Epoch: [26][100/500] loss: 0.54516, MAE: 0.44111, time/step=1024ms, lr=4.65e-05
2024-03-19 03:40:38,700 - logger.py:50 - Epoch: [26][150/500] loss: 0.54655, MAE: 0.44346, time/step=1035ms, lr=4.65e-05
2024-03-19 03:41:29,759 - logger.py:50 - Epoch: [26][200/500] loss: 0.55186, MAE: 0.44345, time/step=1032ms, lr=4.65e-05
2024-03-19 03:42:20,398 - logger.py:50 - Epoch: [26][250/500] loss: 0.81883, MAE: 0.44596, time/step=1028ms, lr=4.65e-05
2024-03-19 03:43:11,292 - logger.py:50 - Epoch: [26][300/500] loss: 1.34079, MAE: 0.45148, time/step=1026ms, lr=4.65e-05
2024-03-19 03:44:02,266 - logger.py:50 - Epoch: [26][350/500] loss: 1.23040, MAE: 0.44885, time/step=1025ms, lr=4.65e-05
2024-03-19 03:44:54,076 - logger.py:50 - Epoch: [26][400/500] loss: 1.16711, MAE: 0.44755, time/step=1027ms, lr=4.65e-05
2024-03-19 03:45:45,997 - logger.py:50 - Epoch: [26][450/500] loss: 1.09216, MAE: 0.44535, time/step=1028ms, lr=4.65e-05
2024-03-19 03:46:36,373 - logger.py:50 - Epoch: [26][499/500] loss: 1.03812, MAE: 0.44413, time/step=1028ms, lr=4.65e-05
2024-03-19 03:47:33,369 - logger.py:50 - Epoch: [26] train LOSS: 1.03812, val LOSS: 0.44255, test LOSS: 0.42720, Time: 571.01s
2024-03-19 03:47:33,369 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 03:47:34,565 - logger.py:50 - Epoch: [27][0/500] loss: 0.35586, MAE: 0.43415, time/step=1194ms, lr=4.62e-05
2024-03-19 03:48:24,823 - logger.py:50 - Epoch: [27][50/500] loss: 0.56560, MAE: 0.43165, time/step=1009ms, lr=4.62e-05
2024-03-19 03:49:15,674 - logger.py:50 - Epoch: [27][100/500] loss: 0.56002, MAE: 0.43161, time/step=1013ms, lr=4.62e-05
2024-03-19 03:50:06,867 - logger.py:50 - Epoch: [27][150/500] loss: 0.53285, MAE: 0.43462, time/step=1017ms, lr=4.62e-05
2024-03-19 03:50:58,615 - logger.py:50 - Epoch: [27][200/500] loss: 0.56388, MAE: 0.43824, time/step=1021ms, lr=4.62e-05
2024-03-19 03:51:49,179 - logger.py:50 - Epoch: [27][250/500] loss: 0.56286, MAE: 0.43727, time/step=1019ms, lr=4.62e-05
2024-03-19 03:52:40,139 - logger.py:50 - Epoch: [27][300/500] loss: 0.56085, MAE: 0.43874, time/step=1019ms, lr=4.62e-05
2024-03-19 03:53:31,257 - logger.py:50 - Epoch: [27][350/500] loss: 0.56527, MAE: 0.43850, time/step=1020ms, lr=4.62e-05
2024-03-19 03:54:23,348 - logger.py:50 - Epoch: [27][400/500] loss: 0.75868, MAE: 0.44220, time/step=1022ms, lr=4.62e-05
2024-03-19 03:55:13,868 - logger.py:50 - Epoch: [27][450/500] loss: 0.74004, MAE: 0.44113, time/step=1021ms, lr=4.62e-05
2024-03-19 03:56:02,440 - logger.py:50 - Epoch: [27][499/500] loss: 1.03222, MAE: 0.44428, time/step=1018ms, lr=4.62e-05
2024-03-19 03:56:58,660 - logger.py:50 - Epoch: [27] train LOSS: 1.03222, val LOSS: 0.43846, test LOSS: 0.42322, Time: 565.29s
2024-03-19 03:56:58,660 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 03:56:59,788 - logger.py:50 - Epoch: [28][0/500] loss: 0.54132, MAE: 0.47178, time/step=1126ms, lr=4.59e-05
2024-03-19 03:57:51,128 - logger.py:50 - Epoch: [28][50/500] loss: 0.57211, MAE: 0.44364, time/step=1029ms, lr=4.59e-05
2024-03-19 03:58:42,378 - logger.py:50 - Epoch: [28][100/500] loss: 1.40210, MAE: 0.45754, time/step=1027ms, lr=4.59e-05
2024-03-19 03:59:33,958 - logger.py:50 - Epoch: [28][150/500] loss: 1.11365, MAE: 0.45169, time/step=1028ms, lr=4.59e-05
2024-03-19 04:00:24,462 - logger.py:50 - Epoch: [28][200/500] loss: 1.69953, MAE: 0.45767, time/step=1024ms, lr=4.59e-05
2024-03-19 04:01:15,993 - logger.py:50 - Epoch: [28][250/500] loss: 1.46662, MAE: 0.45492, time/step=1025ms, lr=4.59e-05
2024-03-19 04:02:06,753 - logger.py:50 - Epoch: [28][300/500] loss: 1.30137, MAE: 0.44956, time/step=1024ms, lr=4.59e-05
2024-03-19 04:02:58,533 - logger.py:50 - Epoch: [28][350/500] loss: 1.20079, MAE: 0.44766, time/step=1025ms, lr=4.59e-05
2024-03-19 04:03:49,258 - logger.py:50 - Epoch: [28][400/500] loss: 1.12941, MAE: 0.44820, time/step=1024ms, lr=4.59e-05
2024-03-19 04:04:40,745 - logger.py:50 - Epoch: [28][450/500] loss: 1.06587, MAE: 0.44606, time/step=1025ms, lr=4.59e-05
2024-03-19 04:05:30,184 - logger.py:50 - Epoch: [28][499/500] loss: 1.01537, MAE: 0.44431, time/step=1023ms, lr=4.59e-05
2024-03-19 04:06:27,158 - logger.py:50 - Epoch: [28] train LOSS: 1.01537, val LOSS: 0.44808, test LOSS: 0.43328, Time: 568.50s
2024-03-19 04:06:27,158 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 04:06:27,867 - logger.py:50 - Epoch: [29][0/500] loss: 0.42432, MAE: 0.50119, time/step=707ms, lr=4.56e-05
2024-03-19 04:07:18,709 - logger.py:50 - Epoch: [29][50/500] loss: 0.72934, MAE: 0.46359, time/step=1011ms, lr=4.56e-05
2024-03-19 04:08:08,835 - logger.py:50 - Epoch: [29][100/500] loss: 0.63840, MAE: 0.45350, time/step=1007ms, lr=4.56e-05
2024-03-19 04:08:59,083 - logger.py:50 - Epoch: [29][150/500] loss: 0.62480, MAE: 0.45061, time/step=1006ms, lr=4.56e-05
2024-03-19 04:09:50,425 - logger.py:50 - Epoch: [29][200/500] loss: 0.59193, MAE: 0.44346, time/step=1011ms, lr=4.56e-05
2024-03-19 04:10:41,515 - logger.py:50 - Epoch: [29][250/500] loss: 0.58460, MAE: 0.44167, time/step=1013ms, lr=4.56e-05
2024-03-19 04:11:32,889 - logger.py:50 - Epoch: [29][300/500] loss: 0.57759, MAE: 0.44037, time/step=1016ms, lr=4.56e-05
2024-03-19 04:12:23,296 - logger.py:50 - Epoch: [29][350/500] loss: 0.57355, MAE: 0.43924, time/step=1015ms, lr=4.56e-05
2024-03-19 04:13:14,629 - logger.py:50 - Epoch: [29][400/500] loss: 0.57151, MAE: 0.43969, time/step=1016ms, lr=4.56e-05
2024-03-19 04:14:06,021 - logger.py:50 - Epoch: [29][450/500] loss: 0.85691, MAE: 0.44214, time/step=1017ms, lr=4.56e-05
2024-03-19 04:14:56,350 - logger.py:50 - Epoch: [29][499/500] loss: 1.00982, MAE: 0.44458, time/step=1018ms, lr=4.56e-05
2024-03-19 04:15:52,560 - logger.py:50 - Epoch: [29] train LOSS: 1.00982, val LOSS: 0.44086, test LOSS: 0.42616, Time: 565.40s
2024-03-19 04:15:52,560 - logger.py:50 - Best -- epoch=13, train LOSS: 1.11847, val LOSS: 0.43671, test LOSS: 0.42187

2024-03-19 04:15:53,256 - logger.py:50 - Epoch: [30][0/500] loss: 0.48806, MAE: 0.46843, time/step=694ms, lr=4.53e-05
2024-03-19 04:16:45,307 - logger.py:50 - Epoch: [30][50/500] loss: 0.51359, MAE: 0.43113, time/step=1034ms, lr=4.53e-05
2024-03-19 04:17:34,705 - logger.py:50 - Epoch: [30][100/500] loss: 0.52876, MAE: 0.43728, time/step=1011ms, lr=4.53e-05
2024-03-19 04:18:26,034 - logger.py:50 - Epoch: [30][150/500] loss: 0.51715, MAE: 0.43971, time/step=1016ms, lr=4.53e-05
2024-03-19 04:19:17,364 - logger.py:50 - Epoch: [30][200/500] loss: 0.53470, MAE: 0.44052, time/step=1019ms, lr=4.53e-05
2024-03-19 04:20:07,790 - logger.py:50 - Epoch: [30][250/500] loss: 1.10360, MAE: 0.44691, time/step=1017ms, lr=4.53e-05
2024-03-19 04:20:59,981 - logger.py:50 - Epoch: [30][300/500] loss: 1.00370, MAE: 0.44429, time/step=1021ms, lr=4.53e-05
2024-03-19 04:21:50,353 - logger.py:50 - Epoch: [30][350/500] loss: 0.94000, MAE: 0.44277, time/step=1019ms, lr=4.53e-05
2024-03-19 04:22:40,964 - logger.py:50 - Epoch: [30][400/500] loss: 0.89865, MAE: 0.44333, time/step=1018ms, lr=4.53e-05
2024-03-19 04:23:32,571 - logger.py:50 - Epoch: [30][450/500] loss: 0.85933, MAE: 0.44255, time/step=1020ms, lr=4.53e-05
2024-03-19 04:24:22,280 - logger.py:50 - Epoch: [30][499/500] loss: 0.99917, MAE: 0.44444, time/step=1019ms, lr=4.53e-05
2024-03-19 04:25:19,570 - logger.py:50 - Epoch: [30] train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103, Time: 567.01s
2024-03-19 04:25:19,570 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 04:25:20,239 - logger.py:50 - Epoch: [31][0/500] loss: 0.39726, MAE: 0.33254, time/step=668ms, lr=4.50e-05
2024-03-19 04:26:11,822 - logger.py:50 - Epoch: [31][50/500] loss: 0.60473, MAE: 0.43391, time/step=1025ms, lr=4.50e-05
2024-03-19 04:27:03,951 - logger.py:50 - Epoch: [31][100/500] loss: 0.55418, MAE: 0.43698, time/step=1033ms, lr=4.50e-05
2024-03-19 04:27:54,281 - logger.py:50 - Epoch: [31][150/500] loss: 0.57464, MAE: 0.44559, time/step=1025ms, lr=4.50e-05
2024-03-19 04:28:45,143 - logger.py:50 - Epoch: [31][200/500] loss: 0.58030, MAE: 0.44539, time/step=1023ms, lr=4.50e-05
2024-03-19 04:29:36,641 - logger.py:50 - Epoch: [31][250/500] loss: 0.56700, MAE: 0.44137, time/step=1024ms, lr=4.50e-05
2024-03-19 04:30:27,286 - logger.py:50 - Epoch: [31][300/500] loss: 0.56372, MAE: 0.44070, time/step=1022ms, lr=4.50e-05
2024-03-19 04:31:17,795 - logger.py:50 - Epoch: [31][350/500] loss: 0.57735, MAE: 0.44095, time/step=1021ms, lr=4.50e-05
2024-03-19 04:32:09,190 - logger.py:50 - Epoch: [31][400/500] loss: 0.72499, MAE: 0.44296, time/step=1021ms, lr=4.50e-05
2024-03-19 04:33:01,241 - logger.py:50 - Epoch: [31][450/500] loss: 0.70272, MAE: 0.44215, time/step=1024ms, lr=4.50e-05
2024-03-19 04:33:51,744 - logger.py:50 - Epoch: [31][499/500] loss: 1.00249, MAE: 0.44409, time/step=1024ms, lr=4.50e-05
2024-03-19 04:34:48,845 - logger.py:50 - Epoch: [31] train LOSS: 1.00249, val LOSS: 0.43660, test LOSS: 0.42143, Time: 569.28s
2024-03-19 04:34:48,845 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 04:34:49,513 - logger.py:50 - Epoch: [32][0/500] loss: 0.48545, MAE: 0.35279, time/step=666ms, lr=4.47e-05
2024-03-19 04:35:40,801 - logger.py:50 - Epoch: [32][50/500] loss: 0.64402, MAE: 0.42481, time/step=1019ms, lr=4.47e-05
2024-03-19 04:36:31,594 - logger.py:50 - Epoch: [32][100/500] loss: 0.60462, MAE: 0.42966, time/step=1017ms, lr=4.47e-05
2024-03-19 04:37:23,618 - logger.py:50 - Epoch: [32][150/500] loss: 0.56824, MAE: 0.43640, time/step=1025ms, lr=4.47e-05
2024-03-19 04:38:14,719 - logger.py:50 - Epoch: [32][200/500] loss: 1.21027, MAE: 0.44771, time/step=1024ms, lr=4.47e-05
2024-03-19 04:39:05,700 - logger.py:50 - Epoch: [32][250/500] loss: 1.08237, MAE: 0.44576, time/step=1023ms, lr=4.47e-05
2024-03-19 04:39:56,373 - logger.py:50 - Epoch: [32][300/500] loss: 1.00858, MAE: 0.44585, time/step=1022ms, lr=4.47e-05
2024-03-19 04:40:47,183 - logger.py:50 - Epoch: [32][350/500] loss: 0.94731, MAE: 0.44315, time/step=1021ms, lr=4.47e-05
2024-03-19 04:41:38,714 - logger.py:50 - Epoch: [32][400/500] loss: 0.89767, MAE: 0.44264, time/step=1022ms, lr=4.47e-05
2024-03-19 04:42:30,692 - logger.py:50 - Epoch: [32][450/500] loss: 1.05986, MAE: 0.44561, time/step=1024ms, lr=4.47e-05
2024-03-19 04:43:20,996 - logger.py:50 - Epoch: [32][499/500] loss: 1.00370, MAE: 0.44472, time/step=1024ms, lr=4.47e-05
2024-03-19 04:44:18,017 - logger.py:50 - Epoch: [32] train LOSS: 1.00370, val LOSS: 0.44375, test LOSS: 0.42881, Time: 569.17s
2024-03-19 04:44:18,017 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 04:44:19,163 - logger.py:50 - Epoch: [33][0/500] loss: 0.36980, MAE: 0.42206, time/step=1144ms, lr=4.44e-05
2024-03-19 04:45:10,472 - logger.py:50 - Epoch: [33][50/500] loss: 0.51632, MAE: 0.44485, time/step=1028ms, lr=4.44e-05
2024-03-19 04:46:01,501 - logger.py:50 - Epoch: [33][100/500] loss: 0.57239, MAE: 0.44467, time/step=1025ms, lr=4.44e-05
2024-03-19 04:46:53,109 - logger.py:50 - Epoch: [33][150/500] loss: 0.56769, MAE: 0.44410, time/step=1027ms, lr=4.44e-05
2024-03-19 04:47:44,138 - logger.py:50 - Epoch: [33][200/500] loss: 0.57166, MAE: 0.44109, time/step=1025ms, lr=4.44e-05
2024-03-19 04:48:35,991 - logger.py:50 - Epoch: [33][250/500] loss: 1.10067, MAE: 0.44461, time/step=1028ms, lr=4.44e-05
2024-03-19 04:49:27,006 - logger.py:50 - Epoch: [33][300/500] loss: 1.00651, MAE: 0.44286, time/step=1027ms, lr=4.44e-05
2024-03-19 04:50:19,176 - logger.py:50 - Epoch: [33][350/500] loss: 1.16249, MAE: 0.44710, time/step=1029ms, lr=4.44e-05
2024-03-19 04:51:09,857 - logger.py:50 - Epoch: [33][400/500] loss: 1.09294, MAE: 0.44571, time/step=1027ms, lr=4.44e-05
2024-03-19 04:52:01,802 - logger.py:50 - Epoch: [33][450/500] loss: 1.03165, MAE: 0.44650, time/step=1028ms, lr=4.44e-05
2024-03-19 04:52:51,385 - logger.py:50 - Epoch: [33][499/500] loss: 0.98242, MAE: 0.44442, time/step=1027ms, lr=4.44e-05
2024-03-19 04:53:47,938 - logger.py:50 - Epoch: [33] train LOSS: 0.98242, val LOSS: 0.44801, test LOSS: 0.43319, Time: 569.92s
2024-03-19 04:53:47,938 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 04:53:49,130 - logger.py:50 - Epoch: [34][0/500] loss: 0.63167, MAE: 0.49308, time/step=1190ms, lr=4.40e-05
2024-03-19 04:54:39,691 - logger.py:50 - Epoch: [34][50/500] loss: 0.51399, MAE: 0.43307, time/step=1015ms, lr=4.40e-05
2024-03-19 04:55:32,625 - logger.py:50 - Epoch: [34][100/500] loss: 1.12800, MAE: 0.44207, time/step=1036ms, lr=4.40e-05
2024-03-19 04:56:23,621 - logger.py:50 - Epoch: [34][150/500] loss: 1.80276, MAE: 0.45229, time/step=1031ms, lr=4.40e-05
2024-03-19 04:57:14,426 - logger.py:50 - Epoch: [34][200/500] loss: 1.53796, MAE: 0.44947, time/step=1027ms, lr=4.40e-05
2024-03-19 04:58:05,422 - logger.py:50 - Epoch: [34][250/500] loss: 1.36180, MAE: 0.44719, time/step=1026ms, lr=4.40e-05
2024-03-19 04:58:57,416 - logger.py:50 - Epoch: [34][300/500] loss: 1.21359, MAE: 0.44709, time/step=1028ms, lr=4.40e-05
2024-03-19 04:59:48,261 - logger.py:50 - Epoch: [34][350/500] loss: 1.12599, MAE: 0.44586, time/step=1027ms, lr=4.40e-05
2024-03-19 05:00:40,423 - logger.py:50 - Epoch: [34][400/500] loss: 1.04981, MAE: 0.44413, time/step=1029ms, lr=4.40e-05
2024-03-19 05:01:31,665 - logger.py:50 - Epoch: [34][450/500] loss: 0.98711, MAE: 0.44299, time/step=1028ms, lr=4.40e-05
2024-03-19 05:02:22,008 - logger.py:50 - Epoch: [34][499/500] loss: 0.94792, MAE: 0.44412, time/step=1028ms, lr=4.40e-05
2024-03-19 05:03:19,450 - logger.py:50 - Epoch: [34] train LOSS: 0.94792, val LOSS: 0.44478, test LOSS: 0.42959, Time: 571.51s
2024-03-19 05:03:19,450 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 05:03:20,498 - logger.py:50 - Epoch: [35][0/500] loss: 0.64905, MAE: 0.43378, time/step=1046ms, lr=4.37e-05
2024-03-19 05:04:12,021 - logger.py:50 - Epoch: [35][50/500] loss: 0.58728, MAE: 0.44435, time/step=1031ms, lr=4.37e-05
2024-03-19 05:05:02,922 - logger.py:50 - Epoch: [35][100/500] loss: 1.35507, MAE: 0.45697, time/step=1024ms, lr=4.37e-05
2024-03-19 05:05:54,406 - logger.py:50 - Epoch: [35][150/500] loss: 1.11935, MAE: 0.45298, time/step=1026ms, lr=4.37e-05
2024-03-19 05:06:44,992 - logger.py:50 - Epoch: [35][200/500] loss: 0.96679, MAE: 0.44529, time/step=1023ms, lr=4.37e-05
2024-03-19 05:07:36,161 - logger.py:50 - Epoch: [35][250/500] loss: 0.87495, MAE: 0.44226, time/step=1023ms, lr=4.37e-05
2024-03-19 05:08:28,113 - logger.py:50 - Epoch: [35][300/500] loss: 0.82781, MAE: 0.44181, time/step=1025ms, lr=4.37e-05
2024-03-19 05:09:18,339 - logger.py:50 - Epoch: [35][350/500] loss: 0.79165, MAE: 0.44108, time/step=1022ms, lr=4.37e-05
2024-03-19 05:10:08,865 - logger.py:50 - Epoch: [35][400/500] loss: 0.75330, MAE: 0.43992, time/step=1021ms, lr=4.37e-05
2024-03-19 05:11:00,750 - logger.py:50 - Epoch: [35][450/500] loss: 1.05802, MAE: 0.44452, time/step=1023ms, lr=4.37e-05
2024-03-19 05:11:51,551 - logger.py:50 - Epoch: [35][499/500] loss: 1.00367, MAE: 0.44440, time/step=1024ms, lr=4.37e-05
2024-03-19 05:12:48,844 - logger.py:50 - Epoch: [35] train LOSS: 1.00367, val LOSS: 0.44288, test LOSS: 0.42831, Time: 569.39s
2024-03-19 05:12:48,845 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 05:12:49,889 - logger.py:50 - Epoch: [36][0/500] loss: 0.50704, MAE: 0.46310, time/step=1043ms, lr=4.34e-05
2024-03-19 05:13:41,880 - logger.py:50 - Epoch: [36][50/500] loss: 0.56026, MAE: 0.43028, time/step=1040ms, lr=4.34e-05
2024-03-19 05:14:33,212 - logger.py:50 - Epoch: [36][100/500] loss: 0.58348, MAE: 0.44002, time/step=1033ms, lr=4.34e-05
2024-03-19 05:15:24,141 - logger.py:50 - Epoch: [36][150/500] loss: 0.56390, MAE: 0.43888, time/step=1028ms, lr=4.34e-05
2024-03-19 05:16:15,326 - logger.py:50 - Epoch: [36][200/500] loss: 0.55496, MAE: 0.43883, time/step=1027ms, lr=4.34e-05
2024-03-19 05:17:05,417 - logger.py:50 - Epoch: [36][250/500] loss: 0.87918, MAE: 0.44461, time/step=1022ms, lr=4.34e-05
2024-03-19 05:17:56,326 - logger.py:50 - Epoch: [36][300/500] loss: 0.81040, MAE: 0.44082, time/step=1022ms, lr=4.34e-05
2024-03-19 05:18:48,028 - logger.py:50 - Epoch: [36][350/500] loss: 0.76812, MAE: 0.43972, time/step=1023ms, lr=4.34e-05
2024-03-19 05:19:38,680 - logger.py:50 - Epoch: [36][400/500] loss: 0.73280, MAE: 0.43970, time/step=1022ms, lr=4.34e-05
2024-03-19 05:20:29,678 - logger.py:50 - Epoch: [36][450/500] loss: 1.02882, MAE: 0.44334, time/step=1022ms, lr=4.34e-05
2024-03-19 05:21:20,034 - logger.py:50 - Epoch: [36][499/500] loss: 0.99057, MAE: 0.44422, time/step=1022ms, lr=4.34e-05
2024-03-19 05:22:16,990 - logger.py:50 - Epoch: [36] train LOSS: 0.99057, val LOSS: 0.44378, test LOSS: 0.42844, Time: 568.15s
2024-03-19 05:22:16,990 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 05:22:18,126 - logger.py:50 - Epoch: [37][0/500] loss: 0.69029, MAE: 0.43765, time/step=1133ms, lr=4.30e-05
2024-03-19 05:23:09,153 - logger.py:50 - Epoch: [37][50/500] loss: 0.49663, MAE: 0.42768, time/step=1023ms, lr=4.30e-05
2024-03-19 05:24:00,404 - logger.py:50 - Epoch: [37][100/500] loss: 0.51776, MAE: 0.43734, time/step=1024ms, lr=4.30e-05
2024-03-19 05:24:50,627 - logger.py:50 - Epoch: [37][150/500] loss: 1.02280, MAE: 0.45076, time/step=1017ms, lr=4.30e-05
2024-03-19 05:25:42,412 - logger.py:50 - Epoch: [37][200/500] loss: 0.89665, MAE: 0.44832, time/step=1022ms, lr=4.30e-05
2024-03-19 05:26:34,043 - logger.py:50 - Epoch: [37][250/500] loss: 0.81293, MAE: 0.44585, time/step=1024ms, lr=4.30e-05
2024-03-19 05:27:25,500 - logger.py:50 - Epoch: [37][300/500] loss: 0.77968, MAE: 0.44341, time/step=1025ms, lr=4.30e-05
2024-03-19 05:28:17,222 - logger.py:50 - Epoch: [37][350/500] loss: 0.75310, MAE: 0.44426, time/step=1026ms, lr=4.30e-05
2024-03-19 05:29:08,615 - logger.py:50 - Epoch: [37][400/500] loss: 0.73014, MAE: 0.44385, time/step=1026ms, lr=4.30e-05
2024-03-19 05:29:59,391 - logger.py:50 - Epoch: [37][450/500] loss: 0.70421, MAE: 0.44093, time/step=1025ms, lr=4.30e-05
2024-03-19 05:30:49,940 - logger.py:50 - Epoch: [37][499/500] loss: 0.98068, MAE: 0.44442, time/step=1026ms, lr=4.30e-05
2024-03-19 05:31:47,399 - logger.py:50 - Epoch: [37] train LOSS: 0.98068, val LOSS: 0.44439, test LOSS: 0.42959, Time: 570.41s
2024-03-19 05:31:47,399 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 05:31:48,122 - logger.py:50 - Epoch: [38][0/500] loss: 0.57061, MAE: 0.51822, time/step=721ms, lr=4.26e-05
2024-03-19 05:32:38,968 - logger.py:50 - Epoch: [38][50/500] loss: 0.57425, MAE: 0.42887, time/step=1011ms, lr=4.26e-05
2024-03-19 05:33:30,639 - logger.py:50 - Epoch: [38][100/500] loss: 0.55122, MAE: 0.43555, time/step=1022ms, lr=4.26e-05
2024-03-19 05:34:21,525 - logger.py:50 - Epoch: [38][150/500] loss: 0.53073, MAE: 0.43453, time/step=1021ms, lr=4.26e-05
2024-03-19 05:35:13,833 - logger.py:50 - Epoch: [38][200/500] loss: 0.55193, MAE: 0.43211, time/step=1027ms, lr=4.26e-05
2024-03-19 05:36:05,419 - logger.py:50 - Epoch: [38][250/500] loss: 0.56097, MAE: 0.43744, time/step=1028ms, lr=4.26e-05
2024-03-19 05:36:57,385 - logger.py:50 - Epoch: [38][300/500] loss: 0.96776, MAE: 0.44606, time/step=1030ms, lr=4.26e-05
2024-03-19 05:37:48,010 - logger.py:50 - Epoch: [38][350/500] loss: 0.92560, MAE: 0.44585, time/step=1027ms, lr=4.26e-05
2024-03-19 05:38:39,653 - logger.py:50 - Epoch: [38][400/500] loss: 0.87222, MAE: 0.44483, time/step=1028ms, lr=4.26e-05
2024-03-19 05:39:30,366 - logger.py:50 - Epoch: [38][450/500] loss: 0.99756, MAE: 0.44581, time/step=1027ms, lr=4.26e-05
2024-03-19 05:40:20,590 - logger.py:50 - Epoch: [38][499/500] loss: 0.95694, MAE: 0.44452, time/step=1026ms, lr=4.26e-05
2024-03-19 05:41:17,580 - logger.py:50 - Epoch: [38] train LOSS: 0.95694, val LOSS: 0.44692, test LOSS: 0.43207, Time: 570.18s
2024-03-19 05:41:17,580 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 05:41:18,752 - logger.py:50 - Epoch: [39][0/500] loss: 0.21486, MAE: 0.41821, time/step=1170ms, lr=4.23e-05
2024-03-19 05:42:09,141 - logger.py:50 - Epoch: [39][50/500] loss: 0.48110, MAE: 0.42935, time/step=1011ms, lr=4.23e-05
2024-03-19 05:43:00,892 - logger.py:50 - Epoch: [39][100/500] loss: 0.49722, MAE: 0.42668, time/step=1023ms, lr=4.23e-05
2024-03-19 05:43:52,188 - logger.py:50 - Epoch: [39][150/500] loss: 0.51330, MAE: 0.43066, time/step=1024ms, lr=4.23e-05
2024-03-19 05:44:41,780 - logger.py:50 - Epoch: [39][200/500] loss: 0.52896, MAE: 0.43142, time/step=1016ms, lr=4.23e-05
2024-03-19 05:45:33,052 - logger.py:50 - Epoch: [39][250/500] loss: 1.34700, MAE: 0.43958, time/step=1018ms, lr=4.23e-05
2024-03-19 05:46:24,586 - logger.py:50 - Epoch: [39][300/500] loss: 1.21554, MAE: 0.43900, time/step=1020ms, lr=4.23e-05
2024-03-19 05:47:16,301 - logger.py:50 - Epoch: [39][350/500] loss: 1.12258, MAE: 0.43969, time/step=1022ms, lr=4.23e-05
2024-03-19 05:48:07,212 - logger.py:50 - Epoch: [39][400/500] loss: 1.36796, MAE: 0.44626, time/step=1022ms, lr=4.23e-05
2024-03-19 05:48:59,389 - logger.py:50 - Epoch: [39][450/500] loss: 1.26816, MAE: 0.44413, time/step=1024ms, lr=4.23e-05
2024-03-19 05:49:49,204 - logger.py:50 - Epoch: [39][499/500] loss: 1.20485, MAE: 0.44419, time/step=1023ms, lr=4.23e-05
2024-03-19 05:50:45,714 - logger.py:50 - Epoch: [39] train LOSS: 1.20485, val LOSS: 0.44958, test LOSS: 0.43553, Time: 568.13s
2024-03-19 05:50:45,715 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 05:50:46,818 - logger.py:50 - Epoch: [40][0/500] loss: 0.27553, MAE: 0.33199, time/step=1101ms, lr=4.19e-05
2024-03-19 05:51:36,819 - logger.py:50 - Epoch: [40][50/500] loss: 3.00251, MAE: 0.45135, time/step=1002ms, lr=4.19e-05
2024-03-19 05:52:27,115 - logger.py:50 - Epoch: [40][100/500] loss: 1.80229, MAE: 0.45168, time/step=1004ms, lr=4.19e-05
2024-03-19 05:53:19,064 - logger.py:50 - Epoch: [40][150/500] loss: 1.41578, MAE: 0.45415, time/step=1016ms, lr=4.19e-05
2024-03-19 05:54:10,612 - logger.py:50 - Epoch: [40][200/500] loss: 1.17820, MAE: 0.45309, time/step=1019ms, lr=4.19e-05
2024-03-19 05:55:02,113 - logger.py:50 - Epoch: [40][250/500] loss: 1.37161, MAE: 0.45478, time/step=1022ms, lr=4.19e-05
2024-03-19 05:55:52,332 - logger.py:50 - Epoch: [40][300/500] loss: 1.24258, MAE: 0.45326, time/step=1019ms, lr=4.19e-05
2024-03-19 05:56:44,850 - logger.py:50 - Epoch: [40][350/500] loss: 1.13273, MAE: 0.45112, time/step=1023ms, lr=4.19e-05
2024-03-19 05:57:36,460 - logger.py:50 - Epoch: [40][400/500] loss: 1.05353, MAE: 0.44821, time/step=1024ms, lr=4.19e-05
2024-03-19 05:58:28,206 - logger.py:50 - Epoch: [40][450/500] loss: 0.99433, MAE: 0.44540, time/step=1025ms, lr=4.19e-05
2024-03-19 05:59:18,588 - logger.py:50 - Epoch: [40][499/500] loss: 0.94256, MAE: 0.44459, time/step=1026ms, lr=4.19e-05
2024-03-19 06:00:15,596 - logger.py:50 - Epoch: [40] train LOSS: 0.94256, val LOSS: 0.44461, test LOSS: 0.42968, Time: 569.88s
2024-03-19 06:00:15,596 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 06:00:16,658 - logger.py:50 - Epoch: [41][0/500] loss: 0.39863, MAE: 0.42626, time/step=1061ms, lr=4.15e-05
2024-03-19 06:01:07,444 - logger.py:50 - Epoch: [41][50/500] loss: 1.72374, MAE: 0.46602, time/step=1017ms, lr=4.15e-05
2024-03-19 06:01:58,436 - logger.py:50 - Epoch: [41][100/500] loss: 1.11819, MAE: 0.44371, time/step=1018ms, lr=4.15e-05
2024-03-19 06:02:49,216 - logger.py:50 - Epoch: [41][150/500] loss: 0.92592, MAE: 0.44587, time/step=1017ms, lr=4.15e-05
2024-03-19 06:03:40,114 - logger.py:50 - Epoch: [41][200/500] loss: 0.83264, MAE: 0.43979, time/step=1017ms, lr=4.15e-05
2024-03-19 06:04:31,943 - logger.py:50 - Epoch: [41][250/500] loss: 0.78006, MAE: 0.44018, time/step=1021ms, lr=4.15e-05
2024-03-19 06:05:23,527 - logger.py:50 - Epoch: [41][300/500] loss: 1.18667, MAE: 0.44549, time/step=1023ms, lr=4.15e-05
2024-03-19 06:06:15,069 - logger.py:50 - Epoch: [41][350/500] loss: 1.09025, MAE: 0.44383, time/step=1024ms, lr=4.15e-05
2024-03-19 06:07:07,088 - logger.py:50 - Epoch: [41][400/500] loss: 1.01742, MAE: 0.44371, time/step=1026ms, lr=4.15e-05
2024-03-19 06:07:58,160 - logger.py:50 - Epoch: [41][450/500] loss: 0.96168, MAE: 0.44362, time/step=1026ms, lr=4.15e-05
2024-03-19 06:08:48,468 - logger.py:50 - Epoch: [41][499/500] loss: 0.93033, MAE: 0.44426, time/step=1026ms, lr=4.15e-05
2024-03-19 06:09:45,417 - logger.py:50 - Epoch: [41] train LOSS: 0.93033, val LOSS: 0.44143, test LOSS: 0.42638, Time: 569.82s
2024-03-19 06:09:45,418 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 06:09:46,126 - logger.py:50 - Epoch: [42][0/500] loss: 0.28562, MAE: 0.35308, time/step=707ms, lr=4.11e-05
2024-03-19 06:10:37,715 - logger.py:50 - Epoch: [42][50/500] loss: 0.59709, MAE: 0.44316, time/step=1025ms, lr=4.11e-05
2024-03-19 06:11:28,034 - logger.py:50 - Epoch: [42][100/500] loss: 0.57379, MAE: 0.43700, time/step=1016ms, lr=4.11e-05
2024-03-19 06:12:18,687 - logger.py:50 - Epoch: [42][150/500] loss: 0.56153, MAE: 0.43315, time/step=1015ms, lr=4.11e-05
2024-03-19 06:13:10,165 - logger.py:50 - Epoch: [42][200/500] loss: 0.54611, MAE: 0.43548, time/step=1019ms, lr=4.11e-05
2024-03-19 06:14:01,669 - logger.py:50 - Epoch: [42][250/500] loss: 0.82517, MAE: 0.44259, time/step=1021ms, lr=4.11e-05
2024-03-19 06:14:53,737 - logger.py:50 - Epoch: [42][300/500] loss: 0.77240, MAE: 0.43889, time/step=1024ms, lr=4.11e-05
2024-03-19 06:15:44,996 - logger.py:50 - Epoch: [42][350/500] loss: 0.74494, MAE: 0.44003, time/step=1024ms, lr=4.11e-05
2024-03-19 06:16:36,557 - logger.py:50 - Epoch: [42][400/500] loss: 0.72770, MAE: 0.43957, time/step=1025ms, lr=4.11e-05
2024-03-19 06:17:27,737 - logger.py:50 - Epoch: [42][450/500] loss: 0.99626, MAE: 0.44364, time/step=1025ms, lr=4.11e-05
2024-03-19 06:18:18,703 - logger.py:50 - Epoch: [42][499/500] loss: 0.94850, MAE: 0.44434, time/step=1027ms, lr=4.11e-05
2024-03-19 06:19:16,254 - logger.py:50 - Epoch: [42] train LOSS: 0.94850, val LOSS: 0.44469, test LOSS: 0.42985, Time: 570.84s
2024-03-19 06:19:16,255 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 06:19:17,516 - logger.py:50 - Epoch: [43][0/500] loss: 0.70148, MAE: 0.37460, time/step=1259ms, lr=4.07e-05
2024-03-19 06:20:08,310 - logger.py:50 - Epoch: [43][50/500] loss: 0.54180, MAE: 0.42984, time/step=1021ms, lr=4.07e-05
2024-03-19 06:21:00,340 - logger.py:50 - Epoch: [43][100/500] loss: 1.72789, MAE: 0.45197, time/step=1031ms, lr=4.07e-05
2024-03-19 06:21:52,523 - logger.py:50 - Epoch: [43][150/500] loss: 1.35232, MAE: 0.45006, time/step=1035ms, lr=4.07e-05
2024-03-19 06:22:43,948 - logger.py:50 - Epoch: [43][200/500] loss: 1.48469, MAE: 0.45478, time/step=1033ms, lr=4.07e-05
2024-03-19 06:23:35,553 - logger.py:50 - Epoch: [43][250/500] loss: 1.29543, MAE: 0.45005, time/step=1033ms, lr=4.07e-05
2024-03-19 06:24:26,106 - logger.py:50 - Epoch: [43][300/500] loss: 1.17818, MAE: 0.44928, time/step=1029ms, lr=4.07e-05
2024-03-19 06:25:16,994 - logger.py:50 - Epoch: [43][350/500] loss: 1.08525, MAE: 0.44791, time/step=1028ms, lr=4.07e-05
2024-03-19 06:26:08,499 - logger.py:50 - Epoch: [43][400/500] loss: 1.00945, MAE: 0.44569, time/step=1028ms, lr=4.07e-05
2024-03-19 06:26:59,852 - logger.py:50 - Epoch: [43][450/500] loss: 0.95578, MAE: 0.44541, time/step=1028ms, lr=4.07e-05
2024-03-19 06:27:50,394 - logger.py:50 - Epoch: [43][499/500] loss: 0.91604, MAE: 0.44449, time/step=1028ms, lr=4.07e-05
2024-03-19 06:28:47,025 - logger.py:50 - Epoch: [43] train LOSS: 0.91604, val LOSS: 0.43684, test LOSS: 0.42214, Time: 570.77s
2024-03-19 06:28:47,025 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 06:28:48,145 - logger.py:50 - Epoch: [44][0/500] loss: 0.75302, MAE: 0.39674, time/step=1118ms, lr=4.03e-05
2024-03-19 06:29:39,935 - logger.py:50 - Epoch: [44][50/500] loss: 0.50509, MAE: 0.43276, time/step=1037ms, lr=4.03e-05
2024-03-19 06:30:31,869 - logger.py:50 - Epoch: [44][100/500] loss: 0.51339, MAE: 0.43275, time/step=1038ms, lr=4.03e-05
2024-03-19 06:31:22,904 - logger.py:50 - Epoch: [44][150/500] loss: 0.54527, MAE: 0.43660, time/step=1032ms, lr=4.03e-05
2024-03-19 06:32:14,810 - logger.py:50 - Epoch: [44][200/500] loss: 0.53748, MAE: 0.43933, time/step=1034ms, lr=4.03e-05
2024-03-19 06:33:06,325 - logger.py:50 - Epoch: [44][250/500] loss: 0.81623, MAE: 0.44528, time/step=1033ms, lr=4.03e-05
2024-03-19 06:33:56,623 - logger.py:50 - Epoch: [44][300/500] loss: 0.77510, MAE: 0.44432, time/step=1029ms, lr=4.03e-05
2024-03-19 06:34:47,349 - logger.py:50 - Epoch: [44][350/500] loss: 0.74129, MAE: 0.44241, time/step=1027ms, lr=4.03e-05
2024-03-19 06:35:38,247 - logger.py:50 - Epoch: [44][400/500] loss: 0.71643, MAE: 0.44195, time/step=1025ms, lr=4.03e-05
2024-03-19 06:36:31,082 - logger.py:50 - Epoch: [44][450/500] loss: 0.96988, MAE: 0.44568, time/step=1029ms, lr=4.03e-05
2024-03-19 06:37:22,430 - logger.py:50 - Epoch: [44][499/500] loss: 0.93067, MAE: 0.44426, time/step=1031ms, lr=4.03e-05
2024-03-19 06:38:19,519 - logger.py:50 - Epoch: [44] train LOSS: 0.93067, val LOSS: 0.44523, test LOSS: 0.43018, Time: 572.49s
2024-03-19 06:38:19,519 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 06:38:20,670 - logger.py:50 - Epoch: [45][0/500] loss: 1.08005, MAE: 0.48105, time/step=1149ms, lr=3.99e-05
2024-03-19 06:39:12,215 - logger.py:50 - Epoch: [45][50/500] loss: 4.36085, MAE: 0.51230, time/step=1033ms, lr=3.99e-05
2024-03-19 06:40:03,247 - logger.py:50 - Epoch: [45][100/500] loss: 2.49126, MAE: 0.47821, time/step=1027ms, lr=3.99e-05
2024-03-19 06:40:53,798 - logger.py:50 - Epoch: [45][150/500] loss: 1.83773, MAE: 0.46484, time/step=1022ms, lr=3.99e-05
2024-03-19 06:41:45,490 - logger.py:50 - Epoch: [45][200/500] loss: 1.52448, MAE: 0.45461, time/step=1025ms, lr=3.99e-05
2024-03-19 06:42:37,375 - logger.py:50 - Epoch: [45][250/500] loss: 1.31865, MAE: 0.44984, time/step=1027ms, lr=3.99e-05
2024-03-19 06:43:28,456 - logger.py:50 - Epoch: [45][300/500] loss: 1.18768, MAE: 0.44905, time/step=1026ms, lr=3.99e-05
2024-03-19 06:44:20,159 - logger.py:50 - Epoch: [45][350/500] loss: 1.09780, MAE: 0.44685, time/step=1027ms, lr=3.99e-05
2024-03-19 06:45:11,046 - logger.py:50 - Epoch: [45][400/500] loss: 1.02935, MAE: 0.44678, time/step=1026ms, lr=3.99e-05
2024-03-19 06:46:02,100 - logger.py:50 - Epoch: [45][450/500] loss: 0.98120, MAE: 0.44617, time/step=1026ms, lr=3.99e-05
2024-03-19 06:46:53,576 - logger.py:50 - Epoch: [45][499/500] loss: 0.92672, MAE: 0.44461, time/step=1028ms, lr=3.99e-05
2024-03-19 06:47:50,564 - logger.py:50 - Epoch: [45] train LOSS: 0.92672, val LOSS: 0.45020, test LOSS: 0.43522, Time: 571.04s
2024-03-19 06:47:50,564 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 06:47:51,739 - logger.py:50 - Epoch: [46][0/500] loss: 0.51969, MAE: 0.38757, time/step=1173ms, lr=3.95e-05
2024-03-19 06:48:43,445 - logger.py:50 - Epoch: [46][50/500] loss: 0.47899, MAE: 0.43542, time/step=1037ms, lr=3.95e-05
2024-03-19 06:49:34,855 - logger.py:50 - Epoch: [46][100/500] loss: 0.48128, MAE: 0.43465, time/step=1033ms, lr=3.95e-05
2024-03-19 06:50:25,659 - logger.py:50 - Epoch: [46][150/500] loss: 0.52727, MAE: 0.43535, time/step=1027ms, lr=3.95e-05
2024-03-19 06:51:17,684 - logger.py:50 - Epoch: [46][200/500] loss: 0.52977, MAE: 0.43409, time/step=1030ms, lr=3.95e-05
2024-03-19 06:52:08,583 - logger.py:50 - Epoch: [46][250/500] loss: 0.54193, MAE: 0.43258, time/step=1028ms, lr=3.95e-05
2024-03-19 06:53:00,048 - logger.py:50 - Epoch: [46][300/500] loss: 0.73376, MAE: 0.43591, time/step=1028ms, lr=3.95e-05
2024-03-19 06:53:51,828 - logger.py:50 - Epoch: [46][350/500] loss: 1.06261, MAE: 0.44252, time/step=1029ms, lr=3.95e-05
2024-03-19 06:54:42,929 - logger.py:50 - Epoch: [46][400/500] loss: 1.00925, MAE: 0.44316, time/step=1028ms, lr=3.95e-05
2024-03-19 06:55:34,107 - logger.py:50 - Epoch: [46][450/500] loss: 0.96123, MAE: 0.44476, time/step=1028ms, lr=3.95e-05
2024-03-19 06:56:23,675 - logger.py:50 - Epoch: [46][499/500] loss: 0.91744, MAE: 0.44421, time/step=1026ms, lr=3.95e-05
2024-03-19 06:57:20,203 - logger.py:50 - Epoch: [46] train LOSS: 0.91744, val LOSS: 0.45297, test LOSS: 0.43787, Time: 569.64s
2024-03-19 06:57:20,203 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 06:57:21,348 - logger.py:50 - Epoch: [47][0/500] loss: 0.25040, MAE: 0.40345, time/step=1143ms, lr=3.91e-05
2024-03-19 06:58:12,408 - logger.py:50 - Epoch: [47][50/500] loss: 0.49386, MAE: 0.43373, time/step=1024ms, lr=3.91e-05
2024-03-19 06:59:03,088 - logger.py:50 - Epoch: [47][100/500] loss: 0.52532, MAE: 0.43990, time/step=1019ms, lr=3.91e-05
2024-03-19 06:59:53,500 - logger.py:50 - Epoch: [47][150/500] loss: 0.53373, MAE: 0.44008, time/step=1015ms, lr=3.91e-05
2024-03-19 07:00:44,422 - logger.py:50 - Epoch: [47][200/500] loss: 0.85951, MAE: 0.44647, time/step=1016ms, lr=3.91e-05
2024-03-19 07:01:35,935 - logger.py:50 - Epoch: [47][250/500] loss: 0.78243, MAE: 0.44487, time/step=1019ms, lr=3.91e-05
2024-03-19 07:02:27,786 - logger.py:50 - Epoch: [47][300/500] loss: 0.74176, MAE: 0.44274, time/step=1022ms, lr=3.91e-05
2024-03-19 07:03:18,582 - logger.py:50 - Epoch: [47][350/500] loss: 1.10686, MAE: 0.44864, time/step=1021ms, lr=3.91e-05
2024-03-19 07:04:10,527 - logger.py:50 - Epoch: [47][400/500] loss: 1.02488, MAE: 0.44370, time/step=1023ms, lr=3.91e-05
2024-03-19 07:05:01,276 - logger.py:50 - Epoch: [47][450/500] loss: 0.97838, MAE: 0.44379, time/step=1022ms, lr=3.91e-05
2024-03-19 07:05:51,477 - logger.py:50 - Epoch: [47][499/500] loss: 0.94310, MAE: 0.44430, time/step=1023ms, lr=3.91e-05
2024-03-19 07:06:48,458 - logger.py:50 - Epoch: [47] train LOSS: 0.94310, val LOSS: 0.45190, test LOSS: 0.43725, Time: 568.25s
2024-03-19 07:06:48,458 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 07:06:49,747 - logger.py:50 - Epoch: [48][0/500] loss: 0.51830, MAE: 0.52220, time/step=1287ms, lr=3.86e-05
2024-03-19 07:07:41,029 - logger.py:50 - Epoch: [48][50/500] loss: 0.50232, MAE: 0.43276, time/step=1031ms, lr=3.86e-05
2024-03-19 07:08:31,936 - logger.py:50 - Epoch: [48][100/500] loss: 0.48745, MAE: 0.43529, time/step=1025ms, lr=3.86e-05
2024-03-19 07:09:24,026 - logger.py:50 - Epoch: [48][150/500] loss: 0.49537, MAE: 0.43588, time/step=1030ms, lr=3.86e-05
2024-03-19 07:10:14,979 - logger.py:50 - Epoch: [48][200/500] loss: 0.51446, MAE: 0.43585, time/step=1027ms, lr=3.86e-05
2024-03-19 07:11:06,047 - logger.py:50 - Epoch: [48][250/500] loss: 0.51386, MAE: 0.43611, time/step=1026ms, lr=3.86e-05
2024-03-19 07:11:56,293 - logger.py:50 - Epoch: [48][300/500] loss: 0.51547, MAE: 0.43952, time/step=1023ms, lr=3.86e-05
2024-03-19 07:12:48,054 - logger.py:50 - Epoch: [48][350/500] loss: 1.03707, MAE: 0.45000, time/step=1024ms, lr=3.86e-05
2024-03-19 07:13:39,465 - logger.py:50 - Epoch: [48][400/500] loss: 0.97171, MAE: 0.44795, time/step=1025ms, lr=3.86e-05
2024-03-19 07:14:30,456 - logger.py:50 - Epoch: [48][450/500] loss: 0.93986, MAE: 0.44559, time/step=1024ms, lr=3.86e-05
2024-03-19 07:15:20,809 - logger.py:50 - Epoch: [48][499/500] loss: 0.90340, MAE: 0.44446, time/step=1025ms, lr=3.86e-05
2024-03-19 07:16:17,473 - logger.py:50 - Epoch: [48] train LOSS: 0.90340, val LOSS: 0.45247, test LOSS: 0.43761, Time: 569.02s
2024-03-19 07:16:17,474 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 07:16:18,637 - logger.py:50 - Epoch: [49][0/500] loss: 0.74557, MAE: 0.43368, time/step=1161ms, lr=3.82e-05
2024-03-19 07:17:10,110 - logger.py:50 - Epoch: [49][50/500] loss: 0.49026, MAE: 0.44024, time/step=1032ms, lr=3.82e-05
2024-03-19 07:18:01,391 - logger.py:50 - Epoch: [49][100/500] loss: 0.53569, MAE: 0.44300, time/step=1029ms, lr=3.82e-05
2024-03-19 07:18:52,756 - logger.py:50 - Epoch: [49][150/500] loss: 0.53638, MAE: 0.44499, time/step=1028ms, lr=3.82e-05
2024-03-19 07:19:43,907 - logger.py:50 - Epoch: [49][200/500] loss: 0.84972, MAE: 0.44726, time/step=1027ms, lr=3.82e-05
2024-03-19 07:20:36,504 - logger.py:50 - Epoch: [49][250/500] loss: 0.78822, MAE: 0.44737, time/step=1032ms, lr=3.82e-05
2024-03-19 07:21:27,188 - logger.py:50 - Epoch: [49][300/500] loss: 1.13678, MAE: 0.45171, time/step=1029ms, lr=3.82e-05
2024-03-19 07:22:18,741 - logger.py:50 - Epoch: [49][350/500] loss: 1.06082, MAE: 0.44867, time/step=1029ms, lr=3.82e-05
2024-03-19 07:23:09,356 - logger.py:50 - Epoch: [49][400/500] loss: 0.99770, MAE: 0.44761, time/step=1027ms, lr=3.82e-05
2024-03-19 07:24:00,931 - logger.py:50 - Epoch: [49][450/500] loss: 0.94626, MAE: 0.44591, time/step=1028ms, lr=3.82e-05
2024-03-19 07:24:49,891 - logger.py:50 - Epoch: [49][499/500] loss: 0.90829, MAE: 0.44429, time/step=1025ms, lr=3.82e-05
2024-03-19 07:25:47,412 - logger.py:50 - Epoch: [49] train LOSS: 0.90829, val LOSS: 0.44883, test LOSS: 0.43366, Time: 569.94s
2024-03-19 07:25:47,413 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 07:25:48,629 - logger.py:50 - Epoch: [50][0/500] loss: 0.35843, MAE: 0.43893, time/step=1214ms, lr=3.78e-05
2024-03-19 07:26:38,902 - logger.py:50 - Epoch: [50][50/500] loss: 2.00828, MAE: 0.47265, time/step=1010ms, lr=3.78e-05
2024-03-19 07:27:29,443 - logger.py:50 - Epoch: [50][100/500] loss: 1.33111, MAE: 0.45487, time/step=1010ms, lr=3.78e-05
2024-03-19 07:28:21,390 - logger.py:50 - Epoch: [50][150/500] loss: 1.05334, MAE: 0.45393, time/step=1020ms, lr=3.78e-05
2024-03-19 07:29:13,232 - logger.py:50 - Epoch: [50][200/500] loss: 1.59588, MAE: 0.45989, time/step=1024ms, lr=3.78e-05
2024-03-19 07:30:05,539 - logger.py:50 - Epoch: [50][250/500] loss: 1.36783, MAE: 0.45510, time/step=1028ms, lr=3.78e-05
2024-03-19 07:30:57,030 - logger.py:50 - Epoch: [50][300/500] loss: 1.22780, MAE: 0.45194, time/step=1029ms, lr=3.78e-05
2024-03-19 07:31:48,783 - logger.py:50 - Epoch: [50][350/500] loss: 1.12734, MAE: 0.44992, time/step=1030ms, lr=3.78e-05
2024-03-19 07:32:39,842 - logger.py:50 - Epoch: [50][400/500] loss: 1.04383, MAE: 0.44757, time/step=1028ms, lr=3.78e-05
2024-03-19 07:33:31,250 - logger.py:50 - Epoch: [50][450/500] loss: 0.98694, MAE: 0.44745, time/step=1028ms, lr=3.78e-05
2024-03-19 07:34:20,772 - logger.py:50 - Epoch: [50][499/500] loss: 0.94228, MAE: 0.44443, time/step=1027ms, lr=3.78e-05
2024-03-19 07:35:17,867 - logger.py:50 - Epoch: [50] train LOSS: 0.94228, val LOSS: 0.44564, test LOSS: 0.43085, Time: 570.45s
2024-03-19 07:35:17,867 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 07:35:19,035 - logger.py:50 - Epoch: [51][0/500] loss: 0.60395, MAE: 0.40023, time/step=1167ms, lr=3.73e-05
2024-03-19 07:36:09,501 - logger.py:50 - Epoch: [51][50/500] loss: 1.72488, MAE: 0.44745, time/step=1012ms, lr=3.73e-05
2024-03-19 07:37:01,578 - logger.py:50 - Epoch: [51][100/500] loss: 1.10504, MAE: 0.44203, time/step=1027ms, lr=3.73e-05
2024-03-19 07:37:52,158 - logger.py:50 - Epoch: [51][150/500] loss: 0.91706, MAE: 0.44152, time/step=1022ms, lr=3.73e-05
2024-03-19 07:38:43,646 - logger.py:50 - Epoch: [51][200/500] loss: 0.81822, MAE: 0.44160, time/step=1024ms, lr=3.73e-05
2024-03-19 07:39:33,954 - logger.py:50 - Epoch: [51][250/500] loss: 0.78829, MAE: 0.44108, time/step=1020ms, lr=3.73e-05
2024-03-19 07:40:25,695 - logger.py:50 - Epoch: [51][300/500] loss: 1.16787, MAE: 0.44667, time/step=1023ms, lr=3.73e-05
2024-03-19 07:41:18,155 - logger.py:50 - Epoch: [51][350/500] loss: 1.07316, MAE: 0.44556, time/step=1026ms, lr=3.73e-05
2024-03-19 07:42:09,460 - logger.py:50 - Epoch: [51][400/500] loss: 1.01286, MAE: 0.44648, time/step=1026ms, lr=3.73e-05
2024-03-19 07:43:00,281 - logger.py:50 - Epoch: [51][450/500] loss: 0.95471, MAE: 0.44495, time/step=1025ms, lr=3.73e-05
2024-03-19 07:43:50,511 - logger.py:50 - Epoch: [51][499/500] loss: 0.90771, MAE: 0.44429, time/step=1025ms, lr=3.73e-05
2024-03-19 07:44:47,632 - logger.py:50 - Epoch: [51] train LOSS: 0.90771, val LOSS: 0.44253, test LOSS: 0.42768, Time: 569.77s
2024-03-19 07:44:47,633 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 07:44:48,352 - logger.py:50 - Epoch: [52][0/500] loss: 0.23314, MAE: 0.42306, time/step=717ms, lr=3.69e-05
2024-03-19 07:45:40,070 - logger.py:50 - Epoch: [52][50/500] loss: 0.46179, MAE: 0.44429, time/step=1028ms, lr=3.69e-05
2024-03-19 07:46:31,776 - logger.py:50 - Epoch: [52][100/500] loss: 0.46546, MAE: 0.43904, time/step=1031ms, lr=3.69e-05
2024-03-19 07:47:22,989 - logger.py:50 - Epoch: [52][150/500] loss: 0.46129, MAE: 0.43491, time/step=1029ms, lr=3.69e-05
2024-03-19 07:48:14,044 - logger.py:50 - Epoch: [52][200/500] loss: 0.47690, MAE: 0.43729, time/step=1027ms, lr=3.69e-05
2024-03-19 07:49:04,159 - logger.py:50 - Epoch: [52][250/500] loss: 0.50670, MAE: 0.43881, time/step=1022ms, lr=3.69e-05
2024-03-19 07:49:55,339 - logger.py:50 - Epoch: [52][300/500] loss: 0.52103, MAE: 0.43943, time/step=1022ms, lr=3.69e-05
2024-03-19 07:50:46,479 - logger.py:50 - Epoch: [52][350/500] loss: 0.52472, MAE: 0.43839, time/step=1022ms, lr=3.69e-05
2024-03-19 07:51:37,576 - logger.py:50 - Epoch: [52][400/500] loss: 0.51718, MAE: 0.43641, time/step=1022ms, lr=3.69e-05
2024-03-19 07:52:29,274 - logger.py:50 - Epoch: [52][450/500] loss: 0.64758, MAE: 0.43880, time/step=1024ms, lr=3.69e-05
2024-03-19 07:53:19,528 - logger.py:50 - Epoch: [52][499/500] loss: 0.88015, MAE: 0.44431, time/step=1024ms, lr=3.69e-05
2024-03-19 07:54:17,076 - logger.py:50 - Epoch: [52] train LOSS: 0.88015, val LOSS: 0.45241, test LOSS: 0.43658, Time: 569.44s
2024-03-19 07:54:17,076 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 07:54:18,212 - logger.py:50 - Epoch: [53][0/500] loss: 1.03904, MAE: 0.45731, time/step=1134ms, lr=3.64e-05
2024-03-19 07:55:08,926 - logger.py:50 - Epoch: [53][50/500] loss: 0.63716, MAE: 0.43576, time/step=1017ms, lr=3.64e-05
2024-03-19 07:56:00,714 - logger.py:50 - Epoch: [53][100/500] loss: 0.58933, MAE: 0.43849, time/step=1026ms, lr=3.64e-05
2024-03-19 07:56:52,457 - logger.py:50 - Epoch: [53][150/500] loss: 0.56663, MAE: 0.44062, time/step=1029ms, lr=3.64e-05
2024-03-19 07:57:43,220 - logger.py:50 - Epoch: [53][200/500] loss: 0.56536, MAE: 0.44078, time/step=1026ms, lr=3.64e-05
2024-03-19 07:58:34,201 - logger.py:50 - Epoch: [53][250/500] loss: 0.56188, MAE: 0.44174, time/step=1024ms, lr=3.64e-05
2024-03-19 07:59:25,248 - logger.py:50 - Epoch: [53][300/500] loss: 0.55764, MAE: 0.44242, time/step=1024ms, lr=3.64e-05
2024-03-19 08:00:16,787 - logger.py:50 - Epoch: [53][350/500] loss: 0.55042, MAE: 0.44092, time/step=1025ms, lr=3.64e-05
2024-03-19 08:01:08,056 - logger.py:50 - Epoch: [53][400/500] loss: 0.68992, MAE: 0.44289, time/step=1025ms, lr=3.64e-05
2024-03-19 08:01:59,408 - logger.py:50 - Epoch: [53][450/500] loss: 0.66213, MAE: 0.44030, time/step=1025ms, lr=3.64e-05
2024-03-19 08:02:49,174 - logger.py:50 - Epoch: [53][499/500] loss: 0.92578, MAE: 0.44437, time/step=1024ms, lr=3.64e-05
2024-03-19 08:03:46,752 - logger.py:50 - Epoch: [53] train LOSS: 0.92578, val LOSS: 0.45597, test LOSS: 0.44094, Time: 569.68s
2024-03-19 08:03:46,752 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 08:03:47,466 - logger.py:50 - Epoch: [54][0/500] loss: 0.40853, MAE: 0.36432, time/step=711ms, lr=3.59e-05
2024-03-19 08:04:37,952 - logger.py:50 - Epoch: [54][50/500] loss: 0.61485, MAE: 0.43025, time/step=1004ms, lr=3.59e-05
2024-03-19 08:05:29,945 - logger.py:50 - Epoch: [54][100/500] loss: 1.21974, MAE: 0.44817, time/step=1022ms, lr=3.59e-05
2024-03-19 08:06:21,887 - logger.py:50 - Epoch: [54][150/500] loss: 0.98848, MAE: 0.44652, time/step=1027ms, lr=3.59e-05
2024-03-19 08:07:13,051 - logger.py:50 - Epoch: [54][200/500] loss: 0.88407, MAE: 0.44422, time/step=1026ms, lr=3.59e-05
2024-03-19 08:08:04,945 - logger.py:50 - Epoch: [54][250/500] loss: 1.27754, MAE: 0.44804, time/step=1029ms, lr=3.59e-05
2024-03-19 08:08:56,196 - logger.py:50 - Epoch: [54][300/500] loss: 1.14301, MAE: 0.44543, time/step=1028ms, lr=3.59e-05
2024-03-19 08:09:48,619 - logger.py:50 - Epoch: [54][350/500] loss: 1.07204, MAE: 0.44603, time/step=1031ms, lr=3.59e-05
2024-03-19 08:10:40,122 - logger.py:50 - Epoch: [54][400/500] loss: 1.01736, MAE: 0.44787, time/step=1031ms, lr=3.59e-05
2024-03-19 08:11:31,038 - logger.py:50 - Epoch: [54][450/500] loss: 0.96012, MAE: 0.44588, time/step=1029ms, lr=3.59e-05
2024-03-19 08:12:21,930 - logger.py:50 - Epoch: [54][499/500] loss: 0.91364, MAE: 0.44446, time/step=1030ms, lr=3.59e-05
2024-03-19 08:13:18,897 - logger.py:50 - Epoch: [54] train LOSS: 0.91364, val LOSS: 0.44106, test LOSS: 0.42616, Time: 572.15s
2024-03-19 08:13:18,898 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 08:13:20,072 - logger.py:50 - Epoch: [55][0/500] loss: 0.23316, MAE: 0.39224, time/step=1172ms, lr=3.55e-05
2024-03-19 08:14:10,401 - logger.py:50 - Epoch: [55][50/500] loss: 2.82990, MAE: 0.47448, time/step=1010ms, lr=3.55e-05
2024-03-19 08:15:02,070 - logger.py:50 - Epoch: [55][100/500] loss: 1.71455, MAE: 0.45424, time/step=1021ms, lr=3.55e-05
2024-03-19 08:15:52,791 - logger.py:50 - Epoch: [55][150/500] loss: 1.82628, MAE: 0.45734, time/step=1019ms, lr=3.55e-05
2024-03-19 08:16:44,004 - logger.py:50 - Epoch: [55][200/500] loss: 1.49289, MAE: 0.44996, time/step=1020ms, lr=3.55e-05
2024-03-19 08:17:34,185 - logger.py:50 - Epoch: [55][250/500] loss: 1.30963, MAE: 0.44971, time/step=1017ms, lr=3.55e-05
2024-03-19 08:18:25,511 - logger.py:50 - Epoch: [55][300/500] loss: 1.17165, MAE: 0.44778, time/step=1019ms, lr=3.55e-05
2024-03-19 08:19:16,908 - logger.py:50 - Epoch: [55][350/500] loss: 1.07687, MAE: 0.44701, time/step=1020ms, lr=3.55e-05
2024-03-19 08:20:07,239 - logger.py:50 - Epoch: [55][400/500] loss: 1.01712, MAE: 0.44598, time/step=1018ms, lr=3.55e-05
2024-03-19 08:20:58,689 - logger.py:50 - Epoch: [55][450/500] loss: 0.96200, MAE: 0.44530, time/step=1019ms, lr=3.55e-05
2024-03-19 08:21:48,324 - logger.py:50 - Epoch: [55][499/500] loss: 0.91448, MAE: 0.44448, time/step=1019ms, lr=3.55e-05
2024-03-19 08:22:44,514 - logger.py:50 - Epoch: [55] train LOSS: 0.91448, val LOSS: 0.44179, test LOSS: 0.42641, Time: 565.62s
2024-03-19 08:22:44,515 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 08:22:45,632 - logger.py:50 - Epoch: [56][0/500] loss: 0.40487, MAE: 0.39789, time/step=1116ms, lr=3.50e-05
2024-03-19 08:23:36,175 - logger.py:50 - Epoch: [56][50/500] loss: 0.48168, MAE: 0.42572, time/step=1013ms, lr=3.50e-05
2024-03-19 08:24:27,635 - logger.py:50 - Epoch: [56][100/500] loss: 0.55017, MAE: 0.43111, time/step=1021ms, lr=3.50e-05
2024-03-19 08:25:18,628 - logger.py:50 - Epoch: [56][150/500] loss: 1.34993, MAE: 0.44853, time/step=1021ms, lr=3.50e-05
2024-03-19 08:26:08,775 - logger.py:50 - Epoch: [56][200/500] loss: 1.14462, MAE: 0.44328, time/step=1016ms, lr=3.50e-05
2024-03-19 08:26:59,815 - logger.py:50 - Epoch: [56][250/500] loss: 1.01204, MAE: 0.44254, time/step=1017ms, lr=3.50e-05
2024-03-19 08:27:51,218 - logger.py:50 - Epoch: [56][300/500] loss: 0.94158, MAE: 0.44176, time/step=1019ms, lr=3.50e-05
2024-03-19 08:28:41,266 - logger.py:50 - Epoch: [56][350/500] loss: 0.88219, MAE: 0.44167, time/step=1016ms, lr=3.50e-05
2024-03-19 08:29:32,430 - logger.py:50 - Epoch: [56][400/500] loss: 0.98470, MAE: 0.44504, time/step=1017ms, lr=3.50e-05
2024-03-19 08:30:23,775 - logger.py:50 - Epoch: [56][450/500] loss: 0.93372, MAE: 0.44412, time/step=1018ms, lr=3.50e-05
2024-03-19 08:31:13,711 - logger.py:50 - Epoch: [56][499/500] loss: 0.89127, MAE: 0.44413, time/step=1018ms, lr=3.50e-05
2024-03-19 08:32:10,687 - logger.py:50 - Epoch: [56] train LOSS: 0.89127, val LOSS: 0.45087, test LOSS: 0.43616, Time: 566.17s
2024-03-19 08:32:10,687 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 08:32:11,817 - logger.py:50 - Epoch: [57][0/500] loss: 0.45154, MAE: 0.50726, time/step=1128ms, lr=3.45e-05
2024-03-19 08:33:03,980 - logger.py:50 - Epoch: [57][50/500] loss: 0.53078, MAE: 0.45055, time/step=1045ms, lr=3.45e-05
2024-03-19 08:33:54,862 - logger.py:50 - Epoch: [57][100/500] loss: 0.57511, MAE: 0.44714, time/step=1031ms, lr=3.45e-05
2024-03-19 08:34:46,416 - logger.py:50 - Epoch: [57][150/500] loss: 0.53551, MAE: 0.44322, time/step=1031ms, lr=3.45e-05
2024-03-19 08:35:38,120 - logger.py:50 - Epoch: [57][200/500] loss: 0.55579, MAE: 0.44471, time/step=1032ms, lr=3.45e-05
2024-03-19 08:36:28,627 - logger.py:50 - Epoch: [57][250/500] loss: 0.55492, MAE: 0.44519, time/step=1028ms, lr=3.45e-05
2024-03-19 08:37:20,314 - logger.py:50 - Epoch: [57][300/500] loss: 0.53630, MAE: 0.44431, time/step=1029ms, lr=3.45e-05
2024-03-19 08:38:11,620 - logger.py:50 - Epoch: [57][350/500] loss: 0.69959, MAE: 0.44433, time/step=1028ms, lr=3.45e-05
2024-03-19 08:39:03,364 - logger.py:50 - Epoch: [57][400/500] loss: 0.68123, MAE: 0.44169, time/step=1029ms, lr=3.45e-05
2024-03-19 08:39:53,196 - logger.py:50 - Epoch: [57][450/500] loss: 0.66715, MAE: 0.44169, time/step=1026ms, lr=3.45e-05
2024-03-19 08:40:43,323 - logger.py:50 - Epoch: [57][499/500] loss: 0.88904, MAE: 0.44436, time/step=1025ms, lr=3.45e-05
2024-03-19 08:41:40,235 - logger.py:50 - Epoch: [57] train LOSS: 0.88904, val LOSS: 0.44523, test LOSS: 0.43025, Time: 569.55s
2024-03-19 08:41:40,236 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 08:41:41,392 - logger.py:50 - Epoch: [58][0/500] loss: 0.49505, MAE: 0.51178, time/step=1154ms, lr=3.40e-05
2024-03-19 08:42:32,046 - logger.py:50 - Epoch: [58][50/500] loss: 0.47477, MAE: 0.43458, time/step=1016ms, lr=3.40e-05
2024-03-19 08:43:23,395 - logger.py:50 - Epoch: [58][100/500] loss: 0.53269, MAE: 0.43910, time/step=1021ms, lr=3.40e-05
2024-03-19 08:44:14,375 - logger.py:50 - Epoch: [58][150/500] loss: 0.50930, MAE: 0.43525, time/step=1021ms, lr=3.40e-05
2024-03-19 08:45:05,197 - logger.py:50 - Epoch: [58][200/500] loss: 0.49638, MAE: 0.43487, time/step=1020ms, lr=3.40e-05
2024-03-19 08:45:57,038 - logger.py:50 - Epoch: [58][250/500] loss: 0.97439, MAE: 0.44351, time/step=1023ms, lr=3.40e-05
2024-03-19 08:46:47,717 - logger.py:50 - Epoch: [58][300/500] loss: 0.90365, MAE: 0.44184, time/step=1022ms, lr=3.40e-05
2024-03-19 08:47:39,117 - logger.py:50 - Epoch: [58][350/500] loss: 0.84666, MAE: 0.44106, time/step=1022ms, lr=3.40e-05
2024-03-19 08:48:30,062 - logger.py:50 - Epoch: [58][400/500] loss: 0.82169, MAE: 0.44146, time/step=1022ms, lr=3.40e-05
2024-03-19 08:49:20,644 - logger.py:50 - Epoch: [58][450/500] loss: 0.92209, MAE: 0.44564, time/step=1021ms, lr=3.40e-05
2024-03-19 08:50:10,904 - logger.py:50 - Epoch: [58][499/500] loss: 0.87650, MAE: 0.44432, time/step=1021ms, lr=3.40e-05
2024-03-19 08:51:07,538 - logger.py:50 - Epoch: [58] train LOSS: 0.87650, val LOSS: 0.43892, test LOSS: 0.42330, Time: 567.30s
2024-03-19 08:51:07,539 - logger.py:50 - Best -- epoch=30, train LOSS: 0.99917, val LOSS: 0.43628, test LOSS: 0.42103

2024-03-19 08:51:08,676 - logger.py:50 - Epoch: [59][0/500] loss: 0.44424, MAE: 0.33139, time/step=1135ms, lr=3.36e-05
2024-03-19 08:51:59,066 - logger.py:50 - Epoch: [59][50/500] loss: 0.54448, MAE: 0.43354, time/step=1010ms, lr=3.36e-05
2024-03-19 08:52:49,593 - logger.py:50 - Epoch: [59][100/500] loss: 1.68602, MAE: 0.46126, time/step=1010ms, lr=3.36e-05
2024-03-19 08:53:40,941 - logger.py:50 - Epoch: [59][150/500] loss: 1.28205, MAE: 0.45074, time/step=1016ms, lr=3.36e-05
2024-03-19 08:54:31,624 - logger.py:50 - Epoch: [59][200/500] loss: 1.09486, MAE: 0.44718, time/step=1015ms, lr=3.36e-05
2024-03-19 08:55:22,397 - logger.py:50 - Epoch: [59][250/500] loss: 0.99610, MAE: 0.44320, time/step=1015ms, lr=3.36e-05
2024-03-19 08:56:14,523 - logger.py:50 - Epoch: [59][300/500] loss: 0.92411, MAE: 0.44307, time/step=1020ms, lr=3.36e-05
2024-03-19 08:57:05,235 - logger.py:50 - Epoch: [59][350/500] loss: 0.87324, MAE: 0.44420, time/step=1019ms, lr=3.36e-05
2024-03-19 08:57:56,929 - logger.py:50 - Epoch: [59][400/500] loss: 0.82949, MAE: 0.44326, time/step=1021ms, lr=3.36e-05
2024-03-19 08:58:48,117 - logger.py:50 - Epoch: [59][450/500] loss: 0.92866, MAE: 0.44560, time/step=1021ms, lr=3.36e-05
2024-03-19 08:59:38,273 - logger.py:50 - Epoch: [59][499/500] loss: 0.88776, MAE: 0.44462, time/step=1021ms, lr=3.36e-05
2024-03-19 09:00:35,126 - logger.py:50 - Epoch: [59] train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112, Time: 567.59s
2024-03-19 09:00:35,126 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 09:00:36,206 - logger.py:50 - Epoch: [60][0/500] loss: 0.58033, MAE: 0.37564, time/step=1079ms, lr=3.31e-05
2024-03-19 09:01:27,772 - logger.py:50 - Epoch: [60][50/500] loss: 0.50345, MAE: 0.41778, time/step=1032ms, lr=3.31e-05
2024-03-19 09:02:18,777 - logger.py:50 - Epoch: [60][100/500] loss: 1.50300, MAE: 0.43991, time/step=1026ms, lr=3.31e-05
2024-03-19 09:03:10,198 - logger.py:50 - Epoch: [60][150/500] loss: 1.17470, MAE: 0.44438, time/step=1027ms, lr=3.31e-05
2024-03-19 09:04:02,272 - logger.py:50 - Epoch: [60][200/500] loss: 0.99833, MAE: 0.44389, time/step=1031ms, lr=3.31e-05
2024-03-19 09:04:52,896 - logger.py:50 - Epoch: [60][250/500] loss: 0.91110, MAE: 0.44184, time/step=1027ms, lr=3.31e-05
2024-03-19 09:05:44,105 - logger.py:50 - Epoch: [60][300/500] loss: 1.24228, MAE: 0.44814, time/step=1027ms, lr=3.31e-05
2024-03-19 09:06:35,382 - logger.py:50 - Epoch: [60][350/500] loss: 1.14023, MAE: 0.44699, time/step=1026ms, lr=3.31e-05
2024-03-19 09:07:26,439 - logger.py:50 - Epoch: [60][400/500] loss: 1.07541, MAE: 0.44509, time/step=1026ms, lr=3.31e-05
2024-03-19 09:08:17,638 - logger.py:50 - Epoch: [60][450/500] loss: 1.01574, MAE: 0.44363, time/step=1026ms, lr=3.31e-05
2024-03-19 09:09:08,108 - logger.py:50 - Epoch: [60][499/500] loss: 0.96361, MAE: 0.44425, time/step=1026ms, lr=3.31e-05
2024-03-19 09:10:05,007 - logger.py:50 - Epoch: [60] train LOSS: 0.96361, val LOSS: 0.44326, test LOSS: 0.42842, Time: 569.88s
2024-03-19 09:10:05,008 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 09:10:06,162 - logger.py:50 - Epoch: [61][0/500] loss: 0.24924, MAE: 0.42021, time/step=1152ms, lr=3.26e-05
2024-03-19 09:10:56,535 - logger.py:50 - Epoch: [61][50/500] loss: 0.50304, MAE: 0.43870, time/step=1010ms, lr=3.26e-05
2024-03-19 09:11:47,947 - logger.py:50 - Epoch: [61][100/500] loss: 0.53008, MAE: 0.44247, time/step=1019ms, lr=3.26e-05
2024-03-19 09:12:38,613 - logger.py:50 - Epoch: [61][150/500] loss: 0.51982, MAE: 0.43690, time/step=1017ms, lr=3.26e-05
2024-03-19 09:13:29,850 - logger.py:50 - Epoch: [61][200/500] loss: 0.50552, MAE: 0.43503, time/step=1019ms, lr=3.26e-05
2024-03-19 09:14:20,429 - logger.py:50 - Epoch: [61][250/500] loss: 0.51980, MAE: 0.43464, time/step=1018ms, lr=3.26e-05
2024-03-19 09:15:10,698 - logger.py:50 - Epoch: [61][300/500] loss: 0.53259, MAE: 0.43587, time/step=1016ms, lr=3.26e-05
2024-03-19 09:16:02,090 - logger.py:50 - Epoch: [61][350/500] loss: 0.53307, MAE: 0.43919, time/step=1017ms, lr=3.26e-05
2024-03-19 09:16:53,327 - logger.py:50 - Epoch: [61][400/500] loss: 0.53046, MAE: 0.43907, time/step=1018ms, lr=3.26e-05
2024-03-19 09:17:44,760 - logger.py:50 - Epoch: [61][450/500] loss: 0.52663, MAE: 0.43923, time/step=1019ms, lr=3.26e-05
2024-03-19 09:18:35,681 - logger.py:50 - Epoch: [61][499/500] loss: 0.89889, MAE: 0.44452, time/step=1021ms, lr=3.26e-05
2024-03-19 09:19:32,587 - logger.py:50 - Epoch: [61] train LOSS: 0.89889, val LOSS: 0.45097, test LOSS: 0.43603, Time: 567.58s
2024-03-19 09:19:32,587 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 09:19:33,803 - logger.py:50 - Epoch: [62][0/500] loss: 0.41744, MAE: 0.48357, time/step=1214ms, lr=3.21e-05
2024-03-19 09:20:24,869 - logger.py:50 - Epoch: [62][50/500] loss: 0.44717, MAE: 0.43256, time/step=1025ms, lr=3.21e-05
2024-03-19 09:21:15,926 - logger.py:50 - Epoch: [62][100/500] loss: 0.49319, MAE: 0.42821, time/step=1023ms, lr=3.21e-05
2024-03-19 09:22:06,536 - logger.py:50 - Epoch: [62][150/500] loss: 0.49584, MAE: 0.43192, time/step=1020ms, lr=3.21e-05
2024-03-19 09:22:57,737 - logger.py:50 - Epoch: [62][200/500] loss: 0.50938, MAE: 0.43391, time/step=1021ms, lr=3.21e-05
2024-03-19 09:23:48,405 - logger.py:50 - Epoch: [62][250/500] loss: 0.75019, MAE: 0.44021, time/step=1019ms, lr=3.21e-05
2024-03-19 09:24:39,360 - logger.py:50 - Epoch: [62][300/500] loss: 0.69878, MAE: 0.43866, time/step=1019ms, lr=3.21e-05
2024-03-19 09:25:30,610 - logger.py:50 - Epoch: [62][350/500] loss: 0.67195, MAE: 0.44051, time/step=1020ms, lr=3.21e-05
2024-03-19 09:26:21,437 - logger.py:50 - Epoch: [62][400/500] loss: 0.95481, MAE: 0.44387, time/step=1020ms, lr=3.21e-05
2024-03-19 09:27:12,835 - logger.py:50 - Epoch: [62][450/500] loss: 0.91676, MAE: 0.44437, time/step=1021ms, lr=3.21e-05
2024-03-19 09:28:02,548 - logger.py:50 - Epoch: [62][499/500] loss: 0.88323, MAE: 0.44420, time/step=1020ms, lr=3.21e-05
2024-03-19 09:28:58,961 - logger.py:50 - Epoch: [62] train LOSS: 0.88323, val LOSS: 0.43969, test LOSS: 0.42395, Time: 566.37s
2024-03-19 09:28:58,961 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 09:29:00,117 - logger.py:50 - Epoch: [63][0/500] loss: 0.89630, MAE: 0.57581, time/step=1154ms, lr=3.16e-05
2024-03-19 09:29:51,352 - logger.py:50 - Epoch: [63][50/500] loss: 0.51461, MAE: 0.43792, time/step=1027ms, lr=3.16e-05
2024-03-19 09:30:42,374 - logger.py:50 - Epoch: [63][100/500] loss: 1.71129, MAE: 0.46126, time/step=1024ms, lr=3.16e-05
2024-03-19 09:31:34,599 - logger.py:50 - Epoch: [63][150/500] loss: 1.31359, MAE: 0.45586, time/step=1031ms, lr=3.16e-05
2024-03-19 09:32:26,257 - logger.py:50 - Epoch: [63][200/500] loss: 1.41159, MAE: 0.45880, time/step=1031ms, lr=3.16e-05
2024-03-19 09:33:16,758 - logger.py:50 - Epoch: [63][250/500] loss: 1.22441, MAE: 0.45336, time/step=1027ms, lr=3.16e-05
2024-03-19 09:34:07,123 - logger.py:50 - Epoch: [63][300/500] loss: 1.10581, MAE: 0.45095, time/step=1024ms, lr=3.16e-05
2024-03-19 09:34:57,685 - logger.py:50 - Epoch: [63][350/500] loss: 1.01957, MAE: 0.44795, time/step=1022ms, lr=3.16e-05
2024-03-19 09:35:49,418 - logger.py:50 - Epoch: [63][400/500] loss: 0.96079, MAE: 0.44605, time/step=1024ms, lr=3.16e-05
2024-03-19 09:36:40,687 - logger.py:50 - Epoch: [63][450/500] loss: 0.91180, MAE: 0.44504, time/step=1024ms, lr=3.16e-05
2024-03-19 09:37:31,233 - logger.py:50 - Epoch: [63][499/500] loss: 0.87558, MAE: 0.44439, time/step=1025ms, lr=3.16e-05
2024-03-19 09:38:28,100 - logger.py:50 - Epoch: [63] train LOSS: 0.87558, val LOSS: 0.43767, test LOSS: 0.42261, Time: 569.14s
2024-03-19 09:38:28,100 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 09:38:29,195 - logger.py:50 - Epoch: [64][0/500] loss: 0.26924, MAE: 0.45918, time/step=1093ms, lr=3.11e-05
2024-03-19 09:39:20,611 - logger.py:50 - Epoch: [64][50/500] loss: 0.47079, MAE: 0.43669, time/step=1030ms, lr=3.11e-05
2024-03-19 09:40:11,728 - logger.py:50 - Epoch: [64][100/500] loss: 0.45938, MAE: 0.43273, time/step=1026ms, lr=3.11e-05
2024-03-19 09:41:02,475 - logger.py:50 - Epoch: [64][150/500] loss: 0.48164, MAE: 0.43902, time/step=1022ms, lr=3.11e-05
2024-03-19 09:41:53,313 - logger.py:50 - Epoch: [64][200/500] loss: 0.48237, MAE: 0.43684, time/step=1021ms, lr=3.11e-05
2024-03-19 09:42:44,799 - logger.py:50 - Epoch: [64][250/500] loss: 0.72922, MAE: 0.44174, time/step=1023ms, lr=3.11e-05
2024-03-19 09:43:36,047 - logger.py:50 - Epoch: [64][300/500] loss: 0.68912, MAE: 0.44409, time/step=1023ms, lr=3.11e-05
2024-03-19 09:44:27,620 - logger.py:50 - Epoch: [64][350/500] loss: 1.00617, MAE: 0.44912, time/step=1024ms, lr=3.11e-05
2024-03-19 09:45:18,261 - logger.py:50 - Epoch: [64][400/500] loss: 0.95492, MAE: 0.44942, time/step=1023ms, lr=3.11e-05
2024-03-19 09:46:08,872 - logger.py:50 - Epoch: [64][450/500] loss: 0.91417, MAE: 0.44630, time/step=1022ms, lr=3.11e-05
2024-03-19 09:46:58,920 - logger.py:50 - Epoch: [64][499/500] loss: 0.87745, MAE: 0.44429, time/step=1022ms, lr=3.11e-05
2024-03-19 09:47:55,780 - logger.py:50 - Epoch: [64] train LOSS: 0.87745, val LOSS: 0.45107, test LOSS: 0.43581, Time: 567.68s
2024-03-19 09:47:55,781 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 09:47:56,423 - logger.py:50 - Epoch: [65][0/500] loss: 0.47058, MAE: 0.45509, time/step=640ms, lr=3.06e-05
2024-03-19 09:48:47,483 - logger.py:50 - Epoch: [65][50/500] loss: 0.49541, MAE: 0.43485, time/step=1014ms, lr=3.06e-05
2024-03-19 09:49:37,988 - logger.py:50 - Epoch: [65][100/500] loss: 0.51087, MAE: 0.43406, time/step=1012ms, lr=3.06e-05
2024-03-19 09:50:28,809 - logger.py:50 - Epoch: [65][150/500] loss: 0.50000, MAE: 0.42827, time/step=1013ms, lr=3.06e-05
2024-03-19 09:51:20,643 - logger.py:50 - Epoch: [65][200/500] loss: 0.49741, MAE: 0.43351, time/step=1019ms, lr=3.06e-05
2024-03-19 09:52:11,836 - logger.py:50 - Epoch: [65][250/500] loss: 0.49388, MAE: 0.43189, time/step=1020ms, lr=3.06e-05
2024-03-19 09:53:03,289 - logger.py:50 - Epoch: [65][300/500] loss: 0.90170, MAE: 0.43935, time/step=1022ms, lr=3.06e-05
2024-03-19 09:53:53,980 - logger.py:50 - Epoch: [65][350/500] loss: 0.86675, MAE: 0.43932, time/step=1021ms, lr=3.06e-05
2024-03-19 09:54:45,628 - logger.py:50 - Epoch: [65][400/500] loss: 0.98290, MAE: 0.44333, time/step=1022ms, lr=3.06e-05
2024-03-19 09:55:36,327 - logger.py:50 - Epoch: [65][450/500] loss: 0.92869, MAE: 0.44520, time/step=1021ms, lr=3.06e-05
2024-03-19 09:56:26,300 - logger.py:50 - Epoch: [65][499/500] loss: 0.88934, MAE: 0.44449, time/step=1021ms, lr=3.06e-05
2024-03-19 09:57:23,294 - logger.py:50 - Epoch: [65] train LOSS: 0.88934, val LOSS: 0.44124, test LOSS: 0.42604, Time: 567.51s
2024-03-19 09:57:23,295 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 09:57:24,418 - logger.py:50 - Epoch: [66][0/500] loss: 0.54603, MAE: 0.45180, time/step=1121ms, lr=3.01e-05
2024-03-19 09:58:16,333 - logger.py:50 - Epoch: [66][50/500] loss: 0.55722, MAE: 0.45075, time/step=1040ms, lr=3.01e-05
2024-03-19 09:59:06,899 - logger.py:50 - Epoch: [66][100/500] loss: 0.53144, MAE: 0.44282, time/step=1026ms, lr=3.01e-05
2024-03-19 09:59:58,229 - logger.py:50 - Epoch: [66][150/500] loss: 0.55369, MAE: 0.44009, time/step=1026ms, lr=3.01e-05
2024-03-19 10:00:48,412 - logger.py:50 - Epoch: [66][200/500] loss: 0.53623, MAE: 0.44179, time/step=1020ms, lr=3.01e-05
2024-03-19 10:01:38,822 - logger.py:50 - Epoch: [66][250/500] loss: 0.53496, MAE: 0.44052, time/step=1018ms, lr=3.01e-05
2024-03-19 10:02:30,220 - logger.py:50 - Epoch: [66][300/500] loss: 0.52626, MAE: 0.43973, time/step=1020ms, lr=3.01e-05
2024-03-19 10:03:22,269 - logger.py:50 - Epoch: [66][350/500] loss: 0.51188, MAE: 0.43858, time/step=1023ms, lr=3.01e-05
2024-03-19 10:04:13,679 - logger.py:50 - Epoch: [66][400/500] loss: 0.51645, MAE: 0.43834, time/step=1023ms, lr=3.01e-05
2024-03-19 10:05:04,220 - logger.py:50 - Epoch: [66][450/500] loss: 0.93604, MAE: 0.44522, time/step=1022ms, lr=3.01e-05
2024-03-19 10:05:55,290 - logger.py:50 - Epoch: [66][499/500] loss: 0.90059, MAE: 0.44413, time/step=1024ms, lr=3.01e-05
2024-03-19 10:06:52,334 - logger.py:50 - Epoch: [66] train LOSS: 0.90059, val LOSS: 0.44313, test LOSS: 0.42832, Time: 569.04s
2024-03-19 10:06:52,335 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 10:06:53,551 - logger.py:50 - Epoch: [67][0/500] loss: 0.42196, MAE: 0.50247, time/step=1215ms, lr=2.96e-05
2024-03-19 10:07:45,143 - logger.py:50 - Epoch: [67][50/500] loss: 0.52317, MAE: 0.44900, time/step=1035ms, lr=2.96e-05
2024-03-19 10:08:36,163 - logger.py:50 - Epoch: [67][100/500] loss: 1.70414, MAE: 0.46431, time/step=1028ms, lr=2.96e-05
2024-03-19 10:09:27,285 - logger.py:50 - Epoch: [67][150/500] loss: 1.33561, MAE: 0.45492, time/step=1026ms, lr=2.96e-05
2024-03-19 10:10:19,055 - logger.py:50 - Epoch: [67][200/500] loss: 1.11409, MAE: 0.44623, time/step=1028ms, lr=2.96e-05
2024-03-19 10:11:10,222 - logger.py:50 - Epoch: [67][250/500] loss: 1.00252, MAE: 0.44316, time/step=1027ms, lr=2.96e-05
2024-03-19 10:12:01,611 - logger.py:50 - Epoch: [67][300/500] loss: 0.91475, MAE: 0.44101, time/step=1027ms, lr=2.96e-05
2024-03-19 10:12:52,767 - logger.py:50 - Epoch: [67][350/500] loss: 0.85790, MAE: 0.43948, time/step=1027ms, lr=2.96e-05
2024-03-19 10:13:44,496 - logger.py:50 - Epoch: [67][400/500] loss: 0.82156, MAE: 0.43984, time/step=1028ms, lr=2.96e-05
2024-03-19 10:14:36,458 - logger.py:50 - Epoch: [67][450/500] loss: 0.79128, MAE: 0.44196, time/step=1029ms, lr=2.96e-05
2024-03-19 10:15:27,770 - logger.py:50 - Epoch: [67][499/500] loss: 0.90097, MAE: 0.44468, time/step=1031ms, lr=2.96e-05
2024-03-19 10:16:25,211 - logger.py:50 - Epoch: [67] train LOSS: 0.90097, val LOSS: 0.44835, test LOSS: 0.43320, Time: 572.88s
2024-03-19 10:16:25,211 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 10:16:26,327 - logger.py:50 - Epoch: [68][0/500] loss: 0.54147, MAE: 0.36245, time/step=1114ms, lr=2.91e-05
2024-03-19 10:17:17,727 - logger.py:50 - Epoch: [68][50/500] loss: 0.49039, MAE: 0.43164, time/step=1030ms, lr=2.91e-05
2024-03-19 10:18:09,517 - logger.py:50 - Epoch: [68][100/500] loss: 0.49093, MAE: 0.43225, time/step=1033ms, lr=2.91e-05
2024-03-19 10:19:00,551 - logger.py:50 - Epoch: [68][150/500] loss: 0.48131, MAE: 0.43773, time/step=1029ms, lr=2.91e-05
2024-03-19 10:19:52,295 - logger.py:50 - Epoch: [68][200/500] loss: 0.48552, MAE: 0.43790, time/step=1030ms, lr=2.91e-05
2024-03-19 10:20:43,605 - logger.py:50 - Epoch: [68][250/500] loss: 0.50535, MAE: 0.44043, time/step=1029ms, lr=2.91e-05
2024-03-19 10:21:34,539 - logger.py:50 - Epoch: [68][300/500] loss: 0.52204, MAE: 0.43857, time/step=1028ms, lr=2.91e-05
2024-03-19 10:22:26,117 - logger.py:50 - Epoch: [68][350/500] loss: 0.91744, MAE: 0.44520, time/step=1028ms, lr=2.91e-05
2024-03-19 10:23:16,975 - logger.py:50 - Epoch: [68][400/500] loss: 1.02475, MAE: 0.44716, time/step=1027ms, lr=2.91e-05
2024-03-19 10:24:08,228 - logger.py:50 - Epoch: [68][450/500] loss: 0.97158, MAE: 0.44655, time/step=1027ms, lr=2.91e-05
2024-03-19 10:24:58,665 - logger.py:50 - Epoch: [68][499/500] loss: 0.92233, MAE: 0.44434, time/step=1027ms, lr=2.91e-05
2024-03-19 10:25:56,139 - logger.py:50 - Epoch: [68] train LOSS: 0.92233, val LOSS: 0.44830, test LOSS: 0.43297, Time: 570.93s
2024-03-19 10:25:56,139 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 10:25:56,910 - logger.py:50 - Epoch: [69][0/500] loss: 0.32064, MAE: 0.53302, time/step=769ms, lr=2.86e-05
2024-03-19 10:26:48,542 - logger.py:50 - Epoch: [69][50/500] loss: 0.51656, MAE: 0.44472, time/step=1027ms, lr=2.86e-05
2024-03-19 10:27:40,862 - logger.py:50 - Epoch: [69][100/500] loss: 1.09130, MAE: 0.46416, time/step=1037ms, lr=2.86e-05
2024-03-19 10:28:32,725 - logger.py:50 - Epoch: [69][150/500] loss: 1.66771, MAE: 0.46583, time/step=1037ms, lr=2.86e-05
2024-03-19 10:29:24,766 - logger.py:50 - Epoch: [69][200/500] loss: 1.37256, MAE: 0.45812, time/step=1038ms, lr=2.86e-05
2024-03-19 10:30:15,460 - logger.py:50 - Epoch: [69][250/500] loss: 1.20661, MAE: 0.45406, time/step=1033ms, lr=2.86e-05
2024-03-19 10:31:06,497 - logger.py:50 - Epoch: [69][300/500] loss: 1.10504, MAE: 0.45064, time/step=1031ms, lr=2.86e-05
2024-03-19 10:31:58,148 - logger.py:50 - Epoch: [69][350/500] loss: 1.01490, MAE: 0.44767, time/step=1031ms, lr=2.86e-05
2024-03-19 10:32:48,782 - logger.py:50 - Epoch: [69][400/500] loss: 0.97198, MAE: 0.44672, time/step=1029ms, lr=2.86e-05
2024-03-19 10:33:40,378 - logger.py:50 - Epoch: [69][450/500] loss: 0.91908, MAE: 0.44451, time/step=1029ms, lr=2.86e-05
2024-03-19 10:34:31,110 - logger.py:50 - Epoch: [69][499/500] loss: 0.88155, MAE: 0.44424, time/step=1030ms, lr=2.86e-05
2024-03-19 10:35:28,976 - logger.py:50 - Epoch: [69] train LOSS: 0.88155, val LOSS: 0.44374, test LOSS: 0.42856, Time: 572.84s
2024-03-19 10:35:28,976 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 10:35:30,112 - logger.py:50 - Epoch: [70][0/500] loss: 0.32257, MAE: 0.31837, time/step=1134ms, lr=2.81e-05
2024-03-19 10:36:21,055 - logger.py:50 - Epoch: [70][50/500] loss: 0.47231, MAE: 0.43557, time/step=1021ms, lr=2.81e-05
2024-03-19 10:37:12,034 - logger.py:50 - Epoch: [70][100/500] loss: 0.50979, MAE: 0.43929, time/step=1020ms, lr=2.81e-05
2024-03-19 10:38:03,903 - logger.py:50 - Epoch: [70][150/500] loss: 0.53337, MAE: 0.44121, time/step=1026ms, lr=2.81e-05
2024-03-19 10:38:55,791 - logger.py:50 - Epoch: [70][200/500] loss: 0.54561, MAE: 0.43740, time/step=1029ms, lr=2.81e-05
2024-03-19 10:39:46,649 - logger.py:50 - Epoch: [70][250/500] loss: 0.53036, MAE: 0.43503, time/step=1027ms, lr=2.81e-05
2024-03-19 10:40:37,937 - logger.py:50 - Epoch: [70][300/500] loss: 0.51855, MAE: 0.43545, time/step=1026ms, lr=2.81e-05
2024-03-19 10:41:29,576 - logger.py:50 - Epoch: [70][350/500] loss: 0.51899, MAE: 0.43571, time/step=1027ms, lr=2.81e-05
2024-03-19 10:42:20,984 - logger.py:50 - Epoch: [70][400/500] loss: 0.95404, MAE: 0.44484, time/step=1027ms, lr=2.81e-05
2024-03-19 10:43:12,912 - logger.py:50 - Epoch: [70][450/500] loss: 0.90643, MAE: 0.44519, time/step=1029ms, lr=2.81e-05
2024-03-19 10:44:03,606 - logger.py:50 - Epoch: [70][499/500] loss: 0.86855, MAE: 0.44433, time/step=1029ms, lr=2.81e-05
2024-03-19 10:45:01,067 - logger.py:50 - Epoch: [70] train LOSS: 0.86855, val LOSS: 0.44037, test LOSS: 0.42554, Time: 572.09s
2024-03-19 10:45:01,067 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 10:45:01,790 - logger.py:50 - Epoch: [71][0/500] loss: 0.36658, MAE: 0.36935, time/step=721ms, lr=2.76e-05
2024-03-19 10:45:52,179 - logger.py:50 - Epoch: [71][50/500] loss: 0.46842, MAE: 0.42991, time/step=1002ms, lr=2.76e-05
2024-03-19 10:46:43,265 - logger.py:50 - Epoch: [71][100/500] loss: 0.48660, MAE: 0.43149, time/step=1012ms, lr=2.76e-05
2024-03-19 10:47:34,062 - logger.py:50 - Epoch: [71][150/500] loss: 0.50995, MAE: 0.43551, time/step=1013ms, lr=2.76e-05
2024-03-19 10:48:25,528 - logger.py:50 - Epoch: [71][200/500] loss: 0.49172, MAE: 0.43513, time/step=1017ms, lr=2.76e-05
2024-03-19 10:49:17,971 - logger.py:50 - Epoch: [71][250/500] loss: 0.50881, MAE: 0.43895, time/step=1024ms, lr=2.76e-05
2024-03-19 10:50:10,321 - logger.py:50 - Epoch: [71][300/500] loss: 0.71362, MAE: 0.44359, time/step=1027ms, lr=2.76e-05
2024-03-19 10:51:01,479 - logger.py:50 - Epoch: [71][350/500] loss: 1.01761, MAE: 0.44845, time/step=1027ms, lr=2.76e-05
2024-03-19 10:51:53,120 - logger.py:50 - Epoch: [71][400/500] loss: 0.94751, MAE: 0.44631, time/step=1028ms, lr=2.76e-05
2024-03-19 10:52:44,356 - logger.py:50 - Epoch: [71][450/500] loss: 0.90478, MAE: 0.44441, time/step=1027ms, lr=2.76e-05
2024-03-19 10:53:33,906 - logger.py:50 - Epoch: [71][499/500] loss: 0.87057, MAE: 0.44424, time/step=1026ms, lr=2.76e-05
2024-03-19 10:54:31,265 - logger.py:50 - Epoch: [71] train LOSS: 0.87057, val LOSS: 0.44198, test LOSS: 0.42714, Time: 570.20s
2024-03-19 10:54:31,265 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 10:54:32,389 - logger.py:50 - Epoch: [72][0/500] loss: 0.38584, MAE: 0.33985, time/step=1122ms, lr=2.70e-05
2024-03-19 10:55:22,214 - logger.py:50 - Epoch: [72][50/500] loss: 0.56836, MAE: 0.44545, time/step=999ms, lr=2.70e-05
2024-03-19 10:56:13,347 - logger.py:50 - Epoch: [72][100/500] loss: 0.56059, MAE: 0.43805, time/step=1011ms, lr=2.70e-05
2024-03-19 10:57:03,811 - logger.py:50 - Epoch: [72][150/500] loss: 0.54357, MAE: 0.44286, time/step=1010ms, lr=2.70e-05
2024-03-19 10:57:54,789 - logger.py:50 - Epoch: [72][200/500] loss: 0.88117, MAE: 0.44958, time/step=1013ms, lr=2.70e-05
2024-03-19 10:58:46,286 - logger.py:50 - Epoch: [72][250/500] loss: 1.30300, MAE: 0.45467, time/step=1016ms, lr=2.70e-05
2024-03-19 10:59:37,861 - logger.py:50 - Epoch: [72][300/500] loss: 1.14748, MAE: 0.45047, time/step=1019ms, lr=2.70e-05
2024-03-19 11:00:28,520 - logger.py:50 - Epoch: [72][350/500] loss: 1.04491, MAE: 0.44714, time/step=1018ms, lr=2.70e-05
2024-03-19 11:01:20,834 - logger.py:50 - Epoch: [72][400/500] loss: 0.97545, MAE: 0.44607, time/step=1021ms, lr=2.70e-05
2024-03-19 11:02:11,296 - logger.py:50 - Epoch: [72][450/500] loss: 0.92116, MAE: 0.44501, time/step=1020ms, lr=2.70e-05
2024-03-19 11:03:02,048 - logger.py:50 - Epoch: [72][499/500] loss: 0.88205, MAE: 0.44434, time/step=1022ms, lr=2.70e-05
2024-03-19 11:04:00,241 - logger.py:50 - Epoch: [72] train LOSS: 0.88205, val LOSS: 0.44743, test LOSS: 0.43247, Time: 568.98s
2024-03-19 11:04:00,241 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 11:04:01,402 - logger.py:50 - Epoch: [73][0/500] loss: 0.75109, MAE: 0.49559, time/step=1158ms, lr=2.65e-05
2024-03-19 11:04:52,905 - logger.py:50 - Epoch: [73][50/500] loss: 0.48924, MAE: 0.44272, time/step=1033ms, lr=2.65e-05
2024-03-19 11:05:44,446 - logger.py:50 - Epoch: [73][100/500] loss: 0.49720, MAE: 0.44606, time/step=1032ms, lr=2.65e-05
2024-03-19 11:06:37,656 - logger.py:50 - Epoch: [73][150/500] loss: 0.48624, MAE: 0.44281, time/step=1042ms, lr=2.65e-05
2024-03-19 11:07:29,130 - logger.py:50 - Epoch: [73][200/500] loss: 0.52863, MAE: 0.43837, time/step=1039ms, lr=2.65e-05
2024-03-19 11:08:20,786 - logger.py:50 - Epoch: [73][250/500] loss: 0.51858, MAE: 0.43665, time/step=1038ms, lr=2.65e-05
2024-03-19 11:09:12,979 - logger.py:50 - Epoch: [73][300/500] loss: 0.51740, MAE: 0.43753, time/step=1039ms, lr=2.65e-05
2024-03-19 11:10:04,641 - logger.py:50 - Epoch: [73][350/500] loss: 0.86131, MAE: 0.44445, time/step=1038ms, lr=2.65e-05
2024-03-19 11:10:57,225 - logger.py:50 - Epoch: [73][400/500] loss: 0.81438, MAE: 0.44278, time/step=1040ms, lr=2.65e-05
2024-03-19 11:11:48,901 - logger.py:50 - Epoch: [73][450/500] loss: 0.77698, MAE: 0.44164, time/step=1039ms, lr=2.65e-05
2024-03-19 11:12:39,822 - logger.py:50 - Epoch: [73][499/500] loss: 0.86381, MAE: 0.44434, time/step=1039ms, lr=2.65e-05
2024-03-19 11:13:37,820 - logger.py:50 - Epoch: [73] train LOSS: 0.86381, val LOSS: 0.44184, test LOSS: 0.42701, Time: 577.58s
2024-03-19 11:13:37,820 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 11:13:38,522 - logger.py:50 - Epoch: [74][0/500] loss: 0.33874, MAE: 0.30490, time/step=700ms, lr=2.60e-05
2024-03-19 11:14:30,416 - logger.py:50 - Epoch: [74][50/500] loss: 0.43889, MAE: 0.42023, time/step=1031ms, lr=2.60e-05
2024-03-19 11:15:22,708 - logger.py:50 - Epoch: [74][100/500] loss: 0.49877, MAE: 0.43485, time/step=1038ms, lr=2.60e-05
2024-03-19 11:16:14,353 - logger.py:50 - Epoch: [74][150/500] loss: 0.50085, MAE: 0.43781, time/step=1037ms, lr=2.60e-05
2024-03-19 11:17:06,734 - logger.py:50 - Epoch: [74][200/500] loss: 0.53086, MAE: 0.43809, time/step=1039ms, lr=2.60e-05
2024-03-19 11:17:57,855 - logger.py:50 - Epoch: [74][250/500] loss: 0.52707, MAE: 0.43758, time/step=1036ms, lr=2.60e-05
2024-03-19 11:18:48,854 - logger.py:50 - Epoch: [74][300/500] loss: 0.50928, MAE: 0.43577, time/step=1033ms, lr=2.60e-05
2024-03-19 11:19:40,514 - logger.py:50 - Epoch: [74][350/500] loss: 0.50700, MAE: 0.43609, time/step=1033ms, lr=2.60e-05
2024-03-19 11:20:32,342 - logger.py:50 - Epoch: [74][400/500] loss: 0.51756, MAE: 0.43588, time/step=1034ms, lr=2.60e-05
2024-03-19 11:21:23,535 - logger.py:50 - Epoch: [74][450/500] loss: 0.89684, MAE: 0.44309, time/step=1033ms, lr=2.60e-05
2024-03-19 11:22:14,438 - logger.py:50 - Epoch: [74][499/500] loss: 0.86079, MAE: 0.44432, time/step=1033ms, lr=2.60e-05
2024-03-19 11:23:11,800 - logger.py:50 - Epoch: [74] train LOSS: 0.86079, val LOSS: 0.44540, test LOSS: 0.43037, Time: 573.98s
2024-03-19 11:23:11,800 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 11:23:12,940 - logger.py:50 - Epoch: [75][0/500] loss: 0.24165, MAE: 0.44396, time/step=1139ms, lr=2.55e-05
2024-03-19 11:24:04,427 - logger.py:50 - Epoch: [75][50/500] loss: 0.54458, MAE: 0.44099, time/step=1032ms, lr=2.55e-05
2024-03-19 11:24:55,448 - logger.py:50 - Epoch: [75][100/500] loss: 1.69416, MAE: 0.46557, time/step=1026ms, lr=2.55e-05
2024-03-19 11:25:46,759 - logger.py:50 - Epoch: [75][150/500] loss: 1.30887, MAE: 0.45719, time/step=1026ms, lr=2.55e-05
2024-03-19 11:26:39,390 - logger.py:50 - Epoch: [75][200/500] loss: 1.08904, MAE: 0.45219, time/step=1033ms, lr=2.55e-05
2024-03-19 11:27:30,884 - logger.py:50 - Epoch: [75][250/500] loss: 1.00488, MAE: 0.45048, time/step=1032ms, lr=2.55e-05
2024-03-19 11:28:22,028 - logger.py:50 - Epoch: [75][300/500] loss: 0.91768, MAE: 0.44780, time/step=1031ms, lr=2.55e-05
2024-03-19 11:29:13,935 - logger.py:50 - Epoch: [75][350/500] loss: 0.86081, MAE: 0.44764, time/step=1032ms, lr=2.55e-05
2024-03-19 11:30:04,852 - logger.py:50 - Epoch: [75][400/500] loss: 0.81547, MAE: 0.44465, time/step=1030ms, lr=2.55e-05
2024-03-19 11:30:56,358 - logger.py:50 - Epoch: [75][450/500] loss: 0.90484, MAE: 0.44557, time/step=1030ms, lr=2.55e-05
2024-03-19 11:31:46,404 - logger.py:50 - Epoch: [75][499/500] loss: 0.85959, MAE: 0.44441, time/step=1029ms, lr=2.55e-05
2024-03-19 11:32:43,781 - logger.py:50 - Epoch: [75] train LOSS: 0.85959, val LOSS: 0.44257, test LOSS: 0.42753, Time: 571.98s
2024-03-19 11:32:43,781 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 11:32:44,915 - logger.py:50 - Epoch: [76][0/500] loss: 1.89468, MAE: 0.54016, time/step=1133ms, lr=2.50e-05
2024-03-19 11:33:36,588 - logger.py:50 - Epoch: [76][50/500] loss: 1.76023, MAE: 0.45628, time/step=1035ms, lr=2.50e-05
2024-03-19 11:34:28,085 - logger.py:50 - Epoch: [76][100/500] loss: 1.14770, MAE: 0.44286, time/step=1033ms, lr=2.50e-05
2024-03-19 11:35:18,953 - logger.py:50 - Epoch: [76][150/500] loss: 1.73894, MAE: 0.45409, time/step=1028ms, lr=2.50e-05
2024-03-19 11:36:10,523 - logger.py:50 - Epoch: [76][200/500] loss: 1.42754, MAE: 0.44924, time/step=1029ms, lr=2.50e-05
2024-03-19 11:37:01,450 - logger.py:50 - Epoch: [76][250/500] loss: 1.24619, MAE: 0.44708, time/step=1027ms, lr=2.50e-05
2024-03-19 11:37:52,398 - logger.py:50 - Epoch: [76][300/500] loss: 1.11620, MAE: 0.44448, time/step=1025ms, lr=2.50e-05
2024-03-19 11:38:44,263 - logger.py:50 - Epoch: [76][350/500] loss: 1.03733, MAE: 0.44590, time/step=1027ms, lr=2.50e-05
2024-03-19 11:39:36,484 - logger.py:50 - Epoch: [76][400/500] loss: 0.97372, MAE: 0.44485, time/step=1029ms, lr=2.50e-05
2024-03-19 11:40:27,775 - logger.py:50 - Epoch: [76][450/500] loss: 0.92516, MAE: 0.44448, time/step=1029ms, lr=2.50e-05
2024-03-19 11:41:18,469 - logger.py:50 - Epoch: [76][499/500] loss: 0.87997, MAE: 0.44437, time/step=1029ms, lr=2.50e-05
2024-03-19 11:42:15,391 - logger.py:50 - Epoch: [76] train LOSS: 0.87997, val LOSS: 0.44725, test LOSS: 0.43221, Time: 571.61s
2024-03-19 11:42:15,391 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 11:42:16,570 - logger.py:50 - Epoch: [77][0/500] loss: 0.34323, MAE: 0.55485, time/step=1177ms, lr=2.45e-05
2024-03-19 11:43:08,181 - logger.py:50 - Epoch: [77][50/500] loss: 0.49089, MAE: 0.43324, time/step=1035ms, lr=2.45e-05
2024-03-19 11:43:59,077 - logger.py:50 - Epoch: [77][100/500] loss: 0.48431, MAE: 0.42554, time/step=1027ms, lr=2.45e-05
2024-03-19 11:44:50,809 - logger.py:50 - Epoch: [77][150/500] loss: 0.49339, MAE: 0.42865, time/step=1029ms, lr=2.45e-05
2024-03-19 11:45:42,437 - logger.py:50 - Epoch: [77][200/500] loss: 0.49817, MAE: 0.43251, time/step=1030ms, lr=2.45e-05
2024-03-19 11:46:33,453 - logger.py:50 - Epoch: [77][250/500] loss: 0.51548, MAE: 0.43213, time/step=1028ms, lr=2.45e-05
2024-03-19 11:47:24,105 - logger.py:50 - Epoch: [77][300/500] loss: 0.51267, MAE: 0.43347, time/step=1026ms, lr=2.45e-05
2024-03-19 11:48:16,270 - logger.py:50 - Epoch: [77][350/500] loss: 0.52122, MAE: 0.43679, time/step=1028ms, lr=2.45e-05
2024-03-19 11:49:07,396 - logger.py:50 - Epoch: [77][400/500] loss: 0.51340, MAE: 0.43548, time/step=1027ms, lr=2.45e-05
2024-03-19 11:49:58,254 - logger.py:50 - Epoch: [77][450/500] loss: 0.91837, MAE: 0.44445, time/step=1026ms, lr=2.45e-05
2024-03-19 11:50:49,947 - logger.py:50 - Epoch: [77][499/500] loss: 0.87556, MAE: 0.44444, time/step=1029ms, lr=2.45e-05
2024-03-19 11:51:47,016 - logger.py:50 - Epoch: [77] train LOSS: 0.87556, val LOSS: 0.44528, test LOSS: 0.43007, Time: 571.63s
2024-03-19 11:51:47,016 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 11:51:48,124 - logger.py:50 - Epoch: [78][0/500] loss: 0.21017, MAE: 0.36681, time/step=1106ms, lr=2.40e-05
2024-03-19 11:52:39,822 - logger.py:50 - Epoch: [78][50/500] loss: 0.44125, MAE: 0.44633, time/step=1035ms, lr=2.40e-05
2024-03-19 11:53:31,005 - logger.py:50 - Epoch: [78][100/500] loss: 0.47404, MAE: 0.44552, time/step=1030ms, lr=2.40e-05
2024-03-19 11:54:21,025 - logger.py:50 - Epoch: [78][150/500] loss: 0.49478, MAE: 0.44322, time/step=1020ms, lr=2.40e-05
2024-03-19 11:55:11,703 - logger.py:50 - Epoch: [78][200/500] loss: 0.48604, MAE: 0.43972, time/step=1018ms, lr=2.40e-05
2024-03-19 11:56:02,156 - logger.py:50 - Epoch: [78][250/500] loss: 0.49588, MAE: 0.43965, time/step=1016ms, lr=2.40e-05
2024-03-19 11:56:53,817 - logger.py:50 - Epoch: [78][300/500] loss: 0.49586, MAE: 0.43983, time/step=1019ms, lr=2.40e-05
2024-03-19 11:57:44,934 - logger.py:50 - Epoch: [78][350/500] loss: 0.50511, MAE: 0.44093, time/step=1020ms, lr=2.40e-05
2024-03-19 11:58:35,962 - logger.py:50 - Epoch: [78][400/500] loss: 0.95168, MAE: 0.44639, time/step=1020ms, lr=2.40e-05
2024-03-19 11:59:26,955 - logger.py:50 - Epoch: [78][450/500] loss: 0.91255, MAE: 0.44485, time/step=1020ms, lr=2.40e-05
2024-03-19 12:00:18,829 - logger.py:50 - Epoch: [78][499/500] loss: 0.87025, MAE: 0.44423, time/step=1024ms, lr=2.40e-05
2024-03-19 12:01:15,476 - logger.py:50 - Epoch: [78] train LOSS: 0.87025, val LOSS: 0.43923, test LOSS: 0.42401, Time: 568.46s
2024-03-19 12:01:15,476 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 12:01:16,670 - logger.py:50 - Epoch: [79][0/500] loss: 0.38925, MAE: 0.48324, time/step=1192ms, lr=2.34e-05
2024-03-19 12:02:08,774 - logger.py:50 - Epoch: [79][50/500] loss: 1.58681, MAE: 0.46857, time/step=1045ms, lr=2.34e-05
2024-03-19 12:02:59,543 - logger.py:50 - Epoch: [79][100/500] loss: 1.07506, MAE: 0.45413, time/step=1030ms, lr=2.34e-05
2024-03-19 12:03:50,650 - logger.py:50 - Epoch: [79][150/500] loss: 0.86567, MAE: 0.44108, time/step=1028ms, lr=2.34e-05
2024-03-19 12:04:42,708 - logger.py:50 - Epoch: [79][200/500] loss: 0.79991, MAE: 0.44130, time/step=1031ms, lr=2.34e-05
2024-03-19 12:05:34,907 - logger.py:50 - Epoch: [79][250/500] loss: 0.74028, MAE: 0.43989, time/step=1034ms, lr=2.34e-05
2024-03-19 12:06:26,788 - logger.py:50 - Epoch: [79][300/500] loss: 0.69619, MAE: 0.43865, time/step=1034ms, lr=2.34e-05
2024-03-19 12:07:16,973 - logger.py:50 - Epoch: [79][350/500] loss: 0.66809, MAE: 0.43929, time/step=1030ms, lr=2.34e-05
2024-03-19 12:08:07,547 - logger.py:50 - Epoch: [79][400/500] loss: 0.96001, MAE: 0.44529, time/step=1028ms, lr=2.34e-05
2024-03-19 12:08:59,242 - logger.py:50 - Epoch: [79][450/500] loss: 0.90476, MAE: 0.44432, time/step=1028ms, lr=2.34e-05
2024-03-19 12:09:50,531 - logger.py:50 - Epoch: [79][499/500] loss: 0.86221, MAE: 0.44438, time/step=1030ms, lr=2.34e-05
2024-03-19 12:10:47,539 - logger.py:50 - Epoch: [79] train LOSS: 0.86221, val LOSS: 0.44180, test LOSS: 0.42507, Time: 572.06s
2024-03-19 12:10:47,539 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 12:10:48,760 - logger.py:50 - Epoch: [80][0/500] loss: 104.92310, MAE: 2.29469, time/step=1218ms, lr=2.29e-05
2024-03-19 12:11:40,554 - logger.py:50 - Epoch: [80][50/500] loss: 2.89557, MAE: 0.46639, time/step=1039ms, lr=2.29e-05
2024-03-19 12:12:31,382 - logger.py:50 - Epoch: [80][100/500] loss: 1.68321, MAE: 0.45416, time/step=1028ms, lr=2.29e-05
2024-03-19 12:13:22,718 - logger.py:50 - Epoch: [80][150/500] loss: 1.31784, MAE: 0.44615, time/step=1028ms, lr=2.29e-05
2024-03-19 12:14:14,162 - logger.py:50 - Epoch: [80][200/500] loss: 1.09948, MAE: 0.44259, time/step=1028ms, lr=2.29e-05
2024-03-19 12:15:05,623 - logger.py:50 - Epoch: [80][250/500] loss: 0.99258, MAE: 0.44042, time/step=1028ms, lr=2.29e-05
2024-03-19 12:15:56,753 - logger.py:50 - Epoch: [80][300/500] loss: 0.91101, MAE: 0.43897, time/step=1027ms, lr=2.29e-05
2024-03-19 12:16:47,983 - logger.py:50 - Epoch: [80][350/500] loss: 0.85640, MAE: 0.43814, time/step=1027ms, lr=2.29e-05
2024-03-19 12:17:38,141 - logger.py:50 - Epoch: [80][400/500] loss: 0.95206, MAE: 0.44231, time/step=1024ms, lr=2.29e-05
2024-03-19 12:18:29,302 - logger.py:50 - Epoch: [80][450/500] loss: 0.90192, MAE: 0.44395, time/step=1024ms, lr=2.29e-05
2024-03-19 12:19:20,002 - logger.py:50 - Epoch: [80][499/500] loss: 0.85961, MAE: 0.44436, time/step=1025ms, lr=2.29e-05
2024-03-19 12:20:16,978 - logger.py:50 - Epoch: [80] train LOSS: 0.85961, val LOSS: 0.44930, test LOSS: 0.43436, Time: 569.44s
2024-03-19 12:20:16,978 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 12:20:18,148 - logger.py:50 - Epoch: [81][0/500] loss: 0.64469, MAE: 0.59443, time/step=1168ms, lr=2.24e-05
2024-03-19 12:21:10,134 - logger.py:50 - Epoch: [81][50/500] loss: 0.49062, MAE: 0.43135, time/step=1042ms, lr=2.24e-05
2024-03-19 12:22:01,846 - logger.py:50 - Epoch: [81][100/500] loss: 2.20818, MAE: 0.46466, time/step=1038ms, lr=2.24e-05
2024-03-19 12:22:52,822 - logger.py:50 - Epoch: [81][150/500] loss: 1.64055, MAE: 0.45800, time/step=1032ms, lr=2.24e-05
2024-03-19 12:23:45,333 - logger.py:50 - Epoch: [81][200/500] loss: 1.34310, MAE: 0.45197, time/step=1037ms, lr=2.24e-05
2024-03-19 12:24:37,147 - logger.py:50 - Epoch: [81][250/500] loss: 1.17781, MAE: 0.44604, time/step=1037ms, lr=2.24e-05
2024-03-19 12:25:28,032 - logger.py:50 - Epoch: [81][300/500] loss: 1.07947, MAE: 0.44450, time/step=1033ms, lr=2.24e-05
2024-03-19 12:26:19,932 - logger.py:50 - Epoch: [81][350/500] loss: 1.01334, MAE: 0.44630, time/step=1034ms, lr=2.24e-05
2024-03-19 12:27:11,234 - logger.py:50 - Epoch: [81][400/500] loss: 0.95060, MAE: 0.44770, time/step=1033ms, lr=2.24e-05
2024-03-19 12:28:01,781 - logger.py:50 - Epoch: [81][450/500] loss: 0.89851, MAE: 0.44564, time/step=1031ms, lr=2.24e-05
2024-03-19 12:28:52,342 - logger.py:50 - Epoch: [81][499/500] loss: 0.85830, MAE: 0.44442, time/step=1031ms, lr=2.24e-05
2024-03-19 12:29:49,311 - logger.py:50 - Epoch: [81] train LOSS: 0.85830, val LOSS: 0.44559, test LOSS: 0.43050, Time: 572.33s
2024-03-19 12:29:49,312 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 12:29:50,016 - logger.py:50 - Epoch: [82][0/500] loss: 0.38978, MAE: 0.42885, time/step=702ms, lr=2.19e-05
2024-03-19 12:30:41,551 - logger.py:50 - Epoch: [82][50/500] loss: 0.47801, MAE: 0.44374, time/step=1024ms, lr=2.19e-05
2024-03-19 12:31:33,447 - logger.py:50 - Epoch: [82][100/500] loss: 0.47177, MAE: 0.44596, time/step=1031ms, lr=2.19e-05
2024-03-19 12:32:24,413 - logger.py:50 - Epoch: [82][150/500] loss: 1.28061, MAE: 0.45662, time/step=1027ms, lr=2.19e-05
2024-03-19 12:33:16,470 - logger.py:50 - Epoch: [82][200/500] loss: 1.09867, MAE: 0.45138, time/step=1031ms, lr=2.19e-05
2024-03-19 12:34:07,696 - logger.py:50 - Epoch: [82][250/500] loss: 0.97669, MAE: 0.44992, time/step=1029ms, lr=2.19e-05
2024-03-19 12:34:59,753 - logger.py:50 - Epoch: [82][300/500] loss: 0.88824, MAE: 0.44673, time/step=1031ms, lr=2.19e-05
2024-03-19 12:35:51,937 - logger.py:50 - Epoch: [82][350/500] loss: 0.82684, MAE: 0.44384, time/step=1033ms, lr=2.19e-05
2024-03-19 12:36:42,957 - logger.py:50 - Epoch: [82][400/500] loss: 0.79436, MAE: 0.44368, time/step=1032ms, lr=2.19e-05
2024-03-19 12:37:33,749 - logger.py:50 - Epoch: [82][450/500] loss: 0.89478, MAE: 0.44569, time/step=1030ms, lr=2.19e-05
2024-03-19 12:38:24,640 - logger.py:50 - Epoch: [82][499/500] loss: 0.86107, MAE: 0.44433, time/step=1031ms, lr=2.19e-05
2024-03-19 12:39:22,112 - logger.py:50 - Epoch: [82] train LOSS: 0.86107, val LOSS: 0.44118, test LOSS: 0.42641, Time: 572.80s
2024-03-19 12:39:22,112 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 12:39:22,797 - logger.py:50 - Epoch: [83][0/500] loss: 0.36545, MAE: 0.44281, time/step=683ms, lr=2.14e-05
2024-03-19 12:40:14,900 - logger.py:50 - Epoch: [83][50/500] loss: 0.57798, MAE: 0.42747, time/step=1035ms, lr=2.14e-05
2024-03-19 12:41:06,554 - logger.py:50 - Epoch: [83][100/500] loss: 0.53615, MAE: 0.43213, time/step=1034ms, lr=2.14e-05
2024-03-19 12:41:57,767 - logger.py:50 - Epoch: [83][150/500] loss: 0.92108, MAE: 0.44173, time/step=1031ms, lr=2.14e-05
2024-03-19 12:42:49,778 - logger.py:50 - Epoch: [83][200/500] loss: 0.81753, MAE: 0.43844, time/step=1033ms, lr=2.14e-05
2024-03-19 12:43:41,104 - logger.py:50 - Epoch: [83][250/500] loss: 0.74882, MAE: 0.44036, time/step=1032ms, lr=2.14e-05
2024-03-19 12:44:32,058 - logger.py:50 - Epoch: [83][300/500] loss: 0.71010, MAE: 0.44172, time/step=1030ms, lr=2.14e-05
2024-03-19 12:45:23,700 - logger.py:50 - Epoch: [83][350/500] loss: 0.68062, MAE: 0.44150, time/step=1030ms, lr=2.14e-05
2024-03-19 12:46:14,990 - logger.py:50 - Epoch: [83][400/500] loss: 0.95450, MAE: 0.44494, time/step=1030ms, lr=2.14e-05
2024-03-19 12:47:06,744 - logger.py:50 - Epoch: [83][450/500] loss: 0.89697, MAE: 0.44328, time/step=1030ms, lr=2.14e-05
2024-03-19 12:47:56,903 - logger.py:50 - Epoch: [83][499/500] loss: 0.85728, MAE: 0.44443, time/step=1030ms, lr=2.14e-05
2024-03-19 12:48:54,368 - logger.py:50 - Epoch: [83] train LOSS: 0.85728, val LOSS: 0.44297, test LOSS: 0.42794, Time: 572.26s
2024-03-19 12:48:54,368 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 12:48:55,088 - logger.py:50 - Epoch: [84][0/500] loss: 0.16440, MAE: 0.35200, time/step=718ms, lr=2.09e-05
2024-03-19 12:49:45,747 - logger.py:50 - Epoch: [84][50/500] loss: 0.50474, MAE: 0.43862, time/step=1007ms, lr=2.09e-05
2024-03-19 12:50:38,593 - logger.py:50 - Epoch: [84][100/500] loss: 0.49128, MAE: 0.43336, time/step=1032ms, lr=2.09e-05
2024-03-19 12:51:30,747 - logger.py:50 - Epoch: [84][150/500] loss: 0.52037, MAE: 0.43484, time/step=1036ms, lr=2.09e-05
2024-03-19 12:52:22,911 - logger.py:50 - Epoch: [84][200/500] loss: 0.51694, MAE: 0.43784, time/step=1038ms, lr=2.09e-05
2024-03-19 12:53:13,941 - logger.py:50 - Epoch: [84][250/500] loss: 0.51344, MAE: 0.43722, time/step=1034ms, lr=2.09e-05
2024-03-19 12:54:06,033 - logger.py:50 - Epoch: [84][300/500] loss: 0.50488, MAE: 0.43744, time/step=1035ms, lr=2.09e-05
2024-03-19 12:54:56,788 - logger.py:50 - Epoch: [84][350/500] loss: 0.83750, MAE: 0.44286, time/step=1033ms, lr=2.09e-05
2024-03-19 12:55:47,856 - logger.py:50 - Epoch: [84][400/500] loss: 0.96179, MAE: 0.44567, time/step=1031ms, lr=2.09e-05
2024-03-19 12:56:38,301 - logger.py:50 - Epoch: [84][450/500] loss: 0.90762, MAE: 0.44555, time/step=1029ms, lr=2.09e-05
2024-03-19 12:57:28,240 - logger.py:50 - Epoch: [84][499/500] loss: 0.86765, MAE: 0.44455, time/step=1028ms, lr=2.09e-05
2024-03-19 12:58:24,834 - logger.py:50 - Epoch: [84] train LOSS: 0.86765, val LOSS: 0.43971, test LOSS: 0.42473, Time: 570.47s
2024-03-19 12:58:24,834 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 12:58:25,975 - logger.py:50 - Epoch: [85][0/500] loss: 0.25611, MAE: 0.46794, time/step=1139ms, lr=2.04e-05
2024-03-19 12:59:17,770 - logger.py:50 - Epoch: [85][50/500] loss: 0.45595, MAE: 0.45592, time/step=1038ms, lr=2.04e-05
2024-03-19 13:00:08,526 - logger.py:50 - Epoch: [85][100/500] loss: 1.18067, MAE: 0.45695, time/step=1027ms, lr=2.04e-05
2024-03-19 13:01:01,054 - logger.py:50 - Epoch: [85][150/500] loss: 0.92726, MAE: 0.44726, time/step=1035ms, lr=2.04e-05
2024-03-19 13:01:51,804 - logger.py:50 - Epoch: [85][200/500] loss: 1.38614, MAE: 0.45142, time/step=1030ms, lr=2.04e-05
2024-03-19 13:02:41,737 - logger.py:50 - Epoch: [85][250/500] loss: 1.22262, MAE: 0.44749, time/step=1024ms, lr=2.04e-05
2024-03-19 13:03:33,671 - logger.py:50 - Epoch: [85][300/500] loss: 1.09645, MAE: 0.44793, time/step=1026ms, lr=2.04e-05
2024-03-19 13:04:24,816 - logger.py:50 - Epoch: [85][350/500] loss: 1.02415, MAE: 0.44651, time/step=1026ms, lr=2.04e-05
2024-03-19 13:05:16,272 - logger.py:50 - Epoch: [85][400/500] loss: 0.96654, MAE: 0.44483, time/step=1026ms, lr=2.04e-05
2024-03-19 13:06:06,240 - logger.py:50 - Epoch: [85][450/500] loss: 0.92684, MAE: 0.44506, time/step=1023ms, lr=2.04e-05
2024-03-19 13:06:56,679 - logger.py:50 - Epoch: [85][499/500] loss: 0.88630, MAE: 0.44421, time/step=1024ms, lr=2.04e-05
2024-03-19 13:07:52,816 - logger.py:50 - Epoch: [85] train LOSS: 0.88630, val LOSS: 0.44492, test LOSS: 0.43011, Time: 567.98s
2024-03-19 13:07:52,816 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 13:07:53,984 - logger.py:50 - Epoch: [86][0/500] loss: 0.51466, MAE: 0.52573, time/step=1165ms, lr=1.99e-05
2024-03-19 13:08:45,746 - logger.py:50 - Epoch: [86][50/500] loss: 0.47459, MAE: 0.42771, time/step=1038ms, lr=1.99e-05
2024-03-19 13:09:37,470 - logger.py:50 - Epoch: [86][100/500] loss: 0.47784, MAE: 0.42801, time/step=1036ms, lr=1.99e-05
2024-03-19 13:10:27,954 - logger.py:50 - Epoch: [86][150/500] loss: 0.49301, MAE: 0.43165, time/step=1027ms, lr=1.99e-05
2024-03-19 13:11:19,211 - logger.py:50 - Epoch: [86][200/500] loss: 0.49704, MAE: 0.43378, time/step=1027ms, lr=1.99e-05
2024-03-19 13:12:10,053 - logger.py:50 - Epoch: [86][250/500] loss: 0.51160, MAE: 0.43144, time/step=1025ms, lr=1.99e-05
2024-03-19 13:13:01,428 - logger.py:50 - Epoch: [86][300/500] loss: 0.51361, MAE: 0.43233, time/step=1025ms, lr=1.99e-05
2024-03-19 13:13:52,238 - logger.py:50 - Epoch: [86][350/500] loss: 0.84388, MAE: 0.43912, time/step=1024ms, lr=1.99e-05
2024-03-19 13:14:43,843 - logger.py:50 - Epoch: [86][400/500] loss: 0.80099, MAE: 0.43988, time/step=1025ms, lr=1.99e-05
2024-03-19 13:15:34,663 - logger.py:50 - Epoch: [86][450/500] loss: 0.89899, MAE: 0.44291, time/step=1024ms, lr=1.99e-05
2024-03-19 13:16:24,670 - logger.py:50 - Epoch: [86][499/500] loss: 0.86185, MAE: 0.44447, time/step=1024ms, lr=1.99e-05
2024-03-19 13:17:21,267 - logger.py:50 - Epoch: [86] train LOSS: 0.86185, val LOSS: 0.44907, test LOSS: 0.43415, Time: 568.45s
2024-03-19 13:17:21,267 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 13:17:21,915 - logger.py:50 - Epoch: [87][0/500] loss: 1.16702, MAE: 0.50734, time/step=646ms, lr=1.94e-05
2024-03-19 13:18:12,099 - logger.py:50 - Epoch: [87][50/500] loss: 1.77634, MAE: 0.48079, time/step=997ms, lr=1.94e-05
2024-03-19 13:19:02,433 - logger.py:50 - Epoch: [87][100/500] loss: 1.11871, MAE: 0.45625, time/step=1002ms, lr=1.94e-05
2024-03-19 13:19:53,947 - logger.py:50 - Epoch: [87][150/500] loss: 0.88271, MAE: 0.45085, time/step=1011ms, lr=1.94e-05
2024-03-19 13:20:44,677 - logger.py:50 - Epoch: [87][200/500] loss: 0.78617, MAE: 0.44548, time/step=1012ms, lr=1.94e-05
2024-03-19 13:21:36,461 - logger.py:50 - Epoch: [87][250/500] loss: 1.19606, MAE: 0.45091, time/step=1017ms, lr=1.94e-05
2024-03-19 13:22:28,221 - logger.py:50 - Epoch: [87][300/500] loss: 1.06263, MAE: 0.44723, time/step=1020ms, lr=1.94e-05
2024-03-19 13:23:20,218 - logger.py:50 - Epoch: [87][350/500] loss: 0.98221, MAE: 0.44471, time/step=1023ms, lr=1.94e-05
2024-03-19 13:24:10,656 - logger.py:50 - Epoch: [87][400/500] loss: 0.92813, MAE: 0.44559, time/step=1021ms, lr=1.94e-05
2024-03-19 13:25:02,461 - logger.py:50 - Epoch: [87][450/500] loss: 0.88754, MAE: 0.44397, time/step=1023ms, lr=1.94e-05
2024-03-19 13:25:53,437 - logger.py:50 - Epoch: [87][499/500] loss: 0.85452, MAE: 0.44430, time/step=1024ms, lr=1.94e-05
2024-03-19 13:26:50,895 - logger.py:50 - Epoch: [87] train LOSS: 0.85452, val LOSS: 0.44817, test LOSS: 0.43309, Time: 569.63s
2024-03-19 13:26:50,896 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 13:26:52,123 - logger.py:50 - Epoch: [88][0/500] loss: 0.10167, MAE: 0.31986, time/step=1226ms, lr=1.89e-05
2024-03-19 13:27:43,166 - logger.py:50 - Epoch: [88][50/500] loss: 1.56871, MAE: 0.48512, time/step=1025ms, lr=1.89e-05
2024-03-19 13:28:34,432 - logger.py:50 - Epoch: [88][100/500] loss: 1.03263, MAE: 0.46404, time/step=1025ms, lr=1.89e-05
2024-03-19 13:29:25,799 - logger.py:50 - Epoch: [88][150/500] loss: 0.87017, MAE: 0.45163, time/step=1026ms, lr=1.89e-05
2024-03-19 13:30:16,977 - logger.py:50 - Epoch: [88][200/500] loss: 0.78442, MAE: 0.45002, time/step=1025ms, lr=1.89e-05
2024-03-19 13:31:08,620 - logger.py:50 - Epoch: [88][250/500] loss: 0.73743, MAE: 0.44629, time/step=1027ms, lr=1.89e-05
2024-03-19 13:31:59,848 - logger.py:50 - Epoch: [88][300/500] loss: 0.69949, MAE: 0.44615, time/step=1026ms, lr=1.89e-05
2024-03-19 13:32:50,798 - logger.py:50 - Epoch: [88][350/500] loss: 0.66640, MAE: 0.44268, time/step=1025ms, lr=1.89e-05
2024-03-19 13:33:42,908 - logger.py:50 - Epoch: [88][400/500] loss: 0.64777, MAE: 0.44222, time/step=1027ms, lr=1.89e-05
2024-03-19 13:34:34,673 - logger.py:50 - Epoch: [88][450/500] loss: 0.89563, MAE: 0.44403, time/step=1028ms, lr=1.89e-05
2024-03-19 13:35:24,687 - logger.py:50 - Epoch: [88][499/500] loss: 0.85532, MAE: 0.44437, time/step=1028ms, lr=1.89e-05
2024-03-19 13:36:22,140 - logger.py:50 - Epoch: [88] train LOSS: 0.85532, val LOSS: 0.44419, test LOSS: 0.42925, Time: 571.24s
2024-03-19 13:36:22,141 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 13:36:23,222 - logger.py:50 - Epoch: [89][0/500] loss: 0.53439, MAE: 0.41531, time/step=1079ms, lr=1.84e-05
2024-03-19 13:37:14,017 - logger.py:50 - Epoch: [89][50/500] loss: 0.51220, MAE: 0.44274, time/step=1017ms, lr=1.84e-05
2024-03-19 13:38:05,055 - logger.py:50 - Epoch: [89][100/500] loss: 0.50162, MAE: 0.43451, time/step=1019ms, lr=1.84e-05
2024-03-19 13:38:55,359 - logger.py:50 - Epoch: [89][150/500] loss: 0.49118, MAE: 0.43453, time/step=1015ms, lr=1.84e-05
2024-03-19 13:39:46,902 - logger.py:50 - Epoch: [89][200/500] loss: 0.50787, MAE: 0.43966, time/step=1019ms, lr=1.84e-05
2024-03-19 13:40:37,676 - logger.py:50 - Epoch: [89][250/500] loss: 0.72869, MAE: 0.44279, time/step=1018ms, lr=1.84e-05
2024-03-19 13:41:28,831 - logger.py:50 - Epoch: [89][300/500] loss: 0.68644, MAE: 0.43999, time/step=1019ms, lr=1.84e-05
2024-03-19 13:42:20,634 - logger.py:50 - Epoch: [89][350/500] loss: 0.66504, MAE: 0.44130, time/step=1021ms, lr=1.84e-05
2024-03-19 13:43:12,207 - logger.py:50 - Epoch: [89][400/500] loss: 0.94191, MAE: 0.44709, time/step=1023ms, lr=1.84e-05
2024-03-19 13:44:03,377 - logger.py:50 - Epoch: [89][450/500] loss: 0.89655, MAE: 0.44495, time/step=1023ms, lr=1.84e-05
2024-03-19 13:44:54,196 - logger.py:50 - Epoch: [89][499/500] loss: 0.85150, MAE: 0.44441, time/step=1024ms, lr=1.84e-05
2024-03-19 13:45:51,656 - logger.py:50 - Epoch: [89] train LOSS: 0.85150, val LOSS: 0.45023, test LOSS: 0.43530, Time: 569.51s
2024-03-19 13:45:51,656 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 13:45:52,811 - logger.py:50 - Epoch: [90][0/500] loss: 0.48333, MAE: 0.47600, time/step=1152ms, lr=1.79e-05
2024-03-19 13:46:43,230 - logger.py:50 - Epoch: [90][50/500] loss: 0.51798, MAE: 0.42646, time/step=1011ms, lr=1.79e-05
2024-03-19 13:47:33,924 - logger.py:50 - Epoch: [90][100/500] loss: 1.70474, MAE: 0.44973, time/step=1013ms, lr=1.79e-05
2024-03-19 13:48:24,375 - logger.py:50 - Epoch: [90][150/500] loss: 1.29848, MAE: 0.44775, time/step=1011ms, lr=1.79e-05
2024-03-19 13:49:16,149 - logger.py:50 - Epoch: [90][200/500] loss: 1.10631, MAE: 0.44798, time/step=1017ms, lr=1.79e-05
2024-03-19 13:50:06,643 - logger.py:50 - Epoch: [90][250/500] loss: 0.97625, MAE: 0.44738, time/step=1016ms, lr=1.79e-05
2024-03-19 13:50:57,715 - logger.py:50 - Epoch: [90][300/500] loss: 0.89692, MAE: 0.44705, time/step=1017ms, lr=1.79e-05
2024-03-19 13:51:49,372 - logger.py:50 - Epoch: [90][350/500] loss: 0.84128, MAE: 0.44578, time/step=1019ms, lr=1.79e-05
2024-03-19 13:52:41,894 - logger.py:50 - Epoch: [90][400/500] loss: 0.92667, MAE: 0.44894, time/step=1023ms, lr=1.79e-05
2024-03-19 13:53:33,591 - logger.py:50 - Epoch: [90][450/500] loss: 0.87463, MAE: 0.44722, time/step=1024ms, lr=1.79e-05
2024-03-19 13:54:24,170 - logger.py:50 - Epoch: [90][499/500] loss: 0.84988, MAE: 0.44443, time/step=1025ms, lr=1.79e-05
2024-03-19 13:55:23,154 - logger.py:50 - Epoch: [90] train LOSS: 0.84988, val LOSS: 0.44745, test LOSS: 0.43249, Time: 571.50s
2024-03-19 13:55:23,154 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 13:55:23,823 - logger.py:50 - Epoch: [91][0/500] loss: 1.34169, MAE: 0.39397, time/step=667ms, lr=1.74e-05
2024-03-19 13:56:17,049 - logger.py:50 - Epoch: [91][50/500] loss: 0.48938, MAE: 0.44199, time/step=1057ms, lr=1.74e-05
2024-03-19 13:57:08,291 - logger.py:50 - Epoch: [91][100/500] loss: 0.48935, MAE: 0.44361, time/step=1041ms, lr=1.74e-05
2024-03-19 13:57:59,834 - logger.py:50 - Epoch: [91][150/500] loss: 0.49485, MAE: 0.44428, time/step=1038ms, lr=1.74e-05
2024-03-19 13:58:51,226 - logger.py:50 - Epoch: [91][200/500] loss: 0.48250, MAE: 0.43668, time/step=1035ms, lr=1.74e-05
2024-03-19 13:59:42,097 - logger.py:50 - Epoch: [91][250/500] loss: 0.49046, MAE: 0.43912, time/step=1032ms, lr=1.74e-05
2024-03-19 14:00:33,393 - logger.py:50 - Epoch: [91][300/500] loss: 0.50953, MAE: 0.44005, time/step=1031ms, lr=1.74e-05
2024-03-19 14:01:24,676 - logger.py:50 - Epoch: [91][350/500] loss: 0.50263, MAE: 0.43868, time/step=1030ms, lr=1.74e-05
2024-03-19 14:02:16,441 - logger.py:50 - Epoch: [91][400/500] loss: 0.62960, MAE: 0.44010, time/step=1031ms, lr=1.74e-05
2024-03-19 14:03:08,380 - logger.py:50 - Epoch: [91][450/500] loss: 0.61785, MAE: 0.44159, time/step=1032ms, lr=1.74e-05
2024-03-19 14:03:58,700 - logger.py:50 - Epoch: [91][499/500] loss: 0.85055, MAE: 0.44451, time/step=1031ms, lr=1.74e-05
2024-03-19 14:04:56,145 - logger.py:50 - Epoch: [91] train LOSS: 0.85055, val LOSS: 0.44792, test LOSS: 0.43171, Time: 572.99s
2024-03-19 14:04:56,145 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 14:04:57,367 - logger.py:50 - Epoch: [92][0/500] loss: 0.23317, MAE: 0.31181, time/step=1219ms, lr=1.70e-05
2024-03-19 14:05:48,358 - logger.py:50 - Epoch: [92][50/500] loss: 0.67233, MAE: 0.45212, time/step=1024ms, lr=1.70e-05
2024-03-19 14:06:40,033 - logger.py:50 - Epoch: [92][100/500] loss: 1.72036, MAE: 0.45844, time/step=1029ms, lr=1.70e-05
2024-03-19 14:07:31,134 - logger.py:50 - Epoch: [92][150/500] loss: 1.32972, MAE: 0.45760, time/step=1026ms, lr=1.70e-05
2024-03-19 14:08:22,062 - logger.py:50 - Epoch: [92][200/500] loss: 1.11796, MAE: 0.45219, time/step=1024ms, lr=1.70e-05
2024-03-19 14:09:13,934 - logger.py:50 - Epoch: [92][250/500] loss: 0.98657, MAE: 0.44755, time/step=1027ms, lr=1.70e-05
2024-03-19 14:10:05,102 - logger.py:50 - Epoch: [92][300/500] loss: 0.90480, MAE: 0.44370, time/step=1026ms, lr=1.70e-05
2024-03-19 14:10:57,383 - logger.py:50 - Epoch: [92][350/500] loss: 0.84453, MAE: 0.44144, time/step=1029ms, lr=1.70e-05
2024-03-19 14:11:48,257 - logger.py:50 - Epoch: [92][400/500] loss: 0.79589, MAE: 0.44011, time/step=1028ms, lr=1.70e-05
2024-03-19 14:12:40,699 - logger.py:50 - Epoch: [92][450/500] loss: 0.89408, MAE: 0.44457, time/step=1030ms, lr=1.70e-05
2024-03-19 14:13:29,962 - logger.py:50 - Epoch: [92][499/500] loss: 0.85180, MAE: 0.44447, time/step=1028ms, lr=1.70e-05
2024-03-19 14:14:26,511 - logger.py:50 - Epoch: [92] train LOSS: 0.85180, val LOSS: 0.44219, test LOSS: 0.42723, Time: 570.37s
2024-03-19 14:14:26,511 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 14:14:27,629 - logger.py:50 - Epoch: [93][0/500] loss: 0.34713, MAE: 0.35301, time/step=1116ms, lr=1.65e-05
2024-03-19 14:15:18,757 - logger.py:50 - Epoch: [93][50/500] loss: 0.67029, MAE: 0.45804, time/step=1024ms, lr=1.65e-05
2024-03-19 14:16:09,287 - logger.py:50 - Epoch: [93][100/500] loss: 0.56739, MAE: 0.44495, time/step=1018ms, lr=1.65e-05
2024-03-19 14:17:01,059 - logger.py:50 - Epoch: [93][150/500] loss: 0.53590, MAE: 0.43781, time/step=1023ms, lr=1.65e-05
2024-03-19 14:17:52,526 - logger.py:50 - Epoch: [93][200/500] loss: 0.51622, MAE: 0.43607, time/step=1025ms, lr=1.65e-05
2024-03-19 14:18:43,857 - logger.py:50 - Epoch: [93][250/500] loss: 0.51392, MAE: 0.43871, time/step=1025ms, lr=1.65e-05
2024-03-19 14:19:34,991 - logger.py:50 - Epoch: [93][300/500] loss: 0.91974, MAE: 0.44653, time/step=1025ms, lr=1.65e-05
2024-03-19 14:20:25,467 - logger.py:50 - Epoch: [93][350/500] loss: 0.85259, MAE: 0.44441, time/step=1023ms, lr=1.65e-05
2024-03-19 14:21:16,491 - logger.py:50 - Epoch: [93][400/500] loss: 0.95374, MAE: 0.44734, time/step=1022ms, lr=1.65e-05
2024-03-19 14:22:08,053 - logger.py:50 - Epoch: [93][450/500] loss: 0.90839, MAE: 0.44591, time/step=1023ms, lr=1.65e-05
2024-03-19 14:22:59,287 - logger.py:50 - Epoch: [93][499/500] loss: 0.85915, MAE: 0.44437, time/step=1026ms, lr=1.65e-05
2024-03-19 14:23:56,785 - logger.py:50 - Epoch: [93] train LOSS: 0.85915, val LOSS: 0.44261, test LOSS: 0.42752, Time: 570.27s
2024-03-19 14:23:56,785 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 14:23:57,532 - logger.py:50 - Epoch: [94][0/500] loss: 0.56520, MAE: 0.35424, time/step=745ms, lr=1.60e-05
2024-03-19 14:24:49,021 - logger.py:50 - Epoch: [94][50/500] loss: 0.50851, MAE: 0.44228, time/step=1024ms, lr=1.60e-05
2024-03-19 14:25:40,442 - logger.py:50 - Epoch: [94][100/500] loss: 0.51319, MAE: 0.44836, time/step=1026ms, lr=1.60e-05
2024-03-19 14:26:32,151 - logger.py:50 - Epoch: [94][150/500] loss: 0.48283, MAE: 0.44179, time/step=1029ms, lr=1.60e-05
2024-03-19 14:27:22,807 - logger.py:50 - Epoch: [94][200/500] loss: 0.49847, MAE: 0.43904, time/step=1025ms, lr=1.60e-05
2024-03-19 14:28:14,862 - logger.py:50 - Epoch: [94][250/500] loss: 0.49554, MAE: 0.43958, time/step=1028ms, lr=1.60e-05
2024-03-19 14:29:05,953 - logger.py:50 - Epoch: [94][300/500] loss: 0.90835, MAE: 0.44403, time/step=1027ms, lr=1.60e-05
2024-03-19 14:29:57,733 - logger.py:50 - Epoch: [94][350/500] loss: 0.84744, MAE: 0.44408, time/step=1028ms, lr=1.60e-05
2024-03-19 14:30:49,554 - logger.py:50 - Epoch: [94][400/500] loss: 0.94241, MAE: 0.44440, time/step=1029ms, lr=1.60e-05
2024-03-19 14:31:40,967 - logger.py:50 - Epoch: [94][450/500] loss: 0.89089, MAE: 0.44535, time/step=1029ms, lr=1.60e-05
2024-03-19 14:32:31,671 - logger.py:50 - Epoch: [94][499/500] loss: 0.84800, MAE: 0.44440, time/step=1030ms, lr=1.60e-05
2024-03-19 14:33:29,165 - logger.py:50 - Epoch: [94] train LOSS: 0.84800, val LOSS: 0.44508, test LOSS: 0.42978, Time: 572.38s
2024-03-19 14:33:29,165 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 14:33:30,274 - logger.py:50 - Epoch: [95][0/500] loss: 0.79262, MAE: 0.41330, time/step=1107ms, lr=1.55e-05
2024-03-19 14:34:20,761 - logger.py:50 - Epoch: [95][50/500] loss: 2.94205, MAE: 0.48085, time/step=1012ms, lr=1.55e-05
2024-03-19 14:35:11,763 - logger.py:50 - Epoch: [95][100/500] loss: 1.69895, MAE: 0.45236, time/step=1016ms, lr=1.55e-05
2024-03-19 14:36:03,492 - logger.py:50 - Epoch: [95][150/500] loss: 1.28872, MAE: 0.45105, time/step=1022ms, lr=1.55e-05
2024-03-19 14:36:54,156 - logger.py:50 - Epoch: [95][200/500] loss: 1.09640, MAE: 0.44871, time/step=1020ms, lr=1.55e-05
2024-03-19 14:37:46,535 - logger.py:50 - Epoch: [95][250/500] loss: 0.96782, MAE: 0.44504, time/step=1025ms, lr=1.55e-05
2024-03-19 14:38:37,756 - logger.py:50 - Epoch: [95][300/500] loss: 0.89121, MAE: 0.44430, time/step=1025ms, lr=1.55e-05
2024-03-19 14:39:28,811 - logger.py:50 - Epoch: [95][350/500] loss: 0.83821, MAE: 0.44201, time/step=1025ms, lr=1.55e-05
2024-03-19 14:40:20,529 - logger.py:50 - Epoch: [95][400/500] loss: 0.93403, MAE: 0.44596, time/step=1026ms, lr=1.55e-05
2024-03-19 14:41:10,539 - logger.py:50 - Epoch: [95][450/500] loss: 0.89018, MAE: 0.44593, time/step=1023ms, lr=1.55e-05
2024-03-19 14:42:01,814 - logger.py:50 - Epoch: [95][499/500] loss: 0.84757, MAE: 0.44449, time/step=1025ms, lr=1.55e-05
2024-03-19 14:42:58,730 - logger.py:50 - Epoch: [95] train LOSS: 0.84757, val LOSS: 0.44708, test LOSS: 0.43209, Time: 569.57s
2024-03-19 14:42:58,731 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 14:42:59,935 - logger.py:50 - Epoch: [96][0/500] loss: 0.35662, MAE: 0.54619, time/step=1202ms, lr=1.51e-05
2024-03-19 14:43:51,540 - logger.py:50 - Epoch: [96][50/500] loss: 2.83059, MAE: 0.47683, time/step=1035ms, lr=1.51e-05
2024-03-19 14:44:42,403 - logger.py:50 - Epoch: [96][100/500] loss: 1.70423, MAE: 0.46139, time/step=1026ms, lr=1.51e-05
2024-03-19 14:45:33,531 - logger.py:50 - Epoch: [96][150/500] loss: 1.30865, MAE: 0.45434, time/step=1025ms, lr=1.51e-05
2024-03-19 14:46:23,718 - logger.py:50 - Epoch: [96][200/500] loss: 1.10588, MAE: 0.44538, time/step=1020ms, lr=1.51e-05
2024-03-19 14:47:15,853 - logger.py:50 - Epoch: [96][250/500] loss: 1.00257, MAE: 0.44329, time/step=1024ms, lr=1.51e-05
2024-03-19 14:48:05,990 - logger.py:50 - Epoch: [96][300/500] loss: 0.91730, MAE: 0.44358, time/step=1021ms, lr=1.51e-05
2024-03-19 14:48:57,719 - logger.py:50 - Epoch: [96][350/500] loss: 0.84743, MAE: 0.44103, time/step=1023ms, lr=1.51e-05
2024-03-19 14:49:49,942 - logger.py:50 - Epoch: [96][400/500] loss: 0.80280, MAE: 0.44244, time/step=1025ms, lr=1.51e-05
2024-03-19 14:50:41,702 - logger.py:50 - Epoch: [96][450/500] loss: 0.89575, MAE: 0.44589, time/step=1027ms, lr=1.51e-05
2024-03-19 14:51:33,102 - logger.py:50 - Epoch: [96][499/500] loss: 0.84803, MAE: 0.44441, time/step=1029ms, lr=1.51e-05
2024-03-19 14:52:30,104 - logger.py:50 - Epoch: [96] train LOSS: 0.84803, val LOSS: 0.44696, test LOSS: 0.43184, Time: 571.37s
2024-03-19 14:52:30,104 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 14:52:31,121 - logger.py:50 - Epoch: [97][0/500] loss: 0.57337, MAE: 0.39655, time/step=1015ms, lr=1.46e-05
2024-03-19 14:53:21,570 - logger.py:50 - Epoch: [97][50/500] loss: 2.79802, MAE: 0.46186, time/step=1009ms, lr=1.46e-05
2024-03-19 14:54:13,533 - logger.py:50 - Epoch: [97][100/500] loss: 1.64701, MAE: 0.45720, time/step=1024ms, lr=1.46e-05
2024-03-19 14:55:03,835 - logger.py:50 - Epoch: [97][150/500] loss: 1.62385, MAE: 0.45743, time/step=1018ms, lr=1.46e-05
2024-03-19 14:55:55,157 - logger.py:50 - Epoch: [97][200/500] loss: 1.34642, MAE: 0.45658, time/step=1020ms, lr=1.46e-05
2024-03-19 14:56:46,734 - logger.py:50 - Epoch: [97][250/500] loss: 1.16757, MAE: 0.45321, time/step=1022ms, lr=1.46e-05
2024-03-19 14:57:38,427 - logger.py:50 - Epoch: [97][300/500] loss: 1.05195, MAE: 0.44864, time/step=1024ms, lr=1.46e-05
2024-03-19 14:58:29,253 - logger.py:50 - Epoch: [97][350/500] loss: 0.96583, MAE: 0.44878, time/step=1023ms, lr=1.46e-05
2024-03-19 14:59:20,031 - logger.py:50 - Epoch: [97][400/500] loss: 0.90811, MAE: 0.44674, time/step=1022ms, lr=1.46e-05
2024-03-19 15:00:11,459 - logger.py:50 - Epoch: [97][450/500] loss: 0.86645, MAE: 0.44584, time/step=1023ms, lr=1.46e-05
2024-03-19 15:01:01,786 - logger.py:50 - Epoch: [97][499/500] loss: 0.84358, MAE: 0.44448, time/step=1023ms, lr=1.46e-05
2024-03-19 15:01:58,415 - logger.py:50 - Epoch: [97] train LOSS: 0.84358, val LOSS: 0.44394, test LOSS: 0.42880, Time: 568.31s
2024-03-19 15:01:58,415 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 15:01:59,249 - logger.py:50 - Epoch: [98][0/500] loss: 0.20822, MAE: 0.51527, time/step=832ms, lr=1.41e-05
2024-03-19 15:02:50,903 - logger.py:50 - Epoch: [98][50/500] loss: 0.46968, MAE: 0.43914, time/step=1029ms, lr=1.41e-05
2024-03-19 15:03:41,271 - logger.py:50 - Epoch: [98][100/500] loss: 0.49605, MAE: 0.43705, time/step=1018ms, lr=1.41e-05
2024-03-19 15:04:32,705 - logger.py:50 - Epoch: [98][150/500] loss: 0.87049, MAE: 0.44737, time/step=1022ms, lr=1.41e-05
2024-03-19 15:05:23,518 - logger.py:50 - Epoch: [98][200/500] loss: 1.36003, MAE: 0.45370, time/step=1020ms, lr=1.41e-05
2024-03-19 15:06:14,591 - logger.py:50 - Epoch: [98][250/500] loss: 1.18509, MAE: 0.44916, time/step=1021ms, lr=1.41e-05
2024-03-19 15:07:06,280 - logger.py:50 - Epoch: [98][300/500] loss: 1.07060, MAE: 0.44817, time/step=1023ms, lr=1.41e-05
2024-03-19 15:07:57,647 - logger.py:50 - Epoch: [98][350/500] loss: 1.01057, MAE: 0.44881, time/step=1023ms, lr=1.41e-05
2024-03-19 15:08:48,376 - logger.py:50 - Epoch: [98][400/500] loss: 0.94485, MAE: 0.44617, time/step=1022ms, lr=1.41e-05
2024-03-19 15:09:39,124 - logger.py:50 - Epoch: [98][450/500] loss: 0.89405, MAE: 0.44551, time/step=1022ms, lr=1.41e-05
2024-03-19 15:10:29,554 - logger.py:50 - Epoch: [98][499/500] loss: 0.85230, MAE: 0.44445, time/step=1022ms, lr=1.41e-05
2024-03-19 15:11:26,084 - logger.py:50 - Epoch: [98] train LOSS: 0.85230, val LOSS: 0.44308, test LOSS: 0.42775, Time: 567.67s
2024-03-19 15:11:26,085 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 15:11:27,207 - logger.py:50 - Epoch: [99][0/500] loss: 0.35785, MAE: 0.44370, time/step=1120ms, lr=1.37e-05
2024-03-19 15:12:19,060 - logger.py:50 - Epoch: [99][50/500] loss: 0.46628, MAE: 0.42479, time/step=1039ms, lr=1.37e-05
2024-03-19 15:13:10,173 - logger.py:50 - Epoch: [99][100/500] loss: 0.45814, MAE: 0.42734, time/step=1031ms, lr=1.37e-05
2024-03-19 15:14:01,606 - logger.py:50 - Epoch: [99][150/500] loss: 0.45324, MAE: 0.42705, time/step=1030ms, lr=1.37e-05
2024-03-19 15:14:52,116 - logger.py:50 - Epoch: [99][200/500] loss: 0.47127, MAE: 0.43157, time/step=1025ms, lr=1.37e-05
2024-03-19 15:15:43,567 - logger.py:50 - Epoch: [99][250/500] loss: 0.47014, MAE: 0.43403, time/step=1026ms, lr=1.37e-05
2024-03-19 15:16:34,619 - logger.py:50 - Epoch: [99][300/500] loss: 0.68991, MAE: 0.43982, time/step=1025ms, lr=1.37e-05
2024-03-19 15:17:26,027 - logger.py:50 - Epoch: [99][350/500] loss: 1.00910, MAE: 0.44738, time/step=1025ms, lr=1.37e-05
2024-03-19 15:18:16,719 - logger.py:50 - Epoch: [99][400/500] loss: 0.94190, MAE: 0.44603, time/step=1024ms, lr=1.37e-05
2024-03-19 15:19:07,113 - logger.py:50 - Epoch: [99][450/500] loss: 0.89343, MAE: 0.44471, time/step=1022ms, lr=1.37e-05
2024-03-19 15:19:57,776 - logger.py:50 - Epoch: [99][499/500] loss: 0.86330, MAE: 0.44447, time/step=1023ms, lr=1.37e-05
2024-03-19 15:20:54,757 - logger.py:50 - Epoch: [99] train LOSS: 0.86330, val LOSS: 0.44711, test LOSS: 0.43207, Time: 568.67s
2024-03-19 15:20:54,757 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 15:20:55,902 - logger.py:50 - Epoch: [100][0/500] loss: 0.56778, MAE: 0.50633, time/step=1142ms, lr=1.32e-05
2024-03-19 15:21:45,672 - logger.py:50 - Epoch: [100][50/500] loss: 0.56851, MAE: 0.45462, time/step=998ms, lr=1.32e-05
2024-03-19 15:22:37,062 - logger.py:50 - Epoch: [100][100/500] loss: 0.53226, MAE: 0.44449, time/step=1013ms, lr=1.32e-05
2024-03-19 15:23:27,546 - logger.py:50 - Epoch: [100][150/500] loss: 0.54777, MAE: 0.44051, time/step=1012ms, lr=1.32e-05
2024-03-19 15:24:18,192 - logger.py:50 - Epoch: [100][200/500] loss: 0.53332, MAE: 0.43737, time/step=1012ms, lr=1.32e-05
2024-03-19 15:25:10,121 - logger.py:50 - Epoch: [100][250/500] loss: 0.52179, MAE: 0.43663, time/step=1017ms, lr=1.32e-05
2024-03-19 15:26:01,734 - logger.py:50 - Epoch: [100][300/500] loss: 0.90313, MAE: 0.44203, time/step=1020ms, lr=1.32e-05
2024-03-19 15:26:53,136 - logger.py:50 - Epoch: [100][350/500] loss: 1.00477, MAE: 0.44538, time/step=1021ms, lr=1.32e-05
2024-03-19 15:27:44,507 - logger.py:50 - Epoch: [100][400/500] loss: 0.94038, MAE: 0.44603, time/step=1022ms, lr=1.32e-05
2024-03-19 15:28:35,142 - logger.py:50 - Epoch: [100][450/500] loss: 0.89012, MAE: 0.44525, time/step=1021ms, lr=1.32e-05
2024-03-19 15:29:26,297 - logger.py:50 - Epoch: [100][499/500] loss: 0.84597, MAE: 0.44436, time/step=1023ms, lr=1.32e-05
2024-03-19 15:30:23,310 - logger.py:50 - Epoch: [100] train LOSS: 0.84597, val LOSS: 0.44450, test LOSS: 0.42923, Time: 568.55s
2024-03-19 15:30:23,311 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 15:30:23,943 - logger.py:50 - Epoch: [101][0/500] loss: 0.36940, MAE: 0.37173, time/step=630ms, lr=1.28e-05
2024-03-19 15:31:15,308 - logger.py:50 - Epoch: [101][50/500] loss: 0.50118, MAE: 0.43773, time/step=1020ms, lr=1.28e-05
2024-03-19 15:32:06,928 - logger.py:50 - Epoch: [101][100/500] loss: 0.46061, MAE: 0.44035, time/step=1026ms, lr=1.28e-05
2024-03-19 15:32:57,567 - logger.py:50 - Epoch: [101][150/500] loss: 0.46432, MAE: 0.44080, time/step=1022ms, lr=1.28e-05
2024-03-19 15:33:47,567 - logger.py:50 - Epoch: [101][200/500] loss: 0.46768, MAE: 0.43842, time/step=1016ms, lr=1.28e-05
2024-03-19 15:34:39,745 - logger.py:50 - Epoch: [101][250/500] loss: 0.47600, MAE: 0.43739, time/step=1022ms, lr=1.28e-05
2024-03-19 15:35:30,808 - logger.py:50 - Epoch: [101][300/500] loss: 1.06802, MAE: 0.45006, time/step=1022ms, lr=1.28e-05
2024-03-19 15:36:21,708 - logger.py:50 - Epoch: [101][350/500] loss: 0.98890, MAE: 0.44772, time/step=1021ms, lr=1.28e-05
2024-03-19 15:37:12,823 - logger.py:50 - Epoch: [101][400/500] loss: 0.92692, MAE: 0.44746, time/step=1021ms, lr=1.28e-05
2024-03-19 15:38:04,438 - logger.py:50 - Epoch: [101][450/500] loss: 0.87917, MAE: 0.44651, time/step=1022ms, lr=1.28e-05
2024-03-19 15:38:54,028 - logger.py:50 - Epoch: [101][499/500] loss: 0.84492, MAE: 0.44445, time/step=1021ms, lr=1.28e-05
2024-03-19 15:39:51,036 - logger.py:50 - Epoch: [101] train LOSS: 0.84492, val LOSS: 0.44257, test LOSS: 0.42754, Time: 567.73s
2024-03-19 15:39:51,037 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 15:39:52,168 - logger.py:50 - Epoch: [102][0/500] loss: 0.47312, MAE: 0.45765, time/step=1130ms, lr=1.24e-05
2024-03-19 15:40:43,290 - logger.py:50 - Epoch: [102][50/500] loss: 2.78189, MAE: 0.46877, time/step=1025ms, lr=1.24e-05
2024-03-19 15:41:34,245 - logger.py:50 - Epoch: [102][100/500] loss: 1.64307, MAE: 0.45235, time/step=1022ms, lr=1.24e-05
2024-03-19 15:42:25,628 - logger.py:50 - Epoch: [102][150/500] loss: 1.24291, MAE: 0.45071, time/step=1024ms, lr=1.24e-05
2024-03-19 15:43:16,582 - logger.py:50 - Epoch: [102][200/500] loss: 1.05675, MAE: 0.44947, time/step=1023ms, lr=1.24e-05
2024-03-19 15:44:08,306 - logger.py:50 - Epoch: [102][250/500] loss: 0.94410, MAE: 0.44688, time/step=1025ms, lr=1.24e-05
2024-03-19 15:44:59,671 - logger.py:50 - Epoch: [102][300/500] loss: 1.05240, MAE: 0.44813, time/step=1025ms, lr=1.24e-05
2024-03-19 15:45:50,402 - logger.py:50 - Epoch: [102][350/500] loss: 0.98652, MAE: 0.44928, time/step=1024ms, lr=1.24e-05
2024-03-19 15:46:42,407 - logger.py:50 - Epoch: [102][400/500] loss: 0.91766, MAE: 0.44765, time/step=1026ms, lr=1.24e-05
2024-03-19 15:47:32,824 - logger.py:50 - Epoch: [102][450/500] loss: 0.88457, MAE: 0.44668, time/step=1024ms, lr=1.24e-05
2024-03-19 15:48:22,658 - logger.py:50 - Epoch: [102][499/500] loss: 0.84307, MAE: 0.44444, time/step=1023ms, lr=1.24e-05
2024-03-19 15:49:20,109 - logger.py:50 - Epoch: [102] train LOSS: 0.84307, val LOSS: 0.44376, test LOSS: 0.42874, Time: 569.07s
2024-03-19 15:49:20,109 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 15:49:20,770 - logger.py:50 - Epoch: [103][0/500] loss: 0.34782, MAE: 0.31509, time/step=659ms, lr=1.19e-05
2024-03-19 15:50:12,738 - logger.py:50 - Epoch: [103][50/500] loss: 1.59695, MAE: 0.44851, time/step=1032ms, lr=1.19e-05
2024-03-19 15:51:03,760 - logger.py:50 - Epoch: [103][100/500] loss: 1.05756, MAE: 0.44604, time/step=1026ms, lr=1.19e-05
2024-03-19 15:51:55,225 - logger.py:50 - Epoch: [103][150/500] loss: 0.90127, MAE: 0.44357, time/step=1027ms, lr=1.19e-05
2024-03-19 15:52:47,019 - logger.py:50 - Epoch: [103][200/500] loss: 0.79417, MAE: 0.44754, time/step=1029ms, lr=1.19e-05
2024-03-19 15:53:37,995 - logger.py:50 - Epoch: [103][250/500] loss: 0.73511, MAE: 0.44451, time/step=1027ms, lr=1.19e-05
2024-03-19 15:54:29,443 - logger.py:50 - Epoch: [103][300/500] loss: 0.68840, MAE: 0.44246, time/step=1028ms, lr=1.19e-05
2024-03-19 15:55:20,096 - logger.py:50 - Epoch: [103][350/500] loss: 0.65913, MAE: 0.44165, time/step=1026ms, lr=1.19e-05
2024-03-19 15:56:10,697 - logger.py:50 - Epoch: [103][400/500] loss: 0.63518, MAE: 0.43969, time/step=1024ms, lr=1.19e-05
2024-03-19 15:57:01,931 - logger.py:50 - Epoch: [103][450/500] loss: 0.88530, MAE: 0.44530, time/step=1024ms, lr=1.19e-05
2024-03-19 15:57:52,053 - logger.py:50 - Epoch: [103][499/500] loss: 0.84549, MAE: 0.44444, time/step=1024ms, lr=1.19e-05
2024-03-19 15:58:48,208 - logger.py:50 - Epoch: [103] train LOSS: 0.84549, val LOSS: 0.44301, test LOSS: 0.42767, Time: 568.10s
2024-03-19 15:58:48,208 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 15:58:49,332 - logger.py:50 - Epoch: [104][0/500] loss: 0.33854, MAE: 0.51558, time/step=1122ms, lr=1.15e-05
2024-03-19 15:59:40,029 - logger.py:50 - Epoch: [104][50/500] loss: 0.51965, MAE: 0.44417, time/step=1016ms, lr=1.15e-05
2024-03-19 16:00:31,238 - logger.py:50 - Epoch: [104][100/500] loss: 1.64950, MAE: 0.45393, time/step=1020ms, lr=1.15e-05
2024-03-19 16:01:23,149 - logger.py:50 - Epoch: [104][150/500] loss: 1.26984, MAE: 0.44628, time/step=1026ms, lr=1.15e-05
2024-03-19 16:02:14,159 - logger.py:50 - Epoch: [104][200/500] loss: 1.08652, MAE: 0.44657, time/step=1025ms, lr=1.15e-05
2024-03-19 16:03:05,103 - logger.py:50 - Epoch: [104][250/500] loss: 0.96860, MAE: 0.44383, time/step=1023ms, lr=1.15e-05
2024-03-19 16:03:56,204 - logger.py:50 - Epoch: [104][300/500] loss: 0.89261, MAE: 0.44313, time/step=1023ms, lr=1.15e-05
2024-03-19 16:04:48,146 - logger.py:50 - Epoch: [104][350/500] loss: 0.99368, MAE: 0.44760, time/step=1025ms, lr=1.15e-05
2024-03-19 16:05:39,900 - logger.py:50 - Epoch: [104][400/500] loss: 0.92589, MAE: 0.44588, time/step=1027ms, lr=1.15e-05
2024-03-19 16:06:31,846 - logger.py:50 - Epoch: [104][450/500] loss: 0.87308, MAE: 0.44384, time/step=1028ms, lr=1.15e-05
2024-03-19 16:07:23,046 - logger.py:50 - Epoch: [104][499/500] loss: 0.84296, MAE: 0.44448, time/step=1030ms, lr=1.15e-05
2024-03-19 16:08:20,641 - logger.py:50 - Epoch: [104] train LOSS: 0.84296, val LOSS: 0.44256, test LOSS: 0.42721, Time: 572.43s
2024-03-19 16:08:20,643 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 16:08:21,765 - logger.py:50 - Epoch: [105][0/500] loss: 0.33782, MAE: 0.34441, time/step=1119ms, lr=1.11e-05
2024-03-19 16:09:12,416 - logger.py:50 - Epoch: [105][50/500] loss: 0.48746, MAE: 0.43756, time/step=1015ms, lr=1.11e-05
2024-03-19 16:10:04,655 - logger.py:50 - Epoch: [105][100/500] loss: 0.45559, MAE: 0.43415, time/step=1030ms, lr=1.11e-05
2024-03-19 16:10:55,626 - logger.py:50 - Epoch: [105][150/500] loss: 1.26320, MAE: 0.44972, time/step=1026ms, lr=1.11e-05
2024-03-19 16:11:46,576 - logger.py:50 - Epoch: [105][200/500] loss: 1.07352, MAE: 0.44382, time/step=1025ms, lr=1.11e-05
2024-03-19 16:12:38,689 - logger.py:50 - Epoch: [105][250/500] loss: 0.96302, MAE: 0.44390, time/step=1028ms, lr=1.11e-05
2024-03-19 16:13:29,662 - logger.py:50 - Epoch: [105][300/500] loss: 0.88027, MAE: 0.44065, time/step=1027ms, lr=1.11e-05
2024-03-19 16:14:21,668 - logger.py:50 - Epoch: [105][350/500] loss: 0.98234, MAE: 0.44548, time/step=1029ms, lr=1.11e-05
2024-03-19 16:15:12,813 - logger.py:50 - Epoch: [105][400/500] loss: 0.91748, MAE: 0.44333, time/step=1028ms, lr=1.11e-05
2024-03-19 16:16:04,613 - logger.py:50 - Epoch: [105][450/500] loss: 0.87264, MAE: 0.44266, time/step=1029ms, lr=1.11e-05
2024-03-19 16:16:55,704 - logger.py:50 - Epoch: [105][499/500] loss: 0.84343, MAE: 0.44448, time/step=1030ms, lr=1.11e-05
2024-03-19 16:17:53,205 - logger.py:50 - Epoch: [105] train LOSS: 0.84343, val LOSS: 0.44324, test LOSS: 0.42796, Time: 572.56s
2024-03-19 16:17:53,205 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 16:17:53,860 - logger.py:50 - Epoch: [106][0/500] loss: 0.47584, MAE: 0.42540, time/step=654ms, lr=1.07e-05
2024-03-19 16:18:45,510 - logger.py:50 - Epoch: [106][50/500] loss: 0.44975, MAE: 0.42244, time/step=1026ms, lr=1.07e-05
2024-03-19 16:19:36,735 - logger.py:50 - Epoch: [106][100/500] loss: 0.51562, MAE: 0.44135, time/step=1025ms, lr=1.07e-05
2024-03-19 16:20:28,358 - logger.py:50 - Epoch: [106][150/500] loss: 0.90425, MAE: 0.44583, time/step=1027ms, lr=1.07e-05
2024-03-19 16:21:20,204 - logger.py:50 - Epoch: [106][200/500] loss: 0.80180, MAE: 0.44583, time/step=1030ms, lr=1.07e-05
2024-03-19 16:22:11,572 - logger.py:50 - Epoch: [106][250/500] loss: 0.74606, MAE: 0.44326, time/step=1029ms, lr=1.07e-05
2024-03-19 16:23:02,577 - logger.py:50 - Epoch: [106][300/500] loss: 0.70355, MAE: 0.44318, time/step=1028ms, lr=1.07e-05
2024-03-19 16:23:54,528 - logger.py:50 - Epoch: [106][350/500] loss: 0.68990, MAE: 0.44345, time/step=1029ms, lr=1.07e-05
2024-03-19 16:24:46,131 - logger.py:50 - Epoch: [106][400/500] loss: 0.95048, MAE: 0.44694, time/step=1030ms, lr=1.07e-05
2024-03-19 16:25:37,546 - logger.py:50 - Epoch: [106][450/500] loss: 0.89787, MAE: 0.44713, time/step=1030ms, lr=1.07e-05
2024-03-19 16:26:28,091 - logger.py:50 - Epoch: [106][499/500] loss: 0.85329, MAE: 0.44444, time/step=1030ms, lr=1.07e-05
2024-03-19 16:27:24,681 - logger.py:50 - Epoch: [106] train LOSS: 0.85329, val LOSS: 0.44451, test LOSS: 0.42940, Time: 571.48s
2024-03-19 16:27:24,681 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 16:27:25,765 - logger.py:50 - Epoch: [107][0/500] loss: 0.16079, MAE: 0.34582, time/step=1082ms, lr=1.03e-05
2024-03-19 16:28:17,494 - logger.py:50 - Epoch: [107][50/500] loss: 0.43579, MAE: 0.43513, time/step=1036ms, lr=1.03e-05
2024-03-19 16:29:09,352 - logger.py:50 - Epoch: [107][100/500] loss: 0.46844, MAE: 0.43792, time/step=1036ms, lr=1.03e-05
2024-03-19 16:30:00,311 - logger.py:50 - Epoch: [107][150/500] loss: 0.46431, MAE: 0.43485, time/step=1031ms, lr=1.03e-05
2024-03-19 16:30:51,453 - logger.py:50 - Epoch: [107][200/500] loss: 0.49204, MAE: 0.43626, time/step=1029ms, lr=1.03e-05
2024-03-19 16:31:43,391 - logger.py:50 - Epoch: [107][250/500] loss: 0.48940, MAE: 0.43931, time/step=1031ms, lr=1.03e-05
2024-03-19 16:32:34,603 - logger.py:50 - Epoch: [107][300/500] loss: 0.50719, MAE: 0.43862, time/step=1030ms, lr=1.03e-05
2024-03-19 16:33:26,175 - logger.py:50 - Epoch: [107][350/500] loss: 0.50247, MAE: 0.43837, time/step=1030ms, lr=1.03e-05
2024-03-19 16:34:17,896 - logger.py:50 - Epoch: [107][400/500] loss: 0.49602, MAE: 0.43622, time/step=1030ms, lr=1.03e-05
2024-03-19 16:35:10,062 - logger.py:50 - Epoch: [107][450/500] loss: 0.49498, MAE: 0.43701, time/step=1032ms, lr=1.03e-05
2024-03-19 16:35:59,886 - logger.py:50 - Epoch: [107][499/500] loss: 0.84459, MAE: 0.44459, time/step=1030ms, lr=1.03e-05
2024-03-19 16:36:57,322 - logger.py:50 - Epoch: [107] train LOSS: 0.84459, val LOSS: 0.44538, test LOSS: 0.43035, Time: 572.64s
2024-03-19 16:36:57,322 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 16:36:58,482 - logger.py:50 - Epoch: [108][0/500] loss: 0.50697, MAE: 0.56390, time/step=1158ms, lr=9.88e-06
2024-03-19 16:37:50,094 - logger.py:50 - Epoch: [108][50/500] loss: 0.59072, MAE: 0.44638, time/step=1035ms, lr=9.88e-06
2024-03-19 16:38:41,580 - logger.py:50 - Epoch: [108][100/500] loss: 0.51948, MAE: 0.44003, time/step=1032ms, lr=9.88e-06
2024-03-19 16:39:33,278 - logger.py:50 - Epoch: [108][150/500] loss: 0.51925, MAE: 0.44033, time/step=1033ms, lr=9.88e-06
2024-03-19 16:40:25,011 - logger.py:50 - Epoch: [108][200/500] loss: 0.51022, MAE: 0.43903, time/step=1033ms, lr=9.88e-06
2024-03-19 16:41:16,786 - logger.py:50 - Epoch: [108][250/500] loss: 0.98156, MAE: 0.44710, time/step=1034ms, lr=9.88e-06
2024-03-19 16:42:08,090 - logger.py:50 - Epoch: [108][300/500] loss: 0.90253, MAE: 0.44660, time/step=1032ms, lr=9.88e-06
2024-03-19 16:42:59,949 - logger.py:50 - Epoch: [108][350/500] loss: 0.84227, MAE: 0.44574, time/step=1033ms, lr=9.88e-06
2024-03-19 16:43:50,804 - logger.py:50 - Epoch: [108][400/500] loss: 0.79894, MAE: 0.44353, time/step=1031ms, lr=9.88e-06
2024-03-19 16:44:41,688 - logger.py:50 - Epoch: [108][450/500] loss: 0.88150, MAE: 0.44512, time/step=1030ms, lr=9.88e-06
2024-03-19 16:45:32,609 - logger.py:50 - Epoch: [108][499/500] loss: 0.84434, MAE: 0.44436, time/step=1031ms, lr=9.88e-06
2024-03-19 16:46:30,096 - logger.py:50 - Epoch: [108] train LOSS: 0.84434, val LOSS: 0.44599, test LOSS: 0.43068, Time: 572.77s
2024-03-19 16:46:30,096 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 16:46:30,917 - logger.py:50 - Epoch: [109][0/500] loss: 0.33457, MAE: 0.44214, time/step=820ms, lr=9.49e-06
2024-03-19 16:47:22,403 - logger.py:50 - Epoch: [109][50/500] loss: 0.48685, MAE: 0.44073, time/step=1026ms, lr=9.49e-06
2024-03-19 16:48:13,938 - logger.py:50 - Epoch: [109][100/500] loss: 0.48246, MAE: 0.44089, time/step=1028ms, lr=9.49e-06
2024-03-19 16:49:05,465 - logger.py:50 - Epoch: [109][150/500] loss: 0.84792, MAE: 0.45126, time/step=1029ms, lr=9.49e-06
2024-03-19 16:49:57,265 - logger.py:50 - Epoch: [109][200/500] loss: 0.76277, MAE: 0.44686, time/step=1031ms, lr=9.49e-06
2024-03-19 16:50:48,432 - logger.py:50 - Epoch: [109][250/500] loss: 1.18474, MAE: 0.45403, time/step=1029ms, lr=9.49e-06
2024-03-19 16:51:39,368 - logger.py:50 - Epoch: [109][300/500] loss: 1.06602, MAE: 0.44733, time/step=1027ms, lr=9.49e-06
2024-03-19 16:52:31,136 - logger.py:50 - Epoch: [109][350/500] loss: 0.98787, MAE: 0.44632, time/step=1029ms, lr=9.49e-06
2024-03-19 16:53:22,889 - logger.py:50 - Epoch: [109][400/500] loss: 0.92769, MAE: 0.44554, time/step=1029ms, lr=9.49e-06
2024-03-19 16:54:14,006 - logger.py:50 - Epoch: [109][450/500] loss: 0.87298, MAE: 0.44423, time/step=1029ms, lr=9.49e-06
2024-03-19 16:55:04,994 - logger.py:50 - Epoch: [109][499/500] loss: 0.84171, MAE: 0.44448, time/step=1030ms, lr=9.49e-06
2024-03-19 16:56:02,453 - logger.py:50 - Epoch: [109] train LOSS: 0.84171, val LOSS: 0.44095, test LOSS: 0.42570, Time: 572.36s
2024-03-19 16:56:02,453 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 16:56:03,166 - logger.py:50 - Epoch: [110][0/500] loss: 0.37683, MAE: 0.44810, time/step=711ms, lr=9.11e-06
2024-03-19 16:56:55,216 - logger.py:50 - Epoch: [110][50/500] loss: 0.50494, MAE: 0.44496, time/step=1035ms, lr=9.11e-06
2024-03-19 16:57:47,177 - logger.py:50 - Epoch: [110][100/500] loss: 0.49805, MAE: 0.44571, time/step=1037ms, lr=9.11e-06
2024-03-19 16:58:38,086 - logger.py:50 - Epoch: [110][150/500] loss: 0.48327, MAE: 0.43960, time/step=1031ms, lr=9.11e-06
2024-03-19 16:59:29,082 - logger.py:50 - Epoch: [110][200/500] loss: 0.48073, MAE: 0.43890, time/step=1028ms, lr=9.11e-06
2024-03-19 17:00:20,942 - logger.py:50 - Epoch: [110][250/500] loss: 0.94906, MAE: 0.44664, time/step=1030ms, lr=9.11e-06
2024-03-19 17:01:12,621 - logger.py:50 - Epoch: [110][300/500] loss: 0.86894, MAE: 0.44347, time/step=1030ms, lr=9.11e-06
2024-03-19 17:02:03,755 - logger.py:50 - Epoch: [110][350/500] loss: 0.81763, MAE: 0.44244, time/step=1029ms, lr=9.11e-06
2024-03-19 17:02:55,505 - logger.py:50 - Epoch: [110][400/500] loss: 0.91040, MAE: 0.44473, time/step=1030ms, lr=9.11e-06
2024-03-19 17:03:47,190 - logger.py:50 - Epoch: [110][450/500] loss: 0.88285, MAE: 0.44492, time/step=1030ms, lr=9.11e-06
2024-03-19 17:04:37,503 - logger.py:50 - Epoch: [110][499/500] loss: 0.83984, MAE: 0.44448, time/step=1030ms, lr=9.11e-06
2024-03-19 17:05:35,002 - logger.py:50 - Epoch: [110] train LOSS: 0.83984, val LOSS: 0.44657, test LOSS: 0.43139, Time: 572.55s
2024-03-19 17:05:35,002 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 17:05:35,647 - logger.py:50 - Epoch: [111][0/500] loss: 1.66342, MAE: 0.56001, time/step=643ms, lr=8.73e-06
2024-03-19 17:06:27,485 - logger.py:50 - Epoch: [111][50/500] loss: 0.43466, MAE: 0.43624, time/step=1029ms, lr=8.73e-06
2024-03-19 17:07:18,272 - logger.py:50 - Epoch: [111][100/500] loss: 0.45793, MAE: 0.43654, time/step=1022ms, lr=8.73e-06
2024-03-19 17:08:09,910 - logger.py:50 - Epoch: [111][150/500] loss: 1.23418, MAE: 0.45066, time/step=1026ms, lr=8.73e-06
2024-03-19 17:09:00,784 - logger.py:50 - Epoch: [111][200/500] loss: 1.04429, MAE: 0.44892, time/step=1024ms, lr=8.73e-06
2024-03-19 17:09:52,614 - logger.py:50 - Epoch: [111][250/500] loss: 1.16484, MAE: 0.45126, time/step=1026ms, lr=8.73e-06
2024-03-19 17:10:44,023 - logger.py:50 - Epoch: [111][300/500] loss: 1.06018, MAE: 0.44916, time/step=1027ms, lr=8.73e-06
2024-03-19 17:11:36,164 - logger.py:50 - Epoch: [111][350/500] loss: 0.98202, MAE: 0.44872, time/step=1029ms, lr=8.73e-06
2024-03-19 17:12:28,070 - logger.py:50 - Epoch: [111][400/500] loss: 0.92481, MAE: 0.44859, time/step=1030ms, lr=8.73e-06
2024-03-19 17:13:19,693 - logger.py:50 - Epoch: [111][450/500] loss: 0.88274, MAE: 0.44630, time/step=1030ms, lr=8.73e-06
2024-03-19 17:14:09,574 - logger.py:50 - Epoch: [111][499/500] loss: 0.84095, MAE: 0.44449, time/step=1029ms, lr=8.73e-06
2024-03-19 17:15:05,879 - logger.py:50 - Epoch: [111] train LOSS: 0.84095, val LOSS: 0.44409, test LOSS: 0.42888, Time: 570.88s
2024-03-19 17:15:05,879 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 17:15:06,582 - logger.py:50 - Epoch: [112][0/500] loss: 0.30439, MAE: 0.45455, time/step=701ms, lr=8.36e-06
2024-03-19 17:15:58,250 - logger.py:50 - Epoch: [112][50/500] loss: 0.45412, MAE: 0.43871, time/step=1027ms, lr=8.36e-06
2024-03-19 17:16:48,365 - logger.py:50 - Epoch: [112][100/500] loss: 1.64475, MAE: 0.45474, time/step=1015ms, lr=8.36e-06
2024-03-19 17:17:38,610 - logger.py:50 - Epoch: [112][150/500] loss: 1.29819, MAE: 0.44608, time/step=1011ms, lr=8.36e-06
2024-03-19 17:18:28,828 - logger.py:50 - Epoch: [112][200/500] loss: 1.09640, MAE: 0.43935, time/step=1010ms, lr=8.36e-06
2024-03-19 17:19:20,400 - logger.py:50 - Epoch: [112][250/500] loss: 0.97350, MAE: 0.43893, time/step=1014ms, lr=8.36e-06
2024-03-19 17:20:12,672 - logger.py:50 - Epoch: [112][300/500] loss: 0.88661, MAE: 0.44068, time/step=1019ms, lr=8.36e-06
2024-03-19 17:21:03,005 - logger.py:50 - Epoch: [112][350/500] loss: 0.83406, MAE: 0.44006, time/step=1017ms, lr=8.36e-06
2024-03-19 17:21:53,481 - logger.py:50 - Epoch: [112][400/500] loss: 0.78780, MAE: 0.43969, time/step=1016ms, lr=8.36e-06
2024-03-19 17:22:44,501 - logger.py:50 - Epoch: [112][450/500] loss: 0.75068, MAE: 0.44067, time/step=1017ms, lr=8.36e-06
2024-03-19 17:23:34,581 - logger.py:50 - Epoch: [112][499/500] loss: 0.84001, MAE: 0.44452, time/step=1017ms, lr=8.36e-06
2024-03-19 17:24:30,416 - logger.py:50 - Epoch: [112] train LOSS: 0.84001, val LOSS: 0.44674, test LOSS: 0.43130, Time: 564.54s
2024-03-19 17:24:30,417 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 17:24:31,613 - logger.py:50 - Epoch: [113][0/500] loss: 0.16826, MAE: 0.36422, time/step=1195ms, lr=8.00e-06
2024-03-19 17:25:22,662 - logger.py:50 - Epoch: [113][50/500] loss: 0.45343, MAE: 0.43032, time/step=1024ms, lr=8.00e-06
2024-03-19 17:26:14,267 - logger.py:50 - Epoch: [113][100/500] loss: 0.45483, MAE: 0.42930, time/step=1028ms, lr=8.00e-06
2024-03-19 17:27:04,871 - logger.py:50 - Epoch: [113][150/500] loss: 1.23630, MAE: 0.44046, time/step=1023ms, lr=8.00e-06
2024-03-19 17:27:56,285 - logger.py:50 - Epoch: [113][200/500] loss: 1.04664, MAE: 0.44445, time/step=1024ms, lr=8.00e-06
2024-03-19 17:28:47,391 - logger.py:50 - Epoch: [113][250/500] loss: 0.94970, MAE: 0.44228, time/step=1024ms, lr=8.00e-06
2024-03-19 17:29:36,692 - logger.py:50 - Epoch: [113][300/500] loss: 0.87231, MAE: 0.43962, time/step=1018ms, lr=8.00e-06
2024-03-19 17:30:26,773 - logger.py:50 - Epoch: [113][350/500] loss: 0.82568, MAE: 0.43945, time/step=1015ms, lr=8.00e-06
2024-03-19 17:31:18,296 - logger.py:50 - Epoch: [113][400/500] loss: 0.77992, MAE: 0.44026, time/step=1017ms, lr=8.00e-06
2024-03-19 17:32:09,399 - logger.py:50 - Epoch: [113][450/500] loss: 0.87939, MAE: 0.44481, time/step=1018ms, lr=8.00e-06
2024-03-19 17:32:59,512 - logger.py:50 - Epoch: [113][499/500] loss: 0.83853, MAE: 0.44448, time/step=1018ms, lr=8.00e-06
2024-03-19 17:33:56,179 - logger.py:50 - Epoch: [113] train LOSS: 0.83853, val LOSS: 0.44475, test LOSS: 0.42973, Time: 565.76s
2024-03-19 17:33:56,179 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 17:33:57,334 - logger.py:50 - Epoch: [114][0/500] loss: 0.24543, MAE: 0.49433, time/step=1153ms, lr=7.64e-06
2024-03-19 17:34:48,937 - logger.py:50 - Epoch: [114][50/500] loss: 0.45616, MAE: 0.45373, time/step=1034ms, lr=7.64e-06
2024-03-19 17:35:40,277 - logger.py:50 - Epoch: [114][100/500] loss: 0.43406, MAE: 0.44709, time/step=1031ms, lr=7.64e-06
2024-03-19 17:36:30,918 - logger.py:50 - Epoch: [114][150/500] loss: 0.44702, MAE: 0.44322, time/step=1025ms, lr=7.64e-06
2024-03-19 17:37:21,955 - logger.py:50 - Epoch: [114][200/500] loss: 1.04849, MAE: 0.44846, time/step=1024ms, lr=7.64e-06
2024-03-19 17:38:12,165 - logger.py:50 - Epoch: [114][250/500] loss: 0.95752, MAE: 0.44464, time/step=1020ms, lr=7.64e-06
2024-03-19 17:39:02,720 - logger.py:50 - Epoch: [114][300/500] loss: 1.06897, MAE: 0.45029, time/step=1018ms, lr=7.64e-06
2024-03-19 17:39:53,797 - logger.py:50 - Epoch: [114][350/500] loss: 0.99064, MAE: 0.44989, time/step=1019ms, lr=7.64e-06
2024-03-19 17:40:44,511 - logger.py:50 - Epoch: [114][400/500] loss: 0.93143, MAE: 0.44707, time/step=1018ms, lr=7.64e-06
2024-03-19 17:41:34,799 - logger.py:50 - Epoch: [114][450/500] loss: 0.87593, MAE: 0.44447, time/step=1017ms, lr=7.64e-06
2024-03-19 17:42:24,883 - logger.py:50 - Epoch: [114][499/500] loss: 0.83909, MAE: 0.44446, time/step=1017ms, lr=7.64e-06
2024-03-19 17:43:21,568 - logger.py:50 - Epoch: [114] train LOSS: 0.83909, val LOSS: 0.44107, test LOSS: 0.42589, Time: 565.39s
2024-03-19 17:43:21,568 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 17:43:22,201 - logger.py:50 - Epoch: [115][0/500] loss: 0.65044, MAE: 0.37684, time/step=631ms, lr=7.29e-06
2024-03-19 17:44:14,222 - logger.py:50 - Epoch: [115][50/500] loss: 0.55006, MAE: 0.44191, time/step=1032ms, lr=7.29e-06
2024-03-19 17:45:04,896 - logger.py:50 - Epoch: [115][100/500] loss: 0.50464, MAE: 0.44551, time/step=1023ms, lr=7.29e-06
2024-03-19 17:45:56,001 - logger.py:50 - Epoch: [115][150/500] loss: 0.52753, MAE: 0.44888, time/step=1023ms, lr=7.29e-06
2024-03-19 17:46:45,907 - logger.py:50 - Epoch: [115][200/500] loss: 0.50614, MAE: 0.44271, time/step=1017ms, lr=7.29e-06
2024-03-19 17:47:36,773 - logger.py:50 - Epoch: [115][250/500] loss: 0.50579, MAE: 0.44096, time/step=1017ms, lr=7.29e-06
2024-03-19 17:48:27,913 - logger.py:50 - Epoch: [115][300/500] loss: 0.68786, MAE: 0.44604, time/step=1018ms, lr=7.29e-06
2024-03-19 17:49:19,330 - logger.py:50 - Epoch: [115][350/500] loss: 0.99358, MAE: 0.44804, time/step=1019ms, lr=7.29e-06
2024-03-19 17:50:09,750 - logger.py:50 - Epoch: [115][400/500] loss: 0.93569, MAE: 0.44644, time/step=1018ms, lr=7.29e-06
2024-03-19 17:51:01,096 - logger.py:50 - Epoch: [115][450/500] loss: 0.88486, MAE: 0.44559, time/step=1019ms, lr=7.29e-06
2024-03-19 17:51:50,801 - logger.py:50 - Epoch: [115][499/500] loss: 0.84011, MAE: 0.44452, time/step=1018ms, lr=7.29e-06
2024-03-19 17:52:46,983 - logger.py:50 - Epoch: [115] train LOSS: 0.84011, val LOSS: 0.44533, test LOSS: 0.43022, Time: 565.42s
2024-03-19 17:52:46,983 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 17:52:48,159 - logger.py:50 - Epoch: [116][0/500] loss: 0.21938, MAE: 0.43910, time/step=1174ms, lr=6.95e-06
2024-03-19 17:53:39,243 - logger.py:50 - Epoch: [116][50/500] loss: 0.46382, MAE: 0.43561, time/step=1025ms, lr=6.95e-06
2024-03-19 17:54:30,087 - logger.py:50 - Epoch: [116][100/500] loss: 0.45343, MAE: 0.43625, time/step=1021ms, lr=6.95e-06
2024-03-19 17:55:21,313 - logger.py:50 - Epoch: [116][150/500] loss: 1.58877, MAE: 0.45636, time/step=1022ms, lr=6.95e-06
2024-03-19 17:56:12,183 - logger.py:50 - Epoch: [116][200/500] loss: 1.31177, MAE: 0.45212, time/step=1021ms, lr=6.95e-06
2024-03-19 17:57:03,150 - logger.py:50 - Epoch: [116][250/500] loss: 1.17034, MAE: 0.45093, time/step=1021ms, lr=6.95e-06
2024-03-19 17:57:53,962 - logger.py:50 - Epoch: [116][300/500] loss: 1.05217, MAE: 0.44901, time/step=1020ms, lr=6.95e-06
2024-03-19 17:58:44,973 - logger.py:50 - Epoch: [116][350/500] loss: 0.96902, MAE: 0.44584, time/step=1020ms, lr=6.95e-06
2024-03-19 17:59:35,181 - logger.py:50 - Epoch: [116][400/500] loss: 0.91167, MAE: 0.44391, time/step=1018ms, lr=6.95e-06
2024-03-19 18:00:25,902 - logger.py:50 - Epoch: [116][450/500] loss: 0.87660, MAE: 0.44492, time/step=1018ms, lr=6.95e-06
2024-03-19 18:01:15,987 - logger.py:50 - Epoch: [116][499/500] loss: 0.83930, MAE: 0.44451, time/step=1018ms, lr=6.95e-06
2024-03-19 18:02:12,648 - logger.py:50 - Epoch: [116] train LOSS: 0.83930, val LOSS: 0.44325, test LOSS: 0.42800, Time: 565.66s
2024-03-19 18:02:12,648 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 18:02:13,808 - logger.py:50 - Epoch: [117][0/500] loss: 0.31045, MAE: 0.43568, time/step=1158ms, lr=6.62e-06
2024-03-19 18:03:05,216 - logger.py:50 - Epoch: [117][50/500] loss: 0.48110, MAE: 0.44039, time/step=1031ms, lr=6.62e-06
2024-03-19 18:03:56,702 - logger.py:50 - Epoch: [117][100/500] loss: 0.49331, MAE: 0.43833, time/step=1030ms, lr=6.62e-06
2024-03-19 18:04:48,153 - logger.py:50 - Epoch: [117][150/500] loss: 0.83703, MAE: 0.44911, time/step=1030ms, lr=6.62e-06
2024-03-19 18:05:39,134 - logger.py:50 - Epoch: [117][200/500] loss: 0.76974, MAE: 0.44937, time/step=1027ms, lr=6.62e-06
2024-03-19 18:06:29,733 - logger.py:50 - Epoch: [117][250/500] loss: 0.71042, MAE: 0.44442, time/step=1024ms, lr=6.62e-06
2024-03-19 18:07:19,976 - logger.py:50 - Epoch: [117][300/500] loss: 1.06367, MAE: 0.45068, time/step=1021ms, lr=6.62e-06
2024-03-19 18:08:11,501 - logger.py:50 - Epoch: [117][350/500] loss: 0.98327, MAE: 0.44713, time/step=1022ms, lr=6.62e-06
2024-03-19 18:09:02,832 - logger.py:50 - Epoch: [117][400/500] loss: 0.92798, MAE: 0.44586, time/step=1023ms, lr=6.62e-06
2024-03-19 18:09:53,614 - logger.py:50 - Epoch: [117][450/500] loss: 0.88862, MAE: 0.44541, time/step=1022ms, lr=6.62e-06
2024-03-19 18:10:43,768 - logger.py:50 - Epoch: [117][499/500] loss: 0.83934, MAE: 0.44451, time/step=1022ms, lr=6.62e-06
2024-03-19 18:11:41,033 - logger.py:50 - Epoch: [117] train LOSS: 0.83934, val LOSS: 0.44244, test LOSS: 0.42718, Time: 568.38s
2024-03-19 18:11:41,033 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 18:11:42,238 - logger.py:50 - Epoch: [118][0/500] loss: 0.19873, MAE: 0.33446, time/step=1202ms, lr=6.30e-06
2024-03-19 18:12:33,194 - logger.py:50 - Epoch: [118][50/500] loss: 0.51948, MAE: 0.43413, time/step=1023ms, lr=6.30e-06
2024-03-19 18:13:24,557 - logger.py:50 - Epoch: [118][100/500] loss: 1.01427, MAE: 0.44720, time/step=1025ms, lr=6.30e-06
2024-03-19 18:14:16,547 - logger.py:50 - Epoch: [118][150/500] loss: 0.82485, MAE: 0.44294, time/step=1030ms, lr=6.30e-06
2024-03-19 18:15:07,709 - logger.py:50 - Epoch: [118][200/500] loss: 0.73071, MAE: 0.43655, time/step=1028ms, lr=6.30e-06
2024-03-19 18:15:57,831 - logger.py:50 - Epoch: [118][250/500] loss: 0.69277, MAE: 0.43699, time/step=1023ms, lr=6.30e-06
2024-03-19 18:16:48,436 - logger.py:50 - Epoch: [118][300/500] loss: 0.66407, MAE: 0.43969, time/step=1021ms, lr=6.30e-06
2024-03-19 18:17:40,498 - logger.py:50 - Epoch: [118][350/500] loss: 0.63840, MAE: 0.44161, time/step=1024ms, lr=6.30e-06
2024-03-19 18:18:31,417 - logger.py:50 - Epoch: [118][400/500] loss: 0.62630, MAE: 0.43945, time/step=1023ms, lr=6.30e-06
2024-03-19 18:19:22,656 - logger.py:50 - Epoch: [118][450/500] loss: 0.61158, MAE: 0.44080, time/step=1024ms, lr=6.30e-06
2024-03-19 18:20:13,035 - logger.py:50 - Epoch: [118][499/500] loss: 0.83807, MAE: 0.44449, time/step=1024ms, lr=6.30e-06
2024-03-19 18:21:09,610 - logger.py:50 - Epoch: [118] train LOSS: 0.83807, val LOSS: 0.44547, test LOSS: 0.43031, Time: 568.58s
2024-03-19 18:21:09,610 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 18:21:10,792 - logger.py:50 - Epoch: [119][0/500] loss: 0.15937, MAE: 0.38922, time/step=1180ms, lr=5.99e-06
2024-03-19 18:22:01,556 - logger.py:50 - Epoch: [119][50/500] loss: 0.44179, MAE: 0.43953, time/step=1019ms, lr=5.99e-06
2024-03-19 18:22:53,440 - logger.py:50 - Epoch: [119][100/500] loss: 0.50159, MAE: 0.43709, time/step=1028ms, lr=5.99e-06
2024-03-19 18:23:44,921 - logger.py:50 - Epoch: [119][150/500] loss: 0.51967, MAE: 0.43660, time/step=1029ms, lr=5.99e-06
2024-03-19 18:24:35,820 - logger.py:50 - Epoch: [119][200/500] loss: 0.49876, MAE: 0.43589, time/step=1026ms, lr=5.99e-06
2024-03-19 18:25:26,734 - logger.py:50 - Epoch: [119][250/500] loss: 0.49216, MAE: 0.43564, time/step=1024ms, lr=5.99e-06
2024-03-19 18:26:17,396 - logger.py:50 - Epoch: [119][300/500] loss: 0.48949, MAE: 0.43730, time/step=1023ms, lr=5.99e-06
2024-03-19 18:27:09,001 - logger.py:50 - Epoch: [119][350/500] loss: 0.48642, MAE: 0.43764, time/step=1024ms, lr=5.99e-06
2024-03-19 18:27:59,870 - logger.py:50 - Epoch: [119][400/500] loss: 0.91283, MAE: 0.44494, time/step=1023ms, lr=5.99e-06
2024-03-19 18:28:51,237 - logger.py:50 - Epoch: [119][450/500] loss: 0.86784, MAE: 0.44589, time/step=1024ms, lr=5.99e-06
2024-03-19 18:29:41,501 - logger.py:50 - Epoch: [119][499/500] loss: 0.83690, MAE: 0.44447, time/step=1024ms, lr=5.99e-06
2024-03-19 18:30:38,568 - logger.py:50 - Epoch: [119] train LOSS: 0.83690, val LOSS: 0.44146, test LOSS: 0.42599, Time: 568.96s
2024-03-19 18:30:38,569 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 18:30:39,213 - logger.py:50 - Epoch: [120][0/500] loss: 0.47148, MAE: 0.38089, time/step=643ms, lr=5.68e-06
2024-03-19 18:31:31,359 - logger.py:50 - Epoch: [120][50/500] loss: 0.47083, MAE: 0.43210, time/step=1035ms, lr=5.68e-06
2024-03-19 18:32:22,984 - logger.py:50 - Epoch: [120][100/500] loss: 0.47999, MAE: 0.43433, time/step=1034ms, lr=5.68e-06
2024-03-19 18:33:12,579 - logger.py:50 - Epoch: [120][150/500] loss: 0.49153, MAE: 0.42949, time/step=1020ms, lr=5.68e-06
2024-03-19 18:34:03,085 - logger.py:50 - Epoch: [120][200/500] loss: 0.49261, MAE: 0.43122, time/step=1017ms, lr=5.68e-06
2024-03-19 18:34:54,440 - logger.py:50 - Epoch: [120][250/500] loss: 0.47694, MAE: 0.43238, time/step=1019ms, lr=5.68e-06
2024-03-19 18:35:45,511 - logger.py:50 - Epoch: [120][300/500] loss: 0.49036, MAE: 0.43476, time/step=1020ms, lr=5.68e-06
2024-03-19 18:36:38,086 - logger.py:50 - Epoch: [120][350/500] loss: 0.49193, MAE: 0.43682, time/step=1024ms, lr=5.68e-06
2024-03-19 18:37:29,038 - logger.py:50 - Epoch: [120][400/500] loss: 0.92787, MAE: 0.44460, time/step=1024ms, lr=5.68e-06
2024-03-19 18:38:20,643 - logger.py:50 - Epoch: [120][450/500] loss: 0.87688, MAE: 0.44649, time/step=1025ms, lr=5.68e-06
2024-03-19 18:39:10,483 - logger.py:50 - Epoch: [120][499/500] loss: 0.83687, MAE: 0.44450, time/step=1024ms, lr=5.68e-06
2024-03-19 18:40:07,524 - logger.py:50 - Epoch: [120] train LOSS: 0.83687, val LOSS: 0.44685, test LOSS: 0.43138, Time: 568.96s
2024-03-19 18:40:07,524 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 18:40:08,157 - logger.py:50 - Epoch: [121][0/500] loss: 0.78895, MAE: 0.51588, time/step=631ms, lr=5.38e-06
2024-03-19 18:40:59,388 - logger.py:50 - Epoch: [121][50/500] loss: 0.48562, MAE: 0.42224, time/step=1017ms, lr=5.38e-06
2024-03-19 18:41:49,580 - logger.py:50 - Epoch: [121][100/500] loss: 0.47257, MAE: 0.42860, time/step=1010ms, lr=5.38e-06
2024-03-19 18:42:40,696 - logger.py:50 - Epoch: [121][150/500] loss: 0.48884, MAE: 0.43487, time/step=1014ms, lr=5.38e-06
2024-03-19 18:43:32,007 - logger.py:50 - Epoch: [121][200/500] loss: 0.48112, MAE: 0.43425, time/step=1017ms, lr=5.38e-06
2024-03-19 18:44:23,017 - logger.py:50 - Epoch: [121][250/500] loss: 0.69956, MAE: 0.44171, time/step=1018ms, lr=5.38e-06
2024-03-19 18:45:14,510 - logger.py:50 - Epoch: [121][300/500] loss: 1.07257, MAE: 0.44707, time/step=1020ms, lr=5.38e-06
2024-03-19 18:46:06,418 - logger.py:50 - Epoch: [121][350/500] loss: 0.99059, MAE: 0.45031, time/step=1022ms, lr=5.38e-06
2024-03-19 18:46:58,272 - logger.py:50 - Epoch: [121][400/500] loss: 0.92569, MAE: 0.44640, time/step=1024ms, lr=5.38e-06
2024-03-19 18:47:49,012 - logger.py:50 - Epoch: [121][450/500] loss: 0.87292, MAE: 0.44535, time/step=1023ms, lr=5.38e-06
2024-03-19 18:48:38,645 - logger.py:50 - Epoch: [121][499/500] loss: 0.83929, MAE: 0.44450, time/step=1022ms, lr=5.38e-06
2024-03-19 18:49:35,702 - logger.py:50 - Epoch: [121] train LOSS: 0.83929, val LOSS: 0.44272, test LOSS: 0.42755, Time: 568.18s
2024-03-19 18:49:35,703 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 18:49:36,873 - logger.py:50 - Epoch: [122][0/500] loss: 0.59417, MAE: 0.40831, time/step=1168ms, lr=5.09e-06
2024-03-19 18:50:27,186 - logger.py:50 - Epoch: [122][50/500] loss: 2.81095, MAE: 0.47846, time/step=1009ms, lr=5.09e-06
2024-03-19 18:51:18,794 - logger.py:50 - Epoch: [122][100/500] loss: 1.66284, MAE: 0.46374, time/step=1021ms, lr=5.09e-06
2024-03-19 18:52:09,549 - logger.py:50 - Epoch: [122][150/500] loss: 1.28105, MAE: 0.45634, time/step=1019ms, lr=5.09e-06
2024-03-19 18:52:59,946 - logger.py:50 - Epoch: [122][200/500] loss: 1.10879, MAE: 0.45037, time/step=1016ms, lr=5.09e-06
2024-03-19 18:53:51,355 - logger.py:50 - Epoch: [122][250/500] loss: 0.98780, MAE: 0.44779, time/step=1019ms, lr=5.09e-06
2024-03-19 18:54:42,784 - logger.py:50 - Epoch: [122][300/500] loss: 0.89668, MAE: 0.44368, time/step=1020ms, lr=5.09e-06
2024-03-19 18:55:33,686 - logger.py:50 - Epoch: [122][350/500] loss: 0.83798, MAE: 0.44121, time/step=1020ms, lr=5.09e-06
2024-03-19 18:56:25,458 - logger.py:50 - Epoch: [122][400/500] loss: 0.79279, MAE: 0.44056, time/step=1022ms, lr=5.09e-06
2024-03-19 18:57:17,078 - logger.py:50 - Epoch: [122][450/500] loss: 0.76172, MAE: 0.44187, time/step=1023ms, lr=5.09e-06
2024-03-19 18:58:08,327 - logger.py:50 - Epoch: [122][499/500] loss: 0.83886, MAE: 0.44446, time/step=1025ms, lr=5.09e-06
2024-03-19 18:59:05,315 - logger.py:50 - Epoch: [122] train LOSS: 0.83886, val LOSS: 0.44275, test LOSS: 0.42700, Time: 569.61s
2024-03-19 18:59:05,316 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 18:59:05,961 - logger.py:50 - Epoch: [123][0/500] loss: 0.40750, MAE: 0.31669, time/step=644ms, lr=4.81e-06
2024-03-19 18:59:56,983 - logger.py:50 - Epoch: [123][50/500] loss: 0.48864, MAE: 0.43085, time/step=1013ms, lr=4.81e-06
2024-03-19 19:00:48,047 - logger.py:50 - Epoch: [123][100/500] loss: 0.49392, MAE: 0.44119, time/step=1017ms, lr=4.81e-06
2024-03-19 19:01:39,329 - logger.py:50 - Epoch: [123][150/500] loss: 0.52498, MAE: 0.43679, time/step=1020ms, lr=4.81e-06
2024-03-19 19:02:29,702 - logger.py:50 - Epoch: [123][200/500] loss: 1.11447, MAE: 0.44570, time/step=1017ms, lr=4.81e-06
2024-03-19 19:03:20,845 - logger.py:50 - Epoch: [123][250/500] loss: 0.98136, MAE: 0.44345, time/step=1018ms, lr=4.81e-06
2024-03-19 19:04:12,406 - logger.py:50 - Epoch: [123][300/500] loss: 0.89621, MAE: 0.44293, time/step=1020ms, lr=4.81e-06
2024-03-19 19:05:03,415 - logger.py:50 - Epoch: [123][350/500] loss: 0.83641, MAE: 0.44062, time/step=1020ms, lr=4.81e-06
2024-03-19 19:05:54,837 - logger.py:50 - Epoch: [123][400/500] loss: 0.92793, MAE: 0.44587, time/step=1021ms, lr=4.81e-06
2024-03-19 19:06:46,584 - logger.py:50 - Epoch: [123][450/500] loss: 0.87165, MAE: 0.44532, time/step=1023ms, lr=4.81e-06
2024-03-19 19:07:36,395 - logger.py:50 - Epoch: [123][499/500] loss: 0.83642, MAE: 0.44461, time/step=1022ms, lr=4.81e-06
2024-03-19 19:08:33,430 - logger.py:50 - Epoch: [123] train LOSS: 0.83642, val LOSS: 0.44426, test LOSS: 0.42907, Time: 568.11s
2024-03-19 19:08:33,430 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 19:08:34,541 - logger.py:50 - Epoch: [124][0/500] loss: 0.19338, MAE: 0.29982, time/step=1109ms, lr=4.54e-06
2024-03-19 19:09:25,211 - logger.py:50 - Epoch: [124][50/500] loss: 0.45558, MAE: 0.45475, time/step=1015ms, lr=4.54e-06
2024-03-19 19:10:15,687 - logger.py:50 - Epoch: [124][100/500] loss: 1.01050, MAE: 0.44990, time/step=1012ms, lr=4.54e-06
2024-03-19 19:11:08,073 - logger.py:50 - Epoch: [124][150/500] loss: 0.84966, MAE: 0.44975, time/step=1024ms, lr=4.54e-06
2024-03-19 19:11:59,293 - logger.py:50 - Epoch: [124][200/500] loss: 0.76522, MAE: 0.44892, time/step=1024ms, lr=4.54e-06
2024-03-19 19:12:50,914 - logger.py:50 - Epoch: [124][250/500] loss: 0.72125, MAE: 0.44741, time/step=1026ms, lr=4.54e-06
2024-03-19 19:13:41,519 - logger.py:50 - Epoch: [124][300/500] loss: 0.68662, MAE: 0.44275, time/step=1024ms, lr=4.54e-06
2024-03-19 19:14:32,720 - logger.py:50 - Epoch: [124][350/500] loss: 0.67217, MAE: 0.44254, time/step=1024ms, lr=4.54e-06
2024-03-19 19:15:23,733 - logger.py:50 - Epoch: [124][400/500] loss: 0.64053, MAE: 0.44183, time/step=1023ms, lr=4.54e-06
2024-03-19 19:16:14,404 - logger.py:50 - Epoch: [124][450/500] loss: 0.62156, MAE: 0.44124, time/step=1022ms, lr=4.54e-06
2024-03-19 19:17:05,676 - logger.py:50 - Epoch: [124][499/500] loss: 0.83782, MAE: 0.44438, time/step=1024ms, lr=4.54e-06
2024-03-19 19:18:02,654 - logger.py:50 - Epoch: [124] train LOSS: 0.83782, val LOSS: 0.44630, test LOSS: 0.43103, Time: 569.22s
2024-03-19 19:18:02,655 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 19:18:03,803 - logger.py:50 - Epoch: [125][0/500] loss: 0.64548, MAE: 0.52756, time/step=1147ms, lr=4.28e-06
2024-03-19 19:18:54,276 - logger.py:50 - Epoch: [125][50/500] loss: 0.47329, MAE: 0.45091, time/step=1012ms, lr=4.28e-06
2024-03-19 19:19:45,763 - logger.py:50 - Epoch: [125][100/500] loss: 0.47703, MAE: 0.44762, time/step=1021ms, lr=4.28e-06
2024-03-19 19:20:36,540 - logger.py:50 - Epoch: [125][150/500] loss: 1.26448, MAE: 0.45400, time/step=1019ms, lr=4.28e-06
2024-03-19 19:21:27,781 - logger.py:50 - Epoch: [125][200/500] loss: 1.06946, MAE: 0.44618, time/step=1021ms, lr=4.28e-06
2024-03-19 19:22:19,416 - logger.py:50 - Epoch: [125][250/500] loss: 0.95157, MAE: 0.44763, time/step=1023ms, lr=4.28e-06
2024-03-19 19:23:10,137 - logger.py:50 - Epoch: [125][300/500] loss: 0.87532, MAE: 0.44524, time/step=1022ms, lr=4.28e-06
2024-03-19 19:24:01,056 - logger.py:50 - Epoch: [125][350/500] loss: 0.81243, MAE: 0.44286, time/step=1021ms, lr=4.28e-06
2024-03-19 19:24:53,710 - logger.py:50 - Epoch: [125][400/500] loss: 0.91925, MAE: 0.44629, time/step=1025ms, lr=4.28e-06
2024-03-19 19:25:44,013 - logger.py:50 - Epoch: [125][450/500] loss: 0.87413, MAE: 0.44664, time/step=1023ms, lr=4.28e-06
2024-03-19 19:26:34,423 - logger.py:50 - Epoch: [125][499/500] loss: 0.83623, MAE: 0.44455, time/step=1024ms, lr=4.28e-06
2024-03-19 19:27:30,577 - logger.py:50 - Epoch: [125] train LOSS: 0.83623, val LOSS: 0.44513, test LOSS: 0.42997, Time: 567.92s
2024-03-19 19:27:30,577 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 19:27:31,694 - logger.py:50 - Epoch: [126][0/500] loss: 0.43904, MAE: 0.44826, time/step=1115ms, lr=4.03e-06
2024-03-19 19:28:23,273 - logger.py:50 - Epoch: [126][50/500] loss: 0.52295, MAE: 0.42848, time/step=1033ms, lr=4.03e-06
2024-03-19 19:28:44,894 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-19 19:28:56,038 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1 (cuda:0)])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
  )
)
2024-03-19 19:28:56,617 - logger.py:50 - Number of params: 2978805
2024-03-19 19:28:59,739 - logger.py:50 - Epoch: [0][0/500] loss: 0.49492, MAE: 0.45309, time/step=3118ms, lr=1.00e-06
2024-03-19 19:29:14,667 - logger.py:50 - Epoch: [126][100/500] loss: 0.47664, MAE: 0.43163, time/step=1031ms, lr=4.03e-06
2024-03-19 19:30:05,489 - logger.py:50 - Epoch: [126][150/500] loss: 0.50697, MAE: 0.43312, time/step=1026ms, lr=4.03e-06
2024-03-19 19:30:12,264 - logger.py:50 - Epoch: [0][50/500] loss: 3.09794, MAE: 0.47250, time/step=1483ms, lr=1.00e-06
2024-03-19 19:30:56,954 - logger.py:50 - Epoch: [126][200/500] loss: 0.51320, MAE: 0.43567, time/step=1027ms, lr=4.03e-06
2024-03-19 19:31:11,516 - logger.py:50 - Epoch: [0][100/500] loss: 2.76946, MAE: 0.46882, time/step=1336ms, lr=1.00e-06
2024-03-19 19:31:48,221 - logger.py:50 - Epoch: [126][250/500] loss: 0.50889, MAE: 0.43777, time/step=1026ms, lr=4.03e-06
2024-03-19 19:32:10,054 - logger.py:50 - Epoch: [0][150/500] loss: 2.02424, MAE: 0.46364, time/step=1281ms, lr=1.00e-06
2024-03-19 19:32:39,771 - logger.py:50 - Epoch: [126][300/500] loss: 0.49741, MAE: 0.43699, time/step=1027ms, lr=4.03e-06
2024-03-19 19:33:08,879 - logger.py:50 - Epoch: [0][200/500] loss: 1.64167, MAE: 0.45632, time/step=1255ms, lr=1.00e-06
2024-03-19 19:33:30,548 - logger.py:50 - Epoch: [126][350/500] loss: 0.83338, MAE: 0.44338, time/step=1026ms, lr=4.03e-06
2024-03-19 19:34:07,262 - logger.py:50 - Epoch: [0][250/500] loss: 1.41023, MAE: 0.45446, time/step=1238ms, lr=1.00e-06
2024-03-19 19:34:21,911 - logger.py:50 - Epoch: [126][400/500] loss: 0.78505, MAE: 0.44261, time/step=1026ms, lr=4.03e-06
2024-03-19 19:35:05,054 - logger.py:50 - Epoch: [0][300/500] loss: 1.25673, MAE: 0.45203, time/step=1224ms, lr=1.00e-06
2024-03-19 19:35:12,511 - logger.py:50 - Epoch: [126][450/500] loss: 0.75301, MAE: 0.44138, time/step=1024ms, lr=4.03e-06
2024-03-19 19:36:01,864 - logger.py:50 - Epoch: [0][350/500] loss: 1.14769, MAE: 0.44734, time/step=1212ms, lr=1.00e-06
2024-03-19 19:36:02,808 - logger.py:50 - Epoch: [126][499/500] loss: 0.83626, MAE: 0.44448, time/step=1024ms, lr=4.03e-06
2024-03-19 19:36:59,829 - logger.py:50 - Epoch: [126] train LOSS: 0.83626, val LOSS: 0.44403, test LOSS: 0.42864, Time: 569.25s
2024-03-19 19:36:59,829 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 19:36:59,915 - logger.py:50 - Epoch: [0][400/500] loss: 1.05738, MAE: 0.44614, time/step=1205ms, lr=1.00e-06
2024-03-19 19:37:01,076 - logger.py:50 - Epoch: [127][0/500] loss: 0.13059, MAE: 0.42094, time/step=1245ms, lr=3.79e-06
2024-03-19 19:37:51,566 - logger.py:50 - Epoch: [127][50/500] loss: 0.47511, MAE: 0.42017, time/step=1014ms, lr=3.79e-06
2024-03-19 19:37:55,758 - logger.py:50 - Epoch: [0][450/500] loss: 1.00125, MAE: 0.44511, time/step=1195ms, lr=1.00e-06
2024-03-19 19:38:42,309 - logger.py:50 - Epoch: [127][100/500] loss: 1.02176, MAE: 0.44158, time/step=1015ms, lr=3.79e-06
2024-03-19 19:38:50,441 - logger.py:50 - Epoch: [0][499/500] loss: 0.95263, MAE: 0.44368, time/step=1188ms, lr=1.00e-06
2024-03-19 19:39:34,117 - logger.py:50 - Epoch: [127][150/500] loss: 0.80966, MAE: 0.43271, time/step=1022ms, lr=3.79e-06
2024-03-19 19:39:54,790 - logger.py:50 - Epoch: [0] train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383, Time: 658.17s
2024-03-19 19:39:54,791 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 19:40:25,616 - logger.py:50 - Epoch: [127][200/500] loss: 0.73537, MAE: 0.43831, time/step=1024ms, lr=3.79e-06
2024-03-19 19:41:03,580 - logger.py:50 - Epoch: [0]EMA val MAE: 0.43649, EMA test MAE: 0.42145, Time: 726.96s
2024-03-19 19:41:03,581 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 19:41:04,392 - logger.py:50 - Epoch: [1][0/500] loss: 0.24001, MAE: 0.37196, time/step=809ms, lr=1.08e-05
2024-03-19 19:41:15,973 - logger.py:50 - Epoch: [127][250/500] loss: 0.68877, MAE: 0.43916, time/step=1020ms, lr=3.79e-06
2024-03-19 19:41:59,305 - logger.py:50 - Epoch: [1][50/500] loss: 0.52271, MAE: 0.43135, time/step=1093ms, lr=1.08e-05
2024-03-19 19:42:07,020 - logger.py:50 - Epoch: [127][300/500] loss: 0.67342, MAE: 0.43963, time/step=1021ms, lr=3.79e-06
2024-03-19 19:42:53,793 - logger.py:50 - Epoch: [1][100/500] loss: 1.79763, MAE: 0.45952, time/step=1091ms, lr=1.08e-05
2024-03-19 19:42:58,144 - logger.py:50 - Epoch: [127][350/500] loss: 0.65069, MAE: 0.43972, time/step=1021ms, lr=3.79e-06
2024-03-19 19:43:48,883 - logger.py:50 - Epoch: [127][400/500] loss: 0.92722, MAE: 0.44574, time/step=1020ms, lr=3.79e-06
2024-03-19 19:43:48,887 - logger.py:50 - Epoch: [1][150/500] loss: 1.36468, MAE: 0.44745, time/step=1095ms, lr=1.08e-05
2024-03-19 19:44:40,523 - logger.py:50 - Epoch: [127][450/500] loss: 0.87882, MAE: 0.44476, time/step=1021ms, lr=3.79e-06
2024-03-19 19:44:44,735 - logger.py:50 - Epoch: [1][200/500] loss: 1.15459, MAE: 0.45071, time/step=1100ms, lr=1.08e-05
2024-03-19 19:45:31,315 - logger.py:50 - Epoch: [127][499/500] loss: 0.83551, MAE: 0.44448, time/step=1023ms, lr=3.79e-06
2024-03-19 19:45:39,213 - logger.py:50 - Epoch: [1][250/500] loss: 1.02079, MAE: 0.44494, time/step=1098ms, lr=1.08e-05
2024-03-19 19:46:27,835 - logger.py:50 - Epoch: [127] train LOSS: 0.83551, val LOSS: 0.44656, test LOSS: 0.43131, Time: 568.01s
2024-03-19 19:46:27,836 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 19:46:28,997 - logger.py:50 - Epoch: [128][0/500] loss: 0.28389, MAE: 0.50339, time/step=1158ms, lr=3.56e-06
2024-03-19 19:46:34,205 - logger.py:50 - Epoch: [1][300/500] loss: 1.14392, MAE: 0.44826, time/step=1098ms, lr=1.08e-05
2024-03-19 19:47:20,058 - logger.py:50 - Epoch: [128][50/500] loss: 2.77493, MAE: 0.47625, time/step=1024ms, lr=3.56e-06
2024-03-19 19:47:28,956 - logger.py:50 - Epoch: [1][350/500] loss: 1.05886, MAE: 0.44665, time/step=1098ms, lr=1.08e-05
2024-03-19 19:48:10,592 - logger.py:50 - Epoch: [128][100/500] loss: 1.62755, MAE: 0.45064, time/step=1017ms, lr=3.56e-06
2024-03-19 19:48:24,831 - logger.py:50 - Epoch: [1][400/500] loss: 0.99179, MAE: 0.44409, time/step=1100ms, lr=1.08e-05
2024-03-19 19:49:02,236 - logger.py:50 - Epoch: [128][150/500] loss: 1.60137, MAE: 0.45323, time/step=1023ms, lr=3.56e-06
2024-03-19 19:49:20,949 - logger.py:50 - Epoch: [1][450/500] loss: 0.93952, MAE: 0.44360, time/step=1103ms, lr=1.08e-05
2024-03-19 19:49:53,814 - logger.py:50 - Epoch: [128][200/500] loss: 1.32516, MAE: 0.45359, time/step=1025ms, lr=3.56e-06
2024-03-19 19:50:15,337 - logger.py:50 - Epoch: [1][499/500] loss: 0.90074, MAE: 0.44401, time/step=1104ms, lr=1.08e-05
2024-03-19 19:50:45,190 - logger.py:50 - Epoch: [128][250/500] loss: 1.15989, MAE: 0.45394, time/step=1025ms, lr=3.56e-06
2024-03-19 19:51:17,948 - logger.py:50 - Epoch: [1] train LOSS: 0.90074, val LOSS: 0.49715, test LOSS: 0.46460, Time: 614.37s
2024-03-19 19:51:17,949 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 19:51:36,742 - logger.py:50 - Epoch: [128][300/500] loss: 1.03816, MAE: 0.45042, time/step=1026ms, lr=3.56e-06
2024-03-19 19:52:20,166 - logger.py:50 - Epoch: [1]EMA val MAE: 0.43686, EMA test MAE: 0.42183, Time: 676.58s
2024-03-19 19:52:20,167 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 19:52:21,516 - logger.py:50 - Epoch: [2][0/500] loss: 0.75315, MAE: 0.54005, time/step=1346ms, lr=2.06e-05
2024-03-19 19:52:27,957 - logger.py:50 - Epoch: [128][350/500] loss: 0.96843, MAE: 0.44711, time/step=1026ms, lr=3.56e-06
2024-03-19 19:53:17,537 - logger.py:50 - Epoch: [2][50/500] loss: 0.48630, MAE: 0.44686, time/step=1125ms, lr=2.06e-05
2024-03-19 19:53:19,147 - logger.py:50 - Epoch: [128][400/500] loss: 0.91922, MAE: 0.44448, time/step=1026ms, lr=3.56e-06
2024-03-19 19:54:09,519 - logger.py:50 - Epoch: [128][450/500] loss: 0.87315, MAE: 0.44385, time/step=1024ms, lr=3.56e-06
2024-03-19 19:54:13,029 - logger.py:50 - Epoch: [2][100/500] loss: 1.75789, MAE: 0.46176, time/step=1117ms, lr=2.06e-05
2024-03-19 19:54:59,740 - logger.py:50 - Epoch: [128][499/500] loss: 0.83578, MAE: 0.44455, time/step=1024ms, lr=3.56e-06
2024-03-19 19:55:07,962 - logger.py:50 - Epoch: [2][150/500] loss: 1.35542, MAE: 0.45608, time/step=1111ms, lr=2.06e-05
2024-03-19 19:55:56,741 - logger.py:50 - Epoch: [128] train LOSS: 0.83578, val LOSS: 0.44339, test LOSS: 0.42817, Time: 568.90s
2024-03-19 19:55:56,742 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 19:55:57,941 - logger.py:50 - Epoch: [129][0/500] loss: 0.46413, MAE: 0.49246, time/step=1197ms, lr=3.33e-06
2024-03-19 19:56:02,521 - logger.py:50 - Epoch: [2][200/500] loss: 1.13629, MAE: 0.44765, time/step=1106ms, lr=2.06e-05
2024-03-19 19:56:47,791 - logger.py:50 - Epoch: [129][50/500] loss: 1.54569, MAE: 0.45814, time/step=1001ms, lr=3.33e-06
2024-03-19 19:56:57,570 - logger.py:50 - Epoch: [2][250/500] loss: 1.01443, MAE: 0.44714, time/step=1105ms, lr=2.06e-05
2024-03-19 19:57:39,116 - logger.py:50 - Epoch: [129][100/500] loss: 1.02440, MAE: 0.44443, time/step=1014ms, lr=3.33e-06
2024-03-19 19:57:53,083 - logger.py:50 - Epoch: [2][300/500] loss: 1.12714, MAE: 0.44908, time/step=1106ms, lr=2.06e-05
2024-03-19 19:58:30,963 - logger.py:50 - Epoch: [129][150/500] loss: 0.84470, MAE: 0.44608, time/step=1021ms, lr=3.33e-06
2024-03-19 19:58:47,779 - logger.py:50 - Epoch: [2][350/500] loss: 1.03473, MAE: 0.44752, time/step=1104ms, lr=2.06e-05
2024-03-19 19:59:21,403 - logger.py:50 - Epoch: [129][200/500] loss: 1.33146, MAE: 0.45292, time/step=1018ms, lr=3.33e-06
2024-03-19 19:59:43,237 - logger.py:50 - Epoch: [2][400/500] loss: 0.97285, MAE: 0.44528, time/step=1105ms, lr=2.06e-05
2024-03-19 20:00:12,813 - logger.py:50 - Epoch: [129][250/500] loss: 1.17484, MAE: 0.44825, time/step=1020ms, lr=3.33e-06
2024-03-19 20:00:38,375 - logger.py:50 - Epoch: [2][450/500] loss: 0.91486, MAE: 0.44458, time/step=1105ms, lr=2.06e-05
2024-03-19 20:01:03,967 - logger.py:50 - Epoch: [129][300/500] loss: 1.05210, MAE: 0.44567, time/step=1021ms, lr=3.33e-06
2024-03-19 20:01:32,524 - logger.py:50 - Epoch: [2][499/500] loss: 0.87720, MAE: 0.44423, time/step=1105ms, lr=2.06e-05
2024-03-19 20:01:55,180 - logger.py:50 - Epoch: [129][350/500] loss: 0.97302, MAE: 0.44526, time/step=1021ms, lr=3.33e-06
2024-03-19 20:02:34,592 - logger.py:50 - Epoch: [2] train LOSS: 0.87720, val LOSS: 0.51380, test LOSS: 0.47301, Time: 614.42s
2024-03-19 20:02:34,592 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 20:02:46,182 - logger.py:50 - Epoch: [129][400/500] loss: 0.91461, MAE: 0.44444, time/step=1021ms, lr=3.33e-06
2024-03-19 20:03:36,316 - logger.py:50 - Epoch: [2]EMA val MAE: 0.43723, EMA test MAE: 0.42221, Time: 676.15s
2024-03-19 20:03:36,317 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 20:03:37,534 - logger.py:50 - Epoch: [3][0/500] loss: 0.34705, MAE: 0.38713, time/step=1214ms, lr=3.04e-05
2024-03-19 20:03:38,172 - logger.py:50 - Epoch: [129][450/500] loss: 0.86734, MAE: 0.44491, time/step=1023ms, lr=3.33e-06
2024-03-19 20:04:28,235 - logger.py:50 - Epoch: [129][499/500] loss: 0.83529, MAE: 0.44444, time/step=1023ms, lr=3.33e-06
2024-03-19 20:04:32,478 - logger.py:50 - Epoch: [3][50/500] loss: 0.48793, MAE: 0.42915, time/step=1101ms, lr=3.04e-05
2024-03-19 20:05:25,229 - logger.py:50 - Epoch: [129] train LOSS: 0.83529, val LOSS: 0.44890, test LOSS: 0.43348, Time: 568.49s
2024-03-19 20:05:25,230 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 20:05:26,320 - logger.py:50 - Epoch: [130][0/500] loss: 0.74162, MAE: 0.43757, time/step=1088ms, lr=3.12e-06
2024-03-19 20:05:27,657 - logger.py:50 - Epoch: [3][100/500] loss: 0.48377, MAE: 0.42722, time/step=1102ms, lr=3.04e-05
2024-03-19 20:06:16,889 - logger.py:50 - Epoch: [130][50/500] loss: 0.49995, MAE: 0.43204, time/step=1013ms, lr=3.12e-06
2024-03-19 20:06:21,194 - logger.py:50 - Epoch: [3][150/500] loss: 0.52292, MAE: 0.43660, time/step=1092ms, lr=3.04e-05
2024-03-19 20:07:08,232 - logger.py:50 - Epoch: [130][100/500] loss: 1.04388, MAE: 0.44569, time/step=1020ms, lr=3.12e-06
2024-03-19 20:07:16,798 - logger.py:50 - Epoch: [3][200/500] loss: 1.10009, MAE: 0.44525, time/step=1097ms, lr=3.04e-05
2024-03-19 20:07:59,216 - logger.py:50 - Epoch: [130][150/500] loss: 0.85862, MAE: 0.44301, time/step=1020ms, lr=3.12e-06
2024-03-19 20:08:12,740 - logger.py:50 - Epoch: [3][250/500] loss: 1.00560, MAE: 0.44464, time/step=1101ms, lr=3.04e-05
2024-03-19 20:08:50,748 - logger.py:50 - Epoch: [130][200/500] loss: 0.77357, MAE: 0.44592, time/step=1022ms, lr=3.12e-06
2024-03-19 20:09:07,947 - logger.py:50 - Epoch: [3][300/500] loss: 0.92318, MAE: 0.44094, time/step=1102ms, lr=3.04e-05
2024-03-19 20:09:41,560 - logger.py:50 - Epoch: [130][250/500] loss: 0.70261, MAE: 0.44090, time/step=1021ms, lr=3.12e-06
2024-03-19 20:10:02,879 - logger.py:50 - Epoch: [3][350/500] loss: 1.03992, MAE: 0.44416, time/step=1101ms, lr=3.04e-05
2024-03-19 20:10:32,975 - logger.py:50 - Epoch: [130][300/500] loss: 0.66309, MAE: 0.43970, time/step=1022ms, lr=3.12e-06
2024-03-19 20:10:57,199 - logger.py:50 - Epoch: [3][400/500] loss: 0.97222, MAE: 0.44313, time/step=1099ms, lr=3.04e-05
2024-03-19 20:11:25,181 - logger.py:50 - Epoch: [130][350/500] loss: 0.64520, MAE: 0.44082, time/step=1025ms, lr=3.12e-06
2024-03-19 20:11:52,579 - logger.py:50 - Epoch: [3][450/500] loss: 0.92228, MAE: 0.44379, time/step=1100ms, lr=3.04e-05
2024-03-19 20:12:16,398 - logger.py:50 - Epoch: [130][400/500] loss: 0.62433, MAE: 0.44085, time/step=1025ms, lr=3.12e-06
2024-03-19 20:12:47,023 - logger.py:50 - Epoch: [3][499/500] loss: 0.88494, MAE: 0.44446, time/step=1101ms, lr=3.04e-05
2024-03-19 20:13:07,027 - logger.py:50 - Epoch: [130][450/500] loss: 0.87080, MAE: 0.44607, time/step=1024ms, lr=3.12e-06
2024-03-19 20:13:49,115 - logger.py:50 - Epoch: [3] train LOSS: 0.88494, val LOSS: 0.50847, test LOSS: 0.47707, Time: 612.80s
2024-03-19 20:13:49,116 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 20:13:57,273 - logger.py:50 - Epoch: [130][499/500] loss: 0.83558, MAE: 0.44455, time/step=1024ms, lr=3.12e-06
2024-03-19 20:14:50,386 - logger.py:50 - Epoch: [3]EMA val MAE: 0.43757, EMA test MAE: 0.42255, Time: 674.07s
2024-03-19 20:14:50,387 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 20:14:51,487 - logger.py:50 - Epoch: [4][0/500] loss: 0.94773, MAE: 0.52370, time/step=1098ms, lr=4.02e-05
2024-03-19 20:14:53,825 - logger.py:50 - Epoch: [130] train LOSS: 0.83558, val LOSS: 0.44482, test LOSS: 0.42957, Time: 568.60s
2024-03-19 20:14:53,826 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 20:14:54,957 - logger.py:50 - Epoch: [131][0/500] loss: 0.59472, MAE: 0.42265, time/step=1129ms, lr=2.91e-06
2024-03-19 20:15:46,586 - logger.py:50 - Epoch: [131][50/500] loss: 0.50334, MAE: 0.44792, time/step=1034ms, lr=2.91e-06
2024-03-19 20:15:46,987 - logger.py:50 - Epoch: [4][50/500] loss: 0.55290, MAE: 0.43264, time/step=1110ms, lr=4.02e-05
2024-03-19 20:16:38,270 - logger.py:50 - Epoch: [131][100/500] loss: 0.47871, MAE: 0.44420, time/step=1034ms, lr=2.91e-06
2024-03-19 20:16:42,764 - logger.py:50 - Epoch: [4][100/500] loss: 0.54271, MAE: 0.44976, time/step=1113ms, lr=4.02e-05
2024-03-19 20:17:28,931 - logger.py:50 - Epoch: [131][150/500] loss: 0.46717, MAE: 0.44172, time/step=1027ms, lr=2.91e-06
2024-03-19 20:17:37,276 - logger.py:50 - Epoch: [4][150/500] loss: 0.52702, MAE: 0.44147, time/step=1105ms, lr=4.02e-05
2024-03-19 20:18:19,326 - logger.py:50 - Epoch: [131][200/500] loss: 1.33889, MAE: 0.45532, time/step=1022ms, lr=2.91e-06
2024-03-19 20:18:32,065 - logger.py:50 - Epoch: [4][200/500] loss: 0.52195, MAE: 0.44128, time/step=1103ms, lr=4.02e-05
2024-03-19 20:19:11,351 - logger.py:50 - Epoch: [131][250/500] loss: 1.17929, MAE: 0.45326, time/step=1026ms, lr=2.91e-06
2024-03-19 20:19:26,493 - logger.py:50 - Epoch: [4][250/500] loss: 0.53719, MAE: 0.44262, time/step=1100ms, lr=4.02e-05
2024-03-19 20:20:02,524 - logger.py:50 - Epoch: [131][300/500] loss: 1.06638, MAE: 0.45130, time/step=1026ms, lr=2.91e-06
2024-03-19 20:20:21,621 - logger.py:50 - Epoch: [4][300/500] loss: 0.53102, MAE: 0.43944, time/step=1100ms, lr=4.02e-05
2024-03-19 20:20:53,300 - logger.py:50 - Epoch: [131][350/500] loss: 0.98166, MAE: 0.44874, time/step=1024ms, lr=2.91e-06
2024-03-19 20:21:16,743 - logger.py:50 - Epoch: [4][350/500] loss: 0.53796, MAE: 0.44031, time/step=1101ms, lr=4.02e-05
2024-03-19 20:21:44,783 - logger.py:50 - Epoch: [131][400/500] loss: 0.91878, MAE: 0.44837, time/step=1025ms, lr=2.91e-06
2024-03-19 20:22:12,096 - logger.py:50 - Epoch: [4][400/500] loss: 0.52686, MAE: 0.43967, time/step=1102ms, lr=4.02e-05
2024-03-19 20:22:36,073 - logger.py:50 - Epoch: [131][450/500] loss: 0.87823, MAE: 0.44660, time/step=1025ms, lr=2.91e-06
2024-03-19 20:23:06,931 - logger.py:50 - Epoch: [4][450/500] loss: 0.75981, MAE: 0.43999, time/step=1101ms, lr=4.02e-05
2024-03-19 20:23:26,036 - logger.py:50 - Epoch: [131][499/500] loss: 0.83541, MAE: 0.44453, time/step=1024ms, lr=2.91e-06
2024-03-19 20:24:01,139 - logger.py:50 - Epoch: [4][499/500] loss: 1.01232, MAE: 0.44379, time/step=1101ms, lr=4.02e-05
2024-03-19 20:24:23,096 - logger.py:50 - Epoch: [131] train LOSS: 0.83541, val LOSS: 0.44468, test LOSS: 0.42961, Time: 569.27s
2024-03-19 20:24:23,098 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 20:24:24,185 - logger.py:50 - Epoch: [132][0/500] loss: 0.34725, MAE: 0.33651, time/step=1085ms, lr=2.72e-06
2024-03-19 20:25:03,151 - logger.py:50 - Epoch: [4] train LOSS: 1.01232, val LOSS: 1.63760, test LOSS: 0.54663, Time: 612.76s
2024-03-19 20:25:03,152 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 20:25:14,568 - logger.py:50 - Epoch: [132][50/500] loss: 0.55206, MAE: 0.42571, time/step=1009ms, lr=2.72e-06
2024-03-19 20:26:04,349 - logger.py:50 - Epoch: [4]EMA val MAE: 0.43786, EMA test MAE: 0.42283, Time: 673.96s
2024-03-19 20:26:04,350 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 20:26:05,496 - logger.py:50 - Epoch: [5][0/500] loss: 0.68625, MAE: 0.45406, time/step=1145ms, lr=4.99e-05
2024-03-19 20:26:06,240 - logger.py:50 - Epoch: [132][100/500] loss: 0.50736, MAE: 0.43045, time/step=1021ms, lr=2.72e-06
2024-03-19 20:26:57,741 - logger.py:50 - Epoch: [132][150/500] loss: 0.53081, MAE: 0.43716, time/step=1024ms, lr=2.72e-06
2024-03-19 20:27:00,118 - logger.py:50 - Epoch: [5][50/500] loss: 0.65519, MAE: 0.44568, time/step=1093ms, lr=4.99e-05
2024-03-19 20:27:49,551 - logger.py:50 - Epoch: [132][200/500] loss: 0.51685, MAE: 0.43780, time/step=1027ms, lr=2.72e-06
2024-03-19 20:27:54,353 - logger.py:50 - Epoch: [5][100/500] loss: 1.83439, MAE: 0.46064, time/step=1089ms, lr=4.99e-05
2024-03-19 20:28:41,487 - logger.py:50 - Epoch: [132][250/500] loss: 0.50141, MAE: 0.43814, time/step=1029ms, lr=2.72e-06
2024-03-19 20:28:49,903 - logger.py:50 - Epoch: [5][150/500] loss: 1.79546, MAE: 0.46386, time/step=1096ms, lr=4.99e-05
2024-03-19 20:29:32,282 - logger.py:50 - Epoch: [132][300/500] loss: 0.49786, MAE: 0.43930, time/step=1027ms, lr=2.72e-06
2024-03-19 20:29:44,868 - logger.py:50 - Epoch: [5][200/500] loss: 1.51011, MAE: 0.45753, time/step=1097ms, lr=4.99e-05
2024-03-19 20:30:24,162 - logger.py:50 - Epoch: [132][350/500] loss: 0.48013, MAE: 0.43725, time/step=1029ms, lr=2.72e-06
2024-03-19 20:30:40,434 - logger.py:50 - Epoch: [5][250/500] loss: 1.30773, MAE: 0.45500, time/step=1100ms, lr=4.99e-05
2024-03-19 20:31:14,606 - logger.py:50 - Epoch: [132][400/500] loss: 0.47959, MAE: 0.43796, time/step=1026ms, lr=2.72e-06
2024-03-19 20:31:34,856 - logger.py:50 - Epoch: [5][300/500] loss: 1.17441, MAE: 0.45028, time/step=1098ms, lr=4.99e-05
2024-03-19 20:32:05,606 - logger.py:50 - Epoch: [132][450/500] loss: 0.86373, MAE: 0.44400, time/step=1026ms, lr=2.72e-06
2024-03-19 20:32:31,519 - logger.py:50 - Epoch: [5][350/500] loss: 1.09057, MAE: 0.44799, time/step=1103ms, lr=4.99e-05
2024-03-19 20:32:55,566 - logger.py:50 - Epoch: [132][499/500] loss: 0.83526, MAE: 0.44440, time/step=1025ms, lr=2.72e-06
2024-03-19 20:33:26,319 - logger.py:50 - Epoch: [5][400/500] loss: 1.01753, MAE: 0.44663, time/step=1102ms, lr=4.99e-05
2024-03-19 20:34:21,775 - logger.py:50 - Epoch: [5][450/500] loss: 0.96122, MAE: 0.44621, time/step=1103ms, lr=4.99e-05
2024-03-19 20:34:34,162 - logger.py:50 - Epoch: [132] train LOSS: 0.83526, val LOSS: 0.44574, test LOSS: 0.43018, Time: 611.06s
2024-03-19 20:34:34,164 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 20:34:35,469 - logger.py:50 - Epoch: [133][0/500] loss: 0.49860, MAE: 0.35166, time/step=1300ms, lr=2.54e-06
2024-03-19 20:35:15,703 - logger.py:50 - Epoch: [5][499/500] loss: 0.91243, MAE: 0.44474, time/step=1103ms, lr=4.99e-05
2024-03-19 20:36:08,982 - logger.py:50 - Epoch: [133][50/500] loss: 0.60829, MAE: 0.43655, time/step=1859ms, lr=2.54e-06
2024-03-19 20:36:17,762 - logger.py:50 - Epoch: [5] train LOSS: 0.91243, val LOSS: 0.50489, test LOSS: 0.47796, Time: 613.41s
2024-03-19 20:36:17,763 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 20:37:19,479 - logger.py:50 - Epoch: [5]EMA val MAE: 0.43810, EMA test MAE: 0.42308, Time: 675.13s
2024-03-19 20:37:19,479 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 20:37:20,788 - logger.py:50 - Epoch: [6][0/500] loss: 0.18985, MAE: 0.42258, time/step=1307ms, lr=4.98e-05
2024-03-19 20:37:42,288 - logger.py:50 - Epoch: [133][100/500] loss: 0.53074, MAE: 0.43669, time/step=1863ms, lr=2.54e-06
2024-03-19 20:38:15,883 - logger.py:50 - Epoch: [6][50/500] loss: 0.47748, MAE: 0.44584, time/step=1106ms, lr=4.98e-05
2024-03-19 20:39:10,350 - logger.py:50 - Epoch: [6][100/500] loss: 0.46821, MAE: 0.43015, time/step=1098ms, lr=4.98e-05
2024-03-19 20:39:13,657 - logger.py:50 - Epoch: [133][150/500] loss: 0.51686, MAE: 0.43633, time/step=1851ms, lr=2.54e-06
2024-03-19 20:40:05,522 - logger.py:50 - Epoch: [6][150/500] loss: 0.47747, MAE: 0.43712, time/step=1100ms, lr=4.98e-05
2024-03-19 20:40:49,463 - logger.py:50 - Epoch: [133][200/500] loss: 0.51429, MAE: 0.43989, time/step=1867ms, lr=2.54e-06
2024-03-19 20:41:00,303 - logger.py:50 - Epoch: [6][200/500] loss: 2.30573, MAE: 0.43638, time/step=1099ms, lr=4.98e-05
2024-03-19 20:41:54,644 - logger.py:50 - Epoch: [6][250/500] loss: 1.98604, MAE: 0.43828, time/step=1096ms, lr=4.98e-05
2024-03-19 20:42:23,268 - logger.py:50 - Epoch: [133][250/500] loss: 0.49922, MAE: 0.43998, time/step=1869ms, lr=2.54e-06
2024-03-19 20:42:49,817 - logger.py:50 - Epoch: [6][300/500] loss: 1.75147, MAE: 0.43783, time/step=1097ms, lr=4.98e-05
2024-03-19 20:43:45,016 - logger.py:50 - Epoch: [6][350/500] loss: 1.57678, MAE: 0.43782, time/step=1098ms, lr=4.98e-05
2024-03-19 20:43:58,510 - logger.py:50 - Epoch: [133][300/500] loss: 0.50039, MAE: 0.43884, time/step=1875ms, lr=2.54e-06
2024-03-19 20:44:39,966 - logger.py:50 - Epoch: [6][400/500] loss: 1.44471, MAE: 0.43786, time/step=1098ms, lr=4.98e-05
2024-03-19 20:45:33,002 - logger.py:50 - Epoch: [133][350/500] loss: 0.65576, MAE: 0.44579, time/step=1877ms, lr=2.54e-06
2024-03-19 20:45:35,155 - logger.py:50 - Epoch: [6][450/500] loss: 1.34584, MAE: 0.43909, time/step=1099ms, lr=4.98e-05
2024-03-19 20:46:29,949 - logger.py:50 - Epoch: [6][499/500] loss: 2.14853, MAE: 0.44294, time/step=1101ms, lr=4.98e-05
2024-03-19 20:47:13,553 - logger.py:50 - Epoch: [133][400/500] loss: 0.92336, MAE: 0.44866, time/step=1894ms, lr=2.54e-06
2024-03-19 20:47:32,424 - logger.py:50 - Epoch: [6] train LOSS: 2.14853, val LOSS: 0.54678, test LOSS: 0.54640, Time: 612.94s
2024-03-19 20:47:32,425 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 20:48:34,192 - logger.py:50 - Epoch: [6]EMA val MAE: 0.43835, EMA test MAE: 0.42330, Time: 674.71s
2024-03-19 20:48:34,192 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 20:48:35,352 - logger.py:50 - Epoch: [7][0/500] loss: 1.41108, MAE: 0.37536, time/step=1158ms, lr=4.97e-05
2024-03-19 20:48:48,807 - logger.py:50 - Epoch: [133][450/500] loss: 0.87519, MAE: 0.44601, time/step=1895ms, lr=2.54e-06
2024-03-19 20:49:29,967 - logger.py:50 - Epoch: [7][50/500] loss: 0.64541, MAE: 0.44368, time/step=1094ms, lr=4.97e-05
2024-03-19 20:50:21,666 - logger.py:50 - Epoch: [133][499/500] loss: 0.83474, MAE: 0.44462, time/step=1895ms, lr=2.54e-06
2024-03-19 20:50:25,338 - logger.py:50 - Epoch: [7][100/500] loss: 0.59923, MAE: 0.43849, time/step=1100ms, lr=4.97e-05
2024-03-19 20:51:20,345 - logger.py:50 - Epoch: [7][150/500] loss: 0.55319, MAE: 0.43847, time/step=1100ms, lr=4.97e-05
2024-03-19 20:52:15,345 - logger.py:50 - Epoch: [7][200/500] loss: 2.07614, MAE: 0.44569, time/step=1100ms, lr=4.97e-05
2024-03-19 20:52:18,311 - logger.py:50 - Epoch: [133] train LOSS: 0.83474, val LOSS: 0.44485, test LOSS: 0.42970, Time: 1064.15s
2024-03-19 20:52:18,313 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 20:52:20,545 - logger.py:50 - Epoch: [134][0/500] loss: 0.28989, MAE: 0.42285, time/step=2227ms, lr=2.36e-06
2024-03-19 20:53:10,082 - logger.py:50 - Epoch: [7][250/500] loss: 1.80228, MAE: 0.44390, time/step=1099ms, lr=4.97e-05
2024-03-19 20:54:00,796 - logger.py:50 - Epoch: [134][50/500] loss: 0.53352, MAE: 0.43146, time/step=2009ms, lr=2.36e-06
2024-03-19 20:54:05,502 - logger.py:50 - Epoch: [7][300/500] loss: 1.60086, MAE: 0.44579, time/step=1101ms, lr=4.97e-05
2024-03-19 20:55:00,722 - logger.py:50 - Epoch: [7][350/500] loss: 1.44068, MAE: 0.44297, time/step=1101ms, lr=4.97e-05
2024-03-19 20:55:42,801 - logger.py:50 - Epoch: [134][100/500] loss: 0.46557, MAE: 0.42990, time/step=2025ms, lr=2.36e-06
2024-03-19 20:55:56,796 - logger.py:50 - Epoch: [7][400/500] loss: 1.33578, MAE: 0.44253, time/step=1104ms, lr=4.97e-05
2024-03-19 20:56:51,332 - logger.py:50 - Epoch: [7][450/500] loss: 1.51005, MAE: 0.44603, time/step=1102ms, lr=4.97e-05
2024-03-19 20:57:26,113 - logger.py:50 - Epoch: [134][150/500] loss: 0.45784, MAE: 0.43006, time/step=2038ms, lr=2.36e-06
2024-03-19 20:57:46,010 - logger.py:50 - Epoch: [7][499/500] loss: 1.41270, MAE: 0.44460, time/step=1104ms, lr=4.97e-05
2024-03-19 20:58:48,451 - logger.py:50 - Epoch: [7] train LOSS: 1.41270, val LOSS: 0.51220, test LOSS: 0.48144, Time: 614.26s
2024-03-19 20:58:48,451 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 20:59:04,697 - logger.py:50 - Epoch: [134][200/500] loss: 0.46635, MAE: 0.43452, time/step=2022ms, lr=2.36e-06
2024-03-19 20:59:50,523 - logger.py:50 - Epoch: [7]EMA val MAE: 0.43840, EMA test MAE: 0.42337, Time: 676.33s
2024-03-19 20:59:50,524 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 20:59:51,809 - logger.py:50 - Epoch: [8][0/500] loss: 0.25253, MAE: 0.51519, time/step=1282ms, lr=4.97e-05
2024-03-19 21:00:38,883 - logger.py:50 - Epoch: [134][250/500] loss: 0.47256, MAE: 0.43548, time/step=1994ms, lr=2.36e-06
2024-03-19 21:00:46,448 - logger.py:50 - Epoch: [8][50/500] loss: 0.49808, MAE: 0.44439, time/step=1097ms, lr=4.97e-05
2024-03-19 21:01:41,976 - logger.py:50 - Epoch: [8][100/500] loss: 0.54963, MAE: 0.44096, time/step=1103ms, lr=4.97e-05
2024-03-19 21:02:17,329 - logger.py:50 - Epoch: [134][300/500] loss: 0.48057, MAE: 0.43612, time/step=1990ms, lr=2.36e-06
2024-03-19 21:02:36,940 - logger.py:50 - Epoch: [8][150/500] loss: 1.32637, MAE: 0.45018, time/step=1102ms, lr=4.97e-05
2024-03-19 21:03:32,378 - logger.py:50 - Epoch: [8][200/500] loss: 1.12670, MAE: 0.44726, time/step=1104ms, lr=4.97e-05
2024-03-19 21:03:55,038 - logger.py:50 - Epoch: [134][350/500] loss: 0.82682, MAE: 0.44084, time/step=1985ms, lr=2.36e-06
2024-03-19 21:04:27,980 - logger.py:50 - Epoch: [8][250/500] loss: 0.99589, MAE: 0.44360, time/step=1105ms, lr=4.97e-05
2024-03-19 21:05:24,582 - logger.py:50 - Epoch: [8][300/500] loss: 0.91039, MAE: 0.44243, time/step=1110ms, lr=4.97e-05
2024-03-19 21:05:35,950 - logger.py:50 - Epoch: [134][400/500] loss: 0.78423, MAE: 0.44193, time/step=1989ms, lr=2.36e-06
2024-03-19 21:06:19,090 - logger.py:50 - Epoch: [8][350/500] loss: 0.85903, MAE: 0.44181, time/step=1107ms, lr=4.97e-05
2024-03-19 21:07:13,222 - logger.py:50 - Epoch: [134][450/500] loss: 0.75244, MAE: 0.44242, time/step=1984ms, lr=2.36e-06
2024-03-19 21:07:14,484 - logger.py:50 - Epoch: [8][400/500] loss: 0.97411, MAE: 0.44622, time/step=1107ms, lr=4.97e-05
2024-03-19 21:08:09,833 - logger.py:50 - Epoch: [8][450/500] loss: 0.91960, MAE: 0.44465, time/step=1107ms, lr=4.97e-05
2024-03-19 21:08:54,121 - logger.py:50 - Epoch: [134][499/500] loss: 0.83427, MAE: 0.44448, time/step=1992ms, lr=2.36e-06
2024-03-19 21:09:04,233 - logger.py:50 - Epoch: [8][499/500] loss: 0.88092, MAE: 0.44446, time/step=1107ms, lr=4.97e-05
2024-03-19 21:10:06,649 - logger.py:50 - Epoch: [8] train LOSS: 0.88092, val LOSS: 0.50871, test LOSS: 0.47960, Time: 616.12s
2024-03-19 21:10:06,650 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 21:10:52,933 - logger.py:50 - Epoch: [134] train LOSS: 0.83427, val LOSS: 0.44398, test LOSS: 0.42880, Time: 1114.62s
2024-03-19 21:10:52,935 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 21:10:54,176 - logger.py:50 - Epoch: [135][0/500] loss: 0.39000, MAE: 0.44862, time/step=1230ms, lr=2.20e-06
2024-03-19 21:11:08,236 - logger.py:50 - Epoch: [8]EMA val MAE: 0.43810, EMA test MAE: 0.42310, Time: 677.71s
2024-03-19 21:11:08,237 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 21:11:09,585 - logger.py:50 - Epoch: [9][0/500] loss: 0.45676, MAE: 0.45817, time/step=1346ms, lr=4.96e-05
2024-03-19 21:12:05,335 - logger.py:50 - Epoch: [9][50/500] loss: 0.55643, MAE: 0.45912, time/step=1120ms, lr=4.96e-05
2024-03-19 21:12:32,648 - logger.py:50 - Epoch: [135][50/500] loss: 0.46928, MAE: 0.44274, time/step=1955ms, lr=2.20e-06
2024-03-19 21:13:00,910 - logger.py:50 - Epoch: [9][100/500] loss: 0.52434, MAE: 0.45204, time/step=1116ms, lr=4.96e-05
2024-03-19 21:13:55,937 - logger.py:50 - Epoch: [9][150/500] loss: 0.50426, MAE: 0.44865, time/step=1111ms, lr=4.96e-05
2024-03-19 21:14:12,068 - logger.py:50 - Epoch: [135][100/500] loss: 0.45743, MAE: 0.44333, time/step=1972ms, lr=2.20e-06
2024-03-19 21:14:50,923 - logger.py:50 - Epoch: [9][200/500] loss: 0.51932, MAE: 0.44174, time/step=1108ms, lr=4.96e-05
2024-03-19 21:15:45,975 - logger.py:50 - Epoch: [9][250/500] loss: 0.51812, MAE: 0.44484, time/step=1107ms, lr=4.96e-05
2024-03-19 21:15:55,078 - logger.py:50 - Epoch: [135][150/500] loss: 0.47051, MAE: 0.44134, time/step=2001ms, lr=2.20e-06
2024-03-19 21:16:42,198 - logger.py:50 - Epoch: [9][300/500] loss: 0.52022, MAE: 0.44091, time/step=1109ms, lr=4.96e-05
2024-03-19 21:17:38,160 - logger.py:50 - Epoch: [135][200/500] loss: 0.77001, MAE: 0.44966, time/step=2016ms, lr=2.20e-06
2024-03-19 21:17:38,257 - logger.py:50 - Epoch: [9][350/500] loss: 0.88174, MAE: 0.44543, time/step=1111ms, lr=4.96e-05
2024-03-19 21:18:33,611 - logger.py:50 - Epoch: [9][400/500] loss: 0.83285, MAE: 0.44369, time/step=1111ms, lr=4.96e-05
2024-03-19 21:19:15,099 - logger.py:50 - Epoch: [135][250/500] loss: 0.70101, MAE: 0.44838, time/step=2001ms, lr=2.20e-06
2024-03-19 21:19:30,280 - logger.py:50 - Epoch: [9][450/500] loss: 0.79145, MAE: 0.44166, time/step=1113ms, lr=4.96e-05
2024-03-19 21:20:24,122 - logger.py:50 - Epoch: [9][499/500] loss: 0.89703, MAE: 0.44437, time/step=1112ms, lr=4.96e-05
2024-03-19 21:20:51,789 - logger.py:50 - Epoch: [135][300/500] loss: 0.67503, MAE: 0.44533, time/step=1990ms, lr=2.20e-06
2024-03-19 21:21:27,143 - logger.py:50 - Epoch: [9] train LOSS: 0.89703, val LOSS: 0.53285, test LOSS: 0.49912, Time: 618.91s
2024-03-19 21:21:27,144 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 21:22:27,442 - logger.py:50 - Epoch: [135][350/500] loss: 0.64301, MAE: 0.44407, time/step=1979ms, lr=2.20e-06
2024-03-19 21:22:29,845 - logger.py:50 - Epoch: [9]EMA val MAE: 0.43800, EMA test MAE: 0.42300, Time: 681.61s
2024-03-19 21:22:29,847 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 21:22:31,172 - logger.py:50 - Epoch: [10][0/500] loss: 0.40598, MAE: 0.37916, time/step=1323ms, lr=4.95e-05
2024-03-19 21:23:27,329 - logger.py:50 - Epoch: [10][50/500] loss: 0.49363, MAE: 0.43565, time/step=1127ms, lr=4.95e-05
2024-03-19 21:24:01,830 - logger.py:50 - Epoch: [135][400/500] loss: 0.62175, MAE: 0.44338, time/step=1967ms, lr=2.20e-06
2024-03-19 21:24:23,088 - logger.py:50 - Epoch: [10][100/500] loss: 0.53999, MAE: 0.44020, time/step=1121ms, lr=4.95e-05
2024-03-19 21:25:18,330 - logger.py:50 - Epoch: [10][150/500] loss: 0.54548, MAE: 0.43769, time/step=1116ms, lr=4.95e-05
2024-03-19 21:25:35,459 - logger.py:50 - Epoch: [135][450/500] loss: 0.60996, MAE: 0.44148, time/step=1957ms, lr=2.20e-06
2024-03-19 21:26:12,430 - logger.py:50 - Epoch: [10][200/500] loss: 0.53722, MAE: 0.43663, time/step=1107ms, lr=4.95e-05
2024-03-19 21:27:04,676 - logger.py:50 - Epoch: [135][499/500] loss: 0.83509, MAE: 0.44448, time/step=1943ms, lr=2.20e-06
2024-03-19 21:27:07,646 - logger.py:50 - Epoch: [10][250/500] loss: 0.55665, MAE: 0.43742, time/step=1107ms, lr=4.95e-05
2024-03-19 21:28:01,844 - logger.py:50 - Epoch: [10][300/500] loss: 0.55057, MAE: 0.43608, time/step=1103ms, lr=4.95e-05
2024-03-19 21:28:55,370 - logger.py:50 - Epoch: [135] train LOSS: 0.83509, val LOSS: 0.44594, test LOSS: 0.43060, Time: 1082.44s
2024-03-19 21:28:55,372 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 21:28:57,578 - logger.py:50 - Epoch: [136][0/500] loss: 0.25404, MAE: 0.41677, time/step=2201ms, lr=2.05e-06
2024-03-19 21:28:58,152 - logger.py:50 - Epoch: [10][350/500] loss: 0.54278, MAE: 0.43761, time/step=1106ms, lr=4.95e-05
2024-03-19 21:29:53,880 - logger.py:50 - Epoch: [10][400/500] loss: 0.77709, MAE: 0.44123, time/step=1107ms, lr=4.95e-05
2024-03-19 21:30:38,420 - logger.py:50 - Epoch: [136][50/500] loss: 0.48527, MAE: 0.42773, time/step=2020ms, lr=2.05e-06
2024-03-19 21:30:49,935 - logger.py:50 - Epoch: [10][450/500] loss: 0.74739, MAE: 0.44094, time/step=1109ms, lr=4.95e-05
2024-03-19 21:31:43,587 - logger.py:50 - Epoch: [10][499/500] loss: 0.95141, MAE: 0.44429, time/step=1107ms, lr=4.95e-05
2024-03-19 21:32:18,036 - logger.py:50 - Epoch: [136][100/500] loss: 0.48342, MAE: 0.43759, time/step=2007ms, lr=2.05e-06
2024-03-19 21:32:46,525 - logger.py:50 - Epoch: [10] train LOSS: 0.95141, val LOSS: 0.50730, test LOSS: 0.48051, Time: 616.68s
2024-03-19 21:32:46,526 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 21:33:48,229 - logger.py:50 - Epoch: [10]EMA val MAE: 0.43798, EMA test MAE: 0.42300, Time: 678.38s
2024-03-19 21:33:48,229 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 21:33:49,495 - logger.py:50 - Epoch: [11][0/500] loss: 0.48318, MAE: 0.42767, time/step=1263ms, lr=4.94e-05
2024-03-19 21:34:01,560 - logger.py:50 - Epoch: [136][150/500] loss: 0.47072, MAE: 0.43736, time/step=2028ms, lr=2.05e-06
2024-03-19 21:34:43,701 - logger.py:50 - Epoch: [11][50/500] loss: 0.54761, MAE: 0.44690, time/step=1088ms, lr=4.94e-05
2024-03-19 21:35:39,129 - logger.py:50 - Epoch: [11][100/500] loss: 0.57905, MAE: 0.44818, time/step=1098ms, lr=4.94e-05
2024-03-19 21:35:44,002 - logger.py:50 - Epoch: [136][200/500] loss: 0.49225, MAE: 0.44028, time/step=2033ms, lr=2.05e-06
2024-03-19 21:36:34,042 - logger.py:50 - Epoch: [11][150/500] loss: 0.58025, MAE: 0.45055, time/step=1098ms, lr=4.94e-05
2024-03-19 21:37:22,081 - logger.py:50 - Epoch: [136][250/500] loss: 0.48389, MAE: 0.43787, time/step=2019ms, lr=2.05e-06
2024-03-19 21:37:29,441 - logger.py:50 - Epoch: [11][200/500] loss: 0.56781, MAE: 0.45022, time/step=1101ms, lr=4.94e-05
2024-03-19 21:38:25,191 - logger.py:50 - Epoch: [11][250/500] loss: 0.54931, MAE: 0.44832, time/step=1103ms, lr=4.94e-05
2024-03-19 21:38:57,506 - logger.py:50 - Epoch: [136][300/500] loss: 0.86826, MAE: 0.44321, time/step=2000ms, lr=2.05e-06
2024-03-19 21:39:21,389 - logger.py:50 - Epoch: [11][300/500] loss: 0.77522, MAE: 0.44951, time/step=1107ms, lr=4.94e-05
2024-03-19 21:40:15,740 - logger.py:50 - Epoch: [11][350/500] loss: 0.73221, MAE: 0.44748, time/step=1104ms, lr=4.94e-05
2024-03-19 21:40:36,206 - logger.py:50 - Epoch: [136][350/500] loss: 0.81275, MAE: 0.44233, time/step=1997ms, lr=2.05e-06
2024-03-19 21:41:10,320 - logger.py:50 - Epoch: [11][400/500] loss: 0.70972, MAE: 0.44402, time/step=1102ms, lr=4.94e-05
2024-03-19 21:42:05,302 - logger.py:50 - Epoch: [11][450/500] loss: 0.97948, MAE: 0.44550, time/step=1102ms, lr=4.94e-05
2024-03-19 21:42:15,499 - logger.py:50 - Epoch: [136][400/500] loss: 0.91305, MAE: 0.44638, time/step=1995ms, lr=2.05e-06
2024-03-19 21:42:59,362 - logger.py:50 - Epoch: [11][499/500] loss: 0.93275, MAE: 0.44447, time/step=1102ms, lr=4.94e-05
2024-03-19 21:43:58,032 - logger.py:50 - Epoch: [136][450/500] loss: 0.87106, MAE: 0.44656, time/step=2001ms, lr=2.05e-06
2024-03-19 21:44:01,416 - logger.py:50 - Epoch: [11] train LOSS: 0.93275, val LOSS: 0.50811, test LOSS: 0.47081, Time: 613.19s
2024-03-19 21:44:01,418 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 21:45:03,135 - logger.py:50 - Epoch: [11]EMA val MAE: 0.43797, EMA test MAE: 0.42299, Time: 674.91s
2024-03-19 21:45:03,136 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 21:45:04,454 - logger.py:50 - Epoch: [12][0/500] loss: 0.38570, MAE: 0.43880, time/step=1316ms, lr=4.92e-05
2024-03-19 21:45:34,948 - logger.py:50 - Epoch: [136][499/500] loss: 0.83387, MAE: 0.44453, time/step=1999ms, lr=2.05e-06
2024-03-19 21:45:59,158 - logger.py:50 - Epoch: [12][50/500] loss: 0.62010, MAE: 0.44075, time/step=1098ms, lr=4.92e-05
2024-03-19 21:46:54,938 - logger.py:50 - Epoch: [12][100/500] loss: 0.57005, MAE: 0.43432, time/step=1107ms, lr=4.92e-05
2024-03-19 21:47:38,362 - logger.py:50 - Epoch: [136] train LOSS: 0.83387, val LOSS: 0.44511, test LOSS: 0.42991, Time: 1122.99s
2024-03-19 21:47:38,363 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 21:47:40,779 - logger.py:50 - Epoch: [137][0/500] loss: 0.39646, MAE: 0.40053, time/step=2412ms, lr=1.90e-06
2024-03-19 21:47:50,111 - logger.py:50 - Epoch: [12][150/500] loss: 0.94899, MAE: 0.44627, time/step=1106ms, lr=4.92e-05
2024-03-19 21:48:45,136 - logger.py:50 - Epoch: [12][200/500] loss: 1.41634, MAE: 0.45168, time/step=1104ms, lr=4.92e-05
2024-03-19 21:49:20,595 - logger.py:50 - Epoch: [137][50/500] loss: 0.51143, MAE: 0.43520, time/step=2004ms, lr=1.90e-06
2024-03-19 21:49:40,907 - logger.py:50 - Epoch: [12][250/500] loss: 1.23518, MAE: 0.44731, time/step=1107ms, lr=4.92e-05
2024-03-19 21:50:35,503 - logger.py:50 - Epoch: [12][300/500] loss: 1.11820, MAE: 0.44738, time/step=1104ms, lr=4.92e-05
2024-03-19 21:51:04,399 - logger.py:50 - Epoch: [137][100/500] loss: 0.99152, MAE: 0.44745, time/step=2040ms, lr=1.90e-06
2024-03-19 21:51:30,899 - logger.py:50 - Epoch: [12][350/500] loss: 1.03293, MAE: 0.44502, time/step=1105ms, lr=4.92e-05
2024-03-19 21:52:25,112 - logger.py:50 - Epoch: [12][400/500] loss: 0.97190, MAE: 0.44557, time/step=1102ms, lr=4.92e-05
2024-03-19 21:52:39,894 - logger.py:50 - Epoch: [137][150/500] loss: 0.83471, MAE: 0.44557, time/step=1997ms, lr=1.90e-06
2024-03-19 21:53:19,771 - logger.py:50 - Epoch: [12][450/500] loss: 0.91787, MAE: 0.44486, time/step=1101ms, lr=4.92e-05
2024-03-19 21:54:13,906 - logger.py:50 - Epoch: [12][499/500] loss: 0.87610, MAE: 0.44434, time/step=1102ms, lr=4.92e-05
2024-03-19 21:54:22,183 - logger.py:50 - Epoch: [137][200/500] loss: 0.74938, MAE: 0.44434, time/step=2009ms, lr=1.90e-06
2024-03-19 21:55:16,272 - logger.py:50 - Epoch: [12] train LOSS: 0.87610, val LOSS: 0.50001, test LOSS: 0.46398, Time: 613.14s
2024-03-19 21:55:16,273 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 21:56:05,217 - logger.py:50 - Epoch: [137][250/500] loss: 0.68104, MAE: 0.44212, time/step=2019ms, lr=1.90e-06
2024-03-19 21:56:17,377 - logger.py:50 - Epoch: [12]EMA val MAE: 0.43804, EMA test MAE: 0.42306, Time: 674.24s
2024-03-19 21:56:17,378 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 21:56:18,577 - logger.py:50 - Epoch: [13][0/500] loss: 0.44351, MAE: 0.44018, time/step=1197ms, lr=4.91e-05
2024-03-19 21:57:13,134 - logger.py:50 - Epoch: [13][50/500] loss: 0.53402, MAE: 0.44203, time/step=1093ms, lr=4.91e-05
2024-03-19 21:57:43,566 - logger.py:50 - Epoch: [137][300/500] loss: 0.65394, MAE: 0.44238, time/step=2011ms, lr=1.90e-06
2024-03-19 21:58:07,768 - logger.py:50 - Epoch: [13][100/500] loss: 0.50129, MAE: 0.42898, time/step=1093ms, lr=4.91e-05
2024-03-19 21:59:01,264 - logger.py:50 - Epoch: [13][150/500] loss: 0.55138, MAE: 0.43364, time/step=1085ms, lr=4.91e-05
2024-03-19 21:59:19,148 - logger.py:50 - Epoch: [137][350/500] loss: 0.63812, MAE: 0.44122, time/step=1997ms, lr=1.90e-06
2024-03-19 21:59:56,461 - logger.py:50 - Epoch: [13][200/500] loss: 0.56835, MAE: 0.43655, time/step=1090ms, lr=4.91e-05
2024-03-19 22:00:50,910 - logger.py:50 - Epoch: [13][250/500] loss: 0.57598, MAE: 0.43753, time/step=1090ms, lr=4.91e-05
2024-03-19 22:00:54,494 - logger.py:50 - Epoch: [137][400/500] loss: 0.61917, MAE: 0.44109, time/step=1985ms, lr=1.90e-06
2024-03-19 22:01:47,173 - logger.py:50 - Epoch: [13][300/500] loss: 0.56205, MAE: 0.43738, time/step=1096ms, lr=4.91e-05
2024-03-19 22:02:34,354 - logger.py:50 - Epoch: [137][450/500] loss: 0.60794, MAE: 0.44121, time/step=1987ms, lr=1.90e-06
2024-03-19 22:02:42,563 - logger.py:50 - Epoch: [13][350/500] loss: 0.54892, MAE: 0.43711, time/step=1097ms, lr=4.91e-05
2024-03-19 22:03:38,343 - logger.py:50 - Epoch: [13][400/500] loss: 0.69938, MAE: 0.44017, time/step=1100ms, lr=4.91e-05
2024-03-19 22:04:04,595 - logger.py:50 - Epoch: [137][499/500] loss: 0.83429, MAE: 0.44449, time/step=1972ms, lr=1.90e-06
2024-03-19 22:04:33,614 - logger.py:50 - Epoch: [13][450/500] loss: 0.68727, MAE: 0.44093, time/step=1100ms, lr=4.91e-05
2024-03-19 22:05:25,893 - logger.py:50 - Epoch: [137] train LOSS: 0.83429, val LOSS: 0.44625, test LOSS: 0.43104, Time: 1067.53s
2024-03-19 22:05:25,894 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 22:05:27,210 - logger.py:50 - Epoch: [138][0/500] loss: 0.16030, MAE: 0.33200, time/step=1313ms, lr=1.77e-06
2024-03-19 22:05:28,214 - logger.py:50 - Epoch: [13][499/500] loss: 0.91223, MAE: 0.44442, time/step=1102ms, lr=4.91e-05
2024-03-19 22:06:26,472 - logger.py:50 - Epoch: [138][50/500] loss: 0.52405, MAE: 0.44772, time/step=1188ms, lr=1.77e-06
2024-03-19 22:06:31,087 - logger.py:50 - Epoch: [13] train LOSS: 0.91223, val LOSS: 0.54195, test LOSS: 0.48578, Time: 613.71s
2024-03-19 22:06:31,089 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 22:07:23,073 - logger.py:50 - Epoch: [138][100/500] loss: 1.69367, MAE: 0.45612, time/step=1160ms, lr=1.77e-06
2024-03-19 22:07:33,105 - logger.py:50 - Epoch: [13]EMA val MAE: 0.43810, EMA test MAE: 0.42311, Time: 675.73s
2024-03-19 22:07:33,106 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 22:07:34,296 - logger.py:50 - Epoch: [14][0/500] loss: 0.27945, MAE: 0.39957, time/step=1188ms, lr=4.90e-05
2024-03-19 22:08:21,040 - logger.py:50 - Epoch: [138][150/500] loss: 1.27888, MAE: 0.44768, time/step=1160ms, lr=1.77e-06
2024-03-19 22:08:29,577 - logger.py:50 - Epoch: [14][50/500] loss: 0.43739, MAE: 0.43205, time/step=1107ms, lr=4.90e-05
2024-03-19 22:09:17,511 - logger.py:50 - Epoch: [138][200/500] loss: 1.09071, MAE: 0.44488, time/step=1152ms, lr=1.77e-06
2024-03-19 22:09:25,093 - logger.py:50 - Epoch: [14][100/500] loss: 0.48214, MAE: 0.43023, time/step=1109ms, lr=4.90e-05
2024-03-19 22:10:15,659 - logger.py:50 - Epoch: [138][250/500] loss: 0.96287, MAE: 0.44256, time/step=1154ms, lr=1.77e-06
2024-03-19 22:10:19,037 - logger.py:50 - Epoch: [14][150/500] loss: 1.66914, MAE: 0.45593, time/step=1099ms, lr=4.90e-05
2024-03-19 22:11:12,756 - logger.py:50 - Epoch: [138][300/500] loss: 1.06194, MAE: 0.44624, time/step=1152ms, lr=1.77e-06
2024-03-19 22:11:13,887 - logger.py:50 - Epoch: [14][200/500] loss: 1.41185, MAE: 0.45188, time/step=1098ms, lr=4.90e-05
2024-03-19 22:12:09,685 - logger.py:50 - Epoch: [14][250/500] loss: 1.24141, MAE: 0.44952, time/step=1102ms, lr=4.90e-05
2024-03-19 22:12:10,168 - logger.py:50 - Epoch: [138][350/500] loss: 0.97233, MAE: 0.44459, time/step=1152ms, lr=1.77e-06
2024-03-19 22:13:04,375 - logger.py:50 - Epoch: [14][300/500] loss: 1.11776, MAE: 0.44832, time/step=1101ms, lr=4.90e-05
2024-03-19 22:13:06,126 - logger.py:50 - Epoch: [138][400/500] loss: 0.91276, MAE: 0.44545, time/step=1148ms, lr=1.77e-06
2024-03-19 22:13:55,849 - logger.py:50 - Epoch: [138][450/500] loss: 0.86155, MAE: 0.44304, time/step=1131ms, lr=1.77e-06
2024-03-19 22:14:00,512 - logger.py:50 - Epoch: [14][350/500] loss: 1.02657, MAE: 0.44627, time/step=1104ms, lr=4.90e-05
2024-03-19 22:14:46,085 - logger.py:50 - Epoch: [138][499/500] loss: 0.83543, MAE: 0.44452, time/step=1120ms, lr=1.77e-06
2024-03-19 22:14:55,537 - logger.py:50 - Epoch: [14][400/500] loss: 0.97325, MAE: 0.44538, time/step=1103ms, lr=4.90e-05
2024-03-19 22:15:43,261 - logger.py:50 - Epoch: [138] train LOSS: 0.83543, val LOSS: 0.44442, test LOSS: 0.42910, Time: 617.37s
2024-03-19 22:15:43,262 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 22:15:43,960 - logger.py:50 - Epoch: [139][0/500] loss: 0.49382, MAE: 0.41071, time/step=694ms, lr=1.65e-06
2024-03-19 22:15:51,861 - logger.py:50 - Epoch: [14][450/500] loss: 0.91750, MAE: 0.44484, time/step=1106ms, lr=4.90e-05
2024-03-19 22:16:35,558 - logger.py:50 - Epoch: [139][50/500] loss: 0.51446, MAE: 0.44588, time/step=1025ms, lr=1.65e-06
2024-03-19 22:16:46,135 - logger.py:50 - Epoch: [14][499/500] loss: 0.87524, MAE: 0.44436, time/step=1106ms, lr=4.90e-05
2024-03-19 22:17:27,051 - logger.py:50 - Epoch: [139][100/500] loss: 1.66733, MAE: 0.46657, time/step=1028ms, lr=1.65e-06
2024-03-19 22:17:48,603 - logger.py:50 - Epoch: [14] train LOSS: 0.87524, val LOSS: 0.51381, test LOSS: 0.48589, Time: 615.50s
2024-03-19 22:17:48,604 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 22:18:19,794 - logger.py:50 - Epoch: [139][150/500] loss: 1.24610, MAE: 0.44906, time/step=1037ms, lr=1.65e-06
2024-03-19 22:18:50,783 - logger.py:50 - Epoch: [14]EMA val MAE: 0.43823, EMA test MAE: 0.42324, Time: 677.68s
2024-03-19 22:18:50,784 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 22:18:52,085 - logger.py:50 - Epoch: [15][0/500] loss: 0.33783, MAE: 0.38145, time/step=1298ms, lr=4.88e-05
2024-03-19 22:19:11,945 - logger.py:50 - Epoch: [139][200/500] loss: 1.06645, MAE: 0.44748, time/step=1038ms, lr=1.65e-06
2024-03-19 22:19:46,919 - logger.py:50 - Epoch: [15][50/500] loss: 0.56353, MAE: 0.43191, time/step=1101ms, lr=4.88e-05
2024-03-19 22:20:04,076 - logger.py:50 - Epoch: [139][250/500] loss: 0.94751, MAE: 0.44639, time/step=1039ms, lr=1.65e-06
2024-03-19 22:20:42,381 - logger.py:50 - Epoch: [15][100/500] loss: 0.53873, MAE: 0.44042, time/step=1105ms, lr=4.88e-05
2024-03-19 22:20:54,993 - logger.py:50 - Epoch: [139][300/500] loss: 0.87234, MAE: 0.44509, time/step=1036ms, lr=1.65e-06
2024-03-19 22:21:36,986 - logger.py:50 - Epoch: [15][150/500] loss: 0.52912, MAE: 0.44089, time/step=1101ms, lr=4.88e-05
2024-03-19 22:21:46,195 - logger.py:50 - Epoch: [139][350/500] loss: 0.83252, MAE: 0.44298, time/step=1034ms, lr=1.65e-06
2024-03-19 22:22:32,342 - logger.py:50 - Epoch: [15][200/500] loss: 0.52639, MAE: 0.44117, time/step=1102ms, lr=4.88e-05
2024-03-19 22:22:37,015 - logger.py:50 - Epoch: [139][400/500] loss: 0.92855, MAE: 0.44699, time/step=1032ms, lr=1.65e-06
2024-03-19 22:23:27,210 - logger.py:50 - Epoch: [15][250/500] loss: 0.52216, MAE: 0.44127, time/step=1101ms, lr=4.88e-05
2024-03-19 22:23:28,215 - logger.py:50 - Epoch: [139][450/500] loss: 0.87530, MAE: 0.44445, time/step=1031ms, lr=1.65e-06
2024-03-19 22:24:19,464 - logger.py:50 - Epoch: [139][499/500] loss: 0.83340, MAE: 0.44450, time/step=1032ms, lr=1.65e-06
2024-03-19 22:24:22,811 - logger.py:50 - Epoch: [15][300/500] loss: 0.74593, MAE: 0.44680, time/step=1103ms, lr=4.88e-05
2024-03-19 22:25:17,258 - logger.py:50 - Epoch: [15][350/500] loss: 0.71452, MAE: 0.44515, time/step=1101ms, lr=4.88e-05
2024-03-19 22:25:17,597 - logger.py:50 - Epoch: [139] train LOSS: 0.83340, val LOSS: 0.44533, test LOSS: 0.43003, Time: 574.33s
2024-03-19 22:25:17,598 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 22:25:18,400 - logger.py:50 - Epoch: [140][0/500] loss: 0.60983, MAE: 0.32658, time/step=800ms, lr=1.54e-06
2024-03-19 22:26:10,797 - logger.py:50 - Epoch: [140][50/500] loss: 1.52127, MAE: 0.46148, time/step=1043ms, lr=1.54e-06
2024-03-19 22:26:11,840 - logger.py:50 - Epoch: [15][400/500] loss: 0.69031, MAE: 0.44208, time/step=1100ms, lr=4.88e-05
2024-03-19 22:27:03,127 - logger.py:50 - Epoch: [140][100/500] loss: 1.02136, MAE: 0.45115, time/step=1045ms, lr=1.54e-06
2024-03-19 22:27:07,874 - logger.py:50 - Epoch: [15][450/500] loss: 0.92960, MAE: 0.44616, time/step=1102ms, lr=4.88e-05
2024-03-19 22:27:54,492 - logger.py:50 - Epoch: [140][150/500] loss: 0.86508, MAE: 0.44887, time/step=1039ms, lr=1.54e-06
2024-03-19 22:28:02,061 - logger.py:50 - Epoch: [15][499/500] loss: 0.88554, MAE: 0.44445, time/step=1103ms, lr=4.88e-05
2024-03-19 22:28:46,751 - logger.py:50 - Epoch: [140][200/500] loss: 0.76842, MAE: 0.44651, time/step=1041ms, lr=1.54e-06
2024-03-19 22:29:04,598 - logger.py:50 - Epoch: [15] train LOSS: 0.88554, val LOSS: 0.65347, test LOSS: 0.47561, Time: 613.81s
2024-03-19 22:29:04,599 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 22:29:40,109 - logger.py:50 - Epoch: [140][250/500] loss: 0.71171, MAE: 0.44569, time/step=1046ms, lr=1.54e-06
2024-03-19 22:30:06,505 - logger.py:50 - Epoch: [15]EMA val MAE: 0.43837, EMA test MAE: 0.42339, Time: 675.72s
2024-03-19 22:30:06,506 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 22:30:07,837 - logger.py:50 - Epoch: [16][0/500] loss: 0.93668, MAE: 0.40767, time/step=1329ms, lr=4.86e-05
2024-03-19 22:30:32,071 - logger.py:50 - Epoch: [140][300/500] loss: 0.67014, MAE: 0.44475, time/step=1045ms, lr=1.54e-06
2024-03-19 22:31:03,398 - logger.py:50 - Epoch: [16][50/500] loss: 0.51190, MAE: 0.43763, time/step=1115ms, lr=4.86e-05
2024-03-19 22:31:23,843 - logger.py:50 - Epoch: [140][350/500] loss: 0.64158, MAE: 0.44421, time/step=1043ms, lr=1.54e-06
2024-03-19 22:31:57,331 - logger.py:50 - Epoch: [16][100/500] loss: 0.52010, MAE: 0.43399, time/step=1097ms, lr=4.86e-05
2024-03-19 22:32:16,378 - logger.py:50 - Epoch: [140][400/500] loss: 0.61886, MAE: 0.44382, time/step=1044ms, lr=1.54e-06
2024-03-19 22:32:51,794 - logger.py:50 - Epoch: [16][150/500] loss: 1.02042, MAE: 0.44237, time/step=1095ms, lr=4.86e-05
2024-03-19 22:33:06,999 - logger.py:50 - Epoch: [140][450/500] loss: 0.87335, MAE: 0.44703, time/step=1041ms, lr=1.54e-06
2024-03-19 22:33:46,794 - logger.py:50 - Epoch: [16][200/500] loss: 0.89020, MAE: 0.44090, time/step=1096ms, lr=4.86e-05
2024-03-19 22:33:57,681 - logger.py:50 - Epoch: [140][499/500] loss: 0.83321, MAE: 0.44453, time/step=1040ms, lr=1.54e-06
2024-03-19 22:34:41,393 - logger.py:50 - Epoch: [16][250/500] loss: 1.52468, MAE: 0.44703, time/step=1095ms, lr=4.86e-05
2024-03-19 22:34:55,783 - logger.py:50 - Epoch: [140] train LOSS: 0.83321, val LOSS: 0.44472, test LOSS: 0.42952, Time: 578.19s
2024-03-19 22:34:55,784 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 22:34:56,520 - logger.py:50 - Epoch: [141][0/500] loss: 0.58763, MAE: 0.45804, time/step=734ms, lr=1.43e-06
2024-03-19 22:35:36,604 - logger.py:50 - Epoch: [16][300/500] loss: 1.35106, MAE: 0.44556, time/step=1097ms, lr=4.86e-05
2024-03-19 22:35:47,813 - logger.py:50 - Epoch: [141][50/500] loss: 0.49951, MAE: 0.42349, time/step=1020ms, lr=1.43e-06
2024-03-19 22:36:32,042 - logger.py:50 - Epoch: [16][350/500] loss: 1.23152, MAE: 0.44656, time/step=1098ms, lr=4.86e-05
2024-03-19 22:36:39,849 - logger.py:50 - Epoch: [141][100/500] loss: 0.47922, MAE: 0.43061, time/step=1030ms, lr=1.43e-06
2024-03-19 22:37:26,723 - logger.py:50 - Epoch: [16][400/500] loss: 1.16039, MAE: 0.44652, time/step=1098ms, lr=4.86e-05
2024-03-19 22:37:32,025 - logger.py:50 - Epoch: [141][150/500] loss: 0.83954, MAE: 0.44116, time/step=1035ms, lr=1.43e-06
2024-03-19 22:38:21,589 - logger.py:50 - Epoch: [16][450/500] loss: 1.08765, MAE: 0.44482, time/step=1098ms, lr=4.86e-05
2024-03-19 22:38:23,103 - logger.py:50 - Epoch: [141][200/500] loss: 0.74156, MAE: 0.43976, time/step=1031ms, lr=1.43e-06
2024-03-19 22:39:14,137 - logger.py:50 - Epoch: [141][250/500] loss: 1.16423, MAE: 0.44796, time/step=1029ms, lr=1.43e-06
2024-03-19 22:39:16,550 - logger.py:50 - Epoch: [16][499/500] loss: 1.02857, MAE: 0.44403, time/step=1100ms, lr=4.86e-05
2024-03-19 22:40:04,727 - logger.py:50 - Epoch: [141][300/500] loss: 1.06155, MAE: 0.44452, time/step=1026ms, lr=1.43e-06
2024-03-19 22:40:18,400 - logger.py:50 - Epoch: [16] train LOSS: 1.02857, val LOSS: 0.50277, test LOSS: 0.47371, Time: 611.89s
2024-03-19 22:40:18,401 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 22:40:56,574 - logger.py:50 - Epoch: [141][350/500] loss: 0.97789, MAE: 0.44509, time/step=1028ms, lr=1.43e-06
2024-03-19 22:41:19,861 - logger.py:50 - Epoch: [16]EMA val MAE: 0.43859, EMA test MAE: 0.42361, Time: 673.35s
2024-03-19 22:41:19,862 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 22:41:21,033 - logger.py:50 - Epoch: [17][0/500] loss: 0.40532, MAE: 0.37323, time/step=1169ms, lr=4.85e-05
2024-03-19 22:41:48,229 - logger.py:50 - Epoch: [141][400/500] loss: 0.91739, MAE: 0.44389, time/step=1029ms, lr=1.43e-06
2024-03-19 22:42:16,483 - logger.py:50 - Epoch: [17][50/500] loss: 0.50233, MAE: 0.43479, time/step=1110ms, lr=4.85e-05
2024-03-19 22:42:39,942 - logger.py:50 - Epoch: [141][450/500] loss: 0.86869, MAE: 0.44310, time/step=1029ms, lr=1.43e-06
2024-03-19 22:43:11,000 - logger.py:50 - Epoch: [17][100/500] loss: 1.46573, MAE: 0.45573, time/step=1100ms, lr=4.85e-05
2024-03-19 22:43:31,819 - logger.py:50 - Epoch: [141][499/500] loss: 0.83377, MAE: 0.44452, time/step=1032ms, lr=1.43e-06
2024-03-19 22:44:05,298 - logger.py:50 - Epoch: [17][150/500] loss: 1.17094, MAE: 0.44985, time/step=1096ms, lr=4.85e-05
2024-03-19 22:44:28,801 - logger.py:50 - Epoch: [141] train LOSS: 0.83377, val LOSS: 0.44539, test LOSS: 0.43007, Time: 573.02s
2024-03-19 22:44:28,803 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 22:44:29,599 - logger.py:50 - Epoch: [142][0/500] loss: 0.20738, MAE: 0.50319, time/step=794ms, lr=1.34e-06
2024-03-19 22:45:00,527 - logger.py:50 - Epoch: [17][200/500] loss: 1.05562, MAE: 0.45207, time/step=1098ms, lr=4.85e-05
2024-03-19 22:45:20,907 - logger.py:50 - Epoch: [142][50/500] loss: 0.51005, MAE: 0.43259, time/step=1022ms, lr=1.34e-06
2024-03-19 22:45:55,117 - logger.py:50 - Epoch: [17][250/500] loss: 0.95070, MAE: 0.44829, time/step=1097ms, lr=4.85e-05
2024-03-19 22:46:12,369 - logger.py:50 - Epoch: [142][100/500] loss: 1.66765, MAE: 0.45213, time/step=1025ms, lr=1.34e-06
2024-03-19 22:46:50,467 - logger.py:50 - Epoch: [17][300/500] loss: 0.86575, MAE: 0.44576, time/step=1098ms, lr=4.85e-05
2024-03-19 22:47:03,874 - logger.py:50 - Epoch: [142][150/500] loss: 1.27396, MAE: 0.45082, time/step=1027ms, lr=1.34e-06
2024-03-19 22:47:44,733 - logger.py:50 - Epoch: [17][350/500] loss: 0.81546, MAE: 0.44432, time/step=1096ms, lr=4.85e-05
2024-03-19 22:47:54,567 - logger.py:50 - Epoch: [142][200/500] loss: 1.36374, MAE: 0.45367, time/step=1024ms, lr=1.34e-06
2024-03-19 22:48:40,197 - logger.py:50 - Epoch: [17][400/500] loss: 0.77247, MAE: 0.44293, time/step=1098ms, lr=4.85e-05
2024-03-19 22:48:45,549 - logger.py:50 - Epoch: [142][250/500] loss: 1.19805, MAE: 0.45230, time/step=1023ms, lr=1.34e-06
2024-03-19 22:49:35,095 - logger.py:50 - Epoch: [17][450/500] loss: 1.01810, MAE: 0.44695, time/step=1098ms, lr=4.85e-05
2024-03-19 22:49:36,920 - logger.py:50 - Epoch: [142][300/500] loss: 1.08236, MAE: 0.45142, time/step=1024ms, lr=1.34e-06
2024-03-19 22:50:28,092 - logger.py:50 - Epoch: [142][350/500] loss: 0.99354, MAE: 0.44786, time/step=1024ms, lr=1.34e-06
2024-03-19 22:50:29,201 - logger.py:50 - Epoch: [17][499/500] loss: 0.96499, MAE: 0.44422, time/step=1099ms, lr=4.85e-05
2024-03-19 22:51:19,792 - logger.py:50 - Epoch: [142][400/500] loss: 0.92378, MAE: 0.44466, time/step=1025ms, lr=1.34e-06
2024-03-19 22:51:31,015 - logger.py:50 - Epoch: [17] train LOSS: 0.96499, val LOSS: 0.51964, test LOSS: 0.46183, Time: 611.15s
2024-03-19 22:51:31,016 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 22:52:11,193 - logger.py:50 - Epoch: [142][450/500] loss: 0.87138, MAE: 0.44475, time/step=1025ms, lr=1.34e-06
2024-03-19 22:52:33,052 - logger.py:50 - Epoch: [17]EMA val MAE: 0.43871, EMA test MAE: 0.42372, Time: 673.19s
2024-03-19 22:52:33,053 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 22:52:33,867 - logger.py:50 - Epoch: [18][0/500] loss: 0.32352, MAE: 0.43498, time/step=811ms, lr=4.83e-05
2024-03-19 22:53:01,328 - logger.py:50 - Epoch: [142][499/500] loss: 0.83387, MAE: 0.44452, time/step=1025ms, lr=1.34e-06
2024-03-19 22:53:28,480 - logger.py:50 - Epoch: [18][50/500] loss: 0.52568, MAE: 0.43127, time/step=1087ms, lr=4.83e-05
2024-03-19 22:53:57,920 - logger.py:50 - Epoch: [142] train LOSS: 0.83387, val LOSS: 0.44534, test LOSS: 0.43016, Time: 569.12s
2024-03-19 22:53:57,921 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 22:53:59,163 - logger.py:50 - Epoch: [143][0/500] loss: 0.38861, MAE: 0.46343, time/step=1240ms, lr=1.26e-06
2024-03-19 22:54:22,997 - logger.py:50 - Epoch: [18][100/500] loss: 0.51717, MAE: 0.43142, time/step=1089ms, lr=4.83e-05
2024-03-19 22:54:49,427 - logger.py:50 - Epoch: [143][50/500] loss: 0.47454, MAE: 0.42393, time/step=1010ms, lr=1.26e-06
2024-03-19 22:55:18,351 - logger.py:50 - Epoch: [18][150/500] loss: 0.49044, MAE: 0.43457, time/step=1095ms, lr=4.83e-05
2024-03-19 22:55:41,202 - logger.py:50 - Epoch: [143][100/500] loss: 0.45570, MAE: 0.42969, time/step=1023ms, lr=1.26e-06
2024-03-19 22:56:14,219 - logger.py:50 - Epoch: [18][200/500] loss: 0.51672, MAE: 0.43808, time/step=1100ms, lr=4.83e-05
2024-03-19 22:56:33,003 - logger.py:50 - Epoch: [143][150/500] loss: 0.83922, MAE: 0.44578, time/step=1027ms, lr=1.26e-06
2024-03-19 22:57:09,248 - logger.py:50 - Epoch: [18][250/500] loss: 0.51445, MAE: 0.43727, time/step=1100ms, lr=4.83e-05
2024-03-19 22:57:24,600 - logger.py:50 - Epoch: [143][200/500] loss: 0.73891, MAE: 0.44312, time/step=1028ms, lr=1.26e-06
2024-03-19 22:58:03,802 - logger.py:50 - Epoch: [18][300/500] loss: 0.51315, MAE: 0.43873, time/step=1099ms, lr=4.83e-05
2024-03-19 22:58:15,592 - logger.py:50 - Epoch: [143][250/500] loss: 0.70130, MAE: 0.44089, time/step=1027ms, lr=1.26e-06
2024-03-19 22:58:58,646 - logger.py:50 - Epoch: [18][350/500] loss: 0.51976, MAE: 0.43845, time/step=1099ms, lr=4.83e-05
2024-03-19 22:59:07,359 - logger.py:50 - Epoch: [143][300/500] loss: 0.65962, MAE: 0.44212, time/step=1028ms, lr=1.26e-06
2024-03-19 22:59:54,746 - logger.py:50 - Epoch: [18][400/500] loss: 0.69631, MAE: 0.44212, time/step=1101ms, lr=4.83e-05
2024-03-19 22:59:59,248 - logger.py:50 - Epoch: [143][350/500] loss: 0.64153, MAE: 0.44206, time/step=1029ms, lr=1.26e-06
2024-03-19 23:00:49,855 - logger.py:50 - Epoch: [18][450/500] loss: 0.67875, MAE: 0.44105, time/step=1102ms, lr=4.83e-05
2024-03-19 23:00:51,056 - logger.py:50 - Epoch: [143][400/500] loss: 0.91360, MAE: 0.44638, time/step=1030ms, lr=1.26e-06
2024-03-19 23:01:41,860 - logger.py:50 - Epoch: [143][450/500] loss: 0.87091, MAE: 0.44436, time/step=1029ms, lr=1.26e-06
2024-03-19 23:01:42,307 - logger.py:50 - Epoch: [18][499/500] loss: 0.97869, MAE: 0.44423, time/step=1099ms, lr=4.83e-05
2024-03-19 23:02:32,244 - logger.py:50 - Epoch: [143][499/500] loss: 0.83347, MAE: 0.44443, time/step=1029ms, lr=1.26e-06
2024-03-19 23:02:44,107 - logger.py:50 - Epoch: [18] train LOSS: 0.97869, val LOSS: 0.95153, test LOSS: 0.50684, Time: 611.05s
2024-03-19 23:02:44,108 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 23:03:29,268 - logger.py:50 - Epoch: [143] train LOSS: 0.83347, val LOSS: 0.44633, test LOSS: 0.43108, Time: 571.35s
2024-03-19 23:03:29,269 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 23:03:30,414 - logger.py:50 - Epoch: [144][0/500] loss: 0.40548, MAE: 0.47652, time/step=1143ms, lr=1.19e-06
2024-03-19 23:03:45,572 - logger.py:50 - Epoch: [18]EMA val MAE: 0.43889, EMA test MAE: 0.42391, Time: 672.52s
2024-03-19 23:03:45,572 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 23:03:46,752 - logger.py:50 - Epoch: [19][0/500] loss: 0.24958, MAE: 0.44525, time/step=1177ms, lr=4.81e-05
2024-03-19 23:04:20,877 - logger.py:50 - Epoch: [144][50/500] loss: 0.56689, MAE: 0.43896, time/step=1012ms, lr=1.19e-06
2024-03-19 23:04:41,460 - logger.py:50 - Epoch: [19][50/500] loss: 0.66093, MAE: 0.43185, time/step=1096ms, lr=4.81e-05
2024-03-19 23:05:11,776 - logger.py:50 - Epoch: [144][100/500] loss: 0.51845, MAE: 0.43118, time/step=1015ms, lr=1.19e-06
2024-03-19 23:05:35,514 - logger.py:50 - Epoch: [19][100/500] loss: 1.79797, MAE: 0.46359, time/step=1089ms, lr=4.81e-05
2024-03-19 23:06:02,905 - logger.py:50 - Epoch: [144][150/500] loss: 0.50766, MAE: 0.43252, time/step=1017ms, lr=1.19e-06
2024-03-19 23:06:29,816 - logger.py:50 - Epoch: [19][150/500] loss: 1.34565, MAE: 0.45605, time/step=1088ms, lr=4.81e-05
2024-03-19 23:06:54,401 - logger.py:50 - Epoch: [144][200/500] loss: 0.50448, MAE: 0.43998, time/step=1021ms, lr=1.19e-06
2024-03-19 23:07:24,325 - logger.py:50 - Epoch: [19][200/500] loss: 1.13120, MAE: 0.45022, time/step=1088ms, lr=4.81e-05
2024-03-19 23:07:46,206 - logger.py:50 - Epoch: [144][250/500] loss: 0.51716, MAE: 0.43991, time/step=1024ms, lr=1.19e-06
2024-03-19 23:08:19,187 - logger.py:50 - Epoch: [19][250/500] loss: 1.00880, MAE: 0.44417, time/step=1090ms, lr=4.81e-05
2024-03-19 23:08:37,208 - logger.py:50 - Epoch: [144][300/500] loss: 0.51007, MAE: 0.43951, time/step=1023ms, lr=1.19e-06
2024-03-19 23:09:14,950 - logger.py:50 - Epoch: [19][300/500] loss: 0.93889, MAE: 0.44396, time/step=1094ms, lr=4.81e-05
2024-03-19 23:09:29,405 - logger.py:50 - Epoch: [144][350/500] loss: 0.50329, MAE: 0.43957, time/step=1026ms, lr=1.19e-06
2024-03-19 23:10:10,948 - logger.py:50 - Epoch: [19][350/500] loss: 0.86965, MAE: 0.44220, time/step=1098ms, lr=4.81e-05
2024-03-19 23:10:19,881 - logger.py:50 - Epoch: [144][400/500] loss: 0.63783, MAE: 0.44180, time/step=1024ms, lr=1.19e-06
2024-03-19 23:11:05,461 - logger.py:50 - Epoch: [19][400/500] loss: 1.00514, MAE: 0.44550, time/step=1097ms, lr=4.81e-05
2024-03-19 23:11:11,617 - logger.py:50 - Epoch: [144][450/500] loss: 0.61525, MAE: 0.44101, time/step=1025ms, lr=1.19e-06
2024-03-19 23:12:01,038 - logger.py:50 - Epoch: [19][450/500] loss: 0.95836, MAE: 0.44546, time/step=1099ms, lr=4.81e-05
2024-03-19 23:12:01,825 - logger.py:50 - Epoch: [144][499/500] loss: 0.83295, MAE: 0.44455, time/step=1025ms, lr=1.19e-06
2024-03-19 23:12:54,929 - logger.py:50 - Epoch: [19][499/500] loss: 0.91254, MAE: 0.44472, time/step=1099ms, lr=4.81e-05
2024-03-19 23:12:58,461 - logger.py:50 - Epoch: [144] train LOSS: 0.83295, val LOSS: 0.44464, test LOSS: 0.42937, Time: 569.19s
2024-03-19 23:12:58,462 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 23:12:59,075 - logger.py:50 - Epoch: [145][0/500] loss: 0.88222, MAE: 0.41424, time/step=610ms, lr=1.13e-06
2024-03-19 23:13:51,051 - logger.py:50 - Epoch: [145][50/500] loss: 0.54547, MAE: 0.43594, time/step=1031ms, lr=1.13e-06
2024-03-19 23:13:56,765 - logger.py:50 - Epoch: [19] train LOSS: 0.91254, val LOSS: 0.49492, test LOSS: 0.46624, Time: 611.19s
2024-03-19 23:13:56,765 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 23:14:41,317 - logger.py:50 - Epoch: [145][100/500] loss: 0.51794, MAE: 0.44049, time/step=1018ms, lr=1.13e-06
2024-03-19 23:14:58,859 - logger.py:50 - Epoch: [19]EMA val MAE: 0.43908, EMA test MAE: 0.42410, Time: 673.29s
2024-03-19 23:14:58,860 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 23:14:59,604 - logger.py:50 - Epoch: [20][0/500] loss: 0.44036, MAE: 0.47421, time/step=742ms, lr=4.79e-05
2024-03-19 23:15:32,381 - logger.py:50 - Epoch: [145][150/500] loss: 0.49005, MAE: 0.43921, time/step=1019ms, lr=1.13e-06
2024-03-19 23:15:55,216 - logger.py:50 - Epoch: [20][50/500] loss: 0.47278, MAE: 0.43082, time/step=1105ms, lr=4.79e-05
2024-03-19 23:16:23,703 - logger.py:50 - Epoch: [145][200/500] loss: 1.06796, MAE: 0.44789, time/step=1021ms, lr=1.13e-06
2024-03-19 23:16:49,058 - logger.py:50 - Epoch: [20][100/500] loss: 0.48928, MAE: 0.43735, time/step=1091ms, lr=4.79e-05
2024-03-19 23:17:14,756 - logger.py:50 - Epoch: [145][250/500] loss: 0.95093, MAE: 0.44397, time/step=1021ms, lr=1.13e-06
2024-03-19 23:17:44,486 - logger.py:50 - Epoch: [20][150/500] loss: 0.47974, MAE: 0.43967, time/step=1097ms, lr=4.79e-05
2024-03-19 23:18:05,140 - logger.py:50 - Epoch: [145][300/500] loss: 0.88371, MAE: 0.44318, time/step=1019ms, lr=1.13e-06
2024-03-19 23:18:39,938 - logger.py:50 - Epoch: [20][200/500] loss: 0.49675, MAE: 0.44052, time/step=1100ms, lr=4.79e-05
2024-03-19 23:18:55,591 - logger.py:50 - Epoch: [145][350/500] loss: 0.83142, MAE: 0.44249, time/step=1017ms, lr=1.13e-06
2024-03-19 23:19:34,383 - logger.py:50 - Epoch: [20][250/500] loss: 1.02348, MAE: 0.44707, time/step=1098ms, lr=4.79e-05
2024-03-19 23:19:46,503 - logger.py:50 - Epoch: [145][400/500] loss: 0.77944, MAE: 0.44214, time/step=1018ms, lr=1.13e-06
2024-03-19 23:20:30,073 - logger.py:50 - Epoch: [20][300/500] loss: 0.92478, MAE: 0.44430, time/step=1100ms, lr=4.79e-05
2024-03-19 23:20:36,700 - logger.py:50 - Epoch: [145][450/500] loss: 0.74379, MAE: 0.44095, time/step=1016ms, lr=1.13e-06
2024-03-19 23:21:24,342 - logger.py:50 - Epoch: [20][350/500] loss: 0.86627, MAE: 0.44274, time/step=1098ms, lr=4.79e-05
2024-03-19 23:21:27,210 - logger.py:50 - Epoch: [145][499/500] loss: 0.83366, MAE: 0.44449, time/step=1017ms, lr=1.13e-06
2024-03-19 23:22:18,577 - logger.py:50 - Epoch: [20][400/500] loss: 0.82750, MAE: 0.44335, time/step=1097ms, lr=4.79e-05
2024-03-19 23:22:23,846 - logger.py:50 - Epoch: [145] train LOSS: 0.83366, val LOSS: 0.44598, test LOSS: 0.43066, Time: 565.38s
2024-03-19 23:22:23,847 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 23:22:24,991 - logger.py:50 - Epoch: [146][0/500] loss: 0.67570, MAE: 0.54028, time/step=1142ms, lr=1.09e-06
2024-03-19 23:23:14,104 - logger.py:50 - Epoch: [20][450/500] loss: 0.79153, MAE: 0.44256, time/step=1098ms, lr=4.79e-05
2024-03-19 23:23:16,430 - logger.py:50 - Epoch: [146][50/500] loss: 2.78673, MAE: 0.48542, time/step=1031ms, lr=1.09e-06
2024-03-19 23:24:05,975 - logger.py:50 - Epoch: [146][100/500] loss: 1.65232, MAE: 0.45378, time/step=1011ms, lr=1.09e-06
2024-03-19 23:24:07,464 - logger.py:50 - Epoch: [20][499/500] loss: 0.89266, MAE: 0.44413, time/step=1097ms, lr=4.79e-05
2024-03-19 23:24:57,634 - logger.py:50 - Epoch: [146][150/500] loss: 1.26016, MAE: 0.44801, time/step=1018ms, lr=1.09e-06
2024-03-19 23:25:08,815 - logger.py:50 - Epoch: [20] train LOSS: 0.89266, val LOSS: 0.55464, test LOSS: 0.48488, Time: 609.96s
2024-03-19 23:25:08,816 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 23:25:49,381 - logger.py:50 - Epoch: [146][200/500] loss: 1.06932, MAE: 0.44359, time/step=1023ms, lr=1.09e-06
2024-03-19 23:26:10,735 - logger.py:50 - Epoch: [20]EMA val MAE: 0.43925, EMA test MAE: 0.42427, Time: 671.88s
2024-03-19 23:26:10,736 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 23:26:11,981 - logger.py:50 - Epoch: [21][0/500] loss: 0.32169, MAE: 0.56295, time/step=1242ms, lr=4.77e-05
2024-03-19 23:26:41,050 - logger.py:50 - Epoch: [146][250/500] loss: 0.95780, MAE: 0.44209, time/step=1025ms, lr=1.09e-06
2024-03-19 23:27:06,385 - logger.py:50 - Epoch: [21][50/500] loss: 2.83084, MAE: 0.48053, time/step=1091ms, lr=4.77e-05
2024-03-19 23:27:32,372 - logger.py:50 - Epoch: [146][300/500] loss: 0.87927, MAE: 0.44284, time/step=1025ms, lr=1.09e-06
2024-03-19 23:28:01,018 - logger.py:50 - Epoch: [21][100/500] loss: 1.69938, MAE: 0.46675, time/step=1092ms, lr=4.77e-05
2024-03-19 23:28:24,717 - logger.py:50 - Epoch: [146][350/500] loss: 0.97006, MAE: 0.44725, time/step=1028ms, lr=1.09e-06
2024-03-19 23:28:54,541 - logger.py:50 - Epoch: [21][150/500] loss: 1.32065, MAE: 0.45544, time/step=1085ms, lr=4.77e-05
2024-03-19 23:29:15,540 - logger.py:50 - Epoch: [146][400/500] loss: 0.91645, MAE: 0.44440, time/step=1027ms, lr=1.09e-06
2024-03-19 23:29:50,273 - logger.py:50 - Epoch: [21][200/500] loss: 1.11504, MAE: 0.45263, time/step=1092ms, lr=4.77e-05
2024-03-19 23:30:07,478 - logger.py:50 - Epoch: [146][450/500] loss: 0.87136, MAE: 0.44390, time/step=1028ms, lr=1.09e-06
2024-03-19 23:30:45,896 - logger.py:50 - Epoch: [21][250/500] loss: 0.98478, MAE: 0.44829, time/step=1096ms, lr=4.77e-05
2024-03-19 23:30:57,840 - logger.py:50 - Epoch: [146][499/500] loss: 0.83329, MAE: 0.44447, time/step=1028ms, lr=1.09e-06
2024-03-19 23:31:40,668 - logger.py:50 - Epoch: [21][300/500] loss: 1.08980, MAE: 0.45048, time/step=1096ms, lr=4.77e-05
2024-03-19 23:31:54,412 - logger.py:50 - Epoch: [146] train LOSS: 0.83329, val LOSS: 0.44559, test LOSS: 0.43028, Time: 570.56s
2024-03-19 23:31:54,413 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 23:31:55,137 - logger.py:50 - Epoch: [147][0/500] loss: 0.19151, MAE: 0.35245, time/step=722ms, lr=1.05e-06
2024-03-19 23:32:36,251 - logger.py:50 - Epoch: [21][350/500] loss: 1.01121, MAE: 0.44721, time/step=1098ms, lr=4.77e-05
2024-03-19 23:32:46,521 - logger.py:50 - Epoch: [147][50/500] loss: 0.44236, MAE: 0.42349, time/step=1022ms, lr=1.05e-06
2024-03-19 23:33:31,301 - logger.py:50 - Epoch: [21][400/500] loss: 0.94959, MAE: 0.44637, time/step=1099ms, lr=4.77e-05
2024-03-19 23:33:37,669 - logger.py:50 - Epoch: [147][100/500] loss: 0.45548, MAE: 0.43115, time/step=1022ms, lr=1.05e-06
2024-03-19 23:34:26,529 - logger.py:50 - Epoch: [21][450/500] loss: 0.90666, MAE: 0.44573, time/step=1099ms, lr=4.77e-05
2024-03-19 23:34:28,923 - logger.py:50 - Epoch: [147][150/500] loss: 0.46037, MAE: 0.43177, time/step=1023ms, lr=1.05e-06
2024-03-19 23:35:19,958 - logger.py:50 - Epoch: [21][499/500] loss: 0.87409, MAE: 0.44436, time/step=1098ms, lr=4.77e-05
2024-03-19 23:35:20,695 - logger.py:50 - Epoch: [147][200/500] loss: 0.44671, MAE: 0.42995, time/step=1026ms, lr=1.05e-06
2024-03-19 23:36:11,837 - logger.py:50 - Epoch: [147][250/500] loss: 0.45381, MAE: 0.42840, time/step=1026ms, lr=1.05e-06
2024-03-19 23:36:22,293 - logger.py:50 - Epoch: [21] train LOSS: 0.87409, val LOSS: 0.52236, test LOSS: 0.48701, Time: 611.56s
2024-03-19 23:36:22,294 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 23:37:03,945 - logger.py:50 - Epoch: [147][300/500] loss: 0.46146, MAE: 0.43185, time/step=1028ms, lr=1.05e-06
2024-03-19 23:37:23,388 - logger.py:50 - Epoch: [21]EMA val MAE: 0.43941, EMA test MAE: 0.42443, Time: 672.65s
2024-03-19 23:37:23,389 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 23:37:24,626 - logger.py:50 - Epoch: [22][0/500] loss: 0.35729, MAE: 0.42565, time/step=1235ms, lr=4.74e-05
2024-03-19 23:37:54,427 - logger.py:50 - Epoch: [147][350/500] loss: 0.97410, MAE: 0.44377, time/step=1026ms, lr=1.05e-06
2024-03-19 23:38:19,147 - logger.py:50 - Epoch: [22][50/500] loss: 0.47031, MAE: 0.44485, time/step=1093ms, lr=4.74e-05
2024-03-19 23:38:45,952 - logger.py:50 - Epoch: [147][400/500] loss: 0.92196, MAE: 0.44701, time/step=1026ms, lr=1.05e-06
2024-03-19 23:39:14,501 - logger.py:50 - Epoch: [22][100/500] loss: 0.52891, MAE: 0.44463, time/step=1100ms, lr=4.74e-05
2024-03-19 23:39:36,943 - logger.py:50 - Epoch: [147][450/500] loss: 0.87440, MAE: 0.44566, time/step=1026ms, lr=1.05e-06
2024-03-19 23:40:09,536 - logger.py:50 - Epoch: [22][150/500] loss: 0.52347, MAE: 0.44415, time/step=1100ms, lr=4.74e-05
2024-03-19 23:40:26,651 - logger.py:50 - Epoch: [147][499/500] loss: 0.83234, MAE: 0.44453, time/step=1024ms, lr=1.05e-06
2024-03-19 23:41:04,364 - logger.py:50 - Epoch: [22][200/500] loss: 0.53105, MAE: 0.44114, time/step=1099ms, lr=4.74e-05
2024-03-19 23:41:24,021 - logger.py:50 - Epoch: [147] train LOSS: 0.83234, val LOSS: 0.44448, test LOSS: 0.42918, Time: 569.61s
2024-03-19 23:41:24,022 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 23:41:25,186 - logger.py:50 - Epoch: [148][0/500] loss: 0.57612, MAE: 0.35235, time/step=1162ms, lr=1.02e-06
2024-03-19 23:41:59,153 - logger.py:50 - Epoch: [22][250/500] loss: 0.99821, MAE: 0.44493, time/step=1099ms, lr=4.74e-05
2024-03-19 23:42:15,837 - logger.py:50 - Epoch: [148][50/500] loss: 1.55073, MAE: 0.46029, time/step=1016ms, lr=1.02e-06
2024-03-19 23:42:53,564 - logger.py:50 - Epoch: [22][300/500] loss: 0.91497, MAE: 0.44314, time/step=1097ms, lr=4.74e-05
2024-03-19 23:43:07,546 - logger.py:50 - Epoch: [148][100/500] loss: 1.01036, MAE: 0.45761, time/step=1025ms, lr=1.02e-06
2024-03-19 23:43:49,269 - logger.py:50 - Epoch: [22][350/500] loss: 1.01722, MAE: 0.44702, time/step=1099ms, lr=4.74e-05
2024-03-19 23:43:59,410 - logger.py:50 - Epoch: [148][150/500] loss: 0.83111, MAE: 0.44879, time/step=1029ms, lr=1.02e-06
2024-03-19 23:44:42,734 - logger.py:50 - Epoch: [22][400/500] loss: 0.96031, MAE: 0.44561, time/step=1096ms, lr=4.74e-05
2024-03-19 23:44:50,348 - logger.py:50 - Epoch: [148][200/500] loss: 1.33994, MAE: 0.46054, time/step=1026ms, lr=1.02e-06
2024-03-19 23:45:38,958 - logger.py:50 - Epoch: [22][450/500] loss: 0.90933, MAE: 0.44640, time/step=1099ms, lr=4.74e-05
2024-03-19 23:45:42,570 - logger.py:50 - Epoch: [148][250/500] loss: 1.16190, MAE: 0.45646, time/step=1030ms, lr=1.02e-06
2024-03-19 23:46:32,221 - logger.py:50 - Epoch: [22][499/500] loss: 0.86861, MAE: 0.44435, time/step=1098ms, lr=4.74e-05
2024-03-19 23:46:33,303 - logger.py:50 - Epoch: [148][300/500] loss: 1.05524, MAE: 0.45129, time/step=1028ms, lr=1.02e-06
2024-03-19 23:47:24,956 - logger.py:50 - Epoch: [148][350/500] loss: 0.97072, MAE: 0.44773, time/step=1028ms, lr=1.02e-06
2024-03-19 23:47:34,623 - logger.py:50 - Epoch: [22] train LOSS: 0.86861, val LOSS: 0.52980, test LOSS: 0.48488, Time: 611.23s
2024-03-19 23:47:34,624 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 23:48:16,390 - logger.py:50 - Epoch: [148][400/500] loss: 0.91085, MAE: 0.44572, time/step=1028ms, lr=1.02e-06
2024-03-19 23:48:36,189 - logger.py:50 - Epoch: [22]EMA val MAE: 0.43963, EMA test MAE: 0.42464, Time: 672.80s
2024-03-19 23:48:36,190 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 23:48:37,394 - logger.py:50 - Epoch: [23][0/500] loss: 0.60408, MAE: 0.51849, time/step=1203ms, lr=4.72e-05
2024-03-19 23:49:08,082 - logger.py:50 - Epoch: [148][450/500] loss: 0.86647, MAE: 0.44631, time/step=1029ms, lr=1.02e-06
2024-03-19 23:49:32,533 - logger.py:50 - Epoch: [23][50/500] loss: 0.49895, MAE: 0.44588, time/step=1105ms, lr=4.72e-05
2024-03-19 23:49:58,991 - logger.py:50 - Epoch: [148][499/500] loss: 0.83372, MAE: 0.44449, time/step=1030ms, lr=1.02e-06
2024-03-19 23:50:27,301 - logger.py:50 - Epoch: [23][100/500] loss: 0.52640, MAE: 0.43304, time/step=1100ms, lr=4.72e-05
2024-03-19 23:50:55,993 - logger.py:50 - Epoch: [148] train LOSS: 0.83372, val LOSS: 0.44426, test LOSS: 0.42889, Time: 571.97s
2024-03-19 23:50:55,994 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-19 23:50:57,128 - logger.py:50 - Epoch: [149][0/500] loss: 0.65402, MAE: 0.43368, time/step=1132ms, lr=1.01e-06
2024-03-19 23:51:21,963 - logger.py:50 - Epoch: [23][150/500] loss: 0.51505, MAE: 0.43269, time/step=1098ms, lr=4.72e-05
2024-03-19 23:51:47,847 - logger.py:50 - Epoch: [149][50/500] loss: 0.47208, MAE: 0.43428, time/step=1017ms, lr=1.01e-06
2024-03-19 23:52:18,188 - logger.py:50 - Epoch: [23][200/500] loss: 1.09966, MAE: 0.44402, time/step=1104ms, lr=4.72e-05
2024-03-19 23:52:41,198 - logger.py:50 - Epoch: [149][100/500] loss: 0.48266, MAE: 0.43478, time/step=1042ms, lr=1.01e-06
2024-03-19 23:53:13,225 - logger.py:50 - Epoch: [23][250/500] loss: 0.97624, MAE: 0.44376, time/step=1104ms, lr=4.72e-05
2024-03-19 23:53:31,984 - logger.py:50 - Epoch: [149][150/500] loss: 0.51917, MAE: 0.43700, time/step=1033ms, lr=1.01e-06
2024-03-19 23:54:09,265 - logger.py:50 - Epoch: [23][300/500] loss: 0.90934, MAE: 0.44395, time/step=1107ms, lr=4.72e-05
2024-03-19 23:54:23,082 - logger.py:50 - Epoch: [149][200/500] loss: 0.51641, MAE: 0.43557, time/step=1030ms, lr=1.01e-06
2024-03-19 23:55:05,214 - logger.py:50 - Epoch: [23][350/500] loss: 0.84830, MAE: 0.44224, time/step=1108ms, lr=4.72e-05
2024-03-19 23:55:14,512 - logger.py:50 - Epoch: [149][250/500] loss: 0.72665, MAE: 0.44270, time/step=1030ms, lr=1.01e-06
2024-03-19 23:56:01,098 - logger.py:50 - Epoch: [23][400/500] loss: 0.81138, MAE: 0.44208, time/step=1109ms, lr=4.72e-05
2024-03-19 23:56:05,729 - logger.py:50 - Epoch: [149][300/500] loss: 1.06397, MAE: 0.44915, time/step=1029ms, lr=1.01e-06
2024-03-19 23:56:56,469 - logger.py:50 - Epoch: [23][450/500] loss: 0.78140, MAE: 0.44052, time/step=1109ms, lr=4.72e-05
2024-03-19 23:56:57,595 - logger.py:50 - Epoch: [149][350/500] loss: 0.97693, MAE: 0.44686, time/step=1030ms, lr=1.01e-06
2024-03-19 23:57:49,751 - logger.py:50 - Epoch: [149][400/500] loss: 0.91577, MAE: 0.44665, time/step=1032ms, lr=1.01e-06
2024-03-19 23:57:50,849 - logger.py:50 - Epoch: [23][499/500] loss: 0.86897, MAE: 0.44447, time/step=1109ms, lr=4.72e-05
2024-03-19 23:58:41,205 - logger.py:50 - Epoch: [149][450/500] loss: 0.86779, MAE: 0.44483, time/step=1032ms, lr=1.01e-06
2024-03-19 23:58:52,811 - logger.py:50 - Epoch: [23] train LOSS: 0.86897, val LOSS: 0.59734, test LOSS: 0.46907, Time: 616.62s
2024-03-19 23:58:52,811 - logger.py:50 - Best -- epoch=0, train LOSS: 0.95263, val LOSS: 0.49469, test LOSS: 0.46383

2024-03-19 23:59:31,114 - logger.py:50 - Epoch: [149][499/500] loss: 0.83284, MAE: 0.44455, time/step=1030ms, lr=1.01e-06
2024-03-19 23:59:55,450 - logger.py:50 - Epoch: [23]EMA val MAE: 0.43981, EMA test MAE: 0.42482, Time: 679.26s
2024-03-19 23:59:55,451 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-19 23:59:56,589 - logger.py:50 - Epoch: [24][0/500] loss: 0.45707, MAE: 0.45825, time/step=1136ms, lr=4.70e-05
2024-03-20 00:00:28,510 - logger.py:50 - Epoch: [149] train LOSS: 0.83284, val LOSS: 0.44418, test LOSS: 0.42896, Time: 572.52s
2024-03-20 00:00:28,511 - logger.py:50 - Best -- epoch=59, train LOSS: 0.88776, val LOSS: 0.43616, test LOSS: 0.42112

2024-03-20 00:00:28,511 - logger.py:50 - fold_10 test LOSS:0.42112
2024-03-20 00:00:53,002 - logger.py:50 - Epoch: [24][50/500] loss: 0.53051, MAE: 0.42967, time/step=1128ms, lr=4.70e-05
2024-03-20 00:01:48,437 - logger.py:50 - Epoch: [24][100/500] loss: 0.54901, MAE: 0.43979, time/step=1119ms, lr=4.70e-05
2024-03-20 00:02:43,301 - logger.py:50 - Epoch: [24][150/500] loss: 0.53215, MAE: 0.43880, time/step=1112ms, lr=4.70e-05
2024-03-20 00:03:38,570 - logger.py:50 - Epoch: [24][200/500] loss: 0.52321, MAE: 0.43883, time/step=1110ms, lr=4.70e-05
2024-03-20 00:11:48,436 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:11:59,366 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1 (cuda:0)])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
  )
)
2024-03-20 00:11:59,380 - logger.py:50 - Number of params: 2978805
2024-03-20 00:12:01,956 - logger.py:50 - Epoch: [0][0/500] loss: 0.48203, MAE: 0.46209, time/step=2573ms, lr=1.00e-06
2024-03-20 00:13:00,629 - logger.py:50 - Epoch: [0][50/500] loss: 3.09758, MAE: 0.47354, time/step=1201ms, lr=1.00e-06
2024-03-20 00:13:57,992 - logger.py:50 - Epoch: [0][100/500] loss: 2.75516, MAE: 0.46932, time/step=1174ms, lr=1.00e-06
2024-03-20 00:14:54,671 - logger.py:50 - Epoch: [0][150/500] loss: 2.01417, MAE: 0.46395, time/step=1161ms, lr=1.00e-06
2024-03-20 00:15:51,243 - logger.py:50 - Epoch: [0][200/500] loss: 1.63366, MAE: 0.45651, time/step=1154ms, lr=1.00e-06
2024-03-20 00:16:47,414 - logger.py:50 - Epoch: [0][250/500] loss: 1.40352, MAE: 0.45460, time/step=1148ms, lr=1.00e-06
2024-03-20 00:17:43,699 - logger.py:50 - Epoch: [0][300/500] loss: 1.25083, MAE: 0.45214, time/step=1144ms, lr=1.00e-06
2024-03-20 00:18:38,373 - logger.py:50 - Epoch: [0][350/500] loss: 1.14246, MAE: 0.44744, time/step=1137ms, lr=1.00e-06
2024-03-20 00:19:33,791 - logger.py:50 - Epoch: [0][400/500] loss: 1.05262, MAE: 0.44624, time/step=1133ms, lr=1.00e-06
2024-03-20 00:20:27,428 - logger.py:50 - Epoch: [0][450/500] loss: 0.99688, MAE: 0.44520, time/step=1126ms, lr=1.00e-06
2024-03-20 00:21:19,899 - logger.py:50 - Epoch: [0][499/500] loss: 0.94857, MAE: 0.44377, time/step=1121ms, lr=1.00e-06
2024-03-20 00:22:20,927 - logger.py:50 - Epoch: [0] train LOSS: 0.94857, val LOSS: 0.49395, test LOSS: 0.46301, Time: 621.55s
2024-03-20 00:22:20,928 - logger.py:50 - Best -- epoch=0, train LOSS: 0.94857, val LOSS: 0.49395, test LOSS: 0.46301

2024-03-20 00:22:22,098 - logger.py:50 - Epoch: [1][0/500] loss: 0.59853, MAE: 0.46380, time/step=1168ms, lr=1.08e-05
2024-03-20 00:23:16,265 - logger.py:50 - Epoch: [1][50/500] loss: 0.50900, MAE: 0.44441, time/step=1085ms, lr=1.08e-05
2024-03-20 00:24:09,512 - logger.py:50 - Epoch: [1][100/500] loss: 0.48767, MAE: 0.44314, time/step=1075ms, lr=1.08e-05
2024-03-20 00:25:02,939 - logger.py:50 - Epoch: [1][150/500] loss: 0.51270, MAE: 0.44461, time/step=1073ms, lr=1.08e-05
2024-03-20 00:25:55,171 - logger.py:50 - Epoch: [1][200/500] loss: 0.51248, MAE: 0.44290, time/step=1066ms, lr=1.08e-05
2024-03-20 00:26:47,614 - logger.py:50 - Epoch: [1][250/500] loss: 0.51307, MAE: 0.44066, time/step=1062ms, lr=1.08e-05
2024-03-20 00:27:41,441 - logger.py:50 - Epoch: [1][300/500] loss: 1.18248, MAE: 0.45027, time/step=1065ms, lr=1.08e-05
2024-03-20 00:28:34,722 - logger.py:50 - Epoch: [1][350/500] loss: 1.09012, MAE: 0.44787, time/step=1065ms, lr=1.08e-05
2024-03-20 00:29:27,501 - logger.py:50 - Epoch: [1][400/500] loss: 1.01114, MAE: 0.44702, time/step=1064ms, lr=1.08e-05
2024-03-20 00:30:20,788 - logger.py:50 - Epoch: [1][450/500] loss: 0.96168, MAE: 0.44494, time/step=1064ms, lr=1.08e-05
2024-03-20 00:31:11,835 - logger.py:50 - Epoch: [1][499/500] loss: 0.92151, MAE: 0.44386, time/step=1062ms, lr=1.08e-05
2024-03-20 00:32:10,624 - logger.py:50 - Epoch: [1] train LOSS: 0.92151, val LOSS: 0.49722, test LOSS: 0.46187, Time: 589.70s
2024-03-20 00:32:10,624 - logger.py:50 - Best -- epoch=0, train LOSS: 0.94857, val LOSS: 0.49395, test LOSS: 0.46301

2024-03-20 00:32:11,753 - logger.py:50 - Epoch: [2][0/500] loss: 0.44784, MAE: 0.40667, time/step=1127ms, lr=2.06e-05
2024-03-20 00:33:04,021 - logger.py:50 - Epoch: [2][50/500] loss: 0.52200, MAE: 0.44316, time/step=1047ms, lr=2.06e-05
2024-03-20 00:33:56,726 - logger.py:50 - Epoch: [2][100/500] loss: 1.72736, MAE: 0.45943, time/step=1050ms, lr=2.06e-05
2024-03-20 00:34:50,156 - logger.py:50 - Epoch: [2][150/500] loss: 1.29721, MAE: 0.45242, time/step=1056ms, lr=2.06e-05
2024-03-20 00:35:43,413 - logger.py:50 - Epoch: [2][200/500] loss: 1.10533, MAE: 0.44901, time/step=1059ms, lr=2.06e-05
2024-03-20 00:36:35,820 - logger.py:50 - Epoch: [2][250/500] loss: 0.99845, MAE: 0.44510, time/step=1057ms, lr=2.06e-05
2024-03-20 00:36:53,725 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:37:03,192 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1 (cuda:0)])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
  )
)
2024-03-20 00:37:03,203 - logger.py:50 - Number of params: 2978805
2024-03-20 00:37:05,289 - logger.py:50 - Epoch: [0][0/500] loss: 0.48183, MAE: 0.46217, time/step=2082ms, lr=1.00e-06
2024-03-20 00:38:04,402 - logger.py:50 - Epoch: [0][50/500] loss: 3.08147, MAE: 0.47361, time/step=1200ms, lr=1.00e-06
2024-03-20 00:39:02,285 - logger.py:50 - Epoch: [0][100/500] loss: 2.72028, MAE: 0.46941, time/step=1179ms, lr=1.00e-06
2024-03-20 00:39:59,390 - logger.py:50 - Epoch: [0][150/500] loss: 1.99074, MAE: 0.46401, time/step=1167ms, lr=1.00e-06
2024-03-20 00:40:56,336 - logger.py:50 - Epoch: [0][200/500] loss: 1.61593, MAE: 0.45656, time/step=1160ms, lr=1.00e-06
2024-03-20 00:41:52,803 - logger.py:50 - Epoch: [0][250/500] loss: 1.38928, MAE: 0.45464, time/step=1154ms, lr=1.00e-06
2024-03-20 00:42:49,522 - logger.py:50 - Epoch: [0][300/500] loss: 1.23888, MAE: 0.45218, time/step=1151ms, lr=1.00e-06
2024-03-20 00:43:44,230 - logger.py:50 - Epoch: [0][350/500] loss: 1.13213, MAE: 0.44747, time/step=1143ms, lr=1.00e-06
2024-03-20 00:44:48,638 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:45:02,009 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1 (cuda:0)])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
  )
)
2024-03-20 00:45:02,021 - logger.py:50 - Number of params: 2978805
2024-03-20 00:45:04,214 - logger.py:50 - Epoch: [0][0/500] loss: 0.48183, MAE: 0.46217, time/step=2190ms, lr=1.00e-06
2024-03-20 00:50:01,484 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:50:01,484 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:50:01,484 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:50:01,485 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:50:01,485 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:50:01,486 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:50:01,493 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:50:01,499 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=64, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:50:25,812 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 00:50:26,138 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 00:50:26,341 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 00:50:26,508 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 00:50:26,833 - logger.py:50 - Number of params: 2978805
2024-03-20 00:50:27,155 - logger.py:50 - Number of params: 2978805
2024-03-20 00:50:27,489 - logger.py:50 - Number of params: 2978805
2024-03-20 00:50:27,671 - logger.py:50 - Number of params: 2978805
2024-03-20 00:50:27,707 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 00:50:28,210 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 00:50:28,580 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 00:50:28,727 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 00:50:28,766 - logger.py:50 - Number of params: 2978805
2024-03-20 00:50:29,315 - logger.py:50 - Number of params: 2978805
2024-03-20 00:50:29,690 - logger.py:50 - Number of params: 2978805
2024-03-20 00:50:29,902 - logger.py:50 - Number of params: 2978805
2024-03-20 00:52:03,946 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:52:17,992 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:52:27,347 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224 (cuda:0)])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672 (cuda:0)])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1 (cuda:0)])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512 (cuda:0)])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128 (cuda:0)])
  )
)
2024-03-20 00:52:27,915 - logger.py:50 - Number of params: 2978805
2024-03-20 00:52:30,402 - logger.py:50 - Epoch: [0][0/500] loss: 0.48186, MAE: 0.46219, time/step=2484ms, lr=1.00e-06
2024-03-20 00:53:27,068 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 00:53:42,876 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 00:53:43,647 - logger.py:50 - Number of params: 2978805
2024-03-20 00:53:46,176 - logger.py:50 - Epoch: [0][0/500] loss: 33.93233, MAE: 0.66743, time/step=2524ms, lr=1.00e-06
2024-03-20 00:54:57,251 - logger.py:50 - Epoch: [0][50/500] loss: 17.10477, MAE: 0.55492, time/step=1443ms, lr=1.00e-06
2024-03-20 00:55:52,428 - logger.py:50 - Epoch: [0][100/500] loss: 16.23915, MAE: 0.53354, time/step=1275ms, lr=1.00e-06
2024-03-20 00:56:50,208 - logger.py:50 - Epoch: [0][150/500] loss: 15.73033, MAE: 0.52005, time/step=1235ms, lr=1.00e-06
2024-03-20 00:57:46,943 - logger.py:50 - Epoch: [0][200/500] loss: 15.53628, MAE: 0.50990, time/step=1210ms, lr=1.00e-06
2024-03-20 00:58:42,609 - logger.py:50 - Epoch: [0][250/500] loss: 14.99710, MAE: 0.49557, time/step=1191ms, lr=1.00e-06
2024-03-20 00:59:38,480 - logger.py:50 - Epoch: [0][300/500] loss: 14.87807, MAE: 0.48793, time/step=1179ms, lr=1.00e-06
2024-03-20 01:00:33,948 - logger.py:50 - Epoch: [0][350/500] loss: 17.77247, MAE: 0.48610, time/step=1169ms, lr=1.00e-06
2024-03-20 01:01:29,353 - logger.py:50 - Epoch: [0][400/500] loss: 17.31092, MAE: 0.48020, time/step=1161ms, lr=1.00e-06
2024-03-20 01:02:25,404 - logger.py:50 - Epoch: [0][450/500] loss: 16.74741, MAE: 0.47343, time/step=1157ms, lr=1.00e-06
2024-03-20 01:03:19,119 - logger.py:50 - Epoch: [0][499/500] loss: 16.41167, MAE: 0.47027, time/step=1151ms, lr=1.00e-06
2024-03-20 01:03:19,838 - logger.py:50 - [0/63] loss: 15.10709, MAE: 0.43117, 
2024-03-20 01:03:24,725 - logger.py:50 - [8/63] loss: 10.68114, MAE: 0.40200, 
2024-03-20 01:03:28,864 - logger.py:50 - [16/63] loss: 12.41567, MAE: 0.42900, 
2024-03-20 01:03:32,833 - logger.py:50 - [24/63] loss: 13.83497, MAE: 0.44327, 
2024-03-20 01:03:36,872 - logger.py:50 - [32/63] loss: 13.05852, MAE: 0.44029, 
2024-03-20 01:03:40,932 - logger.py:50 - [40/63] loss: 13.28095, MAE: 0.44271, 
2024-03-20 01:03:44,489 - logger.py:50 - [48/63] loss: 12.74120, MAE: 0.43690, 
2024-03-20 01:03:48,413 - logger.py:50 - [56/63] loss: 12.57378, MAE: 0.43792, 
2024-03-20 01:03:51,184 - logger.py:50 - [62/63] loss: 12.39346, MAE: 0.43428, 
2024-03-20 01:03:51,453 - logger.py:50 - [0/63] loss: 8.67844, MAE: 0.34988, 
2024-03-20 01:03:55,319 - logger.py:50 - [8/63] loss: 13.66706, MAE: 0.44962, 
2024-03-20 01:03:58,668 - logger.py:50 - [16/63] loss: 13.41812, MAE: 0.43511, 
2024-03-20 01:04:02,473 - logger.py:50 - [24/63] loss: 12.80263, MAE: 0.43053, 
2024-03-20 01:04:06,510 - logger.py:50 - [32/63] loss: 12.42467, MAE: 0.43040, 
2024-03-20 01:04:10,039 - logger.py:50 - [40/63] loss: 12.56251, MAE: 0.43174, 
2024-03-20 01:04:14,086 - logger.py:50 - [48/63] loss: 12.58493, MAE: 0.42783, 
2024-03-20 01:04:17,919 - logger.py:50 - [56/63] loss: 12.90084, MAE: 0.42513, 
2024-03-20 01:04:20,772 - logger.py:50 - [62/63] loss: 12.67522, MAE: 0.42195, 
2024-03-20 01:04:20,976 - logger.py:50 - Epoch: [0] train loss: 16.41167, val loss: 12.39346, test loss: 12.67522, Time: 637.33s
2024-03-20 01:04:20,977 - logger.py:50 - Best -- epoch=0, train loss: 16.41167, val loss: 12.39346, test loss: 12.67522

2024-03-20 01:04:21,517 - logger.py:50 - [0/63] loss: 20.47513, MAE: 0.58197, 
2024-03-20 01:04:32,135 - logger.py:50 - [8/63] loss: 15.48573, MAE: 0.54444, 
2024-03-20 01:04:35,761 - logger.py:50 - [16/63] loss: 17.37820, MAE: 0.57445, 
2024-03-20 01:04:39,709 - logger.py:50 - [24/63] loss: 18.79954, MAE: 0.58794, 
2024-03-20 01:04:43,740 - logger.py:50 - [32/63] loss: 18.11390, MAE: 0.58668, 
2024-03-20 01:04:47,226 - logger.py:50 - [40/63] loss: 18.40223, MAE: 0.59074, 
2024-03-20 01:04:51,159 - logger.py:50 - [48/63] loss: 17.84731, MAE: 0.58344, 
2024-03-20 01:04:54,541 - logger.py:50 - [56/63] loss: 17.66232, MAE: 0.58402, 
2024-03-20 01:04:57,340 - logger.py:50 - [62/63] loss: 17.42831, MAE: 0.57885, 
2024-03-20 01:04:58,118 - logger.py:50 - [0/63] loss: 12.76736, MAE: 0.46486, 
2024-03-20 01:05:01,483 - logger.py:50 - [8/63] loss: 18.59817, MAE: 0.59345, 
2024-03-20 01:05:05,262 - logger.py:50 - [16/63] loss: 18.44837, MAE: 0.57886, 
2024-03-20 01:05:51,577 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=10, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 01:06:07,277 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-20 01:06:08,050 - logger.py:50 - Number of params: 2978805
2024-03-20 01:06:10,354 - logger.py:50 - Epoch: [0][0/500] loss: 33.93233, MAE: 0.66743, time/step=2301ms, lr=1.00e-06
2024-03-20 01:07:21,358 - logger.py:50 - Epoch: [0][50/500] loss: 17.10477, MAE: 0.55492, time/step=1437ms, lr=1.00e-06
2024-03-20 01:08:16,864 - logger.py:50 - Epoch: [0][100/500] loss: 16.23915, MAE: 0.53354, time/step=1275ms, lr=1.00e-06
2024-03-20 01:09:15,028 - logger.py:50 - Epoch: [0][150/500] loss: 15.73033, MAE: 0.52005, time/step=1238ms, lr=1.00e-06
2024-03-20 01:10:11,757 - logger.py:50 - Epoch: [0][200/500] loss: 15.53627, MAE: 0.50990, time/step=1212ms, lr=1.00e-06
2024-03-20 01:11:07,659 - logger.py:50 - Epoch: [0][250/500] loss: 14.99710, MAE: 0.49557, time/step=1194ms, lr=1.00e-06
2024-03-20 01:12:03,814 - logger.py:50 - Epoch: [0][300/500] loss: 14.87807, MAE: 0.48793, time/step=1182ms, lr=1.00e-06
2024-03-20 01:12:59,455 - logger.py:50 - Epoch: [0][350/500] loss: 17.77246, MAE: 0.48610, time/step=1172ms, lr=1.00e-06
2024-03-20 01:13:55,349 - logger.py:50 - Epoch: [0][400/500] loss: 17.31091, MAE: 0.48020, time/step=1165ms, lr=1.00e-06
2024-03-20 01:14:51,911 - logger.py:50 - Epoch: [0][450/500] loss: 16.74741, MAE: 0.47343, time/step=1162ms, lr=1.00e-06
2024-03-20 01:15:45,862 - logger.py:50 - Epoch: [0][499/500] loss: 16.41166, MAE: 0.47027, time/step=1156ms, lr=1.00e-06
2024-03-20 01:16:49,234 - logger.py:50 - Epoch: [0] train loss: 16.41166, val loss: 12.39344, test loss: 12.67520, Time: 641.18s
2024-03-20 01:16:49,235 - logger.py:50 - Best -- epoch=0, train loss: 16.41166, val loss: 12.39344, test loss: 12.67520

2024-03-20 01:17:56,650 - logger.py:50 - Epoch: [0]EMA val MAE: 0.57885, EMA test MAE: 0.56341, Time: 708.60s
2024-03-20 01:17:56,651 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 01:17:57,914 - logger.py:50 - Epoch: [1][0/500] loss: 14.85851, MAE: 0.46073, time/step=1261ms, lr=1.08e-05
2024-03-20 01:18:52,687 - logger.py:50 - Epoch: [1][50/500] loss: 11.96455, MAE: 0.43887, time/step=1099ms, lr=1.08e-05
2024-03-20 01:19:46,787 - logger.py:50 - Epoch: [1][100/500] loss: 14.90577, MAE: 0.44998, time/step=1090ms, lr=1.08e-05
2024-03-20 01:20:41,366 - logger.py:50 - Epoch: [1][150/500] loss: 12.57246, MAE: 0.45069, time/step=1091ms, lr=1.08e-05
2024-03-20 01:21:35,974 - logger.py:50 - Epoch: [1][200/500] loss: 11.39047, MAE: 0.45308, time/step=1091ms, lr=1.08e-05
2024-03-20 01:22:28,809 - logger.py:50 - Epoch: [1][250/500] loss: 10.53477, MAE: 0.45210, time/step=1084ms, lr=1.08e-05
2024-03-20 01:23:21,837 - logger.py:50 - Epoch: [1][300/500] loss: 9.84421, MAE: 0.44995, time/step=1080ms, lr=1.08e-05
2024-03-20 01:24:15,961 - logger.py:50 - Epoch: [1][350/500] loss: 9.37598, MAE: 0.44823, time/step=1081ms, lr=1.08e-05
2024-03-20 01:25:09,514 - logger.py:50 - Epoch: [1][400/500] loss: 8.91105, MAE: 0.44884, time/step=1079ms, lr=1.08e-05
2024-03-20 01:26:02,875 - logger.py:50 - Epoch: [1][450/500] loss: 10.24637, MAE: 0.45202, time/step=1078ms, lr=1.08e-05
2024-03-20 01:26:54,605 - logger.py:50 - Epoch: [1][499/500] loss: 9.78633, MAE: 0.45229, time/step=1076ms, lr=1.08e-05
2024-03-20 01:27:54,865 - logger.py:50 - Epoch: [1] train loss: 9.78633, val loss: 5.02318, test loss: 5.28948, Time: 598.21s
2024-03-20 01:27:54,865 - logger.py:50 - Best -- epoch=1, train loss: 9.78633, val loss: 5.02318, test loss: 5.28948

2024-03-20 01:28:55,197 - logger.py:50 - Epoch: [1]EMA val MAE: 0.57062, EMA test MAE: 0.55523, Time: 658.55s
2024-03-20 01:28:55,197 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 01:28:56,000 - logger.py:50 - Epoch: [2][0/500] loss: 7.99430, MAE: 0.51393, time/step=800ms, lr=2.06e-05
2024-03-20 01:29:49,810 - logger.py:50 - Epoch: [2][50/500] loss: 5.35547, MAE: 0.43888, time/step=1071ms, lr=2.06e-05
2024-03-20 01:30:43,955 - logger.py:50 - Epoch: [2][100/500] loss: 4.87568, MAE: 0.44852, time/step=1077ms, lr=2.06e-05
2024-03-20 01:31:38,319 - logger.py:50 - Epoch: [2][150/500] loss: 4.71209, MAE: 0.45092, time/step=1080ms, lr=2.06e-05
2024-03-20 01:32:31,288 - logger.py:50 - Epoch: [2][200/500] loss: 6.44178, MAE: 0.45777, time/step=1075ms, lr=2.06e-05
2024-03-20 01:33:24,735 - logger.py:50 - Epoch: [2][250/500] loss: 8.87323, MAE: 0.46295, time/step=1074ms, lr=2.06e-05
2024-03-20 01:34:18,896 - logger.py:50 - Epoch: [2][300/500] loss: 8.07927, MAE: 0.46312, time/step=1075ms, lr=2.06e-05
2024-03-20 01:35:13,457 - logger.py:50 - Epoch: [2][350/500] loss: 7.35655, MAE: 0.46019, time/step=1078ms, lr=2.06e-05
2024-03-20 01:36:07,452 - logger.py:50 - Epoch: [2][400/500] loss: 6.84878, MAE: 0.45992, time/step=1078ms, lr=2.06e-05
2024-03-20 01:37:01,826 - logger.py:50 - Epoch: [2][450/500] loss: 6.40050, MAE: 0.45819, time/step=1079ms, lr=2.06e-05
2024-03-20 01:37:56,469 - logger.py:50 - Epoch: [2][499/500] loss: 6.06271, MAE: 0.45783, time/step=1083ms, lr=2.06e-05
2024-03-20 01:38:57,487 - logger.py:50 - Epoch: [2] train loss: 6.06271, val loss: 2.59193, test loss: 2.84773, Time: 602.29s
2024-03-20 01:38:57,487 - logger.py:50 - Best -- epoch=2, train loss: 6.06271, val loss: 2.59193, test loss: 2.84773

2024-03-20 01:39:57,792 - logger.py:50 - Epoch: [2]EMA val MAE: 0.56362, EMA test MAE: 0.54816, Time: 662.59s
2024-03-20 01:39:57,793 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 01:39:59,127 - logger.py:50 - Epoch: [3][0/500] loss: 1.79421, MAE: 0.64069, time/step=1333ms, lr=3.04e-05
2024-03-20 01:40:53,277 - logger.py:50 - Epoch: [3][50/500] loss: 2.47665, MAE: 0.44711, time/step=1088ms, lr=3.04e-05
2024-03-20 01:41:46,839 - logger.py:50 - Epoch: [3][100/500] loss: 2.40057, MAE: 0.44614, time/step=1080ms, lr=3.04e-05
2024-03-20 01:42:40,871 - logger.py:50 - Epoch: [3][150/500] loss: 2.46539, MAE: 0.44673, time/step=1080ms, lr=3.04e-05
2024-03-20 01:43:35,144 - logger.py:50 - Epoch: [3][200/500] loss: 2.38314, MAE: 0.44610, time/step=1081ms, lr=3.04e-05
2024-03-20 01:44:29,037 - logger.py:50 - Epoch: [3][250/500] loss: 2.39270, MAE: 0.44861, time/step=1081ms, lr=3.04e-05
2024-03-20 01:45:22,557 - logger.py:50 - Epoch: [3][300/500] loss: 2.33397, MAE: 0.44806, time/step=1079ms, lr=3.04e-05
2024-03-20 01:46:16,350 - logger.py:50 - Epoch: [3][350/500] loss: 5.69852, MAE: 0.45604, time/step=1079ms, lr=3.04e-05
2024-03-20 01:47:10,903 - logger.py:50 - Epoch: [3][400/500] loss: 5.24910, MAE: 0.45427, time/step=1080ms, lr=3.04e-05
2024-03-20 01:48:05,519 - logger.py:50 - Epoch: [3][450/500] loss: 4.87847, MAE: 0.45347, time/step=1081ms, lr=3.04e-05
2024-03-20 01:48:58,721 - logger.py:50 - Epoch: [3][499/500] loss: 4.55091, MAE: 0.45251, time/step=1082ms, lr=3.04e-05
2024-03-20 01:49:59,601 - logger.py:50 - Epoch: [3] train loss: 4.55091, val loss: 1.63823, test loss: 1.78525, Time: 601.81s
2024-03-20 01:49:59,601 - logger.py:50 - Best -- epoch=3, train loss: 4.55091, val loss: 1.63823, test loss: 1.78525

2024-03-20 01:50:59,918 - logger.py:50 - Epoch: [3]EMA val MAE: 0.55950, EMA test MAE: 0.54388, Time: 662.13s
2024-03-20 01:50:59,918 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 01:51:01,160 - logger.py:50 - Epoch: [4][0/500] loss: 1.13828, MAE: 0.34683, time/step=1240ms, lr=4.02e-05
2024-03-20 01:51:54,178 - logger.py:50 - Epoch: [4][50/500] loss: 16.68771, MAE: 0.47218, time/step=1064ms, lr=4.02e-05
2024-03-20 01:52:47,786 - logger.py:50 - Epoch: [4][100/500] loss: 9.56364, MAE: 0.47181, time/step=1068ms, lr=4.02e-05
2024-03-20 01:53:42,260 - logger.py:50 - Epoch: [4][150/500] loss: 6.86347, MAE: 0.46064, time/step=1075ms, lr=4.02e-05
2024-03-20 01:54:36,531 - logger.py:50 - Epoch: [4][200/500] loss: 5.58915, MAE: 0.45637, time/step=1078ms, lr=4.02e-05
2024-03-20 01:55:29,549 - logger.py:50 - Epoch: [4][250/500] loss: 4.79966, MAE: 0.45332, time/step=1074ms, lr=4.02e-05
2024-03-20 01:56:22,660 - logger.py:50 - Epoch: [4][300/500] loss: 4.25399, MAE: 0.45142, time/step=1072ms, lr=4.02e-05
2024-03-20 01:57:16,388 - logger.py:50 - Epoch: [4][350/500] loss: 3.86907, MAE: 0.45051, time/step=1073ms, lr=4.02e-05
2024-03-20 01:58:10,039 - logger.py:50 - Epoch: [4][400/500] loss: 3.56887, MAE: 0.44926, time/step=1073ms, lr=4.02e-05
2024-03-20 01:59:04,303 - logger.py:50 - Epoch: [4][450/500] loss: 4.20226, MAE: 0.44881, time/step=1074ms, lr=4.02e-05
2024-03-20 01:59:58,028 - logger.py:50 - Epoch: [4][499/500] loss: 3.91662, MAE: 0.44766, time/step=1076ms, lr=4.02e-05
2024-03-20 02:00:58,398 - logger.py:50 - Epoch: [4] train loss: 3.91662, val loss: 1.30871, test loss: 1.29885, Time: 598.48s
2024-03-20 02:00:58,398 - logger.py:50 - Best -- epoch=4, train loss: 3.91662, val loss: 1.30871, test loss: 1.29885

2024-03-20 02:01:58,412 - logger.py:50 - Epoch: [4]EMA val MAE: 0.55759, EMA test MAE: 0.54180, Time: 658.49s
2024-03-20 02:01:58,412 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 02:01:59,618 - logger.py:50 - Epoch: [5][0/500] loss: 1.73600, MAE: 0.50649, time/step=1204ms, lr=4.99e-05
2024-03-20 02:02:52,566 - logger.py:50 - Epoch: [5][50/500] loss: 1.27921, MAE: 0.43946, time/step=1062ms, lr=4.99e-05
2024-03-20 02:03:46,448 - logger.py:50 - Epoch: [5][100/500] loss: 1.33413, MAE: 0.43966, time/step=1070ms, lr=4.99e-05
2024-03-20 02:04:40,963 - logger.py:50 - Epoch: [5][150/500] loss: 1.35872, MAE: 0.43650, time/step=1076ms, lr=4.99e-05
2024-03-20 02:05:35,035 - logger.py:50 - Epoch: [5][200/500] loss: 1.36372, MAE: 0.43742, time/step=1078ms, lr=4.99e-05
2024-03-20 02:06:28,618 - logger.py:50 - Epoch: [5][250/500] loss: 6.04699, MAE: 0.45214, time/step=1077ms, lr=4.99e-05
2024-03-20 02:07:22,161 - logger.py:50 - Epoch: [5][300/500] loss: 5.22171, MAE: 0.45101, time/step=1076ms, lr=4.99e-05
2024-03-20 02:08:16,057 - logger.py:50 - Epoch: [5][350/500] loss: 4.70142, MAE: 0.45009, time/step=1076ms, lr=4.99e-05
2024-03-20 02:09:10,632 - logger.py:50 - Epoch: [5][400/500] loss: 4.27001, MAE: 0.44968, time/step=1078ms, lr=4.99e-05
2024-03-20 02:10:03,949 - logger.py:50 - Epoch: [5][450/500] loss: 3.93275, MAE: 0.44802, time/step=1077ms, lr=4.99e-05
2024-03-20 02:10:56,081 - logger.py:50 - Epoch: [5][499/500] loss: 3.66795, MAE: 0.44618, time/step=1075ms, lr=4.99e-05
2024-03-20 02:11:57,762 - logger.py:50 - Epoch: [5] train loss: 3.66795, val loss: 1.15031, test loss: 1.09005, Time: 599.35s
2024-03-20 02:11:57,762 - logger.py:50 - Best -- epoch=5, train loss: 3.66795, val loss: 1.15031, test loss: 1.09005

2024-03-20 02:12:58,036 - logger.py:50 - Epoch: [5]EMA val MAE: 0.55672, EMA test MAE: 0.54081, Time: 659.62s
2024-03-20 02:12:58,036 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 02:12:58,907 - logger.py:50 - Epoch: [6][0/500] loss: 1.33382, MAE: 0.50416, time/step=867ms, lr=4.98e-05
2024-03-20 02:13:53,205 - logger.py:50 - Epoch: [6][50/500] loss: 9.03270, MAE: 0.45536, time/step=1082ms, lr=4.98e-05
2024-03-20 02:14:47,278 - logger.py:50 - Epoch: [6][100/500] loss: 5.31441, MAE: 0.45740, time/step=1082ms, lr=4.98e-05
2024-03-20 02:15:40,841 - logger.py:50 - Epoch: [6][150/500] loss: 4.06857, MAE: 0.45591, time/step=1078ms, lr=4.98e-05
2024-03-20 02:16:34,579 - logger.py:50 - Epoch: [6][200/500] loss: 3.31960, MAE: 0.45256, time/step=1077ms, lr=4.98e-05
2024-03-20 02:17:28,961 - logger.py:50 - Epoch: [6][250/500] loss: 2.89866, MAE: 0.44835, time/step=1079ms, lr=4.98e-05
2024-03-20 02:18:22,656 - logger.py:50 - Epoch: [6][300/500] loss: 2.59728, MAE: 0.44459, time/step=1078ms, lr=4.98e-05
2024-03-20 02:19:17,679 - logger.py:50 - Epoch: [6][350/500] loss: 2.36419, MAE: 0.44378, time/step=1082ms, lr=4.98e-05
2024-03-20 02:20:13,240 - logger.py:50 - Epoch: [6][400/500] loss: 2.19338, MAE: 0.44269, time/step=1085ms, lr=4.98e-05
2024-03-20 02:21:07,747 - logger.py:50 - Epoch: [6][450/500] loss: 2.06994, MAE: 0.44177, time/step=1086ms, lr=4.98e-05
2024-03-20 02:22:01,187 - logger.py:50 - Epoch: [6][499/500] loss: 3.49191, MAE: 0.44476, time/step=1086ms, lr=4.98e-05
2024-03-20 02:23:02,359 - logger.py:50 - Epoch: [6] train loss: 3.49191, val loss: 1.04277, test loss: 0.99153, Time: 604.32s
2024-03-20 02:23:02,360 - logger.py:50 - Best -- epoch=6, train loss: 3.49191, val loss: 1.04277, test loss: 0.99153

2024-03-20 02:24:02,922 - logger.py:50 - Epoch: [6]EMA val MAE: 0.55656, EMA test MAE: 0.54055, Time: 664.89s
2024-03-20 02:24:02,922 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 02:24:04,168 - logger.py:50 - Epoch: [7][0/500] loss: 0.55167, MAE: 0.36877, time/step=1244ms, lr=4.97e-05
2024-03-20 02:24:58,622 - logger.py:50 - Epoch: [7][50/500] loss: 1.16855, MAE: 0.45349, time/step=1092ms, lr=4.97e-05
2024-03-20 02:25:51,860 - logger.py:50 - Epoch: [7][100/500] loss: 1.12617, MAE: 0.44937, time/step=1079ms, lr=4.97e-05
2024-03-20 02:26:46,749 - logger.py:50 - Epoch: [7][150/500] loss: 1.11219, MAE: 0.44052, time/step=1085ms, lr=4.97e-05
2024-03-20 02:27:39,975 - logger.py:50 - Epoch: [7][200/500] loss: 1.11359, MAE: 0.44000, time/step=1080ms, lr=4.97e-05
2024-03-20 02:28:34,331 - logger.py:50 - Epoch: [7][250/500] loss: 1.09173, MAE: 0.43924, time/step=1081ms, lr=4.97e-05
2024-03-20 02:29:29,539 - logger.py:50 - Epoch: [7][300/500] loss: 3.62441, MAE: 0.44294, time/step=1085ms, lr=4.97e-05
2024-03-20 02:30:24,158 - logger.py:50 - Epoch: [7][350/500] loss: 3.24616, MAE: 0.44278, time/step=1086ms, lr=4.97e-05
2024-03-20 02:31:18,678 - logger.py:50 - Epoch: [7][400/500] loss: 2.95109, MAE: 0.44192, time/step=1087ms, lr=4.97e-05
2024-03-20 02:32:12,721 - logger.py:50 - Epoch: [7][450/500] loss: 3.62780, MAE: 0.44499, time/step=1086ms, lr=4.97e-05
2024-03-20 02:33:05,960 - logger.py:50 - Epoch: [7][499/500] loss: 3.36320, MAE: 0.44494, time/step=1086ms, lr=4.97e-05
2024-03-20 02:34:07,107 - logger.py:50 - Epoch: [7] train loss: 3.36320, val loss: 0.91910, test loss: 0.86616, Time: 604.19s
2024-03-20 02:34:07,108 - logger.py:50 - Best -- epoch=7, train loss: 3.36320, val loss: 0.91910, test loss: 0.86616

2024-03-20 02:35:07,542 - logger.py:50 - Epoch: [7]EMA val MAE: 0.55665, EMA test MAE: 0.54059, Time: 664.62s
2024-03-20 02:35:07,542 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 02:35:08,840 - logger.py:50 - Epoch: [8][0/500] loss: 0.79845, MAE: 0.46978, time/step=1296ms, lr=4.97e-05
2024-03-20 02:36:03,936 - logger.py:50 - Epoch: [8][50/500] loss: 1.11024, MAE: 0.44258, time/step=1106ms, lr=4.97e-05
2024-03-20 02:36:57,873 - logger.py:50 - Epoch: [8][100/500] loss: 0.98238, MAE: 0.44113, time/step=1092ms, lr=4.97e-05
2024-03-20 02:37:51,428 - logger.py:50 - Epoch: [8][150/500] loss: 0.98720, MAE: 0.44081, time/step=1085ms, lr=4.97e-05
2024-03-20 02:38:44,902 - logger.py:50 - Epoch: [8][200/500] loss: 0.94656, MAE: 0.43677, time/step=1081ms, lr=4.97e-05
2024-03-20 02:39:39,031 - logger.py:50 - Epoch: [8][250/500] loss: 2.51368, MAE: 0.44087, time/step=1082ms, lr=4.97e-05
2024-03-20 02:40:33,875 - logger.py:50 - Epoch: [8][300/500] loss: 4.78003, MAE: 0.44927, time/step=1084ms, lr=4.97e-05
2024-03-20 02:41:28,480 - logger.py:50 - Epoch: [8][350/500] loss: 4.25982, MAE: 0.44793, time/step=1085ms, lr=4.97e-05
2024-03-20 02:42:21,980 - logger.py:50 - Epoch: [8][400/500] loss: 3.84908, MAE: 0.44554, time/step=1083ms, lr=4.97e-05
2024-03-20 02:43:16,803 - logger.py:50 - Epoch: [8][450/500] loss: 3.52427, MAE: 0.44511, time/step=1085ms, lr=4.97e-05
2024-03-20 02:44:10,648 - logger.py:50 - Epoch: [8][499/500] loss: 3.26007, MAE: 0.44506, time/step=1086ms, lr=4.97e-05
2024-03-20 02:45:11,776 - logger.py:50 - Epoch: [8] train loss: 3.26007, val loss: 0.84448, test loss: 0.78697, Time: 604.23s
2024-03-20 02:45:11,776 - logger.py:50 - Best -- epoch=8, train loss: 3.26007, val loss: 0.84448, test loss: 0.78697

2024-03-20 02:46:12,248 - logger.py:50 - Epoch: [8]EMA val MAE: 0.55694, EMA test MAE: 0.54086, Time: 664.71s
2024-03-20 02:46:12,248 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 02:46:13,510 - logger.py:50 - Epoch: [9][0/500] loss: 0.85996, MAE: 0.37909, time/step=1259ms, lr=4.96e-05
2024-03-20 02:47:08,114 - logger.py:50 - Epoch: [9][50/500] loss: 0.78415, MAE: 0.42490, time/step=1095ms, lr=4.96e-05
2024-03-20 02:48:01,859 - logger.py:50 - Epoch: [9][100/500] loss: 0.83208, MAE: 0.43011, time/step=1085ms, lr=4.96e-05
2024-03-20 02:48:56,135 - logger.py:50 - Epoch: [9][150/500] loss: 0.86261, MAE: 0.43307, time/step=1085ms, lr=4.96e-05
2024-03-20 02:49:50,793 - logger.py:50 - Epoch: [9][200/500] loss: 0.91187, MAE: 0.43507, time/step=1087ms, lr=4.96e-05
2024-03-20 02:50:44,378 - logger.py:50 - Epoch: [9][250/500] loss: 2.49963, MAE: 0.44087, time/step=1084ms, lr=4.96e-05
2024-03-20 02:51:39,689 - logger.py:50 - Epoch: [9][300/500] loss: 2.21806, MAE: 0.44049, time/step=1088ms, lr=4.96e-05
2024-03-20 02:52:32,988 - logger.py:50 - Epoch: [9][350/500] loss: 2.02157, MAE: 0.43978, time/step=1085ms, lr=4.96e-05
2024-03-20 02:53:27,207 - logger.py:50 - Epoch: [9][400/500] loss: 1.85727, MAE: 0.43941, time/step=1085ms, lr=4.96e-05
2024-03-20 02:54:22,115 - logger.py:50 - Epoch: [9][450/500] loss: 3.43597, MAE: 0.44409, time/step=1086ms, lr=4.96e-05
2024-03-20 02:55:15,179 - logger.py:50 - Epoch: [9][499/500] loss: 3.18946, MAE: 0.44432, time/step=1086ms, lr=4.96e-05
2024-03-20 02:56:16,370 - logger.py:50 - Epoch: [9] train loss: 3.18946, val loss: 0.81796, test loss: 0.77071, Time: 604.12s
2024-03-20 02:56:16,371 - logger.py:50 - Best -- epoch=9, train loss: 3.18946, val loss: 0.81796, test loss: 0.77071

2024-03-20 02:57:17,164 - logger.py:50 - Epoch: [9]EMA val MAE: 0.55724, EMA test MAE: 0.54118, Time: 664.92s
2024-03-20 02:57:17,164 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 02:57:18,494 - logger.py:50 - Epoch: [10][0/500] loss: 0.64450, MAE: 0.38367, time/step=1328ms, lr=4.95e-05
2024-03-20 02:58:12,498 - logger.py:50 - Epoch: [10][50/500] loss: 0.77747, MAE: 0.43982, time/step=1085ms, lr=4.95e-05
2024-03-20 02:59:06,010 - logger.py:50 - Epoch: [10][100/500] loss: 0.87329, MAE: 0.44088, time/step=1078ms, lr=4.95e-05
2024-03-20 03:00:00,696 - logger.py:50 - Epoch: [10][150/500] loss: 0.83071, MAE: 0.43832, time/step=1083ms, lr=4.95e-05
2024-03-20 03:00:54,128 - logger.py:50 - Epoch: [10][200/500] loss: 4.62828, MAE: 0.44640, time/step=1079ms, lr=4.95e-05
2024-03-20 03:01:48,581 - logger.py:50 - Epoch: [10][250/500] loss: 3.89145, MAE: 0.44172, time/step=1081ms, lr=4.95e-05
2024-03-20 03:02:42,648 - logger.py:50 - Epoch: [10][300/500] loss: 3.38241, MAE: 0.44394, time/step=1081ms, lr=4.95e-05
2024-03-20 03:03:37,419 - logger.py:50 - Epoch: [10][350/500] loss: 3.01675, MAE: 0.44429, time/step=1083ms, lr=4.95e-05
2024-03-20 03:04:31,534 - logger.py:50 - Epoch: [10][400/500] loss: 2.73526, MAE: 0.44243, time/step=1083ms, lr=4.95e-05
2024-03-20 03:05:26,987 - logger.py:50 - Epoch: [10][450/500] loss: 2.51471, MAE: 0.44210, time/step=1086ms, lr=4.95e-05
2024-03-20 03:06:21,004 - logger.py:50 - Epoch: [10][499/500] loss: 3.13697, MAE: 0.44453, time/step=1088ms, lr=4.95e-05
2024-03-20 03:07:22,405 - logger.py:50 - Epoch: [10] train loss: 3.13697, val loss: 0.79365, test loss: 0.74739, Time: 605.24s
2024-03-20 03:07:22,405 - logger.py:50 - Best -- epoch=10, train loss: 3.13697, val loss: 0.79365, test loss: 0.74739

2024-03-20 03:08:23,274 - logger.py:50 - Epoch: [10]EMA val MAE: 0.55735, EMA test MAE: 0.54129, Time: 666.11s
2024-03-20 03:08:23,274 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 03:08:24,580 - logger.py:50 - Epoch: [11][0/500] loss: 0.91214, MAE: 0.42396, time/step=1303ms, lr=4.94e-05
2024-03-20 03:09:19,739 - logger.py:50 - Epoch: [11][50/500] loss: 15.53286, MAE: 0.48876, time/step=1107ms, lr=4.94e-05
2024-03-20 03:10:13,214 - logger.py:50 - Epoch: [11][100/500] loss: 12.26793, MAE: 0.47373, time/step=1088ms, lr=4.94e-05
2024-03-20 03:11:07,871 - logger.py:50 - Epoch: [11][150/500] loss: 8.46434, MAE: 0.46045, time/step=1090ms, lr=4.94e-05
2024-03-20 03:12:01,677 - logger.py:50 - Epoch: [11][200/500] loss: 6.60803, MAE: 0.45784, time/step=1087ms, lr=4.94e-05
2024-03-20 03:12:56,384 - logger.py:50 - Epoch: [11][250/500] loss: 5.43065, MAE: 0.45277, time/step=1088ms, lr=4.94e-05
2024-03-20 03:13:50,301 - logger.py:50 - Epoch: [11][300/500] loss: 4.64347, MAE: 0.44938, time/step=1086ms, lr=4.94e-05
2024-03-20 03:14:44,037 - logger.py:50 - Epoch: [11][350/500] loss: 4.08912, MAE: 0.44763, time/step=1085ms, lr=4.94e-05
2024-03-20 03:15:39,068 - logger.py:50 - Epoch: [11][400/500] loss: 3.66306, MAE: 0.44596, time/step=1087ms, lr=4.94e-05
2024-03-20 03:16:33,390 - logger.py:50 - Epoch: [11][450/500] loss: 3.33995, MAE: 0.44533, time/step=1087ms, lr=4.94e-05
2024-03-20 03:17:26,774 - logger.py:50 - Epoch: [11][499/500] loss: 3.08648, MAE: 0.44507, time/step=1087ms, lr=4.94e-05
2024-03-20 03:18:28,160 - logger.py:50 - Epoch: [11] train loss: 3.08648, val loss: 0.71703, test loss: 0.66745, Time: 604.89s
2024-03-20 03:18:28,161 - logger.py:50 - Best -- epoch=11, train loss: 3.08648, val loss: 0.71703, test loss: 0.66745

2024-03-20 03:19:28,443 - logger.py:50 - Epoch: [11]EMA val MAE: 0.55729, EMA test MAE: 0.54122, Time: 665.17s
2024-03-20 03:19:28,444 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 03:19:29,706 - logger.py:50 - Epoch: [12][0/500] loss: 1.19065, MAE: 0.58116, time/step=1260ms, lr=4.92e-05
2024-03-20 03:20:24,263 - logger.py:50 - Epoch: [12][50/500] loss: 0.67797, MAE: 0.43290, time/step=1094ms, lr=4.92e-05
2024-03-20 03:21:18,803 - logger.py:50 - Epoch: [12][100/500] loss: 8.20621, MAE: 0.45369, time/step=1093ms, lr=4.92e-05
2024-03-20 03:22:13,652 - logger.py:50 - Epoch: [12][150/500] loss: 5.75448, MAE: 0.45119, time/step=1094ms, lr=4.92e-05
2024-03-20 03:23:07,655 - logger.py:50 - Epoch: [12][200/500] loss: 4.53281, MAE: 0.45109, time/step=1091ms, lr=4.92e-05
2024-03-20 03:24:01,547 - logger.py:50 - Epoch: [12][250/500] loss: 5.33728, MAE: 0.45169, time/step=1088ms, lr=4.92e-05
2024-03-20 03:24:55,697 - logger.py:50 - Epoch: [12][300/500] loss: 4.57333, MAE: 0.44980, time/step=1087ms, lr=4.92e-05
2024-03-20 03:25:48,857 - logger.py:50 - Epoch: [12][350/500] loss: 4.05223, MAE: 0.44827, time/step=1084ms, lr=4.92e-05
2024-03-20 03:26:41,797 - logger.py:50 - Epoch: [12][400/500] loss: 3.64357, MAE: 0.44593, time/step=1081ms, lr=4.92e-05
2024-03-20 03:27:36,102 - logger.py:50 - Epoch: [12][450/500] loss: 3.31524, MAE: 0.44383, time/step=1081ms, lr=4.92e-05
2024-03-20 03:28:28,302 - logger.py:50 - Epoch: [12][499/500] loss: 3.06361, MAE: 0.44475, time/step=1080ms, lr=4.92e-05
2024-03-20 03:29:28,814 - logger.py:50 - Epoch: [12] train loss: 3.06361, val loss: 0.73055, test loss: 0.68722, Time: 600.37s
2024-03-20 03:29:28,814 - logger.py:50 - Best -- epoch=11, train loss: 3.08648, val loss: 0.71703, test loss: 0.66745

2024-03-20 03:30:29,406 - logger.py:50 - Epoch: [12]EMA val MAE: 0.55702, EMA test MAE: 0.54093, Time: 660.96s
2024-03-20 03:30:29,406 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 03:30:30,667 - logger.py:50 - Epoch: [13][0/500] loss: 0.65696, MAE: 0.43642, time/step=1259ms, lr=4.91e-05
2024-03-20 03:31:24,250 - logger.py:50 - Epoch: [13][50/500] loss: 15.69849, MAE: 0.47783, time/step=1075ms, lr=4.91e-05
2024-03-20 03:32:18,279 - logger.py:50 - Epoch: [13][100/500] loss: 12.22681, MAE: 0.48028, time/step=1078ms, lr=4.91e-05
2024-03-20 03:33:12,639 - logger.py:50 - Epoch: [13][150/500] loss: 8.40202, MAE: 0.46638, time/step=1081ms, lr=4.91e-05
2024-03-20 03:34:07,717 - logger.py:50 - Epoch: [13][200/500] loss: 6.44670, MAE: 0.45789, time/step=1086ms, lr=4.91e-05
2024-03-20 03:35:01,022 - logger.py:50 - Epoch: [13][250/500] loss: 5.33559, MAE: 0.45418, time/step=1082ms, lr=4.91e-05
2024-03-20 03:35:55,342 - logger.py:50 - Epoch: [13][300/500] loss: 4.55712, MAE: 0.45339, time/step=1083ms, lr=4.91e-05
2024-03-20 03:36:49,670 - logger.py:50 - Epoch: [13][350/500] loss: 4.01724, MAE: 0.45261, time/step=1083ms, lr=4.91e-05
2024-03-20 03:37:43,740 - logger.py:50 - Epoch: [13][400/500] loss: 3.61113, MAE: 0.44882, time/step=1083ms, lr=4.91e-05
2024-03-20 03:38:38,084 - logger.py:50 - Epoch: [13][450/500] loss: 3.28530, MAE: 0.44754, time/step=1084ms, lr=4.91e-05
2024-03-20 03:39:29,912 - logger.py:50 - Epoch: [13][499/500] loss: 3.03048, MAE: 0.44466, time/step=1081ms, lr=4.91e-05
2024-03-20 03:40:30,697 - logger.py:50 - Epoch: [13] train loss: 3.03048, val loss: 0.68088, test loss: 0.63608, Time: 601.29s
2024-03-20 03:40:30,697 - logger.py:50 - Best -- epoch=13, train loss: 3.03048, val loss: 0.68088, test loss: 0.63608

2024-03-20 03:41:30,702 - logger.py:50 - Epoch: [13]EMA val MAE: 0.55641, EMA test MAE: 0.54027, Time: 661.30s
2024-03-20 03:41:30,702 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 03:41:31,994 - logger.py:50 - Epoch: [14][0/500] loss: 0.43396, MAE: 0.39330, time/step=1290ms, lr=4.90e-05
2024-03-20 03:42:24,907 - logger.py:50 - Epoch: [14][50/500] loss: 0.81186, MAE: 0.45748, time/step=1063ms, lr=4.90e-05
2024-03-20 03:43:18,930 - logger.py:50 - Epoch: [14][100/500] loss: 0.76693, MAE: 0.45034, time/step=1072ms, lr=4.90e-05
2024-03-20 03:44:12,898 - logger.py:50 - Epoch: [14][150/500] loss: 0.75840, MAE: 0.44445, time/step=1074ms, lr=4.90e-05
2024-03-20 03:45:07,665 - logger.py:50 - Epoch: [14][200/500] loss: 2.71152, MAE: 0.44980, time/step=1079ms, lr=4.90e-05
2024-03-20 03:46:02,137 - logger.py:50 - Epoch: [14][250/500] loss: 2.31187, MAE: 0.44924, time/step=1081ms, lr=4.90e-05
2024-03-20 03:46:55,277 - logger.py:50 - Epoch: [14][300/500] loss: 4.57128, MAE: 0.45154, time/step=1078ms, lr=4.90e-05
2024-03-20 03:47:50,638 - logger.py:50 - Epoch: [14][350/500] loss: 3.99920, MAE: 0.45096, time/step=1082ms, lr=4.90e-05
2024-03-20 03:48:43,937 - logger.py:50 - Epoch: [14][400/500] loss: 3.58855, MAE: 0.44738, time/step=1080ms, lr=4.90e-05
2024-03-20 03:49:38,328 - logger.py:50 - Epoch: [14][450/500] loss: 3.26213, MAE: 0.44466, time/step=1081ms, lr=4.90e-05
2024-03-20 03:50:31,740 - logger.py:50 - Epoch: [14][499/500] loss: 3.00834, MAE: 0.44451, time/step=1082ms, lr=4.90e-05
2024-03-20 03:51:32,678 - logger.py:50 - Epoch: [14] train loss: 3.00834, val loss: 0.67125, test loss: 0.65100, Time: 601.98s
2024-03-20 03:51:32,678 - logger.py:50 - Best -- epoch=14, train loss: 3.00834, val loss: 0.67125, test loss: 0.65100

2024-03-20 03:52:32,879 - logger.py:50 - Epoch: [14]EMA val MAE: 0.55559, EMA test MAE: 0.53940, Time: 662.18s
2024-03-20 03:52:32,879 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 03:52:34,164 - logger.py:50 - Epoch: [15][0/500] loss: 0.35127, MAE: 0.41569, time/step=1283ms, lr=4.88e-05
2024-03-20 03:53:27,756 - logger.py:50 - Epoch: [15][50/500] loss: 8.39796, MAE: 0.46144, time/step=1076ms, lr=4.88e-05
2024-03-20 03:54:21,868 - logger.py:50 - Epoch: [15][100/500] loss: 4.59069, MAE: 0.45119, time/step=1079ms, lr=4.88e-05
2024-03-20 03:55:15,624 - logger.py:50 - Epoch: [15][150/500] loss: 3.29068, MAE: 0.45015, time/step=1078ms, lr=4.88e-05
2024-03-20 03:56:09,476 - logger.py:50 - Epoch: [15][200/500] loss: 2.64505, MAE: 0.44897, time/step=1078ms, lr=4.88e-05
2024-03-20 03:57:03,631 - logger.py:50 - Epoch: [15][250/500] loss: 2.24778, MAE: 0.44517, time/step=1079ms, lr=4.88e-05
2024-03-20 03:57:57,794 - logger.py:50 - Epoch: [15][300/500] loss: 4.50398, MAE: 0.44977, time/step=1079ms, lr=4.88e-05
2024-03-20 03:58:52,075 - logger.py:50 - Epoch: [15][350/500] loss: 3.96867, MAE: 0.44810, time/step=1080ms, lr=4.88e-05
2024-03-20 03:59:45,947 - logger.py:50 - Epoch: [15][400/500] loss: 3.56318, MAE: 0.44788, time/step=1080ms, lr=4.88e-05
2024-03-20 04:00:39,284 - logger.py:50 - Epoch: [15][450/500] loss: 3.24414, MAE: 0.44689, time/step=1078ms, lr=4.88e-05
2024-03-20 04:01:32,940 - logger.py:50 - Epoch: [15][499/500] loss: 2.99244, MAE: 0.44447, time/step=1080ms, lr=4.88e-05
2024-03-20 04:02:33,513 - logger.py:50 - Epoch: [15] train loss: 2.99244, val loss: 0.63394, test loss: 0.62535, Time: 600.63s
2024-03-20 04:02:33,513 - logger.py:50 - Best -- epoch=15, train loss: 2.99244, val loss: 0.63394, test loss: 0.62535

2024-03-20 04:03:33,607 - logger.py:50 - Epoch: [15]EMA val MAE: 0.55447, EMA test MAE: 0.53824, Time: 660.73s
2024-03-20 04:03:33,608 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 04:03:34,343 - logger.py:50 - Epoch: [16][0/500] loss: 0.35174, MAE: 0.42071, time/step=733ms, lr=4.86e-05
2024-03-20 04:04:28,586 - logger.py:50 - Epoch: [16][50/500] loss: 0.61428, MAE: 0.43236, time/step=1078ms, lr=4.86e-05
2024-03-20 04:05:23,923 - logger.py:50 - Epoch: [16][100/500] loss: 0.61574, MAE: 0.43320, time/step=1092ms, lr=4.86e-05
2024-03-20 04:06:17,572 - logger.py:50 - Epoch: [16][150/500] loss: 3.25796, MAE: 0.44684, time/step=1086ms, lr=4.86e-05
2024-03-20 04:07:11,444 - logger.py:50 - Epoch: [16][200/500] loss: 2.61458, MAE: 0.44419, time/step=1084ms, lr=4.86e-05
2024-03-20 04:08:05,748 - logger.py:50 - Epoch: [16][250/500] loss: 2.22297, MAE: 0.44461, time/step=1084ms, lr=4.86e-05
2024-03-20 04:08:59,936 - logger.py:50 - Epoch: [16][300/500] loss: 1.95444, MAE: 0.44171, time/step=1084ms, lr=4.86e-05
2024-03-20 04:09:53,651 - logger.py:50 - Epoch: [16][350/500] loss: 3.91709, MAE: 0.44509, time/step=1083ms, lr=4.86e-05
2024-03-20 04:10:48,880 - logger.py:50 - Epoch: [16][400/500] loss: 3.52101, MAE: 0.44611, time/step=1085ms, lr=4.86e-05
2024-03-20 04:11:42,358 - logger.py:50 - Epoch: [16][450/500] loss: 3.22942, MAE: 0.44588, time/step=1084ms, lr=4.86e-05
2024-03-20 04:12:35,207 - logger.py:50 - Epoch: [16][499/500] loss: 2.97613, MAE: 0.44471, time/step=1083ms, lr=4.86e-05
2024-03-20 04:13:36,037 - logger.py:50 - Epoch: [16] train loss: 2.97613, val loss: 0.61512, test loss: 0.58009, Time: 602.43s
2024-03-20 04:13:36,037 - logger.py:50 - Best -- epoch=16, train loss: 2.97613, val loss: 0.61512, test loss: 0.58009

2024-03-20 04:14:36,346 - logger.py:50 - Epoch: [16]EMA val MAE: 0.55328, EMA test MAE: 0.53700, Time: 662.74s
2024-03-20 04:14:36,347 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 04:14:37,697 - logger.py:50 - Epoch: [17][0/500] loss: 0.59957, MAE: 0.45963, time/step=1348ms, lr=4.85e-05
2024-03-20 04:15:31,613 - logger.py:50 - Epoch: [17][50/500] loss: 0.68336, MAE: 0.45512, time/step=1084ms, lr=4.85e-05
2024-03-20 04:16:25,455 - logger.py:50 - Epoch: [17][100/500] loss: 0.69904, MAE: 0.44650, time/step=1080ms, lr=4.85e-05
2024-03-20 04:17:19,640 - logger.py:50 - Epoch: [17][150/500] loss: 0.70410, MAE: 0.43970, time/step=1081ms, lr=4.85e-05
2024-03-20 04:18:14,667 - logger.py:50 - Epoch: [17][200/500] loss: 4.44519, MAE: 0.44984, time/step=1086ms, lr=4.85e-05
2024-03-20 04:19:09,269 - logger.py:50 - Epoch: [17][250/500] loss: 5.23466, MAE: 0.45128, time/step=1087ms, lr=4.85e-05
2024-03-20 04:20:03,429 - logger.py:50 - Epoch: [17][300/500] loss: 4.47617, MAE: 0.44900, time/step=1087ms, lr=4.85e-05
2024-03-20 04:20:58,568 - logger.py:50 - Epoch: [17][350/500] loss: 3.92425, MAE: 0.44605, time/step=1089ms, lr=4.85e-05
2024-03-20 04:21:52,091 - logger.py:50 - Epoch: [17][400/500] loss: 3.51686, MAE: 0.44536, time/step=1087ms, lr=4.85e-05
2024-03-20 04:22:45,410 - logger.py:50 - Epoch: [17][450/500] loss: 3.20053, MAE: 0.44370, time/step=1084ms, lr=4.85e-05
2024-03-20 04:23:38,618 - logger.py:50 - Epoch: [17][499/500] loss: 2.95165, MAE: 0.44448, time/step=1085ms, lr=4.85e-05
2024-03-20 04:24:39,140 - logger.py:50 - Epoch: [17] train loss: 2.95165, val loss: 0.61973, test loss: 0.58372, Time: 602.79s
2024-03-20 04:24:39,140 - logger.py:50 - Best -- epoch=16, train loss: 2.97613, val loss: 0.61512, test loss: 0.58009

2024-03-20 04:25:39,105 - logger.py:50 - Epoch: [17]EMA val MAE: 0.55209, EMA test MAE: 0.53576, Time: 662.76s
2024-03-20 04:25:39,105 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 04:25:40,305 - logger.py:50 - Epoch: [18][0/500] loss: 0.38282, MAE: 0.43666, time/step=1197ms, lr=4.83e-05
2024-03-20 04:26:34,637 - logger.py:50 - Epoch: [18][50/500] loss: 8.20087, MAE: 0.45894, time/step=1089ms, lr=4.83e-05
2024-03-20 04:27:29,010 - logger.py:50 - Epoch: [18][100/500] loss: 4.50702, MAE: 0.45998, time/step=1088ms, lr=4.83e-05
2024-03-20 04:28:22,642 - logger.py:50 - Epoch: [18][150/500] loss: 3.23488, MAE: 0.45380, time/step=1083ms, lr=4.83e-05
2024-03-20 04:29:17,133 - logger.py:50 - Epoch: [18][200/500] loss: 2.58389, MAE: 0.45111, time/step=1085ms, lr=4.83e-05
2024-03-20 04:30:10,653 - logger.py:50 - Epoch: [18][250/500] loss: 2.18124, MAE: 0.44664, time/step=1082ms, lr=4.83e-05
2024-03-20 04:31:04,442 - logger.py:50 - Epoch: [18][300/500] loss: 1.91349, MAE: 0.44058, time/step=1081ms, lr=4.83e-05
2024-03-20 04:31:58,843 - logger.py:50 - Epoch: [18][350/500] loss: 1.74140, MAE: 0.44086, time/step=1082ms, lr=4.83e-05
2024-03-20 04:32:51,988 - logger.py:50 - Epoch: [18][400/500] loss: 3.48565, MAE: 0.44491, time/step=1080ms, lr=4.83e-05
2024-03-20 04:33:46,337 - logger.py:50 - Epoch: [18][450/500] loss: 3.18507, MAE: 0.44391, time/step=1080ms, lr=4.83e-05
2024-03-20 04:34:39,224 - logger.py:50 - Epoch: [18][499/500] loss: 2.93719, MAE: 0.44372, time/step=1080ms, lr=4.83e-05
2024-03-20 04:35:40,026 - logger.py:50 - Epoch: [18] train loss: 2.93719, val loss: 0.61415, test loss: 0.57708, Time: 600.92s
2024-03-20 04:35:40,026 - logger.py:50 - Best -- epoch=18, train loss: 2.93719, val loss: 0.61415, test loss: 0.57708

2024-03-20 04:36:40,042 - logger.py:50 - Epoch: [18]EMA val MAE: 0.55069, EMA test MAE: 0.53433, Time: 660.94s
2024-03-20 04:36:40,042 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 04:36:40,807 - logger.py:50 - Epoch: [19][0/500] loss: 724.59467, MAE: 1.91138, time/step=762ms, lr=4.81e-05
2024-03-20 04:37:35,719 - logger.py:50 - Epoch: [19][50/500] loss: 22.56136, MAE: 0.50620, time/step=1092ms, lr=4.81e-05
2024-03-20 04:38:29,546 - logger.py:50 - Epoch: [19][100/500] loss: 11.75333, MAE: 0.47682, time/step=1084ms, lr=4.81e-05
2024-03-20 04:39:23,229 - logger.py:50 - Epoch: [19][150/500] loss: 8.08287, MAE: 0.46187, time/step=1081ms, lr=4.81e-05
2024-03-20 04:40:17,370 - logger.py:50 - Epoch: [19][200/500] loss: 6.24744, MAE: 0.45438, time/step=1081ms, lr=4.81e-05
2024-03-20 04:41:10,811 - logger.py:50 - Epoch: [19][250/500] loss: 5.12777, MAE: 0.45232, time/step=1079ms, lr=4.81e-05
2024-03-20 04:42:04,171 - logger.py:50 - Epoch: [19][300/500] loss: 4.40225, MAE: 0.44759, time/step=1077ms, lr=4.81e-05
2024-03-20 04:42:58,013 - logger.py:50 - Epoch: [19][350/500] loss: 3.85787, MAE: 0.44563, time/step=1077ms, lr=4.81e-05
2024-03-20 04:43:52,989 - logger.py:50 - Epoch: [19][400/500] loss: 3.44490, MAE: 0.44507, time/step=1080ms, lr=4.81e-05
2024-03-20 04:44:46,098 - logger.py:50 - Epoch: [19][450/500] loss: 3.13563, MAE: 0.44447, time/step=1078ms, lr=4.81e-05
2024-03-20 04:45:39,308 - logger.py:50 - Epoch: [19][499/500] loss: 2.88214, MAE: 0.44347, time/step=1079ms, lr=4.81e-05
2024-03-20 04:46:40,425 - logger.py:50 - Epoch: [19] train loss: 2.88214, val loss: 0.59339, test loss: 0.56042, Time: 600.38s
2024-03-20 04:46:40,425 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 04:47:40,412 - logger.py:50 - Epoch: [19]EMA val MAE: 0.54932, EMA test MAE: 0.53286, Time: 660.37s
2024-03-20 04:47:40,412 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 04:47:41,167 - logger.py:50 - Epoch: [20][0/500] loss: 0.66190, MAE: 0.54964, time/step=752ms, lr=4.79e-05
2024-03-20 04:48:35,195 - logger.py:50 - Epoch: [20][50/500] loss: 0.58953, MAE: 0.41809, time/step=1074ms, lr=4.79e-05
2024-03-20 04:49:29,470 - logger.py:50 - Epoch: [20][100/500] loss: 0.58216, MAE: 0.43350, time/step=1080ms, lr=4.79e-05
2024-03-20 04:50:23,860 - logger.py:50 - Epoch: [20][150/500] loss: 0.59582, MAE: 0.43493, time/step=1082ms, lr=4.79e-05
2024-03-20 04:51:18,463 - logger.py:50 - Epoch: [20][200/500] loss: 2.54101, MAE: 0.43914, time/step=1085ms, lr=4.79e-05
2024-03-20 04:52:12,260 - logger.py:50 - Epoch: [20][250/500] loss: 2.17014, MAE: 0.43961, time/step=1083ms, lr=4.79e-05
2024-03-20 04:53:06,704 - logger.py:50 - Epoch: [20][300/500] loss: 1.92765, MAE: 0.44045, time/step=1084ms, lr=4.79e-05
2024-03-20 04:54:01,202 - logger.py:50 - Epoch: [20][350/500] loss: 1.73481, MAE: 0.43991, time/step=1085ms, lr=4.79e-05
2024-03-20 04:54:54,359 - logger.py:50 - Epoch: [20][400/500] loss: 3.46810, MAE: 0.44465, time/step=1082ms, lr=4.79e-05
2024-03-20 04:55:47,606 - logger.py:50 - Epoch: [20][450/500] loss: 3.17509, MAE: 0.44389, time/step=1080ms, lr=4.79e-05
2024-03-20 04:56:40,460 - logger.py:50 - Epoch: [20][499/500] loss: 2.92131, MAE: 0.44397, time/step=1080ms, lr=4.79e-05
2024-03-20 04:57:40,822 - logger.py:50 - Epoch: [20] train loss: 2.92131, val loss: 0.60025, test loss: 0.56528, Time: 600.41s
2024-03-20 04:57:40,822 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 04:58:40,747 - logger.py:50 - Epoch: [20]EMA val MAE: 0.54782, EMA test MAE: 0.53129, Time: 660.33s
2024-03-20 04:58:40,747 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 04:58:41,908 - logger.py:50 - Epoch: [21][0/500] loss: 0.54664, MAE: 0.45739, time/step=1159ms, lr=4.77e-05
2024-03-20 04:59:36,446 - logger.py:50 - Epoch: [21][50/500] loss: 0.57851, MAE: 0.42719, time/step=1092ms, lr=4.77e-05
2024-03-20 05:00:29,635 - logger.py:50 - Epoch: [21][100/500] loss: 0.61040, MAE: 0.43202, time/step=1078ms, lr=4.77e-05
2024-03-20 05:01:23,147 - logger.py:50 - Epoch: [21][150/500] loss: 0.61113, MAE: 0.43216, time/step=1075ms, lr=4.77e-05
2024-03-20 05:02:16,794 - logger.py:50 - Epoch: [21][200/500] loss: 0.61402, MAE: 0.43380, time/step=1075ms, lr=4.77e-05
2024-03-20 05:03:10,632 - logger.py:50 - Epoch: [21][250/500] loss: 0.61823, MAE: 0.43634, time/step=1075ms, lr=4.77e-05
2024-03-20 05:04:03,931 - logger.py:50 - Epoch: [21][300/500] loss: 0.64245, MAE: 0.43584, time/step=1074ms, lr=4.77e-05
2024-03-20 05:04:58,351 - logger.py:50 - Epoch: [21][350/500] loss: 0.63000, MAE: 0.43531, time/step=1076ms, lr=4.77e-05
2024-03-20 05:05:52,969 - logger.py:50 - Epoch: [21][400/500] loss: 1.59413, MAE: 0.43785, time/step=1078ms, lr=4.77e-05
2024-03-20 05:06:47,257 - logger.py:50 - Epoch: [21][450/500] loss: 1.48919, MAE: 0.43973, time/step=1079ms, lr=4.77e-05
2024-03-20 05:07:40,233 - logger.py:50 - Epoch: [21][499/500] loss: 2.85789, MAE: 0.44432, time/step=1079ms, lr=4.77e-05
2024-03-20 05:08:40,671 - logger.py:50 - Epoch: [21] train loss: 2.85789, val loss: 0.80680, test loss: 0.86191, Time: 599.92s
2024-03-20 05:08:40,671 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 05:09:40,622 - logger.py:50 - Epoch: [21]EMA val MAE: 0.54651, EMA test MAE: 0.52984, Time: 659.87s
2024-03-20 05:09:40,622 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 05:09:41,915 - logger.py:50 - Epoch: [22][0/500] loss: 1.77497, MAE: 0.52713, time/step=1291ms, lr=4.74e-05
2024-03-20 05:10:35,168 - logger.py:50 - Epoch: [22][50/500] loss: 0.64587, MAE: 0.44514, time/step=1069ms, lr=4.74e-05
2024-03-20 05:11:29,496 - logger.py:50 - Epoch: [22][100/500] loss: 0.78136, MAE: 0.43440, time/step=1078ms, lr=4.74e-05
2024-03-20 05:12:22,861 - logger.py:50 - Epoch: [22][150/500] loss: 0.73720, MAE: 0.43583, time/step=1074ms, lr=4.74e-05
2024-03-20 05:13:16,960 - logger.py:50 - Epoch: [22][200/500] loss: 2.41977, MAE: 0.43985, time/step=1076ms, lr=4.74e-05
2024-03-20 05:14:11,477 - logger.py:50 - Epoch: [22][250/500] loss: 2.10921, MAE: 0.44126, time/step=1079ms, lr=4.74e-05
2024-03-20 05:15:05,467 - logger.py:50 - Epoch: [22][300/500] loss: 3.81489, MAE: 0.45011, time/step=1079ms, lr=4.74e-05
2024-03-20 05:15:59,479 - logger.py:50 - Epoch: [22][350/500] loss: 3.42279, MAE: 0.44826, time/step=1079ms, lr=4.74e-05
2024-03-20 05:16:54,181 - logger.py:50 - Epoch: [22][400/500] loss: 3.14416, MAE: 0.44664, time/step=1081ms, lr=4.74e-05
2024-03-20 05:17:49,024 - logger.py:50 - Epoch: [22][450/500] loss: 2.86710, MAE: 0.44644, time/step=1083ms, lr=4.74e-05
2024-03-20 05:18:42,816 - logger.py:50 - Epoch: [22][499/500] loss: 2.64960, MAE: 0.44546, time/step=1084ms, lr=4.74e-05
2024-03-20 05:19:43,561 - logger.py:50 - Epoch: [22] train loss: 2.64960, val loss: 0.65239, test loss: 0.63357, Time: 602.94s
2024-03-20 05:19:43,562 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 05:20:43,771 - logger.py:50 - Epoch: [22]EMA val MAE: 0.54758, EMA test MAE: 0.53033, Time: 663.15s
2024-03-20 05:20:43,772 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 05:20:45,035 - logger.py:50 - Epoch: [23][0/500] loss: 0.97777, MAE: 0.52108, time/step=1261ms, lr=4.72e-05
2024-03-20 05:21:38,801 - logger.py:50 - Epoch: [23][50/500] loss: 0.67915, MAE: 0.44656, time/step=1079ms, lr=4.72e-05
2024-03-20 05:22:32,956 - logger.py:50 - Epoch: [23][100/500] loss: 0.63628, MAE: 0.44522, time/step=1081ms, lr=4.72e-05
2024-03-20 05:23:27,263 - logger.py:50 - Epoch: [23][150/500] loss: 0.62275, MAE: 0.44288, time/step=1083ms, lr=4.72e-05
2024-03-20 05:24:21,678 - logger.py:50 - Epoch: [23][200/500] loss: 0.62014, MAE: 0.44078, time/step=1084ms, lr=4.72e-05
2024-03-20 05:25:14,755 - logger.py:50 - Epoch: [23][250/500] loss: 0.64051, MAE: 0.44341, time/step=1080ms, lr=4.72e-05
2024-03-20 05:26:10,852 - logger.py:50 - Epoch: [23][300/500] loss: 1.73549, MAE: 0.44370, time/step=1087ms, lr=4.72e-05
2024-03-20 05:27:04,015 - logger.py:50 - Epoch: [23][350/500] loss: 1.59530, MAE: 0.44340, time/step=1083ms, lr=4.72e-05
2024-03-20 05:27:58,515 - logger.py:50 - Epoch: [23][400/500] loss: 1.46517, MAE: 0.44216, time/step=1084ms, lr=4.72e-05
2024-03-20 05:28:51,945 - logger.py:50 - Epoch: [23][450/500] loss: 2.89393, MAE: 0.44292, time/step=1082ms, lr=4.72e-05
2024-03-20 05:29:45,088 - logger.py:50 - Epoch: [23][499/500] loss: 2.67428, MAE: 0.44205, time/step=1083ms, lr=4.72e-05
2024-03-20 05:30:45,652 - logger.py:50 - Epoch: [23] train loss: 2.67428, val loss: 0.60991, test loss: 0.56842, Time: 601.88s
2024-03-20 05:30:45,652 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 05:31:45,614 - logger.py:50 - Epoch: [23]EMA val MAE: 0.54834, EMA test MAE: 0.53053, Time: 661.84s
2024-03-20 05:31:45,614 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 05:31:46,959 - logger.py:50 - Epoch: [24][0/500] loss: 0.57426, MAE: 0.41647, time/step=1342ms, lr=4.70e-05
2024-03-20 05:32:40,848 - logger.py:50 - Epoch: [24][50/500] loss: 0.61290, MAE: 0.42833, time/step=1083ms, lr=4.70e-05
2024-03-20 05:33:34,702 - logger.py:50 - Epoch: [24][100/500] loss: 0.62728, MAE: 0.43143, time/step=1080ms, lr=4.70e-05
2024-03-20 05:34:28,140 - logger.py:50 - Epoch: [24][150/500] loss: 0.59786, MAE: 0.43218, time/step=1076ms, lr=4.70e-05
2024-03-20 05:35:22,091 - logger.py:50 - Epoch: [24][200/500] loss: 5.72955, MAE: 0.44777, time/step=1077ms, lr=4.70e-05
2024-03-20 05:36:15,988 - logger.py:50 - Epoch: [24][250/500] loss: 4.76509, MAE: 0.44789, time/step=1077ms, lr=4.70e-05
2024-03-20 05:37:10,406 - logger.py:50 - Epoch: [24][300/500] loss: 4.12853, MAE: 0.44400, time/step=1079ms, lr=4.70e-05
2024-03-20 05:38:04,383 - logger.py:50 - Epoch: [24][350/500] loss: 3.66397, MAE: 0.44481, time/step=1079ms, lr=4.70e-05
2024-03-20 05:38:58,143 - logger.py:50 - Epoch: [24][400/500] loss: 3.30094, MAE: 0.44319, time/step=1079ms, lr=4.70e-05
2024-03-20 05:39:51,947 - logger.py:50 - Epoch: [24][450/500] loss: 2.99947, MAE: 0.44356, time/step=1078ms, lr=4.70e-05
2024-03-20 05:40:44,805 - logger.py:50 - Epoch: [24][499/500] loss: 2.77496, MAE: 0.44365, time/step=1078ms, lr=4.70e-05
2024-03-20 05:41:45,521 - logger.py:50 - Epoch: [24] train loss: 2.77496, val loss: 0.60414, test loss: 0.56797, Time: 599.91s
2024-03-20 05:41:45,524 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 05:42:45,472 - logger.py:50 - Epoch: [24]EMA val MAE: 0.54811, EMA test MAE: 0.52990, Time: 659.86s
2024-03-20 05:42:45,473 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 05:42:46,249 - logger.py:50 - Epoch: [25][0/500] loss: 0.38166, MAE: 0.40335, time/step=774ms, lr=4.67e-05
2024-03-20 05:43:40,490 - logger.py:50 - Epoch: [25][50/500] loss: 0.59624, MAE: 0.44033, time/step=1079ms, lr=4.67e-05
2024-03-20 05:44:33,624 - logger.py:50 - Epoch: [25][100/500] loss: 0.64045, MAE: 0.43842, time/step=1071ms, lr=4.67e-05
2024-03-20 05:45:27,642 - logger.py:50 - Epoch: [25][150/500] loss: 0.63590, MAE: 0.43582, time/step=1074ms, lr=4.67e-05
2024-03-20 05:46:21,572 - logger.py:50 - Epoch: [25][200/500] loss: 0.60949, MAE: 0.43394, time/step=1075ms, lr=4.67e-05
2024-03-20 05:47:16,057 - logger.py:50 - Epoch: [25][250/500] loss: 0.60663, MAE: 0.43250, time/step=1078ms, lr=4.67e-05
2024-03-20 05:48:10,311 - logger.py:50 - Epoch: [25][300/500] loss: 2.70542, MAE: 0.44184, time/step=1079ms, lr=4.67e-05
2024-03-20 05:49:04,860 - logger.py:50 - Epoch: [25][350/500] loss: 2.96557, MAE: 0.44664, time/step=1081ms, lr=4.67e-05
2024-03-20 05:49:58,565 - logger.py:50 - Epoch: [25][400/500] loss: 2.72281, MAE: 0.44896, time/step=1080ms, lr=4.67e-05
2024-03-20 05:50:52,629 - logger.py:50 - Epoch: [25][450/500] loss: 2.49134, MAE: 0.44521, time/step=1080ms, lr=4.67e-05
2024-03-20 05:51:45,496 - logger.py:50 - Epoch: [25][499/500] loss: 2.30771, MAE: 0.44417, time/step=1080ms, lr=4.67e-05
2024-03-20 05:52:46,155 - logger.py:50 - Epoch: [25] train loss: 2.30771, val loss: 0.63677, test loss: 0.76950, Time: 600.68s
2024-03-20 05:52:46,155 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 05:53:46,138 - logger.py:50 - Epoch: [25]EMA val MAE: 0.54814, EMA test MAE: 0.52956, Time: 660.67s
2024-03-20 05:53:46,139 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 05:53:47,409 - logger.py:50 - Epoch: [26][0/500] loss: 25.95177, MAE: 0.42873, time/step=1268ms, lr=4.65e-05
2024-03-20 05:54:41,705 - logger.py:50 - Epoch: [26][50/500] loss: 1.25724, MAE: 0.44350, time/step=1089ms, lr=4.65e-05
2024-03-20 05:55:35,837 - logger.py:50 - Epoch: [26][100/500] loss: 0.98564, MAE: 0.43963, time/step=1086ms, lr=4.65e-05
2024-03-20 05:56:29,841 - logger.py:50 - Epoch: [26][150/500] loss: 0.85597, MAE: 0.43943, time/step=1084ms, lr=4.65e-05
2024-03-20 05:57:23,958 - logger.py:50 - Epoch: [26][200/500] loss: 0.78777, MAE: 0.43958, time/step=1084ms, lr=4.65e-05
2024-03-20 05:58:18,278 - logger.py:50 - Epoch: [26][250/500] loss: 0.75912, MAE: 0.43825, time/step=1084ms, lr=4.65e-05
2024-03-20 05:59:11,687 - logger.py:50 - Epoch: [26][300/500] loss: 0.73958, MAE: 0.43643, time/step=1082ms, lr=4.65e-05
2024-03-20 06:00:06,867 - logger.py:50 - Epoch: [26][350/500] loss: 1.90467, MAE: 0.44178, time/step=1085ms, lr=4.65e-05
2024-03-20 06:01:00,485 - logger.py:50 - Epoch: [26][400/500] loss: 1.85856, MAE: 0.44208, time/step=1083ms, lr=4.65e-05
2024-03-20 06:01:54,747 - logger.py:50 - Epoch: [26][450/500] loss: 1.71788, MAE: 0.44072, time/step=1083ms, lr=4.65e-05
2024-03-20 06:02:47,635 - logger.py:50 - Epoch: [26][499/500] loss: 1.83127, MAE: 0.44388, time/step=1083ms, lr=4.65e-05
2024-03-20 06:03:48,421 - logger.py:50 - Epoch: [26] train loss: 1.83127, val loss: 0.76138, test loss: 0.67057, Time: 602.28s
2024-03-20 06:03:48,421 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 06:04:48,513 - logger.py:50 - Epoch: [26]EMA val MAE: 0.54852, EMA test MAE: 0.52960, Time: 662.37s
2024-03-20 06:04:48,513 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 06:04:49,826 - logger.py:50 - Epoch: [27][0/500] loss: 0.37617, MAE: 0.37791, time/step=1310ms, lr=4.62e-05
2024-03-20 06:05:43,047 - logger.py:50 - Epoch: [27][50/500] loss: 0.67061, MAE: 0.41992, time/step=1069ms, lr=4.62e-05
2024-03-20 06:06:37,326 - logger.py:50 - Epoch: [27][100/500] loss: 0.66380, MAE: 0.43213, time/step=1077ms, lr=4.62e-05
2024-03-20 06:07:32,111 - logger.py:50 - Epoch: [27][150/500] loss: 0.65355, MAE: 0.43752, time/step=1083ms, lr=4.62e-05
2024-03-20 06:08:26,619 - logger.py:50 - Epoch: [27][200/500] loss: 0.64275, MAE: 0.44026, time/step=1085ms, lr=4.62e-05
2024-03-20 06:09:20,952 - logger.py:50 - Epoch: [27][250/500] loss: 0.64603, MAE: 0.43734, time/step=1085ms, lr=4.62e-05
2024-03-20 06:10:14,521 - logger.py:50 - Epoch: [27][300/500] loss: 0.66157, MAE: 0.43855, time/step=1083ms, lr=4.62e-05
2024-03-20 06:11:09,277 - logger.py:50 - Epoch: [27][350/500] loss: 0.91514, MAE: 0.44136, time/step=1085ms, lr=4.62e-05
2024-03-20 06:12:03,164 - logger.py:50 - Epoch: [27][400/500] loss: 0.88625, MAE: 0.43977, time/step=1084ms, lr=4.62e-05
2024-03-20 06:12:57,833 - logger.py:50 - Epoch: [27][450/500] loss: 1.36582, MAE: 0.44353, time/step=1085ms, lr=4.62e-05
2024-03-20 06:13:50,881 - logger.py:50 - Epoch: [27][499/500] loss: 1.31383, MAE: 0.44373, time/step=1085ms, lr=4.62e-05
2024-03-20 06:14:52,152 - logger.py:50 - Epoch: [27] train loss: 1.31383, val loss: 1.06760, test loss: 0.81393, Time: 603.64s
2024-03-20 06:14:52,152 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 06:15:52,104 - logger.py:50 - Epoch: [27]EMA val MAE: 0.54934, EMA test MAE: 0.53017, Time: 663.59s
2024-03-20 06:15:52,104 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 06:15:53,373 - logger.py:50 - Epoch: [28][0/500] loss: 0.69752, MAE: 0.38983, time/step=1267ms, lr=4.59e-05
2024-03-20 06:16:45,694 - logger.py:50 - Epoch: [28][50/500] loss: 2.85305, MAE: 0.47454, time/step=1051ms, lr=4.59e-05
2024-03-20 06:17:39,588 - logger.py:50 - Epoch: [28][100/500] loss: 1.73542, MAE: 0.45741, time/step=1064ms, lr=4.59e-05
2024-03-20 06:18:33,305 - logger.py:50 - Epoch: [28][150/500] loss: 1.34950, MAE: 0.44444, time/step=1068ms, lr=4.59e-05
2024-03-20 06:19:27,262 - logger.py:50 - Epoch: [28][200/500] loss: 1.14846, MAE: 0.44421, time/step=1070ms, lr=4.59e-05
2024-03-20 06:20:21,412 - logger.py:50 - Epoch: [28][250/500] loss: 1.04852, MAE: 0.44191, time/step=1073ms, lr=4.59e-05
2024-03-20 06:21:14,654 - logger.py:50 - Epoch: [28][300/500] loss: 0.99386, MAE: 0.44065, time/step=1072ms, lr=4.59e-05
2024-03-20 06:22:08,617 - logger.py:50 - Epoch: [28][350/500] loss: 0.94761, MAE: 0.44107, time/step=1073ms, lr=4.59e-05
2024-03-20 06:23:03,609 - logger.py:50 - Epoch: [28][400/500] loss: 0.91141, MAE: 0.44103, time/step=1076ms, lr=4.59e-05
2024-03-20 06:23:57,962 - logger.py:50 - Epoch: [28][450/500] loss: 1.33032, MAE: 0.44374, time/step=1077ms, lr=4.59e-05
2024-03-20 06:24:50,275 - logger.py:50 - Epoch: [28][499/500] loss: 1.29548, MAE: 0.44401, time/step=1076ms, lr=4.59e-05
2024-03-20 06:25:50,366 - logger.py:50 - Epoch: [28] train loss: 1.29548, val loss: 0.64846, test loss: 0.59604, Time: 598.26s
2024-03-20 06:25:50,367 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 06:26:50,152 - logger.py:50 - Epoch: [28]EMA val MAE: 0.54969, EMA test MAE: 0.53039, Time: 658.05s
2024-03-20 06:26:50,153 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 06:26:51,324 - logger.py:50 - Epoch: [29][0/500] loss: 0.69913, MAE: 0.48007, time/step=1169ms, lr=4.56e-05
2024-03-20 06:27:44,844 - logger.py:50 - Epoch: [29][50/500] loss: 0.67323, MAE: 0.43738, time/step=1072ms, lr=4.56e-05
2024-03-20 06:28:39,065 - logger.py:50 - Epoch: [29][100/500] loss: 0.63556, MAE: 0.43930, time/step=1078ms, lr=4.56e-05
2024-03-20 06:29:32,696 - logger.py:50 - Epoch: [29][150/500] loss: 0.63760, MAE: 0.43736, time/step=1076ms, lr=4.56e-05
2024-03-20 06:30:26,643 - logger.py:50 - Epoch: [29][200/500] loss: 1.02407, MAE: 0.44436, time/step=1077ms, lr=4.56e-05
2024-03-20 06:31:20,117 - logger.py:50 - Epoch: [29][250/500] loss: 0.94052, MAE: 0.44227, time/step=1076ms, lr=4.56e-05
2024-03-20 06:32:13,407 - logger.py:50 - Epoch: [29][300/500] loss: 0.87747, MAE: 0.44253, time/step=1074ms, lr=4.56e-05
2024-03-20 06:33:06,368 - logger.py:50 - Epoch: [29][350/500] loss: 0.83817, MAE: 0.44246, time/step=1072ms, lr=4.56e-05
2024-03-20 06:33:58,813 - logger.py:50 - Epoch: [29][400/500] loss: 0.82231, MAE: 0.44011, time/step=1069ms, lr=4.56e-05
2024-03-20 06:34:52,511 - logger.py:50 - Epoch: [29][450/500] loss: 1.20735, MAE: 0.44255, time/step=1070ms, lr=4.56e-05
2024-03-20 06:35:44,889 - logger.py:50 - Epoch: [29][499/500] loss: 1.17470, MAE: 0.44356, time/step=1069ms, lr=4.56e-05
2024-03-20 06:36:44,359 - logger.py:50 - Epoch: [29] train loss: 1.17470, val loss: 0.74507, test loss: 0.59288, Time: 594.21s
2024-03-20 06:36:44,359 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 06:37:43,567 - logger.py:50 - Epoch: [29]EMA val MAE: 0.54893, EMA test MAE: 0.52968, Time: 653.41s
2024-03-20 06:37:43,567 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 06:37:44,188 - logger.py:50 - Epoch: [30][0/500] loss: 0.54116, MAE: 0.52220, time/step=619ms, lr=4.53e-05
2024-03-20 06:38:38,000 - logger.py:50 - Epoch: [30][50/500] loss: 2.39706, MAE: 0.47698, time/step=1067ms, lr=4.53e-05
2024-03-20 06:39:32,270 - logger.py:50 - Epoch: [30][100/500] loss: 1.51987, MAE: 0.46113, time/step=1076ms, lr=4.53e-05
2024-03-20 06:40:24,848 - logger.py:50 - Epoch: [30][150/500] loss: 1.29116, MAE: 0.45572, time/step=1068ms, lr=4.53e-05
2024-03-20 06:41:17,100 - logger.py:50 - Epoch: [30][200/500] loss: 1.11043, MAE: 0.44804, time/step=1062ms, lr=4.53e-05
2024-03-20 06:42:10,466 - logger.py:50 - Epoch: [30][250/500] loss: 1.70610, MAE: 0.45258, time/step=1063ms, lr=4.53e-05
2024-03-20 06:43:03,091 - logger.py:50 - Epoch: [30][300/500] loss: 1.53710, MAE: 0.44910, time/step=1062ms, lr=4.53e-05
2024-03-20 06:43:55,849 - logger.py:50 - Epoch: [30][350/500] loss: 1.40933, MAE: 0.44605, time/step=1061ms, lr=4.53e-05
2024-03-20 06:44:50,216 - logger.py:50 - Epoch: [30][400/500] loss: 1.30602, MAE: 0.44507, time/step=1064ms, lr=4.53e-05
2024-03-20 06:45:42,997 - logger.py:50 - Epoch: [30][450/500] loss: 1.22953, MAE: 0.44450, time/step=1063ms, lr=4.53e-05
2024-03-20 06:46:35,976 - logger.py:50 - Epoch: [30][499/500] loss: 1.16600, MAE: 0.44384, time/step=1065ms, lr=4.53e-05
2024-03-20 06:47:34,903 - logger.py:50 - Epoch: [30] train loss: 1.16600, val loss: 0.61337, test loss: 0.55273, Time: 591.34s
2024-03-20 06:47:34,903 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 06:48:34,105 - logger.py:50 - Epoch: [30]EMA val MAE: 0.54760, EMA test MAE: 0.52847, Time: 650.54s
2024-03-20 06:48:34,105 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 06:48:35,455 - logger.py:50 - Epoch: [31][0/500] loss: 0.49963, MAE: 0.43958, time/step=1347ms, lr=4.50e-05
2024-03-20 06:49:26,438 - logger.py:50 - Epoch: [31][50/500] loss: 0.65734, MAE: 0.46041, time/step=1026ms, lr=4.50e-05
2024-03-20 06:50:19,485 - logger.py:50 - Epoch: [31][100/500] loss: 0.62600, MAE: 0.44407, time/step=1043ms, lr=4.50e-05
2024-03-20 06:51:11,287 - logger.py:50 - Epoch: [31][150/500] loss: 0.60336, MAE: 0.44052, time/step=1041ms, lr=4.50e-05
2024-03-20 06:52:04,247 - logger.py:50 - Epoch: [31][200/500] loss: 0.61436, MAE: 0.44287, time/step=1045ms, lr=4.50e-05
2024-03-20 06:52:57,568 - logger.py:50 - Epoch: [31][250/500] loss: 0.61663, MAE: 0.43961, time/step=1050ms, lr=4.50e-05
2024-03-20 06:53:50,102 - logger.py:50 - Epoch: [31][300/500] loss: 0.60677, MAE: 0.43812, time/step=1050ms, lr=4.50e-05
2024-03-20 06:54:42,613 - logger.py:50 - Epoch: [31][350/500] loss: 1.04161, MAE: 0.44311, time/step=1050ms, lr=4.50e-05
2024-03-20 06:55:35,864 - logger.py:50 - Epoch: [31][400/500] loss: 0.99349, MAE: 0.44209, time/step=1052ms, lr=4.50e-05
2024-03-20 06:56:28,263 - logger.py:50 - Epoch: [31][450/500] loss: 1.20810, MAE: 0.44479, time/step=1051ms, lr=4.50e-05
2024-03-20 06:57:20,363 - logger.py:50 - Epoch: [31][499/500] loss: 1.14961, MAE: 0.44397, time/step=1053ms, lr=4.50e-05
2024-03-20 06:58:18,973 - logger.py:50 - Epoch: [31] train loss: 1.14961, val loss: 0.66223, test loss: 0.55432, Time: 584.87s
2024-03-20 06:58:18,973 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 06:59:17,022 - logger.py:50 - Epoch: [31]EMA val MAE: 0.54560, EMA test MAE: 0.52667, Time: 642.92s
2024-03-20 06:59:17,022 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 06:59:18,208 - logger.py:50 - Epoch: [32][0/500] loss: 0.75836, MAE: 0.43124, time/step=1184ms, lr=4.47e-05
2024-03-20 07:00:10,412 - logger.py:50 - Epoch: [32][50/500] loss: 0.56371, MAE: 0.44770, time/step=1047ms, lr=4.47e-05
2024-03-20 07:01:03,001 - logger.py:50 - Epoch: [32][100/500] loss: 0.56514, MAE: 0.43617, time/step=1049ms, lr=4.47e-05
2024-03-20 07:01:56,342 - logger.py:50 - Epoch: [32][150/500] loss: 1.08195, MAE: 0.44353, time/step=1055ms, lr=4.47e-05
2024-03-20 07:02:48,754 - logger.py:50 - Epoch: [32][200/500] loss: 0.98055, MAE: 0.44091, time/step=1053ms, lr=4.47e-05
2024-03-20 07:03:40,632 - logger.py:50 - Epoch: [32][250/500] loss: 0.90285, MAE: 0.43862, time/step=1050ms, lr=4.47e-05
2024-03-20 07:04:32,909 - logger.py:50 - Epoch: [32][300/500] loss: 1.42763, MAE: 0.44170, time/step=1049ms, lr=4.47e-05
2024-03-20 07:05:25,073 - logger.py:50 - Epoch: [32][350/500] loss: 1.31222, MAE: 0.43973, time/step=1049ms, lr=4.47e-05
2024-03-20 07:06:17,352 - logger.py:50 - Epoch: [32][400/500] loss: 1.22965, MAE: 0.44163, time/step=1048ms, lr=4.47e-05
2024-03-20 07:07:10,266 - logger.py:50 - Epoch: [32][450/500] loss: 1.17195, MAE: 0.44304, time/step=1049ms, lr=4.47e-05
2024-03-20 07:08:01,163 - logger.py:50 - Epoch: [32][499/500] loss: 1.11350, MAE: 0.44349, time/step=1048ms, lr=4.47e-05
2024-03-20 07:08:59,869 - logger.py:50 - Epoch: [32] train loss: 1.11350, val loss: 0.63848, test loss: 0.53484, Time: 582.85s
2024-03-20 07:08:59,869 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 07:09:57,985 - logger.py:50 - Epoch: [32]EMA val MAE: 0.54252, EMA test MAE: 0.52388, Time: 640.96s
2024-03-20 07:09:57,985 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 07:09:59,294 - logger.py:50 - Epoch: [33][0/500] loss: 0.37963, MAE: 0.45412, time/step=1307ms, lr=4.44e-05
2024-03-20 07:10:51,191 - logger.py:50 - Epoch: [33][50/500] loss: 0.63593, MAE: 0.43460, time/step=1043ms, lr=4.44e-05
2024-03-20 07:11:43,301 - logger.py:50 - Epoch: [33][100/500] loss: 0.57356, MAE: 0.43404, time/step=1043ms, lr=4.44e-05
2024-03-20 07:12:35,990 - logger.py:50 - Epoch: [33][150/500] loss: 0.63057, MAE: 0.43413, time/step=1046ms, lr=4.44e-05
2024-03-20 07:13:28,523 - logger.py:50 - Epoch: [33][200/500] loss: 0.63587, MAE: 0.43821, time/step=1047ms, lr=4.44e-05
2024-03-20 07:14:20,531 - logger.py:50 - Epoch: [33][250/500] loss: 0.63733, MAE: 0.43900, time/step=1046ms, lr=4.44e-05
2024-03-20 07:15:13,476 - logger.py:50 - Epoch: [33][300/500] loss: 1.50726, MAE: 0.45010, time/step=1048ms, lr=4.44e-05
2024-03-20 07:16:05,890 - logger.py:50 - Epoch: [33][350/500] loss: 1.38143, MAE: 0.44761, time/step=1048ms, lr=4.44e-05
2024-03-20 07:16:58,299 - logger.py:50 - Epoch: [33][400/500] loss: 1.28512, MAE: 0.44742, time/step=1048ms, lr=4.44e-05
2024-03-20 07:17:50,950 - logger.py:50 - Epoch: [33][450/500] loss: 1.21087, MAE: 0.44475, time/step=1049ms, lr=4.44e-05
2024-03-20 07:18:42,092 - logger.py:50 - Epoch: [33][499/500] loss: 1.15288, MAE: 0.44369, time/step=1048ms, lr=4.44e-05
2024-03-20 07:19:40,706 - logger.py:50 - Epoch: [33] train loss: 1.15288, val loss: 0.71859, test loss: 0.55976, Time: 582.72s
2024-03-20 07:19:40,706 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 07:20:38,746 - logger.py:50 - Epoch: [33]EMA val MAE: 0.53915, EMA test MAE: 0.52087, Time: 640.76s
2024-03-20 07:20:38,746 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 07:20:39,395 - logger.py:50 - Epoch: [34][0/500] loss: 0.90608, MAE: 0.52801, time/step=647ms, lr=4.40e-05
2024-03-20 07:21:31,494 - logger.py:50 - Epoch: [34][50/500] loss: 2.50862, MAE: 0.47438, time/step=1034ms, lr=4.40e-05
2024-03-20 07:22:24,093 - logger.py:50 - Epoch: [34][100/500] loss: 1.52798, MAE: 0.45779, time/step=1043ms, lr=4.40e-05
2024-03-20 07:23:16,729 - logger.py:50 - Epoch: [34][150/500] loss: 1.18946, MAE: 0.44913, time/step=1046ms, lr=4.40e-05
2024-03-20 07:24:09,087 - logger.py:50 - Epoch: [34][200/500] loss: 1.05922, MAE: 0.44909, time/step=1046ms, lr=4.40e-05
2024-03-20 07:25:01,184 - logger.py:50 - Epoch: [34][250/500] loss: 0.96788, MAE: 0.44626, time/step=1046ms, lr=4.40e-05
2024-03-20 07:25:53,921 - logger.py:50 - Epoch: [34][300/500] loss: 0.91577, MAE: 0.44568, time/step=1047ms, lr=4.40e-05
2024-03-20 07:26:45,609 - logger.py:50 - Epoch: [34][350/500] loss: 1.33901, MAE: 0.45015, time/step=1045ms, lr=4.40e-05
2024-03-20 07:27:37,968 - logger.py:50 - Epoch: [34][400/500] loss: 1.24841, MAE: 0.44755, time/step=1045ms, lr=4.40e-05
2024-03-20 07:28:29,598 - logger.py:50 - Epoch: [34][450/500] loss: 1.18254, MAE: 0.44557, time/step=1044ms, lr=4.40e-05
2024-03-20 07:29:20,724 - logger.py:50 - Epoch: [34][499/500] loss: 1.13898, MAE: 0.44365, time/step=1044ms, lr=4.40e-05
2024-03-20 07:30:18,692 - logger.py:50 - Epoch: [34] train loss: 1.13898, val loss: 0.60986, test loss: 0.57419, Time: 579.95s
2024-03-20 07:30:18,693 - logger.py:50 - Best -- epoch=19, train loss: 2.88214, val loss: 0.59339, test loss: 0.56042

2024-03-20 07:31:16,288 - logger.py:50 - Epoch: [34]EMA val MAE: 0.53478, EMA test MAE: 0.51692, Time: 637.54s
2024-03-20 07:31:16,288 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 07:31:17,609 - logger.py:50 - Epoch: [35][0/500] loss: 0.24464, MAE: 0.38152, time/step=1319ms, lr=4.37e-05
2024-03-20 07:32:09,920 - logger.py:50 - Epoch: [35][50/500] loss: 0.68118, MAE: 0.44937, time/step=1052ms, lr=4.37e-05
2024-03-20 07:33:01,388 - logger.py:50 - Epoch: [35][100/500] loss: 0.70589, MAE: 0.44838, time/step=1041ms, lr=4.37e-05
2024-03-20 07:33:53,576 - logger.py:50 - Epoch: [35][150/500] loss: 0.65989, MAE: 0.43999, time/step=1042ms, lr=4.37e-05
2024-03-20 07:34:45,643 - logger.py:50 - Epoch: [35][200/500] loss: 0.64088, MAE: 0.43930, time/step=1042ms, lr=4.37e-05
2024-03-20 07:35:37,648 - logger.py:50 - Epoch: [35][250/500] loss: 0.62499, MAE: 0.43726, time/step=1041ms, lr=4.37e-05
2024-03-20 07:36:29,599 - logger.py:50 - Epoch: [35][300/500] loss: 1.06325, MAE: 0.44406, time/step=1041ms, lr=4.37e-05
2024-03-20 07:37:20,616 - logger.py:50 - Epoch: [35][350/500] loss: 0.99201, MAE: 0.44092, time/step=1038ms, lr=4.37e-05
2024-03-20 07:38:12,300 - logger.py:50 - Epoch: [35][400/500] loss: 0.93955, MAE: 0.43948, time/step=1037ms, lr=4.37e-05
2024-03-20 07:39:03,578 - logger.py:50 - Epoch: [35][450/500] loss: 1.13859, MAE: 0.44492, time/step=1036ms, lr=4.37e-05
2024-03-20 07:39:53,612 - logger.py:50 - Epoch: [35][499/500] loss: 1.08757, MAE: 0.44382, time/step=1035ms, lr=4.37e-05
2024-03-20 07:40:51,514 - logger.py:50 - Epoch: [35] train loss: 1.08757, val loss: 0.57928, test loss: 0.53741, Time: 575.23s
2024-03-20 07:40:51,514 - logger.py:50 - Best -- epoch=35, train loss: 1.08757, val loss: 0.57928, test loss: 0.53741

2024-03-20 07:41:48,291 - logger.py:50 - Epoch: [35]EMA val MAE: 0.53073, EMA test MAE: 0.51330, Time: 632.00s
2024-03-20 07:41:48,291 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 07:41:49,453 - logger.py:50 - Epoch: [36][0/500] loss: 1.17956, MAE: 0.48471, time/step=1160ms, lr=4.34e-05
2024-03-20 07:42:40,781 - logger.py:50 - Epoch: [36][50/500] loss: 0.64226, MAE: 0.45410, time/step=1029ms, lr=4.34e-05
2024-03-20 07:43:32,498 - logger.py:50 - Epoch: [36][100/500] loss: 0.60589, MAE: 0.44640, time/step=1032ms, lr=4.34e-05
2024-03-20 07:44:23,628 - logger.py:50 - Epoch: [36][150/500] loss: 0.62013, MAE: 0.45088, time/step=1029ms, lr=4.34e-05
2024-03-20 07:45:15,863 - logger.py:50 - Epoch: [36][200/500] loss: 0.95645, MAE: 0.45535, time/step=1033ms, lr=4.34e-05
2024-03-20 07:46:07,661 - logger.py:50 - Epoch: [36][250/500] loss: 0.90388, MAE: 0.44938, time/step=1033ms, lr=4.34e-05
2024-03-20 07:46:58,961 - logger.py:50 - Epoch: [36][300/500] loss: 0.84539, MAE: 0.44548, time/step=1032ms, lr=4.34e-05
2024-03-20 07:47:49,900 - logger.py:50 - Epoch: [36][350/500] loss: 0.80547, MAE: 0.44270, time/step=1030ms, lr=4.34e-05
2024-03-20 07:48:41,642 - logger.py:50 - Epoch: [36][400/500] loss: 0.77877, MAE: 0.44149, time/step=1031ms, lr=4.34e-05
2024-03-20 07:49:33,750 - logger.py:50 - Epoch: [36][450/500] loss: 1.14138, MAE: 0.44459, time/step=1032ms, lr=4.34e-05
2024-03-20 07:50:24,831 - logger.py:50 - Epoch: [36][499/500] loss: 1.09326, MAE: 0.44343, time/step=1033ms, lr=4.34e-05
2024-03-20 07:51:22,970 - logger.py:50 - Epoch: [36] train loss: 1.09326, val loss: 1.00901, test loss: 0.56438, Time: 574.68s
2024-03-20 07:51:22,970 - logger.py:50 - Best -- epoch=35, train loss: 1.08757, val loss: 0.57928, test loss: 0.53741

2024-03-20 07:52:20,777 - logger.py:50 - Epoch: [36]EMA val MAE: 0.52575, EMA test MAE: 0.50875, Time: 632.49s
2024-03-20 07:52:20,778 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 07:52:21,482 - logger.py:50 - Epoch: [37][0/500] loss: 0.52790, MAE: 0.45299, time/step=702ms, lr=4.30e-05
2024-03-20 07:53:11,662 - logger.py:50 - Epoch: [37][50/500] loss: 3.30139, MAE: 0.46999, time/step=998ms, lr=4.30e-05
2024-03-20 07:54:03,552 - logger.py:50 - Epoch: [37][100/500] loss: 2.03374, MAE: 0.45728, time/step=1018ms, lr=4.30e-05
2024-03-20 07:54:55,004 - logger.py:50 - Epoch: [37][150/500] loss: 1.55498, MAE: 0.44326, time/step=1021ms, lr=4.30e-05
2024-03-20 07:55:48,313 - logger.py:50 - Epoch: [37][200/500] loss: 1.83595, MAE: 0.45241, time/step=1033ms, lr=4.30e-05
2024-03-20 07:56:40,774 - logger.py:50 - Epoch: [37][250/500] loss: 1.58462, MAE: 0.45294, time/step=1036ms, lr=4.30e-05
2024-03-20 07:57:33,734 - logger.py:50 - Epoch: [37][300/500] loss: 1.40252, MAE: 0.44909, time/step=1040ms, lr=4.30e-05
2024-03-20 07:58:25,137 - logger.py:50 - Epoch: [37][350/500] loss: 1.29186, MAE: 0.44678, time/step=1038ms, lr=4.30e-05
2024-03-20 07:59:17,404 - logger.py:50 - Epoch: [37][400/500] loss: 1.20746, MAE: 0.44591, time/step=1039ms, lr=4.30e-05
2024-03-20 08:00:10,132 - logger.py:50 - Epoch: [37][450/500] loss: 1.13853, MAE: 0.44429, time/step=1041ms, lr=4.30e-05
2024-03-20 08:01:01,695 - logger.py:50 - Epoch: [37][499/500] loss: 1.07985, MAE: 0.44402, time/step=1042ms, lr=4.30e-05
2024-03-20 08:02:00,038 - logger.py:50 - Epoch: [37] train loss: 1.07985, val loss: 0.56908, test loss: 0.51985, Time: 579.26s
2024-03-20 08:02:00,038 - logger.py:50 - Best -- epoch=37, train loss: 1.07985, val loss: 0.56908, test loss: 0.51985

2024-03-20 08:02:57,804 - logger.py:50 - Epoch: [37]EMA val MAE: 0.52124, EMA test MAE: 0.50464, Time: 637.03s
2024-03-20 08:02:57,805 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 08:02:58,970 - logger.py:50 - Epoch: [38][0/500] loss: 0.75604, MAE: 0.42594, time/step=1164ms, lr=4.26e-05
2024-03-20 08:03:51,165 - logger.py:50 - Epoch: [38][50/500] loss: 0.62936, MAE: 0.44182, time/step=1046ms, lr=4.26e-05
2024-03-20 08:04:43,388 - logger.py:50 - Epoch: [38][100/500] loss: 1.31856, MAE: 0.45378, time/step=1045ms, lr=4.26e-05
2024-03-20 08:05:36,023 - logger.py:50 - Epoch: [38][150/500] loss: 1.06781, MAE: 0.44832, time/step=1048ms, lr=4.26e-05
2024-03-20 08:06:28,576 - logger.py:50 - Epoch: [38][200/500] loss: 0.94572, MAE: 0.44485, time/step=1049ms, lr=4.26e-05
2024-03-20 08:07:20,079 - logger.py:50 - Epoch: [38][250/500] loss: 0.87247, MAE: 0.44455, time/step=1045ms, lr=4.26e-05
2024-03-20 08:08:11,863 - logger.py:50 - Epoch: [38][300/500] loss: 0.81187, MAE: 0.44388, time/step=1043ms, lr=4.26e-05
2024-03-20 08:09:03,383 - logger.py:50 - Epoch: [38][350/500] loss: 0.78559, MAE: 0.44163, time/step=1042ms, lr=4.26e-05
2024-03-20 08:09:55,155 - logger.py:50 - Epoch: [38][400/500] loss: 0.76227, MAE: 0.44000, time/step=1041ms, lr=4.26e-05
2024-03-20 08:10:47,076 - logger.py:50 - Epoch: [38][450/500] loss: 1.13773, MAE: 0.44333, time/step=1041ms, lr=4.26e-05
2024-03-20 08:11:39,019 - logger.py:50 - Epoch: [38][499/500] loss: 1.09167, MAE: 0.44344, time/step=1042ms, lr=4.26e-05
2024-03-20 08:12:37,243 - logger.py:50 - Epoch: [38] train loss: 1.09167, val loss: 0.65311, test loss: 0.56990, Time: 579.44s
2024-03-20 08:12:37,243 - logger.py:50 - Best -- epoch=37, train loss: 1.07985, val loss: 0.56908, test loss: 0.51985

2024-03-20 08:13:35,086 - logger.py:50 - Epoch: [38]EMA val MAE: 0.51660, EMA test MAE: 0.50037, Time: 637.28s
2024-03-20 08:13:35,087 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 08:13:35,735 - logger.py:50 - Epoch: [39][0/500] loss: 0.44368, MAE: 0.39047, time/step=646ms, lr=4.23e-05
2024-03-20 08:14:27,861 - logger.py:50 - Epoch: [39][50/500] loss: 0.58533, MAE: 0.44716, time/step=1035ms, lr=4.23e-05
2024-03-20 08:15:19,158 - logger.py:50 - Epoch: [39][100/500] loss: 0.62197, MAE: 0.44414, time/step=1030ms, lr=4.23e-05
2024-03-20 08:16:11,333 - logger.py:50 - Epoch: [39][150/500] loss: 1.20794, MAE: 0.44811, time/step=1035ms, lr=4.23e-05
2024-03-20 08:17:03,911 - logger.py:50 - Epoch: [39][200/500] loss: 1.04595, MAE: 0.44463, time/step=1039ms, lr=4.23e-05
2024-03-20 08:17:56,179 - logger.py:50 - Epoch: [39][250/500] loss: 0.96828, MAE: 0.44285, time/step=1040ms, lr=4.23e-05
2024-03-20 08:18:48,029 - logger.py:50 - Epoch: [39][300/500] loss: 0.90557, MAE: 0.44169, time/step=1040ms, lr=4.23e-05
2024-03-20 08:19:40,537 - logger.py:50 - Epoch: [39][350/500] loss: 0.87306, MAE: 0.44094, time/step=1041ms, lr=4.23e-05
2024-03-20 08:20:33,066 - logger.py:50 - Epoch: [39][400/500] loss: 0.83605, MAE: 0.43974, time/step=1042ms, lr=4.23e-05
2024-03-20 08:21:24,644 - logger.py:50 - Epoch: [39][450/500] loss: 0.81215, MAE: 0.43927, time/step=1041ms, lr=4.23e-05
2024-03-20 08:22:16,446 - logger.py:50 - Epoch: [39][499/500] loss: 1.12973, MAE: 0.44367, time/step=1043ms, lr=4.23e-05
2024-03-20 08:23:14,629 - logger.py:50 - Epoch: [39] train loss: 1.12973, val loss: 0.58693, test loss: 0.55543, Time: 579.54s
2024-03-20 08:23:14,629 - logger.py:50 - Best -- epoch=37, train loss: 1.07985, val loss: 0.56908, test loss: 0.51985

2024-03-20 08:24:12,299 - logger.py:50 - Epoch: [39]EMA val MAE: 0.51214, EMA test MAE: 0.49627, Time: 637.21s
2024-03-20 08:24:12,299 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 08:24:13,441 - logger.py:50 - Epoch: [40][0/500] loss: 0.91839, MAE: 0.40221, time/step=1140ms, lr=4.19e-05
2024-03-20 08:25:06,074 - logger.py:50 - Epoch: [40][50/500] loss: 0.61513, MAE: 0.43470, time/step=1054ms, lr=4.19e-05
2024-03-20 08:25:58,587 - logger.py:50 - Epoch: [40][100/500] loss: 0.60349, MAE: 0.43340, time/step=1052ms, lr=4.19e-05
2024-03-20 08:26:48,774 - logger.py:50 - Epoch: [40][150/500] loss: 0.59663, MAE: 0.43377, time/step=1036ms, lr=4.19e-05
2024-03-20 08:27:41,355 - logger.py:50 - Epoch: [40][200/500] loss: 0.58877, MAE: 0.43390, time/step=1040ms, lr=4.19e-05
2024-03-20 08:28:33,917 - logger.py:50 - Epoch: [40][250/500] loss: 0.58671, MAE: 0.43582, time/step=1042ms, lr=4.19e-05
2024-03-20 08:29:27,190 - logger.py:50 - Epoch: [40][300/500] loss: 0.59118, MAE: 0.43720, time/step=1046ms, lr=4.19e-05
2024-03-20 08:30:20,011 - logger.py:50 - Epoch: [40][350/500] loss: 0.82894, MAE: 0.44054, time/step=1048ms, lr=4.19e-05
2024-03-20 08:31:12,419 - logger.py:50 - Epoch: [40][400/500] loss: 1.20571, MAE: 0.44777, time/step=1048ms, lr=4.19e-05
2024-03-20 08:32:03,621 - logger.py:50 - Epoch: [40][450/500] loss: 1.13594, MAE: 0.44518, time/step=1045ms, lr=4.19e-05
2024-03-20 08:32:53,101 - logger.py:50 - Epoch: [40][499/500] loss: 1.09646, MAE: 0.44367, time/step=1042ms, lr=4.19e-05
2024-03-20 08:33:51,010 - logger.py:50 - Epoch: [40] train loss: 1.09646, val loss: 0.56590, test loss: 0.53084, Time: 578.71s
2024-03-20 08:33:51,010 - logger.py:50 - Best -- epoch=40, train loss: 1.09646, val loss: 0.56590, test loss: 0.53084

2024-03-20 08:34:48,884 - logger.py:50 - Epoch: [40]EMA val MAE: 0.50880, EMA test MAE: 0.49324, Time: 636.58s
2024-03-20 08:34:48,884 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 08:34:49,661 - logger.py:50 - Epoch: [41][0/500] loss: 0.57837, MAE: 0.50178, time/step=775ms, lr=4.15e-05
2024-03-20 08:35:41,153 - logger.py:50 - Epoch: [41][50/500] loss: 0.58426, MAE: 0.45463, time/step=1025ms, lr=4.15e-05
2024-03-20 08:36:32,387 - logger.py:50 - Epoch: [41][100/500] loss: 0.56695, MAE: 0.43329, time/step=1025ms, lr=4.15e-05
2024-03-20 08:37:24,293 - logger.py:50 - Epoch: [41][150/500] loss: 0.56328, MAE: 0.43291, time/step=1029ms, lr=4.15e-05
2024-03-20 08:38:16,262 - logger.py:50 - Epoch: [41][200/500] loss: 1.24155, MAE: 0.44706, time/step=1032ms, lr=4.15e-05
2024-03-20 08:39:07,413 - logger.py:50 - Epoch: [41][250/500] loss: 1.11286, MAE: 0.44412, time/step=1030ms, lr=4.15e-05
2024-03-20 08:39:59,549 - logger.py:50 - Epoch: [41][300/500] loss: 1.36627, MAE: 0.44671, time/step=1032ms, lr=4.15e-05
2024-03-20 08:40:51,762 - logger.py:50 - Epoch: [41][350/500] loss: 1.25138, MAE: 0.44619, time/step=1034ms, lr=4.15e-05
2024-03-20 08:41:44,485 - logger.py:50 - Epoch: [41][400/500] loss: 1.16280, MAE: 0.44480, time/step=1036ms, lr=4.15e-05
2024-03-20 08:42:35,779 - logger.py:50 - Epoch: [41][450/500] loss: 1.09976, MAE: 0.44370, time/step=1035ms, lr=4.15e-05
2024-03-20 08:43:26,570 - logger.py:50 - Epoch: [41][499/500] loss: 1.04290, MAE: 0.44363, time/step=1035ms, lr=4.15e-05
2024-03-20 08:44:25,260 - logger.py:50 - Epoch: [41] train loss: 1.04290, val loss: 0.56135, test loss: 0.54607, Time: 576.38s
2024-03-20 08:44:25,260 - logger.py:50 - Best -- epoch=41, train loss: 1.04290, val loss: 0.56135, test loss: 0.54607

2024-03-20 08:45:22,768 - logger.py:50 - Epoch: [41]EMA val MAE: 0.50520, EMA test MAE: 0.48989, Time: 633.88s
2024-03-20 08:45:22,768 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 08:45:23,986 - logger.py:50 - Epoch: [42][0/500] loss: 0.75515, MAE: 0.46841, time/step=1216ms, lr=4.11e-05
2024-03-20 08:46:15,443 - logger.py:50 - Epoch: [42][50/500] loss: 0.59347, MAE: 0.43960, time/step=1033ms, lr=4.11e-05
2024-03-20 08:47:08,132 - logger.py:50 - Epoch: [42][100/500] loss: 2.00612, MAE: 0.46115, time/step=1043ms, lr=4.11e-05
2024-03-20 08:47:59,220 - logger.py:50 - Epoch: [42][150/500] loss: 1.56025, MAE: 0.45339, time/step=1036ms, lr=4.11e-05
2024-03-20 08:48:50,699 - logger.py:50 - Epoch: [42][200/500] loss: 1.32492, MAE: 0.45092, time/step=1034ms, lr=4.11e-05
2024-03-20 08:49:42,601 - logger.py:50 - Epoch: [42][250/500] loss: 1.18294, MAE: 0.44779, time/step=1035ms, lr=4.11e-05
2024-03-20 08:50:35,150 - logger.py:50 - Epoch: [42][300/500] loss: 1.37471, MAE: 0.45263, time/step=1038ms, lr=4.11e-05
2024-03-20 08:51:26,969 - logger.py:50 - Epoch: [42][350/500] loss: 1.25746, MAE: 0.44861, time/step=1038ms, lr=4.11e-05
2024-03-20 08:52:18,273 - logger.py:50 - Epoch: [42][400/500] loss: 1.17299, MAE: 0.44612, time/step=1036ms, lr=4.11e-05
2024-03-20 08:53:09,836 - logger.py:50 - Epoch: [42][450/500] loss: 1.10719, MAE: 0.44467, time/step=1036ms, lr=4.11e-05
2024-03-20 08:54:01,156 - logger.py:50 - Epoch: [42][499/500] loss: 1.04825, MAE: 0.44355, time/step=1037ms, lr=4.11e-05
2024-03-20 08:54:59,071 - logger.py:50 - Epoch: [42] train loss: 1.04825, val loss: 0.54891, test loss: 0.51043, Time: 576.30s
2024-03-20 08:54:59,071 - logger.py:50 - Best -- epoch=42, train loss: 1.04825, val loss: 0.54891, test loss: 0.51043

2024-03-20 08:55:56,333 - logger.py:50 - Epoch: [42]EMA val MAE: 0.50185, EMA test MAE: 0.48672, Time: 633.57s
2024-03-20 08:55:56,333 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 08:55:57,537 - logger.py:50 - Epoch: [43][0/500] loss: 0.51284, MAE: 0.44674, time/step=1201ms, lr=4.07e-05
2024-03-20 08:56:48,625 - logger.py:50 - Epoch: [43][50/500] loss: 1.87273, MAE: 0.46532, time/step=1025ms, lr=4.07e-05
2024-03-20 08:57:41,122 - logger.py:50 - Epoch: [43][100/500] loss: 1.19112, MAE: 0.44225, time/step=1037ms, lr=4.07e-05
2024-03-20 08:58:31,775 - logger.py:50 - Epoch: [43][150/500] loss: 0.99438, MAE: 0.44130, time/step=1029ms, lr=4.07e-05
2024-03-20 08:59:23,340 - logger.py:50 - Epoch: [43][200/500] loss: 0.88467, MAE: 0.43892, time/step=1030ms, lr=4.07e-05
2024-03-20 09:00:14,852 - logger.py:50 - Epoch: [43][250/500] loss: 0.85176, MAE: 0.43983, time/step=1030ms, lr=4.07e-05
2024-03-20 09:01:07,577 - logger.py:50 - Epoch: [43][300/500] loss: 1.34296, MAE: 0.44615, time/step=1034ms, lr=4.07e-05
2024-03-20 09:01:58,950 - logger.py:50 - Epoch: [43][350/500] loss: 1.24203, MAE: 0.44497, time/step=1033ms, lr=4.07e-05
2024-03-20 09:02:51,773 - logger.py:50 - Epoch: [43][400/500] loss: 1.16019, MAE: 0.44519, time/step=1036ms, lr=4.07e-05
2024-03-20 09:03:43,227 - logger.py:50 - Epoch: [43][450/500] loss: 1.09232, MAE: 0.44316, time/step=1035ms, lr=4.07e-05
2024-03-20 09:04:34,151 - logger.py:50 - Epoch: [43][499/500] loss: 1.04684, MAE: 0.44358, time/step=1036ms, lr=4.07e-05
2024-03-20 09:05:31,831 - logger.py:50 - Epoch: [43] train loss: 1.04684, val loss: 0.55415, test loss: 0.52203, Time: 575.50s
2024-03-20 09:05:31,831 - logger.py:50 - Best -- epoch=42, train loss: 1.04825, val loss: 0.54891, test loss: 0.51043

2024-03-20 09:06:29,076 - logger.py:50 - Epoch: [43]EMA val MAE: 0.49882, EMA test MAE: 0.48383, Time: 632.74s
2024-03-20 09:06:29,076 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 09:06:30,328 - logger.py:50 - Epoch: [44][0/500] loss: 0.65724, MAE: 0.47827, time/step=1249ms, lr=4.03e-05
2024-03-20 09:07:21,594 - logger.py:50 - Epoch: [44][50/500] loss: 0.52835, MAE: 0.43443, time/step=1030ms, lr=4.03e-05
2024-03-20 09:08:13,325 - logger.py:50 - Epoch: [44][100/500] loss: 0.58175, MAE: 0.44282, time/step=1032ms, lr=4.03e-05
2024-03-20 09:09:05,465 - logger.py:50 - Epoch: [44][150/500] loss: 2.08321, MAE: 0.45979, time/step=1036ms, lr=4.03e-05
2024-03-20 09:09:57,608 - logger.py:50 - Epoch: [44][200/500] loss: 1.73590, MAE: 0.45852, time/step=1037ms, lr=4.03e-05
2024-03-20 09:10:50,056 - logger.py:50 - Epoch: [44][250/500] loss: 1.51089, MAE: 0.45435, time/step=1040ms, lr=4.03e-05
2024-03-20 09:11:40,829 - logger.py:50 - Epoch: [44][300/500] loss: 1.35595, MAE: 0.45005, time/step=1036ms, lr=4.03e-05
2024-03-20 09:12:33,636 - logger.py:50 - Epoch: [44][350/500] loss: 1.24262, MAE: 0.45044, time/step=1039ms, lr=4.03e-05
2024-03-20 09:13:25,215 - logger.py:50 - Epoch: [44][400/500] loss: 1.17299, MAE: 0.44954, time/step=1038ms, lr=4.03e-05
2024-03-20 09:14:17,738 - logger.py:50 - Epoch: [44][450/500] loss: 1.09727, MAE: 0.44708, time/step=1039ms, lr=4.03e-05
2024-03-20 09:15:08,180 - logger.py:50 - Epoch: [44][499/500] loss: 1.04117, MAE: 0.44376, time/step=1038ms, lr=4.03e-05
2024-03-20 09:16:06,005 - logger.py:50 - Epoch: [44] train loss: 1.04117, val loss: 0.54988, test loss: 0.51228, Time: 576.93s
2024-03-20 09:16:06,005 - logger.py:50 - Best -- epoch=42, train loss: 1.04825, val loss: 0.54891, test loss: 0.51043

2024-03-20 09:17:03,556 - logger.py:50 - Epoch: [44]EMA val MAE: 0.49591, EMA test MAE: 0.48103, Time: 634.48s
2024-03-20 09:17:03,556 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 09:17:04,770 - logger.py:50 - Epoch: [45][0/500] loss: 2.10923, MAE: 0.41349, time/step=1212ms, lr=3.99e-05
2024-03-20 09:17:55,980 - logger.py:50 - Epoch: [45][50/500] loss: 3.98573, MAE: 0.45811, time/step=1028ms, lr=3.99e-05
2024-03-20 09:18:46,952 - logger.py:50 - Epoch: [45][100/500] loss: 2.34452, MAE: 0.44850, time/step=1024ms, lr=3.99e-05
2024-03-20 09:19:39,979 - logger.py:50 - Epoch: [45][150/500] loss: 1.73920, MAE: 0.44609, time/step=1036ms, lr=3.99e-05
2024-03-20 09:20:31,891 - logger.py:50 - Epoch: [45][200/500] loss: 1.44130, MAE: 0.44381, time/step=1036ms, lr=3.99e-05
2024-03-20 09:21:23,577 - logger.py:50 - Epoch: [45][250/500] loss: 1.26015, MAE: 0.44089, time/step=1036ms, lr=3.99e-05
2024-03-20 09:22:14,306 - logger.py:50 - Epoch: [45][300/500] loss: 1.64716, MAE: 0.44438, time/step=1032ms, lr=3.99e-05
2024-03-20 09:23:06,330 - logger.py:50 - Epoch: [45][350/500] loss: 1.49007, MAE: 0.44298, time/step=1034ms, lr=3.99e-05
2024-03-20 09:23:58,336 - logger.py:50 - Epoch: [45][400/500] loss: 1.38219, MAE: 0.44292, time/step=1034ms, lr=3.99e-05
2024-03-20 09:24:50,597 - logger.py:50 - Epoch: [45][450/500] loss: 1.29680, MAE: 0.44287, time/step=1036ms, lr=3.99e-05
2024-03-20 09:25:41,417 - logger.py:50 - Epoch: [45][499/500] loss: 1.21895, MAE: 0.44282, time/step=1036ms, lr=3.99e-05
2024-03-20 09:26:39,347 - logger.py:50 - Epoch: [45] train loss: 1.21895, val loss: 0.54285, test loss: 0.50377, Time: 575.79s
2024-03-20 09:26:39,347 - logger.py:50 - Best -- epoch=45, train loss: 1.21895, val loss: 0.54285, test loss: 0.50377

2024-03-20 09:27:36,829 - logger.py:50 - Epoch: [45]EMA val MAE: 0.49324, EMA test MAE: 0.47844, Time: 633.27s
2024-03-20 09:27:36,829 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 09:27:37,590 - logger.py:50 - Epoch: [46][0/500] loss: 0.89886, MAE: 0.52815, time/step=759ms, lr=3.95e-05
2024-03-20 09:28:29,312 - logger.py:50 - Epoch: [46][50/500] loss: 0.56701, MAE: 0.44775, time/step=1029ms, lr=3.95e-05
2024-03-20 09:29:21,000 - logger.py:50 - Epoch: [46][100/500] loss: 0.53439, MAE: 0.43874, time/step=1031ms, lr=3.95e-05
2024-03-20 09:30:12,372 - logger.py:50 - Epoch: [46][150/500] loss: 0.55001, MAE: 0.44441, time/step=1030ms, lr=3.95e-05
2024-03-20 09:31:04,221 - logger.py:50 - Epoch: [46][200/500] loss: 1.30842, MAE: 0.44848, time/step=1032ms, lr=3.95e-05
2024-03-20 09:31:55,600 - logger.py:50 - Epoch: [46][250/500] loss: 1.17676, MAE: 0.44464, time/step=1031ms, lr=3.95e-05
2024-03-20 09:32:47,648 - logger.py:50 - Epoch: [46][300/500] loss: 1.09872, MAE: 0.44566, time/step=1033ms, lr=3.95e-05
2024-03-20 09:33:40,249 - logger.py:50 - Epoch: [46][350/500] loss: 1.27817, MAE: 0.44779, time/step=1035ms, lr=3.95e-05
2024-03-20 09:34:32,498 - logger.py:50 - Epoch: [46][400/500] loss: 1.19275, MAE: 0.44712, time/step=1037ms, lr=3.95e-05
2024-03-20 09:35:24,695 - logger.py:50 - Epoch: [46][450/500] loss: 1.11945, MAE: 0.44376, time/step=1037ms, lr=3.95e-05
2024-03-20 09:36:15,305 - logger.py:50 - Epoch: [46][499/500] loss: 1.07412, MAE: 0.44380, time/step=1037ms, lr=3.95e-05
2024-03-20 09:37:13,257 - logger.py:50 - Epoch: [46] train loss: 1.07412, val loss: 0.54902, test loss: 0.51378, Time: 576.43s
2024-03-20 09:37:13,257 - logger.py:50 - Best -- epoch=45, train loss: 1.21895, val loss: 0.54285, test loss: 0.50377

2024-03-20 09:38:10,756 - logger.py:50 - Epoch: [46]EMA val MAE: 0.49102, EMA test MAE: 0.47627, Time: 633.93s
2024-03-20 09:38:10,757 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 09:38:11,449 - logger.py:50 - Epoch: [47][0/500] loss: 0.37458, MAE: 0.45436, time/step=690ms, lr=3.91e-05
2024-03-20 09:39:03,473 - logger.py:50 - Epoch: [47][50/500] loss: 0.58745, MAE: 0.44738, time/step=1034ms, lr=3.91e-05
2024-03-20 09:39:55,678 - logger.py:50 - Epoch: [47][100/500] loss: 1.38668, MAE: 0.46343, time/step=1039ms, lr=3.91e-05
2024-03-20 09:40:47,922 - logger.py:50 - Epoch: [47][150/500] loss: 2.08857, MAE: 0.46615, time/step=1041ms, lr=3.91e-05
2024-03-20 09:41:39,067 - logger.py:50 - Epoch: [47][200/500] loss: 1.70776, MAE: 0.45635, time/step=1036ms, lr=3.91e-05
2024-03-20 09:42:30,460 - logger.py:50 - Epoch: [47][250/500] loss: 1.48116, MAE: 0.45193, time/step=1035ms, lr=3.91e-05
2024-03-20 09:43:22,422 - logger.py:50 - Epoch: [47][300/500] loss: 1.33632, MAE: 0.45161, time/step=1035ms, lr=3.91e-05
2024-03-20 09:44:14,367 - logger.py:50 - Epoch: [47][350/500] loss: 1.22421, MAE: 0.44670, time/step=1036ms, lr=3.91e-05
2024-03-20 09:45:06,282 - logger.py:50 - Epoch: [47][400/500] loss: 1.14901, MAE: 0.44301, time/step=1036ms, lr=3.91e-05
2024-03-20 09:45:59,613 - logger.py:50 - Epoch: [47][450/500] loss: 1.08128, MAE: 0.44520, time/step=1040ms, lr=3.91e-05
2024-03-20 09:46:50,882 - logger.py:50 - Epoch: [47][499/500] loss: 1.03753, MAE: 0.44328, time/step=1040ms, lr=3.91e-05
2024-03-20 09:47:48,322 - logger.py:50 - Epoch: [47] train loss: 1.03753, val loss: 0.59520, test loss: 0.56241, Time: 577.57s
2024-03-20 09:47:48,323 - logger.py:50 - Best -- epoch=45, train loss: 1.21895, val loss: 0.54285, test loss: 0.50377

2024-03-20 09:48:45,441 - logger.py:50 - Epoch: [47]EMA val MAE: 0.48927, EMA test MAE: 0.47458, Time: 634.68s
2024-03-20 09:48:45,441 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 09:48:46,723 - logger.py:50 - Epoch: [48][0/500] loss: 0.36426, MAE: 0.40023, time/step=1279ms, lr=3.86e-05
2024-03-20 09:49:37,908 - logger.py:50 - Epoch: [48][50/500] loss: 0.56437, MAE: 0.43737, time/step=1029ms, lr=3.86e-05
2024-03-20 09:50:28,767 - logger.py:50 - Epoch: [48][100/500] loss: 0.57670, MAE: 0.43837, time/step=1023ms, lr=3.86e-05
2024-03-20 09:51:19,751 - logger.py:50 - Epoch: [48][150/500] loss: 0.58710, MAE: 0.43750, time/step=1022ms, lr=3.86e-05
2024-03-20 09:52:11,079 - logger.py:50 - Epoch: [48][200/500] loss: 0.59773, MAE: 0.43725, time/step=1023ms, lr=3.86e-05
2024-03-20 09:53:03,549 - logger.py:50 - Epoch: [48][250/500] loss: 0.58421, MAE: 0.43933, time/step=1028ms, lr=3.86e-05
2024-03-20 09:53:55,412 - logger.py:50 - Epoch: [48][300/500] loss: 1.00337, MAE: 0.44422, time/step=1030ms, lr=3.86e-05
2024-03-20 09:54:46,514 - logger.py:50 - Epoch: [48][350/500] loss: 0.94741, MAE: 0.44436, time/step=1029ms, lr=3.86e-05
2024-03-20 09:55:39,379 - logger.py:50 - Epoch: [48][400/500] loss: 0.88650, MAE: 0.44145, time/step=1032ms, lr=3.86e-05
2024-03-20 09:56:31,594 - logger.py:50 - Epoch: [48][450/500] loss: 0.85068, MAE: 0.44147, time/step=1034ms, lr=3.86e-05
2024-03-20 09:57:21,364 - logger.py:50 - Epoch: [48][499/500] loss: 0.97564, MAE: 0.44372, time/step=1032ms, lr=3.86e-05
2024-03-20 09:58:18,888 - logger.py:50 - Epoch: [48] train loss: 0.97564, val loss: 0.58358, test loss: 0.54379, Time: 573.45s
2024-03-20 09:58:18,888 - logger.py:50 - Best -- epoch=45, train loss: 1.21895, val loss: 0.54285, test loss: 0.50377

2024-03-20 09:59:15,942 - logger.py:50 - Epoch: [48]EMA val MAE: 0.48762, EMA test MAE: 0.47298, Time: 630.50s
2024-03-20 09:59:15,942 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 09:59:17,171 - logger.py:50 - Epoch: [49][0/500] loss: 0.78805, MAE: 0.49161, time/step=1227ms, lr=3.82e-05
2024-03-20 10:00:08,598 - logger.py:50 - Epoch: [49][50/500] loss: 0.57202, MAE: 0.44224, time/step=1032ms, lr=3.82e-05
2024-03-20 10:00:59,376 - logger.py:50 - Epoch: [49][100/500] loss: 0.57073, MAE: 0.44111, time/step=1024ms, lr=3.82e-05
2024-03-20 10:01:52,023 - logger.py:50 - Epoch: [49][150/500] loss: 0.57911, MAE: 0.43510, time/step=1034ms, lr=3.82e-05
2024-03-20 10:02:44,232 - logger.py:50 - Epoch: [49][200/500] loss: 2.53340, MAE: 0.43987, time/step=1036ms, lr=3.82e-05
2024-03-20 10:03:36,631 - logger.py:50 - Epoch: [49][250/500] loss: 2.17827, MAE: 0.44054, time/step=1039ms, lr=3.82e-05
2024-03-20 10:04:29,629 - logger.py:50 - Epoch: [49][300/500] loss: 3.55209, MAE: 0.44569, time/step=1042ms, lr=3.82e-05
2024-03-20 10:05:21,940 - logger.py:50 - Epoch: [49][350/500] loss: 3.11943, MAE: 0.44429, time/step=1043ms, lr=3.82e-05
2024-03-20 10:06:14,686 - logger.py:50 - Epoch: [49][400/500] loss: 2.80269, MAE: 0.44421, time/step=1044ms, lr=3.82e-05
2024-03-20 10:07:07,589 - logger.py:50 - Epoch: [49][450/500] loss: 2.54732, MAE: 0.44341, time/step=1046ms, lr=3.82e-05
2024-03-20 10:07:57,867 - logger.py:50 - Epoch: [49][499/500] loss: 2.36048, MAE: 0.44292, time/step=1044ms, lr=3.82e-05
2024-03-20 10:08:56,405 - logger.py:50 - Epoch: [49] train loss: 2.36048, val loss: 0.54439, test loss: 0.50883, Time: 580.46s
2024-03-20 10:08:56,405 - logger.py:50 - Best -- epoch=45, train loss: 1.21895, val loss: 0.54285, test loss: 0.50377

2024-03-20 10:09:54,418 - logger.py:50 - Epoch: [49]EMA val MAE: 0.48564, EMA test MAE: 0.47106, Time: 638.48s
2024-03-20 10:09:54,418 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 10:09:55,650 - logger.py:50 - Epoch: [50][0/500] loss: 0.90542, MAE: 0.43411, time/step=1229ms, lr=3.78e-05
2024-03-20 10:10:48,725 - logger.py:50 - Epoch: [50][50/500] loss: 0.50273, MAE: 0.42169, time/step=1065ms, lr=3.78e-05
2024-03-20 10:11:41,660 - logger.py:50 - Epoch: [50][100/500] loss: 0.58428, MAE: 0.42855, time/step=1062ms, lr=3.78e-05
2024-03-20 10:12:33,930 - logger.py:50 - Epoch: [50][150/500] loss: 0.57678, MAE: 0.43092, time/step=1056ms, lr=3.78e-05
2024-03-20 10:13:25,814 - logger.py:50 - Epoch: [50][200/500] loss: 2.74752, MAE: 0.43981, time/step=1052ms, lr=3.78e-05
2024-03-20 10:14:18,036 - logger.py:50 - Epoch: [50][250/500] loss: 3.76252, MAE: 0.44566, time/step=1050ms, lr=3.78e-05
2024-03-20 10:15:10,179 - logger.py:50 - Epoch: [50][300/500] loss: 3.24337, MAE: 0.44195, time/step=1049ms, lr=3.78e-05
2024-03-20 10:16:02,936 - logger.py:50 - Epoch: [50][350/500] loss: 2.86178, MAE: 0.44280, time/step=1050ms, lr=3.78e-05
2024-03-20 10:16:54,504 - logger.py:50 - Epoch: [50][400/500] loss: 2.58216, MAE: 0.44516, time/step=1048ms, lr=3.78e-05
2024-03-20 10:17:47,086 - logger.py:50 - Epoch: [50][450/500] loss: 2.36337, MAE: 0.44369, time/step=1048ms, lr=3.78e-05
2024-03-20 10:18:38,957 - logger.py:50 - Epoch: [50][499/500] loss: 2.18020, MAE: 0.44286, time/step=1049ms, lr=3.78e-05
2024-03-20 10:19:38,087 - logger.py:50 - Epoch: [50] train loss: 2.18020, val loss: 0.54340, test loss: 0.51005, Time: 583.67s
2024-03-20 10:19:38,087 - logger.py:50 - Best -- epoch=45, train loss: 1.21895, val loss: 0.54285, test loss: 0.50377

2024-03-20 10:20:36,350 - logger.py:50 - Epoch: [50]EMA val MAE: 0.48397, EMA test MAE: 0.46939, Time: 641.93s
2024-03-20 10:20:36,351 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 10:20:37,040 - logger.py:50 - Epoch: [51][0/500] loss: 0.86875, MAE: 0.48609, time/step=687ms, lr=3.73e-05
2024-03-20 10:21:28,029 - logger.py:50 - Epoch: [51][50/500] loss: 5.58945, MAE: 0.46200, time/step=1013ms, lr=3.73e-05
2024-03-20 10:22:19,404 - logger.py:50 - Epoch: [51][100/500] loss: 3.08013, MAE: 0.44512, time/step=1020ms, lr=3.73e-05
2024-03-20 10:23:12,733 - logger.py:50 - Epoch: [51][150/500] loss: 2.23180, MAE: 0.43857, time/step=1036ms, lr=3.73e-05
2024-03-20 10:24:05,054 - logger.py:50 - Epoch: [51][200/500] loss: 1.79265, MAE: 0.43670, time/step=1038ms, lr=3.73e-05
2024-03-20 10:24:57,719 - logger.py:50 - Epoch: [51][250/500] loss: 1.54551, MAE: 0.43965, time/step=1041ms, lr=3.73e-05
2024-03-20 10:25:49,530 - logger.py:50 - Epoch: [51][300/500] loss: 2.35570, MAE: 0.44519, time/step=1040ms, lr=3.73e-05
2024-03-20 10:26:43,044 - logger.py:50 - Epoch: [51][350/500] loss: 2.12056, MAE: 0.44558, time/step=1045ms, lr=3.73e-05
2024-03-20 10:27:35,920 - logger.py:50 - Epoch: [51][400/500] loss: 1.92969, MAE: 0.44410, time/step=1046ms, lr=3.73e-05
2024-03-20 10:28:28,384 - logger.py:50 - Epoch: [51][450/500] loss: 1.79355, MAE: 0.44273, time/step=1047ms, lr=3.73e-05
2024-03-20 10:29:20,402 - logger.py:50 - Epoch: [51][499/500] loss: 1.67367, MAE: 0.44304, time/step=1048ms, lr=3.73e-05
2024-03-20 10:30:18,970 - logger.py:50 - Epoch: [51] train loss: 1.67367, val loss: 0.55780, test loss: 0.90778, Time: 582.62s
2024-03-20 10:30:18,970 - logger.py:50 - Best -- epoch=45, train loss: 1.21895, val loss: 0.54285, test loss: 0.50377

2024-03-20 10:31:17,067 - logger.py:50 - Epoch: [51]EMA val MAE: 0.48290, EMA test MAE: 0.46831, Time: 640.72s
2024-03-20 10:31:17,067 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 10:31:17,815 - logger.py:50 - Epoch: [52][0/500] loss: 0.52945, MAE: 0.39996, time/step=745ms, lr=3.69e-05
2024-03-20 10:32:10,530 - logger.py:50 - Epoch: [52][50/500] loss: 1.39916, MAE: 0.44360, time/step=1048ms, lr=3.69e-05
2024-03-20 10:33:03,308 - logger.py:50 - Epoch: [52][100/500] loss: 1.00747, MAE: 0.44033, time/step=1052ms, lr=3.69e-05
2024-03-20 10:33:55,885 - logger.py:50 - Epoch: [52][150/500] loss: 0.85810, MAE: 0.44026, time/step=1052ms, lr=3.69e-05
2024-03-20 10:34:48,741 - logger.py:50 - Epoch: [52][200/500] loss: 0.77641, MAE: 0.43941, time/step=1053ms, lr=3.69e-05
2024-03-20 10:35:40,554 - logger.py:50 - Epoch: [52][250/500] loss: 0.73460, MAE: 0.43797, time/step=1050ms, lr=3.69e-05
2024-03-20 10:36:32,988 - logger.py:50 - Epoch: [52][300/500] loss: 0.70804, MAE: 0.43887, time/step=1050ms, lr=3.69e-05
2024-03-20 10:37:25,227 - logger.py:50 - Epoch: [52][350/500] loss: 0.67219, MAE: 0.43638, time/step=1049ms, lr=3.69e-05
2024-03-20 10:38:17,188 - logger.py:50 - Epoch: [52][400/500] loss: 1.00812, MAE: 0.44202, time/step=1048ms, lr=3.69e-05
2024-03-20 10:39:09,785 - logger.py:50 - Epoch: [52][450/500] loss: 0.96854, MAE: 0.44214, time/step=1048ms, lr=3.69e-05
2024-03-20 10:40:01,289 - logger.py:50 - Epoch: [52][499/500] loss: 1.07768, MAE: 0.44378, time/step=1048ms, lr=3.69e-05
2024-03-20 10:40:59,140 - logger.py:50 - Epoch: [52] train loss: 1.07768, val loss: 0.56563, test loss: 0.53328, Time: 582.07s
2024-03-20 10:40:59,140 - logger.py:50 - Best -- epoch=45, train loss: 1.21895, val loss: 0.54285, test loss: 0.50377

2024-03-20 10:41:56,977 - logger.py:50 - Epoch: [52]EMA val MAE: 0.48211, EMA test MAE: 0.46751, Time: 639.91s
2024-03-20 10:41:56,978 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 10:41:58,142 - logger.py:50 - Epoch: [53][0/500] loss: 0.27795, MAE: 0.35868, time/step=1162ms, lr=3.64e-05
2024-03-20 10:42:49,860 - logger.py:50 - Epoch: [53][50/500] loss: 0.65228, MAE: 0.45227, time/step=1037ms, lr=3.64e-05
2024-03-20 10:43:41,741 - logger.py:50 - Epoch: [53][100/500] loss: 0.61133, MAE: 0.44595, time/step=1037ms, lr=3.64e-05
2024-03-20 10:44:33,963 - logger.py:50 - Epoch: [53][150/500] loss: 0.57335, MAE: 0.44180, time/step=1040ms, lr=3.64e-05
2024-03-20 10:45:26,194 - logger.py:50 - Epoch: [53][200/500] loss: 0.57326, MAE: 0.44096, time/step=1041ms, lr=3.64e-05
2024-03-20 10:46:18,130 - logger.py:50 - Epoch: [53][250/500] loss: 1.17393, MAE: 0.44561, time/step=1040ms, lr=3.64e-05
2024-03-20 10:47:10,823 - logger.py:50 - Epoch: [53][300/500] loss: 1.28906, MAE: 0.44935, time/step=1043ms, lr=3.64e-05
2024-03-20 10:48:01,068 - logger.py:50 - Epoch: [53][350/500] loss: 1.18992, MAE: 0.44877, time/step=1037ms, lr=3.64e-05
2024-03-20 10:48:52,464 - logger.py:50 - Epoch: [53][400/500] loss: 1.10913, MAE: 0.44668, time/step=1036ms, lr=3.64e-05
2024-03-20 10:49:44,440 - logger.py:50 - Epoch: [53][450/500] loss: 1.06085, MAE: 0.44451, time/step=1036ms, lr=3.64e-05
2024-03-20 10:50:35,501 - logger.py:50 - Epoch: [53][499/500] loss: 1.01400, MAE: 0.44350, time/step=1037ms, lr=3.64e-05
2024-03-20 10:51:33,553 - logger.py:50 - Epoch: [53] train loss: 1.01400, val loss: 0.53673, test loss: 0.50628, Time: 576.58s
2024-03-20 10:51:33,553 - logger.py:50 - Best -- epoch=53, train loss: 1.01400, val loss: 0.53673, test loss: 0.50628

2024-03-20 10:52:30,851 - logger.py:50 - Epoch: [53]EMA val MAE: 0.48124, EMA test MAE: 0.46664, Time: 633.87s
2024-03-20 10:52:30,851 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 10:52:31,536 - logger.py:50 - Epoch: [54][0/500] loss: 0.33554, MAE: 0.38928, time/step=683ms, lr=3.59e-05
2024-03-20 10:53:23,695 - logger.py:50 - Epoch: [54][50/500] loss: 0.50303, MAE: 0.43699, time/step=1036ms, lr=3.59e-05
2024-03-20 10:54:14,769 - logger.py:50 - Epoch: [54][100/500] loss: 0.51341, MAE: 0.43976, time/step=1029ms, lr=3.59e-05
2024-03-20 10:55:06,673 - logger.py:50 - Epoch: [54][150/500] loss: 0.52753, MAE: 0.43736, time/step=1032ms, lr=3.59e-05
2024-03-20 10:55:58,816 - logger.py:50 - Epoch: [54][200/500] loss: 0.53571, MAE: 0.43721, time/step=1035ms, lr=3.59e-05
2024-03-20 10:56:49,898 - logger.py:50 - Epoch: [54][250/500] loss: 1.05785, MAE: 0.44660, time/step=1032ms, lr=3.59e-05
2024-03-20 10:57:40,972 - logger.py:50 - Epoch: [54][300/500] loss: 1.25222, MAE: 0.44657, time/step=1030ms, lr=3.59e-05
2024-03-20 10:58:34,114 - logger.py:50 - Epoch: [54][350/500] loss: 1.14956, MAE: 0.44595, time/step=1035ms, lr=3.59e-05
2024-03-20 10:59:26,443 - logger.py:50 - Epoch: [54][400/500] loss: 1.08375, MAE: 0.44472, time/step=1036ms, lr=3.59e-05
2024-03-20 11:00:18,466 - logger.py:50 - Epoch: [54][450/500] loss: 1.03436, MAE: 0.44409, time/step=1037ms, lr=3.59e-05
2024-03-20 11:01:09,205 - logger.py:50 - Epoch: [54][499/500] loss: 0.98378, MAE: 0.44361, time/step=1037ms, lr=3.59e-05
2024-03-20 11:02:06,861 - logger.py:50 - Epoch: [54] train loss: 0.98378, val loss: 0.53839, test loss: 0.50842, Time: 576.01s
2024-03-20 11:02:06,862 - logger.py:50 - Best -- epoch=53, train loss: 1.01400, val loss: 0.53673, test loss: 0.50628

2024-03-20 11:03:04,228 - logger.py:50 - Epoch: [54]EMA val MAE: 0.48054, EMA test MAE: 0.46595, Time: 633.38s
2024-03-20 11:03:04,228 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 11:03:05,549 - logger.py:50 - Epoch: [55][0/500] loss: 0.44644, MAE: 0.45322, time/step=1319ms, lr=3.55e-05
2024-03-20 11:03:57,606 - logger.py:50 - Epoch: [55][50/500] loss: 0.49985, MAE: 0.42311, time/step=1047ms, lr=3.55e-05
2024-03-20 11:04:49,334 - logger.py:50 - Epoch: [55][100/500] loss: 0.54396, MAE: 0.42817, time/step=1041ms, lr=3.55e-05
2024-03-20 11:05:41,270 - logger.py:50 - Epoch: [55][150/500] loss: 1.38467, MAE: 0.44375, time/step=1040ms, lr=3.55e-05
2024-03-20 11:06:32,363 - logger.py:50 - Epoch: [55][200/500] loss: 1.16975, MAE: 0.44057, time/step=1035ms, lr=3.55e-05
2024-03-20 11:07:23,820 - logger.py:50 - Epoch: [55][250/500] loss: 1.04528, MAE: 0.44097, time/step=1034ms, lr=3.55e-05
2024-03-20 11:08:15,433 - logger.py:50 - Epoch: [55][300/500] loss: 1.35638, MAE: 0.44675, time/step=1034ms, lr=3.55e-05
2024-03-20 11:09:07,044 - logger.py:50 - Epoch: [55][350/500] loss: 1.25594, MAE: 0.44581, time/step=1034ms, lr=3.55e-05
2024-03-20 11:09:58,545 - logger.py:50 - Epoch: [55][400/500] loss: 1.17441, MAE: 0.44585, time/step=1033ms, lr=3.55e-05
2024-03-20 11:10:50,081 - logger.py:50 - Epoch: [55][450/500] loss: 1.10057, MAE: 0.44391, time/step=1033ms, lr=3.55e-05
2024-03-20 11:11:41,554 - logger.py:50 - Epoch: [55][499/500] loss: 1.04702, MAE: 0.44394, time/step=1035ms, lr=3.55e-05
2024-03-20 11:12:39,342 - logger.py:50 - Epoch: [55] train loss: 1.04702, val loss: 0.54303, test loss: 0.51088, Time: 575.11s
2024-03-20 11:12:39,343 - logger.py:50 - Best -- epoch=53, train loss: 1.01400, val loss: 0.53673, test loss: 0.50628

2024-03-20 11:13:36,622 - logger.py:50 - Epoch: [55]EMA val MAE: 0.47932, EMA test MAE: 0.46471, Time: 632.39s
2024-03-20 11:13:36,622 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 11:13:37,219 - logger.py:50 - Epoch: [56][0/500] loss: 0.37812, MAE: 0.50869, time/step=594ms, lr=3.50e-05
2024-03-20 11:14:28,853 - logger.py:50 - Epoch: [56][50/500] loss: 0.57065, MAE: 0.45112, time/step=1024ms, lr=3.50e-05
2024-03-20 11:15:20,771 - logger.py:50 - Epoch: [56][100/500] loss: 1.21290, MAE: 0.45701, time/step=1031ms, lr=3.50e-05
2024-03-20 11:16:11,816 - logger.py:50 - Epoch: [56][150/500] loss: 2.00964, MAE: 0.46291, time/step=1028ms, lr=3.50e-05
2024-03-20 11:17:03,139 - logger.py:50 - Epoch: [56][200/500] loss: 1.66217, MAE: 0.45757, time/step=1027ms, lr=3.50e-05
2024-03-20 11:17:54,962 - logger.py:50 - Epoch: [56][250/500] loss: 1.43526, MAE: 0.45115, time/step=1029ms, lr=3.50e-05
2024-03-20 11:18:46,476 - logger.py:50 - Epoch: [56][300/500] loss: 1.29651, MAE: 0.44954, time/step=1029ms, lr=3.50e-05
2024-03-20 11:19:37,776 - logger.py:50 - Epoch: [56][350/500] loss: 1.18722, MAE: 0.44576, time/step=1029ms, lr=3.50e-05
2024-03-20 11:20:30,351 - logger.py:50 - Epoch: [56][400/500] loss: 1.10505, MAE: 0.44648, time/step=1032ms, lr=3.50e-05
2024-03-20 11:21:22,564 - logger.py:50 - Epoch: [56][450/500] loss: 1.03640, MAE: 0.44449, time/step=1033ms, lr=3.50e-05
2024-03-20 11:22:14,316 - logger.py:50 - Epoch: [56][499/500] loss: 0.98384, MAE: 0.44348, time/step=1035ms, lr=3.50e-05
2024-03-20 11:23:12,273 - logger.py:50 - Epoch: [56] train loss: 0.98384, val loss: 0.53225, test loss: 0.50022, Time: 575.65s
2024-03-20 11:23:12,273 - logger.py:50 - Best -- epoch=56, train loss: 0.98384, val loss: 0.53225, test loss: 0.50022

2024-03-20 11:24:09,588 - logger.py:50 - Epoch: [56]EMA val MAE: 0.47814, EMA test MAE: 0.46353, Time: 632.97s
2024-03-20 11:24:09,588 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 11:24:10,741 - logger.py:50 - Epoch: [57][0/500] loss: 0.17717, MAE: 0.28872, time/step=1151ms, lr=3.45e-05
2024-03-20 11:25:01,920 - logger.py:50 - Epoch: [57][50/500] loss: 0.53228, MAE: 0.43607, time/step=1026ms, lr=3.45e-05
2024-03-20 11:25:54,548 - logger.py:50 - Epoch: [57][100/500] loss: 1.80168, MAE: 0.44965, time/step=1039ms, lr=3.45e-05
2024-03-20 11:26:46,389 - logger.py:50 - Epoch: [57][150/500] loss: 1.39071, MAE: 0.43939, time/step=1038ms, lr=3.45e-05
2024-03-20 11:27:37,367 - logger.py:50 - Epoch: [57][200/500] loss: 1.19466, MAE: 0.43708, time/step=1034ms, lr=3.45e-05
2024-03-20 11:28:29,460 - logger.py:50 - Epoch: [57][250/500] loss: 1.07550, MAE: 0.43768, time/step=1035ms, lr=3.45e-05
2024-03-20 11:29:20,783 - logger.py:50 - Epoch: [57][300/500] loss: 0.97579, MAE: 0.43739, time/step=1034ms, lr=3.45e-05
2024-03-20 11:30:12,457 - logger.py:50 - Epoch: [57][350/500] loss: 0.92894, MAE: 0.44016, time/step=1034ms, lr=3.45e-05
2024-03-20 11:31:04,495 - logger.py:50 - Epoch: [57][400/500] loss: 0.87860, MAE: 0.43963, time/step=1035ms, lr=3.45e-05
2024-03-20 11:31:57,231 - logger.py:50 - Epoch: [57][450/500] loss: 0.98361, MAE: 0.44358, time/step=1037ms, lr=3.45e-05
2024-03-20 11:32:47,950 - logger.py:50 - Epoch: [57][499/500] loss: 0.94108, MAE: 0.44361, time/step=1037ms, lr=3.45e-05
2024-03-20 11:33:45,721 - logger.py:50 - Epoch: [57] train loss: 0.94108, val loss: 0.53333, test loss: 0.50294, Time: 576.13s
2024-03-20 11:33:45,721 - logger.py:50 - Best -- epoch=56, train loss: 0.98384, val loss: 0.53225, test loss: 0.50022

2024-03-20 11:34:43,217 - logger.py:50 - Epoch: [57]EMA val MAE: 0.47700, EMA test MAE: 0.46239, Time: 633.63s
2024-03-20 11:34:43,217 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 11:34:44,475 - logger.py:50 - Epoch: [58][0/500] loss: 0.50412, MAE: 0.38613, time/step=1255ms, lr=3.40e-05
2024-03-20 11:35:36,639 - logger.py:50 - Epoch: [58][50/500] loss: 0.63272, MAE: 0.43971, time/step=1047ms, lr=3.40e-05
2024-03-20 11:36:28,700 - logger.py:50 - Epoch: [58][100/500] loss: 0.62706, MAE: 0.44270, time/step=1044ms, lr=3.40e-05
2024-03-20 11:37:20,500 - logger.py:50 - Epoch: [58][150/500] loss: 0.59972, MAE: 0.44498, time/step=1042ms, lr=3.40e-05
2024-03-20 11:38:11,280 - logger.py:50 - Epoch: [58][200/500] loss: 0.59558, MAE: 0.44328, time/step=1035ms, lr=3.40e-05
2024-03-20 11:39:03,329 - logger.py:50 - Epoch: [58][250/500] loss: 1.05666, MAE: 0.44859, time/step=1036ms, lr=3.40e-05
2024-03-20 11:39:56,323 - logger.py:50 - Epoch: [58][300/500] loss: 0.98195, MAE: 0.44768, time/step=1040ms, lr=3.40e-05
2024-03-20 11:40:47,823 - logger.py:50 - Epoch: [58][350/500] loss: 0.93211, MAE: 0.44609, time/step=1039ms, lr=3.40e-05
2024-03-20 11:41:39,958 - logger.py:50 - Epoch: [58][400/500] loss: 1.21480, MAE: 0.44918, time/step=1039ms, lr=3.40e-05
2024-03-20 11:42:31,566 - logger.py:50 - Epoch: [58][450/500] loss: 1.14239, MAE: 0.44770, time/step=1038ms, lr=3.40e-05
2024-03-20 11:43:20,817 - logger.py:50 - Epoch: [58][499/500] loss: 1.09060, MAE: 0.44362, time/step=1035ms, lr=3.40e-05
2024-03-20 11:44:18,650 - logger.py:50 - Epoch: [58] train loss: 1.09060, val loss: 0.55412, test loss: 0.52359, Time: 575.43s
2024-03-20 11:44:18,651 - logger.py:50 - Best -- epoch=56, train loss: 0.98384, val loss: 0.53225, test loss: 0.50022

2024-03-20 11:45:15,952 - logger.py:50 - Epoch: [58]EMA val MAE: 0.47595, EMA test MAE: 0.46135, Time: 632.73s
2024-03-20 11:45:15,952 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 11:45:16,593 - logger.py:50 - Epoch: [59][0/500] loss: 0.61808, MAE: 0.37897, time/step=638ms, lr=3.36e-05
2024-03-20 11:46:09,253 - logger.py:50 - Epoch: [59][50/500] loss: 0.43258, MAE: 0.43093, time/step=1045ms, lr=3.36e-05
2024-03-20 11:47:01,827 - logger.py:50 - Epoch: [59][100/500] loss: 0.47831, MAE: 0.43808, time/step=1048ms, lr=3.36e-05
2024-03-20 11:47:53,283 - logger.py:50 - Epoch: [59][150/500] loss: 0.55768, MAE: 0.44034, time/step=1042ms, lr=3.36e-05
2024-03-20 11:48:45,452 - logger.py:50 - Epoch: [59][200/500] loss: 0.57268, MAE: 0.43588, time/step=1042ms, lr=3.36e-05
2024-03-20 11:49:36,104 - logger.py:50 - Epoch: [59][250/500] loss: 0.57696, MAE: 0.43590, time/step=1036ms, lr=3.36e-05
2024-03-20 11:50:28,829 - logger.py:50 - Epoch: [59][300/500] loss: 0.57030, MAE: 0.43583, time/step=1039ms, lr=3.36e-05
2024-03-20 11:51:20,824 - logger.py:50 - Epoch: [59][350/500] loss: 0.56302, MAE: 0.43492, time/step=1040ms, lr=3.36e-05
2024-03-20 11:52:12,452 - logger.py:50 - Epoch: [59][400/500] loss: 0.87457, MAE: 0.44004, time/step=1039ms, lr=3.36e-05
2024-03-20 11:53:03,737 - logger.py:50 - Epoch: [59][450/500] loss: 1.08045, MAE: 0.44310, time/step=1037ms, lr=3.36e-05
2024-03-20 11:53:54,697 - logger.py:50 - Epoch: [59][499/500] loss: 1.02926, MAE: 0.44376, time/step=1037ms, lr=3.36e-05
2024-03-20 11:54:52,466 - logger.py:50 - Epoch: [59] train loss: 1.02926, val loss: 0.53312, test loss: 0.50206, Time: 576.51s
2024-03-20 11:54:52,466 - logger.py:50 - Best -- epoch=56, train loss: 0.98384, val loss: 0.53225, test loss: 0.50022

2024-03-20 11:55:50,170 - logger.py:50 - Epoch: [59]EMA val MAE: 0.47472, EMA test MAE: 0.46011, Time: 634.22s
2024-03-20 11:55:50,170 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 11:55:50,803 - logger.py:50 - Epoch: [60][0/500] loss: 0.71654, MAE: 0.40435, time/step=631ms, lr=3.31e-05
2024-03-20 11:56:43,410 - logger.py:50 - Epoch: [60][50/500] loss: 0.55052, MAE: 0.45331, time/step=1044ms, lr=3.31e-05
2024-03-20 11:57:35,910 - logger.py:50 - Epoch: [60][100/500] loss: 0.55362, MAE: 0.45199, time/step=1047ms, lr=3.31e-05
2024-03-20 11:58:27,209 - logger.py:50 - Epoch: [60][150/500] loss: 1.01564, MAE: 0.46171, time/step=1040ms, lr=3.31e-05
2024-03-20 11:59:19,705 - logger.py:50 - Epoch: [60][200/500] loss: 0.90005, MAE: 0.45409, time/step=1042ms, lr=3.31e-05
2024-03-20 12:00:11,999 - logger.py:50 - Epoch: [60][250/500] loss: 0.82378, MAE: 0.44993, time/step=1043ms, lr=3.31e-05
2024-03-20 12:01:03,286 - logger.py:50 - Epoch: [60][300/500] loss: 0.77198, MAE: 0.44596, time/step=1040ms, lr=3.31e-05
2024-03-20 12:01:55,051 - logger.py:50 - Epoch: [60][350/500] loss: 1.14504, MAE: 0.44747, time/step=1040ms, lr=3.31e-05
2024-03-20 12:02:46,714 - logger.py:50 - Epoch: [60][400/500] loss: 1.07747, MAE: 0.44573, time/step=1039ms, lr=3.31e-05
2024-03-20 12:03:37,761 - logger.py:50 - Epoch: [60][450/500] loss: 1.01948, MAE: 0.44493, time/step=1037ms, lr=3.31e-05
2024-03-20 12:04:29,118 - logger.py:50 - Epoch: [60][499/500] loss: 0.97097, MAE: 0.44345, time/step=1038ms, lr=3.31e-05
2024-03-20 12:05:26,913 - logger.py:50 - Epoch: [60] train loss: 0.97097, val loss: 0.52418, test loss: 0.49465, Time: 576.74s
2024-03-20 12:05:26,913 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 12:06:24,093 - logger.py:50 - Epoch: [60]EMA val MAE: 0.47326, EMA test MAE: 0.45863, Time: 633.92s
2024-03-20 12:06:24,093 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 12:06:24,920 - logger.py:50 - Epoch: [61][0/500] loss: 0.26913, MAE: 0.47971, time/step=825ms, lr=3.26e-05
2024-03-20 12:07:16,770 - logger.py:50 - Epoch: [61][50/500] loss: 0.54722, MAE: 0.44014, time/step=1033ms, lr=3.26e-05
2024-03-20 12:08:08,340 - logger.py:50 - Epoch: [61][100/500] loss: 0.55592, MAE: 0.43758, time/step=1032ms, lr=3.26e-05
2024-03-20 12:08:59,291 - logger.py:50 - Epoch: [61][150/500] loss: 1.39055, MAE: 0.45103, time/step=1028ms, lr=3.26e-05
2024-03-20 12:09:50,992 - logger.py:50 - Epoch: [61][200/500] loss: 1.16996, MAE: 0.44493, time/step=1029ms, lr=3.26e-05
2024-03-20 12:10:42,736 - logger.py:50 - Epoch: [61][250/500] loss: 1.05941, MAE: 0.44300, time/step=1030ms, lr=3.26e-05
2024-03-20 12:11:35,322 - logger.py:50 - Epoch: [61][300/500] loss: 1.19418, MAE: 0.44601, time/step=1034ms, lr=3.26e-05
2024-03-20 12:12:26,771 - logger.py:50 - Epoch: [61][350/500] loss: 1.10006, MAE: 0.44689, time/step=1033ms, lr=3.26e-05
2024-03-20 12:13:18,197 - logger.py:50 - Epoch: [61][400/500] loss: 1.04445, MAE: 0.44540, time/step=1033ms, lr=3.26e-05
2024-03-20 12:14:08,279 - logger.py:50 - Epoch: [61][450/500] loss: 0.98888, MAE: 0.44501, time/step=1029ms, lr=3.26e-05
2024-03-20 12:14:59,774 - logger.py:50 - Epoch: [61][499/500] loss: 0.94552, MAE: 0.44373, time/step=1031ms, lr=3.26e-05
2024-03-20 12:15:57,195 - logger.py:50 - Epoch: [61] train loss: 0.94552, val loss: 0.53617, test loss: 0.49956, Time: 573.10s
2024-03-20 12:15:57,195 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 12:16:54,808 - logger.py:50 - Epoch: [61]EMA val MAE: 0.47203, EMA test MAE: 0.45740, Time: 630.71s
2024-03-20 12:16:54,808 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 12:16:56,024 - logger.py:50 - Epoch: [62][0/500] loss: 0.39870, MAE: 0.45964, time/step=1213ms, lr=3.21e-05
2024-03-20 12:17:47,835 - logger.py:50 - Epoch: [62][50/500] loss: 0.55208, MAE: 0.43957, time/step=1040ms, lr=3.21e-05
2024-03-20 12:18:41,140 - logger.py:50 - Epoch: [62][100/500] loss: 0.54172, MAE: 0.43714, time/step=1053ms, lr=3.21e-05
2024-03-20 12:19:32,502 - logger.py:50 - Epoch: [62][150/500] loss: 0.54104, MAE: 0.43798, time/step=1044ms, lr=3.21e-05
2024-03-20 12:20:24,860 - logger.py:50 - Epoch: [62][200/500] loss: 0.56052, MAE: 0.43850, time/step=1045ms, lr=3.21e-05
2024-03-20 12:21:17,429 - logger.py:50 - Epoch: [62][250/500] loss: 1.08265, MAE: 0.44541, time/step=1046ms, lr=3.21e-05
2024-03-20 12:22:08,423 - logger.py:50 - Epoch: [62][300/500] loss: 1.01043, MAE: 0.44311, time/step=1042ms, lr=3.21e-05
2024-03-20 12:23:00,485 - logger.py:50 - Epoch: [62][350/500] loss: 0.94674, MAE: 0.44301, time/step=1042ms, lr=3.21e-05
2024-03-20 12:23:52,289 - logger.py:50 - Epoch: [62][400/500] loss: 0.89525, MAE: 0.44171, time/step=1041ms, lr=3.21e-05
2024-03-20 12:24:44,224 - logger.py:50 - Epoch: [62][450/500] loss: 0.85542, MAE: 0.44147, time/step=1041ms, lr=3.21e-05
2024-03-20 12:25:35,457 - logger.py:50 - Epoch: [62][499/500] loss: 0.96315, MAE: 0.44356, time/step=1041ms, lr=3.21e-05
2024-03-20 12:26:33,537 - logger.py:50 - Epoch: [62] train loss: 0.96315, val loss: 0.54672, test loss: 0.61634, Time: 578.73s
2024-03-20 12:26:33,538 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 12:27:31,206 - logger.py:50 - Epoch: [62]EMA val MAE: 0.47091, EMA test MAE: 0.45628, Time: 636.40s
2024-03-20 12:27:31,206 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 12:27:32,363 - logger.py:50 - Epoch: [63][0/500] loss: 0.70917, MAE: 0.46167, time/step=1154ms, lr=3.16e-05
2024-03-20 12:28:24,724 - logger.py:50 - Epoch: [63][50/500] loss: 0.68866, MAE: 0.43434, time/step=1049ms, lr=3.16e-05
2024-03-20 12:29:17,074 - logger.py:50 - Epoch: [63][100/500] loss: 1.85404, MAE: 0.45835, time/step=1048ms, lr=3.16e-05
2024-03-20 12:30:09,695 - logger.py:50 - Epoch: [63][150/500] loss: 1.42752, MAE: 0.45619, time/step=1050ms, lr=3.16e-05
2024-03-20 12:31:02,049 - logger.py:50 - Epoch: [63][200/500] loss: 1.23329, MAE: 0.45399, time/step=1049ms, lr=3.16e-05
2024-03-20 12:31:53,569 - logger.py:50 - Epoch: [63][250/500] loss: 1.10191, MAE: 0.44967, time/step=1045ms, lr=3.16e-05
2024-03-20 12:32:45,758 - logger.py:50 - Epoch: [63][300/500] loss: 1.00665, MAE: 0.44636, time/step=1045ms, lr=3.16e-05
2024-03-20 12:33:36,831 - logger.py:50 - Epoch: [63][350/500] loss: 1.20337, MAE: 0.44919, time/step=1042ms, lr=3.16e-05
2024-03-20 12:34:27,580 - logger.py:50 - Epoch: [63][400/500] loss: 1.12049, MAE: 0.44640, time/step=1038ms, lr=3.16e-05
2024-03-20 12:35:19,384 - logger.py:50 - Epoch: [63][450/500] loss: 1.06494, MAE: 0.44476, time/step=1038ms, lr=3.16e-05
2024-03-20 12:36:10,953 - logger.py:50 - Epoch: [63][499/500] loss: 1.01736, MAE: 0.44390, time/step=1039ms, lr=3.16e-05
2024-03-20 12:37:08,996 - logger.py:50 - Epoch: [63] train loss: 1.01736, val loss: 0.53121, test loss: 0.51278, Time: 577.79s
2024-03-20 12:37:08,997 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 12:38:06,976 - logger.py:50 - Epoch: [63]EMA val MAE: 0.46966, EMA test MAE: 0.45504, Time: 635.77s
2024-03-20 12:38:06,976 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 12:38:08,180 - logger.py:50 - Epoch: [64][0/500] loss: 0.40990, MAE: 0.42056, time/step=1201ms, lr=3.11e-05
2024-03-20 12:38:59,183 - logger.py:50 - Epoch: [64][50/500] loss: 0.62681, MAE: 0.43611, time/step=1024ms, lr=3.11e-05
2024-03-20 12:39:51,883 - logger.py:50 - Epoch: [64][100/500] loss: 0.58119, MAE: 0.43634, time/step=1039ms, lr=3.11e-05
2024-03-20 12:40:44,687 - logger.py:50 - Epoch: [64][150/500] loss: 0.56308, MAE: 0.43331, time/step=1044ms, lr=3.11e-05
2024-03-20 12:41:36,131 - logger.py:50 - Epoch: [64][200/500] loss: 1.29295, MAE: 0.44039, time/step=1041ms, lr=3.11e-05
2024-03-20 12:42:27,829 - logger.py:50 - Epoch: [64][250/500] loss: 1.13578, MAE: 0.43853, time/step=1039ms, lr=3.11e-05
2024-03-20 12:43:19,708 - logger.py:50 - Epoch: [64][300/500] loss: 1.03612, MAE: 0.43720, time/step=1039ms, lr=3.11e-05
2024-03-20 12:44:11,039 - logger.py:50 - Epoch: [64][350/500] loss: 0.96341, MAE: 0.43560, time/step=1037ms, lr=3.11e-05
2024-03-20 12:45:03,633 - logger.py:50 - Epoch: [64][400/500] loss: 0.91462, MAE: 0.43729, time/step=1039ms, lr=3.11e-05
2024-03-20 12:45:56,764 - logger.py:50 - Epoch: [64][450/500] loss: 1.19436, MAE: 0.44233, time/step=1042ms, lr=3.11e-05
2024-03-20 12:46:47,833 - logger.py:50 - Epoch: [64][499/500] loss: 1.13238, MAE: 0.44298, time/step=1042ms, lr=3.11e-05
2024-03-20 12:47:45,523 - logger.py:50 - Epoch: [64] train loss: 1.13238, val loss: 0.52596, test loss: 0.49764, Time: 578.55s
2024-03-20 12:47:45,524 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 12:48:43,200 - logger.py:50 - Epoch: [64]EMA val MAE: 0.46828, EMA test MAE: 0.45364, Time: 636.22s
2024-03-20 12:48:43,200 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 12:48:44,409 - logger.py:50 - Epoch: [65][0/500] loss: 0.49690, MAE: 0.47455, time/step=1206ms, lr=3.06e-05
2024-03-20 12:49:35,660 - logger.py:50 - Epoch: [65][50/500] loss: 1.87185, MAE: 0.45622, time/step=1029ms, lr=3.06e-05
2024-03-20 12:50:28,113 - logger.py:50 - Epoch: [65][100/500] loss: 2.42229, MAE: 0.46415, time/step=1039ms, lr=3.06e-05
2024-03-20 12:51:19,542 - logger.py:50 - Epoch: [65][150/500] loss: 1.80108, MAE: 0.45240, time/step=1035ms, lr=3.06e-05
2024-03-20 12:52:12,002 - logger.py:50 - Epoch: [65][200/500] loss: 1.52121, MAE: 0.45060, time/step=1039ms, lr=3.06e-05
2024-03-20 12:53:05,584 - logger.py:50 - Epoch: [65][250/500] loss: 1.31238, MAE: 0.44891, time/step=1045ms, lr=3.06e-05
2024-03-20 12:53:56,876 - logger.py:50 - Epoch: [65][300/500] loss: 1.21257, MAE: 0.44624, time/step=1042ms, lr=3.06e-05
2024-03-20 12:54:48,851 - logger.py:50 - Epoch: [65][350/500] loss: 1.11275, MAE: 0.44682, time/step=1042ms, lr=3.06e-05
2024-03-20 12:55:41,452 - logger.py:50 - Epoch: [65][400/500] loss: 1.04747, MAE: 0.44674, time/step=1043ms, lr=3.06e-05
2024-03-20 12:56:33,083 - logger.py:50 - Epoch: [65][450/500] loss: 0.99439, MAE: 0.44550, time/step=1042ms, lr=3.06e-05
2024-03-20 12:57:24,438 - logger.py:50 - Epoch: [65][499/500] loss: 0.94776, MAE: 0.44375, time/step=1042ms, lr=3.06e-05
2024-03-20 12:58:23,174 - logger.py:50 - Epoch: [65] train loss: 0.94776, val loss: 0.52619, test loss: 0.49685, Time: 579.97s
2024-03-20 12:58:23,174 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 12:59:20,439 - logger.py:50 - Epoch: [65]EMA val MAE: 0.46738, EMA test MAE: 0.45273, Time: 637.24s
2024-03-20 12:59:20,439 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 12:59:21,630 - logger.py:50 - Epoch: [66][0/500] loss: 0.32618, MAE: 0.37677, time/step=1189ms, lr=3.01e-05
2024-03-20 13:00:14,260 - logger.py:50 - Epoch: [66][50/500] loss: 0.44013, MAE: 0.43577, time/step=1055ms, lr=3.01e-05
2024-03-20 13:01:06,276 - logger.py:50 - Epoch: [66][100/500] loss: 0.48569, MAE: 0.42981, time/step=1048ms, lr=3.01e-05
2024-03-20 13:01:57,858 - logger.py:50 - Epoch: [66][150/500] loss: 1.32046, MAE: 0.44797, time/step=1042ms, lr=3.01e-05
2024-03-20 13:02:49,657 - logger.py:50 - Epoch: [66][200/500] loss: 1.52358, MAE: 0.45059, time/step=1041ms, lr=3.01e-05
2024-03-20 13:03:41,587 - logger.py:50 - Epoch: [66][250/500] loss: 1.33021, MAE: 0.45155, time/step=1040ms, lr=3.01e-05
2024-03-20 13:04:32,918 - logger.py:50 - Epoch: [66][300/500] loss: 1.21247, MAE: 0.44893, time/step=1038ms, lr=3.01e-05
2024-03-20 13:05:25,576 - logger.py:50 - Epoch: [66][350/500] loss: 1.11850, MAE: 0.44810, time/step=1040ms, lr=3.01e-05
2024-03-20 13:06:16,584 - logger.py:50 - Epoch: [66][400/500] loss: 1.05585, MAE: 0.44650, time/step=1038ms, lr=3.01e-05
2024-03-20 13:07:08,644 - logger.py:50 - Epoch: [66][450/500] loss: 0.99795, MAE: 0.44501, time/step=1038ms, lr=3.01e-05
2024-03-20 13:08:00,356 - logger.py:50 - Epoch: [66][499/500] loss: 0.95148, MAE: 0.44373, time/step=1040ms, lr=3.01e-05
2024-03-20 13:08:57,517 - logger.py:50 - Epoch: [66] train loss: 0.95148, val loss: 0.52492, test loss: 0.49063, Time: 577.08s
2024-03-20 13:08:57,517 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 13:09:54,531 - logger.py:50 - Epoch: [66]EMA val MAE: 0.46624, EMA test MAE: 0.45158, Time: 634.09s
2024-03-20 13:09:54,532 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 13:09:55,739 - logger.py:50 - Epoch: [67][0/500] loss: 1.03594, MAE: 0.43918, time/step=1205ms, lr=2.96e-05
2024-03-20 13:10:47,558 - logger.py:50 - Epoch: [67][50/500] loss: 0.55133, MAE: 0.43987, time/step=1040ms, lr=2.96e-05
2024-03-20 13:11:39,196 - logger.py:50 - Epoch: [67][100/500] loss: 0.51015, MAE: 0.43421, time/step=1036ms, lr=2.96e-05
2024-03-20 13:12:30,006 - logger.py:50 - Epoch: [67][150/500] loss: 0.54848, MAE: 0.43927, time/step=1030ms, lr=2.96e-05
2024-03-20 13:13:20,812 - logger.py:50 - Epoch: [67][200/500] loss: 0.55573, MAE: 0.43817, time/step=1026ms, lr=2.96e-05
2024-03-20 13:14:12,940 - logger.py:50 - Epoch: [67][250/500] loss: 0.54672, MAE: 0.43611, time/step=1030ms, lr=2.96e-05
2024-03-20 13:15:03,897 - logger.py:50 - Epoch: [67][300/500] loss: 0.55702, MAE: 0.43696, time/step=1028ms, lr=2.96e-05
2024-03-20 13:15:55,736 - logger.py:50 - Epoch: [67][350/500] loss: 0.94154, MAE: 0.44267, time/step=1029ms, lr=2.96e-05
2024-03-20 13:16:47,574 - logger.py:50 - Epoch: [67][400/500] loss: 0.89368, MAE: 0.44382, time/step=1030ms, lr=2.96e-05
2024-03-20 13:17:39,639 - logger.py:50 - Epoch: [67][450/500] loss: 0.85039, MAE: 0.44187, time/step=1031ms, lr=2.96e-05
2024-03-20 13:18:30,350 - logger.py:50 - Epoch: [67][499/500] loss: 0.97581, MAE: 0.44360, time/step=1032ms, lr=2.96e-05
2024-03-20 13:19:28,233 - logger.py:50 - Epoch: [67] train loss: 0.97581, val loss: 0.53856, test loss: 0.52296, Time: 573.70s
2024-03-20 13:19:28,233 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 13:20:25,373 - logger.py:50 - Epoch: [67]EMA val MAE: 0.46519, EMA test MAE: 0.45052, Time: 630.84s
2024-03-20 13:20:25,373 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 13:20:26,566 - logger.py:50 - Epoch: [68][0/500] loss: 0.72891, MAE: 0.56167, time/step=1191ms, lr=2.91e-05
2024-03-20 13:21:17,440 - logger.py:50 - Epoch: [68][50/500] loss: 0.52611, MAE: 0.43192, time/step=1021ms, lr=2.91e-05
2024-03-20 13:22:08,473 - logger.py:50 - Epoch: [68][100/500] loss: 0.50506, MAE: 0.43675, time/step=1021ms, lr=2.91e-05
2024-03-20 13:23:00,403 - logger.py:50 - Epoch: [68][150/500] loss: 1.37394, MAE: 0.45465, time/step=1027ms, lr=2.91e-05
2024-03-20 13:23:52,446 - logger.py:50 - Epoch: [68][200/500] loss: 1.62513, MAE: 0.46058, time/step=1030ms, lr=2.91e-05
2024-03-20 13:24:43,188 - logger.py:50 - Epoch: [68][250/500] loss: 1.42517, MAE: 0.45703, time/step=1027ms, lr=2.91e-05
2024-03-20 13:25:34,689 - logger.py:50 - Epoch: [68][300/500] loss: 1.27817, MAE: 0.45126, time/step=1028ms, lr=2.91e-05
2024-03-20 13:26:26,349 - logger.py:50 - Epoch: [68][350/500] loss: 1.16724, MAE: 0.44746, time/step=1028ms, lr=2.91e-05
2024-03-20 13:27:18,534 - logger.py:50 - Epoch: [68][400/500] loss: 1.09886, MAE: 0.44678, time/step=1030ms, lr=2.91e-05
2024-03-20 13:28:10,948 - logger.py:50 - Epoch: [68][450/500] loss: 1.03483, MAE: 0.44454, time/step=1032ms, lr=2.91e-05
2024-03-20 13:29:00,812 - logger.py:50 - Epoch: [68][499/500] loss: 0.98588, MAE: 0.44391, time/step=1031ms, lr=2.91e-05
2024-03-20 13:29:58,615 - logger.py:50 - Epoch: [68] train loss: 0.98588, val loss: 0.52491, test loss: 0.49261, Time: 573.24s
2024-03-20 13:29:58,615 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 13:30:55,541 - logger.py:50 - Epoch: [68]EMA val MAE: 0.46409, EMA test MAE: 0.44940, Time: 630.17s
2024-03-20 13:30:55,541 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 13:30:56,233 - logger.py:50 - Epoch: [69][0/500] loss: 0.41231, MAE: 0.39779, time/step=690ms, lr=2.86e-05
2024-03-20 13:31:47,920 - logger.py:50 - Epoch: [69][50/500] loss: 2.58216, MAE: 0.47688, time/step=1027ms, lr=2.86e-05
2024-03-20 13:32:38,784 - logger.py:50 - Epoch: [69][100/500] loss: 1.61622, MAE: 0.45911, time/step=1022ms, lr=2.86e-05
2024-03-20 13:33:31,346 - logger.py:50 - Epoch: [69][150/500] loss: 1.28300, MAE: 0.45058, time/step=1032ms, lr=2.86e-05
2024-03-20 13:34:22,630 - logger.py:50 - Epoch: [69][200/500] loss: 1.09606, MAE: 0.44506, time/step=1030ms, lr=2.86e-05
2024-03-20 13:35:14,495 - logger.py:50 - Epoch: [69][250/500] loss: 0.99149, MAE: 0.44397, time/step=1032ms, lr=2.86e-05
2024-03-20 13:36:06,004 - logger.py:50 - Epoch: [69][300/500] loss: 0.91694, MAE: 0.44224, time/step=1031ms, lr=2.86e-05
2024-03-20 13:36:57,412 - logger.py:50 - Epoch: [69][350/500] loss: 0.85952, MAE: 0.44042, time/step=1031ms, lr=2.86e-05
2024-03-20 13:37:48,943 - logger.py:50 - Epoch: [69][400/500] loss: 0.82252, MAE: 0.43968, time/step=1031ms, lr=2.86e-05
2024-03-20 13:38:40,245 - logger.py:50 - Epoch: [69][450/500] loss: 1.07180, MAE: 0.44397, time/step=1030ms, lr=2.86e-05
2024-03-20 13:39:29,955 - logger.py:50 - Epoch: [69][499/500] loss: 1.02181, MAE: 0.44346, time/step=1029ms, lr=2.86e-05
2024-03-20 13:40:27,414 - logger.py:50 - Epoch: [69] train loss: 1.02181, val loss: 0.53003, test loss: 0.50059, Time: 571.87s
2024-03-20 13:40:27,414 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 13:41:24,201 - logger.py:50 - Epoch: [69]EMA val MAE: 0.46325, EMA test MAE: 0.44855, Time: 628.66s
2024-03-20 13:41:24,201 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 13:41:25,424 - logger.py:50 - Epoch: [70][0/500] loss: 0.38244, MAE: 0.47666, time/step=1220ms, lr=2.81e-05
2024-03-20 13:42:16,301 - logger.py:50 - Epoch: [70][50/500] loss: 0.58603, MAE: 0.43236, time/step=1022ms, lr=2.81e-05
2024-03-20 13:43:08,380 - logger.py:50 - Epoch: [70][100/500] loss: 0.60058, MAE: 0.43841, time/step=1031ms, lr=2.81e-05
2024-03-20 13:44:00,315 - logger.py:50 - Epoch: [70][150/500] loss: 0.56668, MAE: 0.43967, time/step=1034ms, lr=2.81e-05
2024-03-20 13:44:52,291 - logger.py:50 - Epoch: [70][200/500] loss: 0.55686, MAE: 0.43859, time/step=1035ms, lr=2.81e-05
2024-03-20 13:45:43,991 - logger.py:50 - Epoch: [70][250/500] loss: 0.56084, MAE: 0.43816, time/step=1035ms, lr=2.81e-05
2024-03-20 13:46:35,614 - logger.py:50 - Epoch: [70][300/500] loss: 0.55035, MAE: 0.43737, time/step=1035ms, lr=2.81e-05
2024-03-20 13:47:28,329 - logger.py:50 - Epoch: [70][350/500] loss: 0.54302, MAE: 0.43631, time/step=1037ms, lr=2.81e-05
2024-03-20 13:48:20,576 - logger.py:50 - Epoch: [70][400/500] loss: 0.56371, MAE: 0.43811, time/step=1038ms, lr=2.81e-05
2024-03-20 13:49:12,056 - logger.py:50 - Epoch: [70][450/500] loss: 0.82789, MAE: 0.44183, time/step=1037ms, lr=2.81e-05
2024-03-20 13:50:04,310 - logger.py:50 - Epoch: [70][499/500] loss: 0.95181, MAE: 0.44378, time/step=1040ms, lr=2.81e-05
2024-03-20 13:51:02,456 - logger.py:50 - Epoch: [70] train loss: 0.95181, val loss: 0.54389, test loss: 0.51531, Time: 578.25s
2024-03-20 13:51:02,456 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 13:52:00,034 - logger.py:50 - Epoch: [70]EMA val MAE: 0.46243, EMA test MAE: 0.44772, Time: 635.83s
2024-03-20 13:52:00,034 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 13:52:01,287 - logger.py:50 - Epoch: [71][0/500] loss: 0.24994, MAE: 0.43146, time/step=1251ms, lr=2.76e-05
2024-03-20 13:52:53,558 - logger.py:50 - Epoch: [71][50/500] loss: 0.60764, MAE: 0.45013, time/step=1049ms, lr=2.76e-05
2024-03-20 13:53:44,965 - logger.py:50 - Epoch: [71][100/500] loss: 0.57613, MAE: 0.44868, time/step=1039ms, lr=2.76e-05
2024-03-20 13:54:36,984 - logger.py:50 - Epoch: [71][150/500] loss: 0.55386, MAE: 0.44537, time/step=1039ms, lr=2.76e-05
2024-03-20 13:55:28,619 - logger.py:50 - Epoch: [71][200/500] loss: 0.55408, MAE: 0.44406, time/step=1038ms, lr=2.76e-05
2024-03-20 13:56:20,903 - logger.py:50 - Epoch: [71][250/500] loss: 0.55983, MAE: 0.44397, time/step=1039ms, lr=2.76e-05
2024-03-20 13:57:13,027 - logger.py:50 - Epoch: [71][300/500] loss: 0.81791, MAE: 0.44623, time/step=1040ms, lr=2.76e-05
2024-03-20 13:58:04,750 - logger.py:50 - Epoch: [71][350/500] loss: 0.78404, MAE: 0.44414, time/step=1039ms, lr=2.76e-05
2024-03-20 13:58:57,086 - logger.py:50 - Epoch: [71][400/500] loss: 0.76157, MAE: 0.44262, time/step=1040ms, lr=2.76e-05
2024-03-20 13:59:49,329 - logger.py:50 - Epoch: [71][450/500] loss: 0.72830, MAE: 0.43967, time/step=1041ms, lr=2.76e-05
2024-03-20 14:00:40,850 - logger.py:50 - Epoch: [71][499/500] loss: 0.95407, MAE: 0.44353, time/step=1042ms, lr=2.76e-05
2024-03-20 14:01:39,479 - logger.py:50 - Epoch: [71] train loss: 0.95407, val loss: 0.52500, test loss: 0.50169, Time: 579.44s
2024-03-20 14:01:39,479 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 14:02:37,032 - logger.py:50 - Epoch: [71]EMA val MAE: 0.46149, EMA test MAE: 0.44676, Time: 637.00s
2024-03-20 14:02:37,032 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 14:02:38,215 - logger.py:50 - Epoch: [72][0/500] loss: 0.39909, MAE: 0.51471, time/step=1181ms, lr=2.70e-05
2024-03-20 14:03:30,735 - logger.py:50 - Epoch: [72][50/500] loss: 2.90072, MAE: 0.48606, time/step=1053ms, lr=2.70e-05
2024-03-20 14:04:23,335 - logger.py:50 - Epoch: [72][100/500] loss: 1.71089, MAE: 0.45444, time/step=1052ms, lr=2.70e-05
2024-03-20 14:05:15,081 - logger.py:50 - Epoch: [72][150/500] loss: 1.32400, MAE: 0.45181, time/step=1047ms, lr=2.70e-05
2024-03-20 14:06:06,384 - logger.py:50 - Epoch: [72][200/500] loss: 1.14661, MAE: 0.44745, time/step=1042ms, lr=2.70e-05
2024-03-20 14:06:58,909 - logger.py:50 - Epoch: [72][250/500] loss: 1.04032, MAE: 0.44704, time/step=1043ms, lr=2.70e-05
2024-03-20 14:07:50,864 - logger.py:50 - Epoch: [72][300/500] loss: 0.94752, MAE: 0.44396, time/step=1043ms, lr=2.70e-05
2024-03-20 14:08:42,807 - logger.py:50 - Epoch: [72][350/500] loss: 0.89210, MAE: 0.44359, time/step=1042ms, lr=2.70e-05
2024-03-20 14:09:35,528 - logger.py:50 - Epoch: [72][400/500] loss: 0.85580, MAE: 0.44339, time/step=1044ms, lr=2.70e-05
2024-03-20 14:10:28,475 - logger.py:50 - Epoch: [72][450/500] loss: 0.82127, MAE: 0.44161, time/step=1045ms, lr=2.70e-05
2024-03-20 14:11:18,219 - logger.py:50 - Epoch: [72][499/500] loss: 0.94680, MAE: 0.44375, time/step=1042ms, lr=2.70e-05
2024-03-20 14:12:16,992 - logger.py:50 - Epoch: [72] train loss: 0.94680, val loss: 0.53584, test loss: 0.50326, Time: 579.96s
2024-03-20 14:12:16,992 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 14:13:14,942 - logger.py:50 - Epoch: [72]EMA val MAE: 0.46069, EMA test MAE: 0.44594, Time: 637.91s
2024-03-20 14:13:14,942 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 14:13:16,180 - logger.py:50 - Epoch: [73][0/500] loss: 0.32699, MAE: 0.46553, time/step=1236ms, lr=2.65e-05
2024-03-20 14:14:08,211 - logger.py:50 - Epoch: [73][50/500] loss: 0.60481, MAE: 0.43560, time/step=1044ms, lr=2.65e-05
2024-03-20 14:15:01,374 - logger.py:50 - Epoch: [73][100/500] loss: 0.56364, MAE: 0.43813, time/step=1054ms, lr=2.65e-05
2024-03-20 14:15:53,239 - logger.py:50 - Epoch: [73][150/500] loss: 1.41248, MAE: 0.44827, time/step=1048ms, lr=2.65e-05
2024-03-20 14:16:45,139 - logger.py:50 - Epoch: [73][200/500] loss: 1.18998, MAE: 0.44358, time/step=1046ms, lr=2.65e-05
2024-03-20 14:17:37,277 - logger.py:50 - Epoch: [73][250/500] loss: 1.05484, MAE: 0.44398, time/step=1045ms, lr=2.65e-05
2024-03-20 14:18:28,642 - logger.py:50 - Epoch: [73][300/500] loss: 0.97591, MAE: 0.44292, time/step=1042ms, lr=2.65e-05
2024-03-20 14:19:20,956 - logger.py:50 - Epoch: [73][350/500] loss: 0.93755, MAE: 0.44315, time/step=1043ms, lr=2.65e-05
2024-03-20 14:20:12,726 - logger.py:50 - Epoch: [73][400/500] loss: 0.88183, MAE: 0.44236, time/step=1042ms, lr=2.65e-05
2024-03-20 14:21:04,101 - logger.py:50 - Epoch: [73][450/500] loss: 0.98631, MAE: 0.44488, time/step=1040ms, lr=2.65e-05
2024-03-20 14:21:55,367 - logger.py:50 - Epoch: [73][499/500] loss: 0.93412, MAE: 0.44360, time/step=1041ms, lr=2.65e-05
2024-03-20 14:22:52,885 - logger.py:50 - Epoch: [73] train loss: 0.93412, val loss: 0.52692, test loss: 0.49789, Time: 577.94s
2024-03-20 14:22:52,885 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 14:23:49,986 - logger.py:50 - Epoch: [73]EMA val MAE: 0.45982, EMA test MAE: 0.44506, Time: 635.04s
2024-03-20 14:23:49,986 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 14:23:51,169 - logger.py:50 - Epoch: [74][0/500] loss: 0.33616, MAE: 0.32914, time/step=1180ms, lr=2.60e-05
2024-03-20 14:24:42,560 - logger.py:50 - Epoch: [74][50/500] loss: 0.51164, MAE: 0.44303, time/step=1031ms, lr=2.60e-05
2024-03-20 14:25:34,854 - logger.py:50 - Epoch: [74][100/500] loss: 0.53731, MAE: 0.44656, time/step=1038ms, lr=2.60e-05
2024-03-20 14:26:26,212 - logger.py:50 - Epoch: [74][150/500] loss: 0.56879, MAE: 0.44223, time/step=1035ms, lr=2.60e-05
2024-03-20 14:27:16,580 - logger.py:50 - Epoch: [74][200/500] loss: 0.56163, MAE: 0.44265, time/step=1028ms, lr=2.60e-05
2024-03-20 14:28:07,989 - logger.py:50 - Epoch: [74][250/500] loss: 0.57796, MAE: 0.44526, time/step=1028ms, lr=2.60e-05
2024-03-20 14:29:01,773 - logger.py:50 - Epoch: [74][300/500] loss: 0.78481, MAE: 0.44968, time/step=1036ms, lr=2.60e-05
2024-03-20 14:29:54,065 - logger.py:50 - Epoch: [74][350/500] loss: 1.09304, MAE: 0.44955, time/step=1037ms, lr=2.60e-05
2024-03-20 14:30:45,119 - logger.py:50 - Epoch: [74][400/500] loss: 1.01307, MAE: 0.44729, time/step=1035ms, lr=2.60e-05
2024-03-20 14:31:36,610 - logger.py:50 - Epoch: [74][450/500] loss: 0.96167, MAE: 0.44455, time/step=1035ms, lr=2.60e-05
2024-03-20 14:32:26,779 - logger.py:50 - Epoch: [74][499/500] loss: 0.92104, MAE: 0.44363, time/step=1034ms, lr=2.60e-05
2024-03-20 14:33:24,148 - logger.py:50 - Epoch: [74] train loss: 0.92104, val loss: 0.52537, test loss: 0.49504, Time: 574.16s
2024-03-20 14:33:24,149 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 14:34:20,972 - logger.py:50 - Epoch: [74]EMA val MAE: 0.45903, EMA test MAE: 0.44425, Time: 630.99s
2024-03-20 14:34:20,973 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 14:34:22,181 - logger.py:50 - Epoch: [75][0/500] loss: 0.28762, MAE: 0.39695, time/step=1207ms, lr=2.55e-05
2024-03-20 14:35:13,723 - logger.py:50 - Epoch: [75][50/500] loss: 0.60928, MAE: 0.43178, time/step=1034ms, lr=2.55e-05
2024-03-20 14:36:04,864 - logger.py:50 - Epoch: [75][100/500] loss: 0.58665, MAE: 0.43821, time/step=1029ms, lr=2.55e-05
2024-03-20 14:36:56,511 - logger.py:50 - Epoch: [75][150/500] loss: 0.56231, MAE: 0.43771, time/step=1030ms, lr=2.55e-05
2024-03-20 14:37:47,252 - logger.py:50 - Epoch: [75][200/500] loss: 0.55061, MAE: 0.43542, time/step=1026ms, lr=2.55e-05
2024-03-20 14:38:38,507 - logger.py:50 - Epoch: [75][250/500] loss: 1.04773, MAE: 0.44522, time/step=1026ms, lr=2.55e-05
2024-03-20 14:39:30,313 - logger.py:50 - Epoch: [75][300/500] loss: 0.95504, MAE: 0.44309, time/step=1028ms, lr=2.55e-05
2024-03-20 14:40:21,174 - logger.py:50 - Epoch: [75][350/500] loss: 0.90047, MAE: 0.44212, time/step=1026ms, lr=2.55e-05
2024-03-20 14:41:13,469 - logger.py:50 - Epoch: [75][400/500] loss: 0.85127, MAE: 0.44319, time/step=1029ms, lr=2.55e-05
2024-03-20 14:42:05,289 - logger.py:50 - Epoch: [75][450/500] loss: 0.81419, MAE: 0.44174, time/step=1030ms, lr=2.55e-05
2024-03-20 14:42:55,471 - logger.py:50 - Epoch: [75][499/500] loss: 0.92070, MAE: 0.44370, time/step=1029ms, lr=2.55e-05
2024-03-20 14:43:52,775 - logger.py:50 - Epoch: [75] train loss: 0.92070, val loss: 0.52691, test loss: 0.49595, Time: 571.80s
2024-03-20 14:43:52,775 - logger.py:50 - Best -- epoch=60, train loss: 0.97097, val loss: 0.52418, test loss: 0.49465

2024-03-20 14:44:49,647 - logger.py:50 - Epoch: [75]EMA val MAE: 0.45826, EMA test MAE: 0.44347, Time: 628.67s
2024-03-20 14:44:49,647 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 14:44:50,807 - logger.py:50 - Epoch: [76][0/500] loss: 0.22351, MAE: 0.32008, time/step=1158ms, lr=2.50e-05
2024-03-20 14:45:42,848 - logger.py:50 - Epoch: [76][50/500] loss: 0.48682, MAE: 0.41546, time/step=1043ms, lr=2.50e-05
2024-03-20 14:46:33,928 - logger.py:50 - Epoch: [76][100/500] loss: 1.72567, MAE: 0.44917, time/step=1032ms, lr=2.50e-05
2024-03-20 14:47:26,403 - logger.py:50 - Epoch: [76][150/500] loss: 1.32498, MAE: 0.44351, time/step=1038ms, lr=2.50e-05
2024-03-20 14:48:17,322 - logger.py:50 - Epoch: [76][200/500] loss: 1.47281, MAE: 0.44996, time/step=1033ms, lr=2.50e-05
2024-03-20 14:49:07,656 - logger.py:50 - Epoch: [76][250/500] loss: 1.28334, MAE: 0.44352, time/step=1028ms, lr=2.50e-05
2024-03-20 14:49:58,606 - logger.py:50 - Epoch: [76][300/500] loss: 1.15958, MAE: 0.44248, time/step=1026ms, lr=2.50e-05
2024-03-20 14:50:49,890 - logger.py:50 - Epoch: [76][350/500] loss: 1.07534, MAE: 0.44250, time/step=1026ms, lr=2.50e-05
2024-03-20 14:51:41,459 - logger.py:50 - Epoch: [76][400/500] loss: 1.01028, MAE: 0.44329, time/step=1027ms, lr=2.50e-05
2024-03-20 14:52:34,000 - logger.py:50 - Epoch: [76][450/500] loss: 0.96428, MAE: 0.44318, time/step=1030ms, lr=2.50e-05
2024-03-20 14:53:25,151 - logger.py:50 - Epoch: [76][499/500] loss: 0.93054, MAE: 0.44362, time/step=1031ms, lr=2.50e-05
2024-03-20 14:54:22,369 - logger.py:50 - Epoch: [76] train loss: 0.93054, val loss: 0.52407, test loss: 0.49405, Time: 572.72s
2024-03-20 14:54:22,369 - logger.py:50 - Best -- epoch=76, train loss: 0.93054, val loss: 0.52407, test loss: 0.49405

2024-03-20 14:55:19,452 - logger.py:50 - Epoch: [76]EMA val MAE: 0.45761, EMA test MAE: 0.44281, Time: 629.81s
2024-03-20 14:55:19,453 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 14:55:20,739 - logger.py:50 - Epoch: [77][0/500] loss: 4.08555, MAE: 0.42447, time/step=1285ms, lr=2.45e-05
2024-03-20 14:56:10,926 - logger.py:50 - Epoch: [77][50/500] loss: 0.63317, MAE: 0.44209, time/step=1009ms, lr=2.45e-05
2024-03-20 14:57:02,273 - logger.py:50 - Epoch: [77][100/500] loss: 0.60060, MAE: 0.44376, time/step=1018ms, lr=2.45e-05
2024-03-20 14:57:53,160 - logger.py:50 - Epoch: [77][150/500] loss: 0.57266, MAE: 0.44591, time/step=1018ms, lr=2.45e-05
2024-03-20 14:58:44,903 - logger.py:50 - Epoch: [77][200/500] loss: 0.56414, MAE: 0.44454, time/step=1022ms, lr=2.45e-05
2024-03-20 14:59:36,077 - logger.py:50 - Epoch: [77][250/500] loss: 0.55414, MAE: 0.44128, time/step=1022ms, lr=2.45e-05
2024-03-20 15:00:28,777 - logger.py:50 - Epoch: [77][300/500] loss: 0.53416, MAE: 0.43911, time/step=1028ms, lr=2.45e-05
2024-03-20 15:01:21,445 - logger.py:50 - Epoch: [77][350/500] loss: 0.52206, MAE: 0.43873, time/step=1031ms, lr=2.45e-05
2024-03-20 15:02:13,346 - logger.py:50 - Epoch: [77][400/500] loss: 0.52708, MAE: 0.43823, time/step=1032ms, lr=2.45e-05
2024-03-20 15:03:04,769 - logger.py:50 - Epoch: [77][450/500] loss: 0.80794, MAE: 0.44164, time/step=1032ms, lr=2.45e-05
2024-03-20 15:03:55,310 - logger.py:50 - Epoch: [77][499/500] loss: 0.93998, MAE: 0.44381, time/step=1032ms, lr=2.45e-05
2024-03-20 15:04:52,779 - logger.py:50 - Epoch: [77] train loss: 0.93998, val loss: 0.55477, test loss: 0.54568, Time: 573.33s
2024-03-20 15:04:52,779 - logger.py:50 - Best -- epoch=76, train loss: 0.93054, val loss: 0.52407, test loss: 0.49405

2024-03-20 15:05:50,444 - logger.py:50 - Epoch: [77]EMA val MAE: 0.45692, EMA test MAE: 0.44212, Time: 630.99s
2024-03-20 15:05:50,444 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 15:05:51,628 - logger.py:50 - Epoch: [78][0/500] loss: 0.44848, MAE: 0.46512, time/step=1181ms, lr=2.40e-05
2024-03-20 15:06:43,279 - logger.py:50 - Epoch: [78][50/500] loss: 3.29176, MAE: 0.45625, time/step=1036ms, lr=2.40e-05
2024-03-20 15:07:35,421 - logger.py:50 - Epoch: [78][100/500] loss: 1.86415, MAE: 0.44019, time/step=1039ms, lr=2.40e-05
2024-03-20 15:08:27,073 - logger.py:50 - Epoch: [78][150/500] loss: 1.47066, MAE: 0.43679, time/step=1037ms, lr=2.40e-05
2024-03-20 15:09:18,646 - logger.py:50 - Epoch: [78][200/500] loss: 1.26008, MAE: 0.44039, time/step=1036ms, lr=2.40e-05
2024-03-20 15:10:09,602 - logger.py:50 - Epoch: [78][250/500] loss: 1.10974, MAE: 0.44078, time/step=1032ms, lr=2.40e-05
2024-03-20 15:11:03,924 - logger.py:50 - Epoch: [78][300/500] loss: 1.00030, MAE: 0.44051, time/step=1041ms, lr=2.40e-05
2024-03-20 15:11:55,716 - logger.py:50 - Epoch: [78][350/500] loss: 0.93503, MAE: 0.44094, time/step=1041ms, lr=2.40e-05
2024-03-20 15:12:47,695 - logger.py:50 - Epoch: [78][400/500] loss: 0.88577, MAE: 0.44080, time/step=1041ms, lr=2.40e-05
2024-03-20 15:13:39,158 - logger.py:50 - Epoch: [78][450/500] loss: 1.14698, MAE: 0.44482, time/step=1039ms, lr=2.40e-05
2024-03-20 15:14:29,515 - logger.py:50 - Epoch: [78][499/500] loss: 1.08446, MAE: 0.44317, time/step=1038ms, lr=2.40e-05
2024-03-20 15:15:27,236 - logger.py:50 - Epoch: [78] train loss: 1.08446, val loss: 0.51506, test loss: 0.48383, Time: 576.79s
2024-03-20 15:15:27,237 - logger.py:50 - Best -- epoch=78, train loss: 1.08446, val loss: 0.51506, test loss: 0.48383

2024-03-20 15:16:24,380 - logger.py:50 - Epoch: [78]EMA val MAE: 0.45612, EMA test MAE: 0.44129, Time: 633.94s
2024-03-20 15:16:24,380 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 15:16:25,102 - logger.py:50 - Epoch: [79][0/500] loss: 0.61556, MAE: 0.48007, time/step=720ms, lr=2.34e-05
2024-03-20 15:17:16,881 - logger.py:50 - Epoch: [79][50/500] loss: 0.57089, MAE: 0.41617, time/step=1029ms, lr=2.34e-05
2024-03-20 15:18:08,725 - logger.py:50 - Epoch: [79][100/500] loss: 0.56447, MAE: 0.43163, time/step=1033ms, lr=2.34e-05
2024-03-20 15:19:00,472 - logger.py:50 - Epoch: [79][150/500] loss: 0.55179, MAE: 0.43349, time/step=1034ms, lr=2.34e-05
2024-03-20 15:19:52,070 - logger.py:50 - Epoch: [79][200/500] loss: 0.88932, MAE: 0.44103, time/step=1033ms, lr=2.34e-05
2024-03-20 15:20:44,085 - logger.py:50 - Epoch: [79][250/500] loss: 0.82640, MAE: 0.44068, time/step=1035ms, lr=2.34e-05
2024-03-20 15:21:36,956 - logger.py:50 - Epoch: [79][300/500] loss: 1.18320, MAE: 0.44779, time/step=1038ms, lr=2.34e-05
2024-03-20 15:22:29,044 - logger.py:50 - Epoch: [79][350/500] loss: 1.10118, MAE: 0.44476, time/step=1039ms, lr=2.34e-05
2024-03-20 15:23:21,260 - logger.py:50 - Epoch: [79][400/500] loss: 1.03034, MAE: 0.44282, time/step=1040ms, lr=2.34e-05
2024-03-20 15:24:14,359 - logger.py:50 - Epoch: [79][450/500] loss: 0.97492, MAE: 0.44362, time/step=1042ms, lr=2.34e-05
2024-03-20 15:25:05,457 - logger.py:50 - Epoch: [79][499/500] loss: 0.93657, MAE: 0.44366, time/step=1042ms, lr=2.34e-05
2024-03-20 15:26:03,355 - logger.py:50 - Epoch: [79] train loss: 0.93657, val loss: 0.51861, test loss: 0.49038, Time: 578.97s
2024-03-20 15:26:03,355 - logger.py:50 - Best -- epoch=78, train loss: 1.08446, val loss: 0.51506, test loss: 0.48383

2024-03-20 15:27:01,223 - logger.py:50 - Epoch: [79]EMA val MAE: 0.45554, EMA test MAE: 0.44070, Time: 636.84s
2024-03-20 15:27:01,223 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 15:27:02,497 - logger.py:50 - Epoch: [80][0/500] loss: 0.38274, MAE: 0.39420, time/step=1272ms, lr=2.29e-05
2024-03-20 15:27:55,185 - logger.py:50 - Epoch: [80][50/500] loss: 0.50268, MAE: 0.43419, time/step=1058ms, lr=2.29e-05
2024-03-20 15:28:47,467 - logger.py:50 - Epoch: [80][100/500] loss: 0.50675, MAE: 0.43693, time/step=1052ms, lr=2.29e-05
2024-03-20 15:29:39,503 - logger.py:50 - Epoch: [80][150/500] loss: 0.52138, MAE: 0.43486, time/step=1048ms, lr=2.29e-05
2024-03-20 15:30:31,771 - logger.py:50 - Epoch: [80][200/500] loss: 1.11656, MAE: 0.44460, time/step=1047ms, lr=2.29e-05
2024-03-20 15:31:23,236 - logger.py:50 - Epoch: [80][250/500] loss: 1.00233, MAE: 0.44348, time/step=1044ms, lr=2.29e-05
2024-03-20 15:32:15,752 - logger.py:50 - Epoch: [80][300/500] loss: 0.93980, MAE: 0.44215, time/step=1045ms, lr=2.29e-05
2024-03-20 15:33:08,737 - logger.py:50 - Epoch: [80][350/500] loss: 0.89473, MAE: 0.44190, time/step=1047ms, lr=2.29e-05
2024-03-20 15:34:00,581 - logger.py:50 - Epoch: [80][400/500] loss: 1.02340, MAE: 0.44441, time/step=1046ms, lr=2.29e-05
2024-03-20 15:34:52,143 - logger.py:50 - Epoch: [80][450/500] loss: 0.97339, MAE: 0.44391, time/step=1044ms, lr=2.29e-05
2024-03-20 15:35:42,610 - logger.py:50 - Epoch: [80][499/500] loss: 0.92881, MAE: 0.44379, time/step=1043ms, lr=2.29e-05
2024-03-20 15:36:39,741 - logger.py:50 - Epoch: [80] train loss: 0.92881, val loss: 0.51928, test loss: 0.48807, Time: 578.52s
2024-03-20 15:36:39,742 - logger.py:50 - Best -- epoch=78, train loss: 1.08446, val loss: 0.51506, test loss: 0.48383

2024-03-20 15:37:37,424 - logger.py:50 - Epoch: [80]EMA val MAE: 0.45494, EMA test MAE: 0.44009, Time: 636.20s
2024-03-20 15:37:37,424 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 15:37:38,622 - logger.py:50 - Epoch: [81][0/500] loss: 0.60716, MAE: 0.41564, time/step=1196ms, lr=2.24e-05
2024-03-20 15:38:29,869 - logger.py:50 - Epoch: [81][50/500] loss: 2.69775, MAE: 0.46478, time/step=1028ms, lr=2.24e-05
2024-03-20 15:39:21,172 - logger.py:50 - Epoch: [81][100/500] loss: 1.63449, MAE: 0.44828, time/step=1027ms, lr=2.24e-05
2024-03-20 15:40:11,875 - logger.py:50 - Epoch: [81][150/500] loss: 1.31828, MAE: 0.44746, time/step=1023ms, lr=2.24e-05
2024-03-20 15:41:03,932 - logger.py:50 - Epoch: [81][200/500] loss: 1.11959, MAE: 0.44724, time/step=1027ms, lr=2.24e-05
2024-03-20 15:41:56,178 - logger.py:50 - Epoch: [81][250/500] loss: 0.99494, MAE: 0.44431, time/step=1031ms, lr=2.24e-05
2024-03-20 15:42:47,335 - logger.py:50 - Epoch: [81][300/500] loss: 0.93434, MAE: 0.44432, time/step=1030ms, lr=2.24e-05
2024-03-20 15:43:38,657 - logger.py:50 - Epoch: [81][350/500] loss: 0.87577, MAE: 0.44336, time/step=1029ms, lr=2.24e-05
2024-03-20 15:44:31,267 - logger.py:50 - Epoch: [81][400/500] loss: 0.83308, MAE: 0.44141, time/step=1032ms, lr=2.24e-05
2024-03-20 15:45:23,299 - logger.py:50 - Epoch: [81][450/500] loss: 0.79664, MAE: 0.43942, time/step=1033ms, lr=2.24e-05
2024-03-20 15:46:14,829 - logger.py:50 - Epoch: [81][499/500] loss: 1.02199, MAE: 0.44327, time/step=1035ms, lr=2.24e-05
2024-03-20 15:47:13,160 - logger.py:50 - Epoch: [81] train loss: 1.02199, val loss: 0.52896, test loss: 0.50590, Time: 575.74s
2024-03-20 15:47:13,160 - logger.py:50 - Best -- epoch=78, train loss: 1.08446, val loss: 0.51506, test loss: 0.48383

2024-03-20 15:48:11,370 - logger.py:50 - Epoch: [81]EMA val MAE: 0.45427, EMA test MAE: 0.43940, Time: 633.95s
2024-03-20 15:48:11,370 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 15:48:12,067 - logger.py:50 - Epoch: [82][0/500] loss: 1.40414, MAE: 0.45038, time/step=694ms, lr=2.19e-05
2024-03-20 15:49:05,678 - logger.py:50 - Epoch: [82][50/500] loss: 0.56713, MAE: 0.44140, time/step=1065ms, lr=2.19e-05
2024-03-20 15:49:57,852 - logger.py:50 - Epoch: [82][100/500] loss: 0.57965, MAE: 0.43348, time/step=1054ms, lr=2.19e-05
2024-03-20 15:50:49,302 - logger.py:50 - Epoch: [82][150/500] loss: 0.56286, MAE: 0.43666, time/step=1046ms, lr=2.19e-05
2024-03-20 15:51:41,029 - logger.py:50 - Epoch: [82][200/500] loss: 0.54711, MAE: 0.43217, time/step=1043ms, lr=2.19e-05
2024-03-20 15:52:33,225 - logger.py:50 - Epoch: [82][250/500] loss: 0.54816, MAE: 0.43420, time/step=1043ms, lr=2.19e-05
2024-03-20 15:53:26,059 - logger.py:50 - Epoch: [82][300/500] loss: 0.54075, MAE: 0.43541, time/step=1045ms, lr=2.19e-05
2024-03-20 15:54:17,178 - logger.py:50 - Epoch: [82][350/500] loss: 0.53529, MAE: 0.43617, time/step=1042ms, lr=2.19e-05
2024-03-20 15:55:09,483 - logger.py:50 - Epoch: [82][400/500] loss: 0.53673, MAE: 0.43740, time/step=1043ms, lr=2.19e-05
2024-03-20 15:56:01,882 - logger.py:50 - Epoch: [82][450/500] loss: 0.53265, MAE: 0.43615, time/step=1043ms, lr=2.19e-05
2024-03-20 15:56:53,269 - logger.py:50 - Epoch: [82][499/500] loss: 0.93250, MAE: 0.44369, time/step=1044ms, lr=2.19e-05
2024-03-20 15:57:50,934 - logger.py:50 - Epoch: [82] train loss: 0.93250, val loss: 0.58302, test loss: 0.56372, Time: 579.56s
2024-03-20 15:57:50,934 - logger.py:50 - Best -- epoch=78, train loss: 1.08446, val loss: 0.51506, test loss: 0.48383

2024-03-20 15:58:48,004 - logger.py:50 - Epoch: [82]EMA val MAE: 0.45373, EMA test MAE: 0.43885, Time: 636.63s
2024-03-20 15:58:48,005 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 15:58:49,306 - logger.py:50 - Epoch: [83][0/500] loss: 0.45997, MAE: 0.46730, time/step=1299ms, lr=2.14e-05
2024-03-20 15:59:40,340 - logger.py:50 - Epoch: [83][50/500] loss: 0.53148, MAE: 0.43498, time/step=1026ms, lr=2.14e-05
2024-03-20 16:00:31,325 - logger.py:50 - Epoch: [83][100/500] loss: 0.55676, MAE: 0.42822, time/step=1023ms, lr=2.14e-05
2024-03-20 16:01:23,459 - logger.py:50 - Epoch: [83][150/500] loss: 0.53327, MAE: 0.43035, time/step=1029ms, lr=2.14e-05
2024-03-20 16:02:15,286 - logger.py:50 - Epoch: [83][200/500] loss: 0.53848, MAE: 0.43242, time/step=1031ms, lr=2.14e-05
2024-03-20 16:03:06,364 - logger.py:50 - Epoch: [83][250/500] loss: 0.54968, MAE: 0.43186, time/step=1029ms, lr=2.14e-05
2024-03-20 16:03:58,575 - logger.py:50 - Epoch: [83][300/500] loss: 0.94620, MAE: 0.43972, time/step=1032ms, lr=2.14e-05
2024-03-20 16:04:49,541 - logger.py:50 - Epoch: [83][350/500] loss: 0.90614, MAE: 0.44057, time/step=1030ms, lr=2.14e-05
2024-03-20 16:05:42,187 - logger.py:50 - Epoch: [83][400/500] loss: 0.85953, MAE: 0.44146, time/step=1033ms, lr=2.14e-05
2024-03-20 16:06:33,900 - logger.py:50 - Epoch: [83][450/500] loss: 0.82033, MAE: 0.44158, time/step=1033ms, lr=2.14e-05
2024-03-20 16:07:24,745 - logger.py:50 - Epoch: [83][499/500] loss: 0.95812, MAE: 0.44391, time/step=1033ms, lr=2.14e-05
2024-03-20 16:08:22,092 - logger.py:50 - Epoch: [83] train loss: 0.95812, val loss: 0.52749, test loss: 0.49578, Time: 574.09s
2024-03-20 16:08:22,092 - logger.py:50 - Best -- epoch=78, train loss: 1.08446, val loss: 0.51506, test loss: 0.48383

2024-03-20 16:09:19,164 - logger.py:50 - Epoch: [83]EMA val MAE: 0.45325, EMA test MAE: 0.43836, Time: 631.16s
2024-03-20 16:09:19,164 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 16:09:20,362 - logger.py:50 - Epoch: [84][0/500] loss: 0.68562, MAE: 0.38339, time/step=1196ms, lr=2.09e-05
2024-03-20 16:10:11,252 - logger.py:50 - Epoch: [84][50/500] loss: 0.59454, MAE: 0.44588, time/step=1021ms, lr=2.09e-05
2024-03-20 16:11:02,790 - logger.py:50 - Epoch: [84][100/500] loss: 0.53737, MAE: 0.43734, time/step=1026ms, lr=2.09e-05
2024-03-20 16:11:54,142 - logger.py:50 - Epoch: [84][150/500] loss: 0.54600, MAE: 0.43630, time/step=1026ms, lr=2.09e-05
2024-03-20 16:12:45,807 - logger.py:50 - Epoch: [84][200/500] loss: 0.52774, MAE: 0.43659, time/step=1028ms, lr=2.09e-05
2024-03-20 16:13:38,058 - logger.py:50 - Epoch: [84][250/500] loss: 1.04009, MAE: 0.44568, time/step=1031ms, lr=2.09e-05
2024-03-20 16:14:29,198 - logger.py:50 - Epoch: [84][300/500] loss: 0.95401, MAE: 0.44583, time/step=1030ms, lr=2.09e-05
2024-03-20 16:15:21,509 - logger.py:50 - Epoch: [84][350/500] loss: 0.89785, MAE: 0.44471, time/step=1032ms, lr=2.09e-05
2024-03-20 16:16:13,543 - logger.py:50 - Epoch: [84][400/500] loss: 1.01459, MAE: 0.44465, time/step=1033ms, lr=2.09e-05
2024-03-20 16:17:04,695 - logger.py:50 - Epoch: [84][450/500] loss: 0.96599, MAE: 0.44487, time/step=1032ms, lr=2.09e-05
2024-03-20 16:17:54,494 - logger.py:50 - Epoch: [84][499/500] loss: 0.92968, MAE: 0.44350, time/step=1031ms, lr=2.09e-05
2024-03-20 16:18:52,071 - logger.py:50 - Epoch: [84] train loss: 0.92968, val loss: 0.52034, test loss: 0.49158, Time: 572.91s
2024-03-20 16:18:52,071 - logger.py:50 - Best -- epoch=78, train loss: 1.08446, val loss: 0.51506, test loss: 0.48383

2024-03-20 16:19:49,184 - logger.py:50 - Epoch: [84]EMA val MAE: 0.45266, EMA test MAE: 0.43776, Time: 630.02s
2024-03-20 16:19:49,184 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 16:19:49,856 - logger.py:50 - Epoch: [85][0/500] loss: 0.41689, MAE: 0.24033, time/step=669ms, lr=2.04e-05
2024-03-20 16:20:42,009 - logger.py:50 - Epoch: [85][50/500] loss: 0.50963, MAE: 0.42534, time/step=1036ms, lr=2.04e-05
2024-03-20 16:21:32,998 - logger.py:50 - Epoch: [85][100/500] loss: 1.78327, MAE: 0.45138, time/step=1028ms, lr=2.04e-05
2024-03-20 16:22:24,775 - logger.py:50 - Epoch: [85][150/500] loss: 1.35643, MAE: 0.44432, time/step=1030ms, lr=2.04e-05
2024-03-20 16:23:17,407 - logger.py:50 - Epoch: [85][200/500] loss: 1.15436, MAE: 0.44564, time/step=1036ms, lr=2.04e-05
2024-03-20 16:24:08,766 - logger.py:50 - Epoch: [85][250/500] loss: 1.02451, MAE: 0.44331, time/step=1034ms, lr=2.04e-05
2024-03-20 16:25:00,539 - logger.py:50 - Epoch: [85][300/500] loss: 0.93751, MAE: 0.44255, time/step=1034ms, lr=2.04e-05
2024-03-20 16:25:53,091 - logger.py:50 - Epoch: [85][350/500] loss: 1.07580, MAE: 0.44361, time/step=1037ms, lr=2.04e-05
2024-03-20 16:26:45,607 - logger.py:50 - Epoch: [85][400/500] loss: 1.01449, MAE: 0.44554, time/step=1038ms, lr=2.04e-05
2024-03-20 16:27:37,374 - logger.py:50 - Epoch: [85][450/500] loss: 0.95856, MAE: 0.44520, time/step=1038ms, lr=2.04e-05
2024-03-20 16:28:28,172 - logger.py:50 - Epoch: [85][499/500] loss: 0.91625, MAE: 0.44369, time/step=1038ms, lr=2.04e-05
2024-03-20 16:29:26,597 - logger.py:50 - Epoch: [85] train loss: 0.91625, val loss: 0.51229, test loss: 0.48131, Time: 577.41s
2024-03-20 16:29:26,597 - logger.py:50 - Best -- epoch=85, train loss: 0.91625, val loss: 0.51229, test loss: 0.48131

2024-03-20 16:30:24,342 - logger.py:50 - Epoch: [85]EMA val MAE: 0.45217, EMA test MAE: 0.43726, Time: 635.16s
2024-03-20 16:30:24,342 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 16:30:25,552 - logger.py:50 - Epoch: [86][0/500] loss: 0.21742, MAE: 0.36546, time/step=1208ms, lr=1.99e-05
2024-03-20 16:31:18,033 - logger.py:50 - Epoch: [86][50/500] loss: 2.92472, MAE: 0.46865, time/step=1053ms, lr=1.99e-05
2024-03-20 16:32:10,841 - logger.py:50 - Epoch: [86][100/500] loss: 1.72767, MAE: 0.45850, time/step=1054ms, lr=1.99e-05
2024-03-20 16:33:02,894 - logger.py:50 - Epoch: [86][150/500] loss: 1.33157, MAE: 0.45400, time/step=1050ms, lr=1.99e-05
2024-03-20 16:33:54,471 - logger.py:50 - Epoch: [86][200/500] loss: 1.13775, MAE: 0.45135, time/step=1045ms, lr=1.99e-05
2024-03-20 16:34:46,013 - logger.py:50 - Epoch: [86][250/500] loss: 1.02100, MAE: 0.44565, time/step=1043ms, lr=1.99e-05
2024-03-20 16:35:37,877 - logger.py:50 - Epoch: [86][300/500] loss: 0.94634, MAE: 0.44275, time/step=1042ms, lr=1.99e-05
2024-03-20 16:36:29,449 - logger.py:50 - Epoch: [86][350/500] loss: 0.89613, MAE: 0.44222, time/step=1040ms, lr=1.99e-05
2024-03-20 16:37:21,866 - logger.py:50 - Epoch: [86][400/500] loss: 1.02022, MAE: 0.44513, time/step=1041ms, lr=1.99e-05
2024-03-20 16:38:14,418 - logger.py:50 - Epoch: [86][450/500] loss: 0.96951, MAE: 0.44511, time/step=1042ms, lr=1.99e-05
2024-03-20 16:39:06,239 - logger.py:50 - Epoch: [86][499/500] loss: 0.92270, MAE: 0.44360, time/step=1044ms, lr=1.99e-05
2024-03-20 16:40:04,506 - logger.py:50 - Epoch: [86] train loss: 0.92270, val loss: 0.51863, test loss: 0.48871, Time: 580.16s
2024-03-20 16:40:04,506 - logger.py:50 - Best -- epoch=85, train loss: 0.91625, val loss: 0.51229, test loss: 0.48131

2024-03-20 16:41:02,365 - logger.py:50 - Epoch: [86]EMA val MAE: 0.45172, EMA test MAE: 0.43681, Time: 638.02s
2024-03-20 16:41:02,365 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 16:41:03,066 - logger.py:50 - Epoch: [87][0/500] loss: 0.71724, MAE: 0.38759, time/step=699ms, lr=1.94e-05
2024-03-20 16:41:54,751 - logger.py:50 - Epoch: [87][50/500] loss: 0.53855, MAE: 0.43412, time/step=1027ms, lr=1.94e-05
2024-03-20 16:42:47,072 - logger.py:50 - Epoch: [87][100/500] loss: 1.82380, MAE: 0.46049, time/step=1037ms, lr=1.94e-05
2024-03-20 16:43:39,172 - logger.py:50 - Epoch: [87][150/500] loss: 1.41021, MAE: 0.46103, time/step=1038ms, lr=1.94e-05
2024-03-20 16:44:30,775 - logger.py:50 - Epoch: [87][200/500] loss: 1.17656, MAE: 0.45026, time/step=1037ms, lr=1.94e-05
2024-03-20 16:45:22,611 - logger.py:50 - Epoch: [87][250/500] loss: 1.04808, MAE: 0.44731, time/step=1037ms, lr=1.94e-05
2024-03-20 16:46:15,454 - logger.py:50 - Epoch: [87][300/500] loss: 1.17048, MAE: 0.44846, time/step=1040ms, lr=1.94e-05
2024-03-20 16:47:07,141 - logger.py:50 - Epoch: [87][350/500] loss: 1.09280, MAE: 0.44667, time/step=1039ms, lr=1.94e-05
2024-03-20 16:48:00,066 - logger.py:50 - Epoch: [87][400/500] loss: 1.01092, MAE: 0.44538, time/step=1042ms, lr=1.94e-05
2024-03-20 16:48:52,060 - logger.py:50 - Epoch: [87][450/500] loss: 0.96258, MAE: 0.44435, time/step=1041ms, lr=1.94e-05
2024-03-20 16:49:44,045 - logger.py:50 - Epoch: [87][499/500] loss: 0.91826, MAE: 0.44370, time/step=1043ms, lr=1.94e-05
2024-03-20 16:50:42,956 - logger.py:50 - Epoch: [87] train loss: 0.91826, val loss: 0.51335, test loss: 0.48098, Time: 580.59s
2024-03-20 16:50:42,957 - logger.py:50 - Best -- epoch=85, train loss: 0.91625, val loss: 0.51229, test loss: 0.48131

2024-03-20 16:51:41,275 - logger.py:50 - Epoch: [87]EMA val MAE: 0.45128, EMA test MAE: 0.43636, Time: 638.91s
2024-03-20 16:51:41,275 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 16:51:42,467 - logger.py:50 - Epoch: [88][0/500] loss: 0.15643, MAE: 0.33628, time/step=1189ms, lr=1.89e-05
2024-03-20 16:52:35,203 - logger.py:50 - Epoch: [88][50/500] loss: 0.56170, MAE: 0.43488, time/step=1057ms, lr=1.89e-05
2024-03-20 16:53:27,012 - logger.py:50 - Epoch: [88][100/500] loss: 0.53432, MAE: 0.43705, time/step=1047ms, lr=1.89e-05
2024-03-20 16:54:19,069 - logger.py:50 - Epoch: [88][150/500] loss: 0.51953, MAE: 0.43844, time/step=1045ms, lr=1.89e-05
2024-03-20 16:55:10,843 - logger.py:50 - Epoch: [88][200/500] loss: 0.51918, MAE: 0.43966, time/step=1043ms, lr=1.89e-05
2024-03-20 16:56:02,359 - logger.py:50 - Epoch: [88][250/500] loss: 0.53333, MAE: 0.43974, time/step=1040ms, lr=1.89e-05
2024-03-20 16:56:53,385 - logger.py:50 - Epoch: [88][300/500] loss: 0.94334, MAE: 0.44314, time/step=1037ms, lr=1.89e-05
2024-03-20 16:57:45,945 - logger.py:50 - Epoch: [88][350/500] loss: 0.89849, MAE: 0.44313, time/step=1039ms, lr=1.89e-05
2024-03-20 16:58:38,499 - logger.py:50 - Epoch: [88][400/500] loss: 0.84554, MAE: 0.44184, time/step=1040ms, lr=1.89e-05
2024-03-20 16:59:30,470 - logger.py:50 - Epoch: [88][450/500] loss: 0.80688, MAE: 0.43991, time/step=1040ms, lr=1.89e-05
2024-03-20 17:00:21,305 - logger.py:50 - Epoch: [88][499/500] loss: 0.91343, MAE: 0.44364, time/step=1040ms, lr=1.89e-05
2024-03-20 17:01:18,984 - logger.py:50 - Epoch: [88] train loss: 0.91343, val loss: 0.51408, test loss: 0.48509, Time: 577.71s
2024-03-20 17:01:18,984 - logger.py:50 - Best -- epoch=85, train loss: 0.91625, val loss: 0.51229, test loss: 0.48131

2024-03-20 17:02:16,640 - logger.py:50 - Epoch: [88]EMA val MAE: 0.45087, EMA test MAE: 0.43594, Time: 635.36s
2024-03-20 17:02:16,640 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 17:02:17,396 - logger.py:50 - Epoch: [89][0/500] loss: 0.75813, MAE: 0.40968, time/step=753ms, lr=1.84e-05
2024-03-20 17:03:09,171 - logger.py:50 - Epoch: [89][50/500] loss: 0.48110, MAE: 0.42730, time/step=1030ms, lr=1.84e-05
2024-03-20 17:04:01,101 - logger.py:50 - Epoch: [89][100/500] loss: 1.17883, MAE: 0.44384, time/step=1034ms, lr=1.84e-05
2024-03-20 17:04:52,073 - logger.py:50 - Epoch: [89][150/500] loss: 0.99183, MAE: 0.43936, time/step=1029ms, lr=1.84e-05
2024-03-20 17:05:43,785 - logger.py:50 - Epoch: [89][200/500] loss: 0.88131, MAE: 0.44075, time/step=1031ms, lr=1.84e-05
2024-03-20 17:06:36,491 - logger.py:50 - Epoch: [89][250/500] loss: 0.81965, MAE: 0.44180, time/step=1035ms, lr=1.84e-05
2024-03-20 17:07:28,190 - logger.py:50 - Epoch: [89][300/500] loss: 0.76689, MAE: 0.43938, time/step=1035ms, lr=1.84e-05
2024-03-20 17:08:20,000 - logger.py:50 - Epoch: [89][350/500] loss: 1.07935, MAE: 0.44690, time/step=1035ms, lr=1.84e-05
2024-03-20 17:09:11,378 - logger.py:50 - Epoch: [89][400/500] loss: 1.01279, MAE: 0.44725, time/step=1034ms, lr=1.84e-05
2024-03-20 17:10:03,112 - logger.py:50 - Epoch: [89][450/500] loss: 0.95819, MAE: 0.44672, time/step=1034ms, lr=1.84e-05
2024-03-20 17:10:53,945 - logger.py:50 - Epoch: [89][499/500] loss: 0.91462, MAE: 0.44378, time/step=1035ms, lr=1.84e-05
2024-03-20 17:11:51,771 - logger.py:50 - Epoch: [89] train loss: 0.91462, val loss: 0.51254, test loss: 0.48146, Time: 575.13s
2024-03-20 17:11:51,771 - logger.py:50 - Best -- epoch=85, train loss: 0.91625, val loss: 0.51229, test loss: 0.48131

2024-03-20 17:12:49,633 - logger.py:50 - Epoch: [89]EMA val MAE: 0.45047, EMA test MAE: 0.43554, Time: 632.99s
2024-03-20 17:12:49,633 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 17:12:50,281 - logger.py:50 - Epoch: [90][0/500] loss: 0.22700, MAE: 0.36503, time/step=645ms, lr=1.79e-05
2024-03-20 17:13:42,265 - logger.py:50 - Epoch: [90][50/500] loss: 0.51100, MAE: 0.41082, time/step=1032ms, lr=1.79e-05
2024-03-20 17:14:33,703 - logger.py:50 - Epoch: [90][100/500] loss: 0.49721, MAE: 0.42887, time/step=1030ms, lr=1.79e-05
2024-03-20 17:15:25,488 - logger.py:50 - Epoch: [90][150/500] loss: 1.32208, MAE: 0.44047, time/step=1032ms, lr=1.79e-05
2024-03-20 17:16:18,022 - logger.py:50 - Epoch: [90][200/500] loss: 1.13578, MAE: 0.44162, time/step=1037ms, lr=1.79e-05
2024-03-20 17:17:09,049 - logger.py:50 - Epoch: [90][250/500] loss: 1.00915, MAE: 0.44229, time/step=1034ms, lr=1.79e-05
2024-03-20 17:18:00,915 - logger.py:50 - Epoch: [90][300/500] loss: 0.93016, MAE: 0.44208, time/step=1034ms, lr=1.79e-05
2024-03-20 17:18:53,517 - logger.py:50 - Epoch: [90][350/500] loss: 0.87737, MAE: 0.44136, time/step=1037ms, lr=1.79e-05
2024-03-20 17:19:45,999 - logger.py:50 - Epoch: [90][400/500] loss: 0.82445, MAE: 0.44072, time/step=1038ms, lr=1.79e-05
2024-03-20 17:20:36,909 - logger.py:50 - Epoch: [90][450/500] loss: 0.79155, MAE: 0.44220, time/step=1036ms, lr=1.79e-05
2024-03-20 17:21:28,153 - logger.py:50 - Epoch: [90][499/500] loss: 0.90731, MAE: 0.44372, time/step=1037ms, lr=1.79e-05
2024-03-20 17:22:25,862 - logger.py:50 - Epoch: [90] train loss: 0.90731, val loss: 0.53585, test loss: 0.50662, Time: 576.23s
2024-03-20 17:22:25,863 - logger.py:50 - Best -- epoch=85, train loss: 0.91625, val loss: 0.51229, test loss: 0.48131

2024-03-20 17:23:23,262 - logger.py:50 - Epoch: [90]EMA val MAE: 0.45013, EMA test MAE: 0.43520, Time: 633.63s
2024-03-20 17:23:23,262 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 17:23:24,499 - logger.py:50 - Epoch: [91][0/500] loss: 0.58732, MAE: 0.44309, time/step=1235ms, lr=1.74e-05
2024-03-20 17:24:16,606 - logger.py:50 - Epoch: [91][50/500] loss: 0.52533, MAE: 0.42939, time/step=1046ms, lr=1.74e-05
2024-03-20 17:25:08,157 - logger.py:50 - Epoch: [91][100/500] loss: 0.51751, MAE: 0.43719, time/step=1039ms, lr=1.74e-05
2024-03-20 17:26:00,345 - logger.py:50 - Epoch: [91][150/500] loss: 0.49805, MAE: 0.43770, time/step=1040ms, lr=1.74e-05
2024-03-20 17:26:52,182 - logger.py:50 - Epoch: [91][200/500] loss: 0.51792, MAE: 0.44004, time/step=1039ms, lr=1.74e-05
2024-03-20 17:27:43,695 - logger.py:50 - Epoch: [91][250/500] loss: 0.52473, MAE: 0.43994, time/step=1038ms, lr=1.74e-05
2024-03-20 17:28:35,851 - logger.py:50 - Epoch: [91][300/500] loss: 0.94134, MAE: 0.44609, time/step=1038ms, lr=1.74e-05
2024-03-20 17:29:27,814 - logger.py:50 - Epoch: [91][350/500] loss: 0.88659, MAE: 0.44474, time/step=1039ms, lr=1.74e-05
2024-03-20 17:30:20,015 - logger.py:50 - Epoch: [91][400/500] loss: 0.83892, MAE: 0.44369, time/step=1039ms, lr=1.74e-05
2024-03-20 17:31:11,221 - logger.py:50 - Epoch: [91][450/500] loss: 0.95156, MAE: 0.44497, time/step=1038ms, lr=1.74e-05
2024-03-20 17:32:01,135 - logger.py:50 - Epoch: [91][499/500] loss: 0.90942, MAE: 0.44363, time/step=1036ms, lr=1.74e-05
2024-03-20 17:32:59,309 - logger.py:50 - Epoch: [91] train loss: 0.90942, val loss: 0.51200, test loss: 0.48262, Time: 576.05s
2024-03-20 17:32:59,309 - logger.py:50 - Best -- epoch=91, train loss: 0.90942, val loss: 0.51200, test loss: 0.48262

2024-03-20 17:33:56,315 - logger.py:50 - Epoch: [91]EMA val MAE: 0.44977, EMA test MAE: 0.43483, Time: 633.05s
2024-03-20 17:33:56,316 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 17:33:57,520 - logger.py:50 - Epoch: [92][0/500] loss: 0.20525, MAE: 0.45607, time/step=1202ms, lr=1.70e-05
2024-03-20 17:34:49,465 - logger.py:50 - Epoch: [92][50/500] loss: 0.51123, MAE: 0.42772, time/step=1042ms, lr=1.70e-05
2024-03-20 17:35:41,214 - logger.py:50 - Epoch: [92][100/500] loss: 1.23375, MAE: 0.44621, time/step=1039ms, lr=1.70e-05
2024-03-20 17:36:33,769 - logger.py:50 - Epoch: [92][150/500] loss: 0.97935, MAE: 0.44468, time/step=1043ms, lr=1.70e-05
2024-03-20 17:37:25,317 - logger.py:50 - Epoch: [92][200/500] loss: 0.89949, MAE: 0.44360, time/step=1040ms, lr=1.70e-05
2024-03-20 17:38:16,436 - logger.py:50 - Epoch: [92][250/500] loss: 1.32422, MAE: 0.44914, time/step=1036ms, lr=1.70e-05
2024-03-20 17:39:06,956 - logger.py:50 - Epoch: [92][300/500] loss: 1.20059, MAE: 0.44767, time/step=1032ms, lr=1.70e-05
2024-03-20 17:39:57,600 - logger.py:50 - Epoch: [92][350/500] loss: 1.11126, MAE: 0.44675, time/step=1029ms, lr=1.70e-05
2024-03-20 17:40:49,985 - logger.py:50 - Epoch: [92][400/500] loss: 1.04475, MAE: 0.44618, time/step=1032ms, lr=1.70e-05
2024-03-20 17:41:41,056 - logger.py:50 - Epoch: [92][450/500] loss: 0.98731, MAE: 0.44516, time/step=1030ms, lr=1.70e-05
2024-03-20 17:42:31,503 - logger.py:50 - Epoch: [92][499/500] loss: 0.94047, MAE: 0.44370, time/step=1030ms, lr=1.70e-05
2024-03-20 17:43:28,823 - logger.py:50 - Epoch: [92] train loss: 0.94047, val loss: 0.51276, test loss: 0.48213, Time: 572.51s
2024-03-20 17:43:28,823 - logger.py:50 - Best -- epoch=91, train loss: 0.90942, val loss: 0.51200, test loss: 0.48262

2024-03-20 17:44:25,897 - logger.py:50 - Epoch: [92]EMA val MAE: 0.44942, EMA test MAE: 0.43448, Time: 629.58s
2024-03-20 17:44:25,897 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 17:44:27,061 - logger.py:50 - Epoch: [93][0/500] loss: 0.43737, MAE: 0.40995, time/step=1161ms, lr=1.65e-05
2024-03-20 17:45:18,133 - logger.py:50 - Epoch: [93][50/500] loss: 0.51854, MAE: 0.43037, time/step=1024ms, lr=1.65e-05
2024-03-20 17:46:09,957 - logger.py:50 - Epoch: [93][100/500] loss: 0.54964, MAE: 0.43382, time/step=1030ms, lr=1.65e-05
2024-03-20 17:47:00,318 - logger.py:50 - Epoch: [93][150/500] loss: 0.56061, MAE: 0.43495, time/step=1023ms, lr=1.65e-05
2024-03-20 17:47:51,860 - logger.py:50 - Epoch: [93][200/500] loss: 0.55659, MAE: 0.43703, time/step=1025ms, lr=1.65e-05
2024-03-20 17:48:44,530 - logger.py:50 - Epoch: [93][250/500] loss: 1.34375, MAE: 0.45080, time/step=1030ms, lr=1.65e-05
2024-03-20 17:49:35,427 - logger.py:50 - Epoch: [93][300/500] loss: 1.20572, MAE: 0.44846, time/step=1028ms, lr=1.65e-05
2024-03-20 17:50:26,660 - logger.py:50 - Epoch: [93][350/500] loss: 1.10502, MAE: 0.44610, time/step=1028ms, lr=1.65e-05
2024-03-20 17:51:19,517 - logger.py:50 - Epoch: [93][400/500] loss: 1.02678, MAE: 0.44590, time/step=1031ms, lr=1.65e-05
2024-03-20 17:52:10,553 - logger.py:50 - Epoch: [93][450/500] loss: 0.96785, MAE: 0.44353, time/step=1030ms, lr=1.65e-05
2024-03-20 17:53:01,944 - logger.py:50 - Epoch: [93][499/500] loss: 0.92589, MAE: 0.44348, time/step=1032ms, lr=1.65e-05
2024-03-20 17:53:59,550 - logger.py:50 - Epoch: [93] train loss: 0.92589, val loss: 0.50982, test loss: 0.48054, Time: 573.65s
2024-03-20 17:53:59,550 - logger.py:50 - Best -- epoch=93, train loss: 0.92589, val loss: 0.50982, test loss: 0.48054

2024-03-20 17:54:56,856 - logger.py:50 - Epoch: [93]EMA val MAE: 0.44911, EMA test MAE: 0.43417, Time: 630.96s
2024-03-20 17:54:56,856 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 17:54:58,068 - logger.py:50 - Epoch: [94][0/500] loss: 0.53477, MAE: 0.49177, time/step=1210ms, lr=1.60e-05
2024-03-20 17:55:50,553 - logger.py:50 - Epoch: [94][50/500] loss: 0.52463, MAE: 0.45226, time/step=1053ms, lr=1.60e-05
2024-03-20 17:56:41,622 - logger.py:50 - Epoch: [94][100/500] loss: 0.53610, MAE: 0.45261, time/step=1037ms, lr=1.60e-05
2024-03-20 17:57:33,338 - logger.py:50 - Epoch: [94][150/500] loss: 0.51509, MAE: 0.44838, time/step=1036ms, lr=1.60e-05
2024-03-20 17:58:25,903 - logger.py:50 - Epoch: [94][200/500] loss: 0.50561, MAE: 0.44552, time/step=1040ms, lr=1.60e-05
2024-03-20 17:59:18,007 - logger.py:50 - Epoch: [94][250/500] loss: 0.51849, MAE: 0.44232, time/step=1040ms, lr=1.60e-05
2024-03-20 18:00:10,116 - logger.py:50 - Epoch: [94][300/500] loss: 0.53143, MAE: 0.43929, time/step=1041ms, lr=1.60e-05
2024-03-20 18:01:02,243 - logger.py:50 - Epoch: [94][350/500] loss: 0.73395, MAE: 0.44056, time/step=1041ms, lr=1.60e-05
2024-03-20 18:01:53,500 - logger.py:50 - Epoch: [94][400/500] loss: 0.72009, MAE: 0.44063, time/step=1039ms, lr=1.60e-05
2024-03-20 18:02:45,213 - logger.py:50 - Epoch: [94][450/500] loss: 0.69932, MAE: 0.43889, time/step=1038ms, lr=1.60e-05
2024-03-20 18:03:35,480 - logger.py:50 - Epoch: [94][499/500] loss: 0.92647, MAE: 0.44367, time/step=1037ms, lr=1.60e-05
2024-03-20 18:04:33,409 - logger.py:50 - Epoch: [94] train loss: 0.92647, val loss: 0.51202, test loss: 0.48482, Time: 576.55s
2024-03-20 18:04:33,409 - logger.py:50 - Best -- epoch=93, train loss: 0.92589, val loss: 0.50982, test loss: 0.48054

2024-03-20 18:05:30,706 - logger.py:50 - Epoch: [94]EMA val MAE: 0.44884, EMA test MAE: 0.43390, Time: 633.85s
2024-03-20 18:05:30,707 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 18:05:31,947 - logger.py:50 - Epoch: [95][0/500] loss: 0.85169, MAE: 0.42871, time/step=1238ms, lr=1.55e-05
2024-03-20 18:06:23,135 - logger.py:50 - Epoch: [95][50/500] loss: 0.49254, MAE: 0.43536, time/step=1028ms, lr=1.55e-05
2024-03-20 18:07:15,459 - logger.py:50 - Epoch: [95][100/500] loss: 0.50404, MAE: 0.44198, time/step=1037ms, lr=1.55e-05
2024-03-20 18:08:08,024 - logger.py:50 - Epoch: [95][150/500] loss: 0.52469, MAE: 0.44307, time/step=1042ms, lr=1.55e-05
2024-03-20 18:08:59,073 - logger.py:50 - Epoch: [95][200/500] loss: 0.52207, MAE: 0.44030, time/step=1037ms, lr=1.55e-05
2024-03-20 18:09:50,418 - logger.py:50 - Epoch: [95][250/500] loss: 0.51957, MAE: 0.44246, time/step=1035ms, lr=1.55e-05
2024-03-20 18:10:41,544 - logger.py:50 - Epoch: [95][300/500] loss: 0.52945, MAE: 0.44184, time/step=1033ms, lr=1.55e-05
2024-03-20 18:11:34,850 - logger.py:50 - Epoch: [95][350/500] loss: 0.72851, MAE: 0.44381, time/step=1037ms, lr=1.55e-05
2024-03-20 18:12:26,544 - logger.py:50 - Epoch: [95][400/500] loss: 0.71079, MAE: 0.44152, time/step=1037ms, lr=1.55e-05
2024-03-20 18:13:18,238 - logger.py:50 - Epoch: [95][450/500] loss: 0.69528, MAE: 0.43986, time/step=1037ms, lr=1.55e-05
2024-03-20 18:14:09,151 - logger.py:50 - Epoch: [95][499/500] loss: 0.92601, MAE: 0.44372, time/step=1037ms, lr=1.55e-05
2024-03-20 18:15:07,013 - logger.py:50 - Epoch: [95] train loss: 0.92601, val loss: 0.51097, test loss: 0.48142, Time: 576.31s
2024-03-20 18:15:07,013 - logger.py:50 - Best -- epoch=93, train loss: 0.92589, val loss: 0.50982, test loss: 0.48054

2024-03-20 18:16:04,398 - logger.py:50 - Epoch: [95]EMA val MAE: 0.44853, EMA test MAE: 0.43357, Time: 633.69s
2024-03-20 18:16:04,398 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 18:16:05,547 - logger.py:50 - Epoch: [96][0/500] loss: 0.57151, MAE: 0.48845, time/step=1147ms, lr=1.51e-05
2024-03-20 18:16:57,363 - logger.py:50 - Epoch: [96][50/500] loss: 0.52014, MAE: 0.43836, time/step=1038ms, lr=1.51e-05
2024-03-20 18:17:49,312 - logger.py:50 - Epoch: [96][100/500] loss: 1.75683, MAE: 0.46102, time/step=1039ms, lr=1.51e-05
2024-03-20 18:18:41,643 - logger.py:50 - Epoch: [96][150/500] loss: 1.32847, MAE: 0.45352, time/step=1041ms, lr=1.51e-05
2024-03-20 18:19:33,663 - logger.py:50 - Epoch: [96][200/500] loss: 1.13306, MAE: 0.45160, time/step=1041ms, lr=1.51e-05
2024-03-20 18:20:24,914 - logger.py:50 - Epoch: [96][250/500] loss: 1.01486, MAE: 0.44837, time/step=1038ms, lr=1.51e-05
2024-03-20 18:21:17,302 - logger.py:50 - Epoch: [96][300/500] loss: 0.92909, MAE: 0.44735, time/step=1040ms, lr=1.51e-05
2024-03-20 18:22:08,188 - logger.py:50 - Epoch: [96][350/500] loss: 0.87144, MAE: 0.44204, time/step=1036ms, lr=1.51e-05
2024-03-20 18:22:59,969 - logger.py:50 - Epoch: [96][400/500] loss: 0.83221, MAE: 0.44061, time/step=1036ms, lr=1.51e-05
2024-03-20 18:23:52,435 - logger.py:50 - Epoch: [96][450/500] loss: 0.95124, MAE: 0.44255, time/step=1038ms, lr=1.51e-05
2024-03-20 18:24:42,938 - logger.py:50 - Epoch: [96][499/500] loss: 0.90819, MAE: 0.44359, time/step=1037ms, lr=1.51e-05
2024-03-20 18:25:41,012 - logger.py:50 - Epoch: [96] train loss: 0.90819, val loss: 0.50881, test loss: 0.48096, Time: 576.61s
2024-03-20 18:25:41,012 - logger.py:50 - Best -- epoch=96, train loss: 0.90819, val loss: 0.50881, test loss: 0.48096

2024-03-20 18:26:38,435 - logger.py:50 - Epoch: [96]EMA val MAE: 0.44824, EMA test MAE: 0.43328, Time: 634.04s
2024-03-20 18:26:38,436 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 18:26:39,157 - logger.py:50 - Epoch: [97][0/500] loss: 0.31842, MAE: 0.43913, time/step=719ms, lr=1.46e-05
2024-03-20 18:27:30,675 - logger.py:50 - Epoch: [97][50/500] loss: 0.53176, MAE: 0.42692, time/step=1024ms, lr=1.46e-05
2024-03-20 18:28:22,787 - logger.py:50 - Epoch: [97][100/500] loss: 0.55182, MAE: 0.42283, time/step=1033ms, lr=1.46e-05
2024-03-20 18:29:14,404 - logger.py:50 - Epoch: [97][150/500] loss: 0.53069, MAE: 0.42855, time/step=1033ms, lr=1.46e-05
2024-03-20 18:30:06,723 - logger.py:50 - Epoch: [97][200/500] loss: 0.86783, MAE: 0.44071, time/step=1036ms, lr=1.46e-05
2024-03-20 18:30:58,531 - logger.py:50 - Epoch: [97][250/500] loss: 1.27844, MAE: 0.44982, time/step=1036ms, lr=1.46e-05
2024-03-20 18:31:50,975 - logger.py:50 - Epoch: [97][300/500] loss: 1.15337, MAE: 0.44726, time/step=1038ms, lr=1.46e-05
2024-03-20 18:32:42,732 - logger.py:50 - Epoch: [97][350/500] loss: 1.06342, MAE: 0.44628, time/step=1038ms, lr=1.46e-05
2024-03-20 18:33:35,078 - logger.py:50 - Epoch: [97][400/500] loss: 0.99697, MAE: 0.44588, time/step=1039ms, lr=1.46e-05
2024-03-20 18:34:27,060 - logger.py:50 - Epoch: [97][450/500] loss: 0.95395, MAE: 0.44413, time/step=1039ms, lr=1.46e-05
2024-03-20 18:35:18,823 - logger.py:50 - Epoch: [97][499/500] loss: 0.90877, MAE: 0.44375, time/step=1041ms, lr=1.46e-05
2024-03-20 18:36:17,367 - logger.py:50 - Epoch: [97] train loss: 0.90877, val loss: 0.50757, test loss: 0.47661, Time: 578.93s
2024-03-20 18:36:17,367 - logger.py:50 - Best -- epoch=97, train loss: 0.90877, val loss: 0.50757, test loss: 0.47661

2024-03-20 18:37:15,056 - logger.py:50 - Epoch: [97]EMA val MAE: 0.44799, EMA test MAE: 0.43304, Time: 636.62s
2024-03-20 18:37:15,057 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 18:37:15,785 - logger.py:50 - Epoch: [98][0/500] loss: 1.04298, MAE: 0.57023, time/step=726ms, lr=1.41e-05
2024-03-20 18:38:07,603 - logger.py:50 - Epoch: [98][50/500] loss: 0.61832, MAE: 0.43129, time/step=1030ms, lr=1.41e-05
2024-03-20 18:38:59,874 - logger.py:50 - Epoch: [98][100/500] loss: 0.55610, MAE: 0.44261, time/step=1038ms, lr=1.41e-05
2024-03-20 18:39:51,443 - logger.py:50 - Epoch: [98][150/500] loss: 0.54276, MAE: 0.44004, time/step=1036ms, lr=1.41e-05
2024-03-20 18:40:43,706 - logger.py:50 - Epoch: [98][200/500] loss: 1.14070, MAE: 0.44912, time/step=1038ms, lr=1.41e-05
2024-03-20 18:41:35,931 - logger.py:50 - Epoch: [98][250/500] loss: 1.02088, MAE: 0.44370, time/step=1039ms, lr=1.41e-05
2024-03-20 18:42:28,480 - logger.py:50 - Epoch: [98][300/500] loss: 1.14626, MAE: 0.44731, time/step=1041ms, lr=1.41e-05
2024-03-20 18:43:20,722 - logger.py:50 - Epoch: [98][350/500] loss: 1.06742, MAE: 0.44428, time/step=1042ms, lr=1.41e-05
2024-03-20 18:44:13,221 - logger.py:50 - Epoch: [98][400/500] loss: 0.99035, MAE: 0.44282, time/step=1043ms, lr=1.41e-05
2024-03-20 18:45:04,736 - logger.py:50 - Epoch: [98][450/500] loss: 0.94511, MAE: 0.44423, time/step=1041ms, lr=1.41e-05
2024-03-20 18:45:55,878 - logger.py:50 - Epoch: [98][499/500] loss: 0.89947, MAE: 0.44369, time/step=1042ms, lr=1.41e-05
2024-03-20 18:46:54,093 - logger.py:50 - Epoch: [98] train loss: 0.89947, val loss: 0.50818, test loss: 0.47675, Time: 579.04s
2024-03-20 18:46:54,094 - logger.py:50 - Best -- epoch=97, train loss: 0.90877, val loss: 0.50757, test loss: 0.47661

2024-03-20 18:47:51,833 - logger.py:50 - Epoch: [98]EMA val MAE: 0.44774, EMA test MAE: 0.43278, Time: 636.78s
2024-03-20 18:47:51,833 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 18:47:52,965 - logger.py:50 - Epoch: [99][0/500] loss: 3.43190, MAE: 0.56876, time/step=1130ms, lr=1.37e-05
2024-03-20 18:48:44,434 - logger.py:50 - Epoch: [99][50/500] loss: 0.60836, MAE: 0.44121, time/step=1031ms, lr=1.37e-05
2024-03-20 18:49:36,237 - logger.py:50 - Epoch: [99][100/500] loss: 0.57575, MAE: 0.44512, time/step=1034ms, lr=1.37e-05
2024-03-20 18:50:28,053 - logger.py:50 - Epoch: [99][150/500] loss: 0.56209, MAE: 0.44659, time/step=1035ms, lr=1.37e-05
2024-03-20 18:51:20,516 - logger.py:50 - Epoch: [99][200/500] loss: 0.56002, MAE: 0.44189, time/step=1038ms, lr=1.37e-05
2024-03-20 18:52:12,740 - logger.py:50 - Epoch: [99][250/500] loss: 0.54499, MAE: 0.43838, time/step=1039ms, lr=1.37e-05
2024-03-20 18:53:05,676 - logger.py:50 - Epoch: [99][300/500] loss: 0.53343, MAE: 0.43880, time/step=1043ms, lr=1.37e-05
2024-03-20 18:53:58,667 - logger.py:50 - Epoch: [99][350/500] loss: 0.52586, MAE: 0.43891, time/step=1045ms, lr=1.37e-05
2024-03-20 18:54:51,148 - logger.py:50 - Epoch: [99][400/500] loss: 0.51804, MAE: 0.43806, time/step=1046ms, lr=1.37e-05
2024-03-20 18:55:42,499 - logger.py:50 - Epoch: [99][450/500] loss: 0.66720, MAE: 0.44047, time/step=1044ms, lr=1.37e-05
2024-03-20 18:56:33,584 - logger.py:50 - Epoch: [99][499/500] loss: 0.89814, MAE: 0.44364, time/step=1043ms, lr=1.37e-05
2024-03-20 18:57:31,743 - logger.py:50 - Epoch: [99] train loss: 0.89814, val loss: 0.51204, test loss: 0.48217, Time: 579.91s
2024-03-20 18:57:31,743 - logger.py:50 - Best -- epoch=97, train loss: 0.90877, val loss: 0.50757, test loss: 0.47661

2024-03-20 18:58:29,364 - logger.py:50 - Epoch: [99]EMA val MAE: 0.44749, EMA test MAE: 0.43254, Time: 637.53s
2024-03-20 18:58:29,364 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 18:58:30,068 - logger.py:50 - Epoch: [100][0/500] loss: 0.57832, MAE: 0.42689, time/step=702ms, lr=1.32e-05
2024-03-20 18:59:22,746 - logger.py:50 - Epoch: [100][50/500] loss: 0.52357, MAE: 0.43568, time/step=1047ms, lr=1.32e-05
2024-03-20 19:00:15,563 - logger.py:50 - Epoch: [100][100/500] loss: 0.51788, MAE: 0.42927, time/step=1051ms, lr=1.32e-05
2024-03-20 19:01:08,469 - logger.py:50 - Epoch: [100][150/500] loss: 0.51104, MAE: 0.43293, time/step=1054ms, lr=1.32e-05
2024-03-20 19:02:00,194 - logger.py:50 - Epoch: [100][200/500] loss: 0.51539, MAE: 0.43403, time/step=1049ms, lr=1.32e-05
2024-03-20 19:02:52,147 - logger.py:50 - Epoch: [100][250/500] loss: 0.50653, MAE: 0.43521, time/step=1047ms, lr=1.32e-05
2024-03-20 19:03:43,522 - logger.py:50 - Epoch: [100][300/500] loss: 0.50783, MAE: 0.43587, time/step=1044ms, lr=1.32e-05
2024-03-20 19:04:35,293 - logger.py:50 - Epoch: [100][350/500] loss: 0.50909, MAE: 0.43754, time/step=1043ms, lr=1.32e-05
2024-03-20 19:05:26,919 - logger.py:50 - Epoch: [100][400/500] loss: 0.98020, MAE: 0.44464, time/step=1041ms, lr=1.32e-05
2024-03-20 19:06:18,668 - logger.py:50 - Epoch: [100][450/500] loss: 0.94633, MAE: 0.44383, time/step=1041ms, lr=1.32e-05
2024-03-20 19:07:09,917 - logger.py:50 - Epoch: [100][499/500] loss: 0.90449, MAE: 0.44354, time/step=1041ms, lr=1.32e-05
2024-03-20 19:08:07,875 - logger.py:50 - Epoch: [100] train loss: 0.90449, val loss: 0.50716, test loss: 0.47644, Time: 578.51s
2024-03-20 19:08:07,875 - logger.py:50 - Best -- epoch=100, train loss: 0.90449, val loss: 0.50716, test loss: 0.47644

2024-03-20 19:09:05,386 - logger.py:50 - Epoch: [100]EMA val MAE: 0.44727, EMA test MAE: 0.43232, Time: 636.02s
2024-03-20 19:09:05,386 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 19:09:06,498 - logger.py:50 - Epoch: [101][0/500] loss: 0.38550, MAE: 0.36172, time/step=1110ms, lr=1.28e-05
2024-03-20 19:09:57,759 - logger.py:50 - Epoch: [101][50/500] loss: 0.47588, MAE: 0.43940, time/step=1027ms, lr=1.28e-05
2024-03-20 19:10:49,812 - logger.py:50 - Epoch: [101][100/500] loss: 0.53943, MAE: 0.44503, time/step=1034ms, lr=1.28e-05
2024-03-20 19:11:42,314 - logger.py:50 - Epoch: [101][150/500] loss: 1.37713, MAE: 0.45389, time/step=1039ms, lr=1.28e-05
2024-03-20 19:12:35,090 - logger.py:50 - Epoch: [101][200/500] loss: 1.17207, MAE: 0.45108, time/step=1043ms, lr=1.28e-05
2024-03-20 19:13:27,218 - logger.py:50 - Epoch: [101][250/500] loss: 1.30377, MAE: 0.45544, time/step=1043ms, lr=1.28e-05
2024-03-20 19:14:18,307 - logger.py:50 - Epoch: [101][300/500] loss: 1.17233, MAE: 0.45041, time/step=1040ms, lr=1.28e-05
2024-03-20 19:15:10,612 - logger.py:50 - Epoch: [101][350/500] loss: 1.07484, MAE: 0.44622, time/step=1041ms, lr=1.28e-05
2024-03-20 19:16:02,524 - logger.py:50 - Epoch: [101][400/500] loss: 1.00812, MAE: 0.44552, time/step=1040ms, lr=1.28e-05
2024-03-20 19:16:53,879 - logger.py:50 - Epoch: [101][450/500] loss: 0.95357, MAE: 0.44411, time/step=1039ms, lr=1.28e-05
2024-03-20 19:17:45,663 - logger.py:50 - Epoch: [101][499/500] loss: 0.90965, MAE: 0.44378, time/step=1041ms, lr=1.28e-05
2024-03-20 19:18:43,422 - logger.py:50 - Epoch: [101] train loss: 0.90965, val loss: 0.50917, test loss: 0.47903, Time: 578.04s
2024-03-20 19:18:43,422 - logger.py:50 - Best -- epoch=100, train loss: 0.90449, val loss: 0.50716, test loss: 0.47644

2024-03-20 19:19:40,735 - logger.py:50 - Epoch: [101]EMA val MAE: 0.44708, EMA test MAE: 0.43212, Time: 635.35s
2024-03-20 19:19:40,736 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 19:19:41,400 - logger.py:50 - Epoch: [102][0/500] loss: 0.48300, MAE: 0.36592, time/step=662ms, lr=1.24e-05
2024-03-20 19:20:33,400 - logger.py:50 - Epoch: [102][50/500] loss: 2.04720, MAE: 0.46165, time/step=1033ms, lr=1.24e-05
2024-03-20 19:21:25,451 - logger.py:50 - Epoch: [102][100/500] loss: 2.51801, MAE: 0.47378, time/step=1037ms, lr=1.24e-05
2024-03-20 19:22:16,615 - logger.py:50 - Epoch: [102][150/500] loss: 1.86068, MAE: 0.46038, time/step=1032ms, lr=1.24e-05
2024-03-20 19:23:08,540 - logger.py:50 - Epoch: [102][200/500] loss: 1.55049, MAE: 0.45367, time/step=1034ms, lr=1.24e-05
2024-03-20 19:24:00,638 - logger.py:50 - Epoch: [102][250/500] loss: 1.32988, MAE: 0.44800, time/step=1035ms, lr=1.24e-05
2024-03-20 19:24:52,550 - logger.py:50 - Epoch: [102][300/500] loss: 1.18992, MAE: 0.44642, time/step=1036ms, lr=1.24e-05
2024-03-20 19:25:43,560 - logger.py:50 - Epoch: [102][350/500] loss: 1.09581, MAE: 0.44460, time/step=1034ms, lr=1.24e-05
2024-03-20 19:26:35,814 - logger.py:50 - Epoch: [102][400/500] loss: 1.02832, MAE: 0.44422, time/step=1035ms, lr=1.24e-05
2024-03-20 19:27:28,280 - logger.py:50 - Epoch: [102][450/500] loss: 0.96099, MAE: 0.44154, time/step=1037ms, lr=1.24e-05
2024-03-20 19:28:19,236 - logger.py:50 - Epoch: [102][499/500] loss: 0.92975, MAE: 0.44365, time/step=1037ms, lr=1.24e-05
2024-03-20 19:29:17,690 - logger.py:50 - Epoch: [102] train loss: 0.92975, val loss: 0.50714, test loss: 0.47616, Time: 576.95s
2024-03-20 19:29:17,690 - logger.py:50 - Best -- epoch=102, train loss: 0.92975, val loss: 0.50714, test loss: 0.47616

2024-03-20 19:30:14,932 - logger.py:50 - Epoch: [102]EMA val MAE: 0.44685, EMA test MAE: 0.43189, Time: 634.20s
2024-03-20 19:30:14,932 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 19:30:15,716 - logger.py:50 - Epoch: [103][0/500] loss: 0.34749, MAE: 0.54737, time/step=782ms, lr=1.19e-05
2024-03-20 19:31:08,254 - logger.py:50 - Epoch: [103][50/500] loss: 0.45690, MAE: 0.43081, time/step=1045ms, lr=1.19e-05
2024-03-20 19:31:59,452 - logger.py:50 - Epoch: [103][100/500] loss: 0.53212, MAE: 0.43207, time/step=1035ms, lr=1.19e-05
2024-03-20 19:32:51,101 - logger.py:50 - Epoch: [103][150/500] loss: 0.51402, MAE: 0.42861, time/step=1034ms, lr=1.19e-05
2024-03-20 19:33:42,207 - logger.py:50 - Epoch: [103][200/500] loss: 0.51393, MAE: 0.43049, time/step=1031ms, lr=1.19e-05
2024-03-20 19:34:34,549 - logger.py:50 - Epoch: [103][250/500] loss: 0.52325, MAE: 0.43346, time/step=1034ms, lr=1.19e-05
2024-03-20 19:35:26,627 - logger.py:50 - Epoch: [103][300/500] loss: 0.93405, MAE: 0.44269, time/step=1036ms, lr=1.19e-05
2024-03-20 19:36:18,755 - logger.py:50 - Epoch: [103][350/500] loss: 0.87062, MAE: 0.44228, time/step=1037ms, lr=1.19e-05
2024-03-20 19:37:10,069 - logger.py:50 - Epoch: [103][400/500] loss: 1.00331, MAE: 0.44577, time/step=1035ms, lr=1.19e-05
2024-03-20 19:38:02,397 - logger.py:50 - Epoch: [103][450/500] loss: 0.95158, MAE: 0.44470, time/step=1037ms, lr=1.19e-05
2024-03-20 19:38:53,190 - logger.py:50 - Epoch: [103][499/500] loss: 0.90794, MAE: 0.44373, time/step=1037ms, lr=1.19e-05
2024-03-20 19:39:51,204 - logger.py:50 - Epoch: [103] train loss: 0.90794, val loss: 0.50599, test loss: 0.47919, Time: 576.27s
2024-03-20 19:39:51,204 - logger.py:50 - Best -- epoch=103, train loss: 0.90794, val loss: 0.50599, test loss: 0.47919

2024-03-20 19:40:48,516 - logger.py:50 - Epoch: [103]EMA val MAE: 0.44666, EMA test MAE: 0.43170, Time: 633.58s
2024-03-20 19:40:48,516 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 19:40:49,737 - logger.py:50 - Epoch: [104][0/500] loss: 0.47113, MAE: 0.45197, time/step=1219ms, lr=1.15e-05
2024-03-20 19:41:40,886 - logger.py:50 - Epoch: [104][50/500] loss: 1.90749, MAE: 0.45413, time/step=1027ms, lr=1.15e-05
2024-03-20 19:42:32,703 - logger.py:50 - Epoch: [104][100/500] loss: 1.21583, MAE: 0.44411, time/step=1032ms, lr=1.15e-05
2024-03-20 19:43:23,997 - logger.py:50 - Epoch: [104][150/500] loss: 0.97192, MAE: 0.44062, time/step=1030ms, lr=1.15e-05
2024-03-20 19:44:16,296 - logger.py:50 - Epoch: [104][200/500] loss: 0.85261, MAE: 0.43591, time/step=1034ms, lr=1.15e-05
2024-03-20 19:45:08,446 - logger.py:50 - Epoch: [104][250/500] loss: 1.27539, MAE: 0.44788, time/step=1036ms, lr=1.15e-05
2024-03-20 19:46:00,276 - logger.py:50 - Epoch: [104][300/500] loss: 1.15113, MAE: 0.44894, time/step=1036ms, lr=1.15e-05
2024-03-20 19:46:51,214 - logger.py:50 - Epoch: [104][350/500] loss: 1.07230, MAE: 0.44617, time/step=1033ms, lr=1.15e-05
2024-03-20 19:47:44,396 - logger.py:50 - Epoch: [104][400/500] loss: 0.99915, MAE: 0.44456, time/step=1037ms, lr=1.15e-05
2024-03-20 19:48:37,093 - logger.py:50 - Epoch: [104][450/500] loss: 0.94865, MAE: 0.44437, time/step=1039ms, lr=1.15e-05
2024-03-20 19:49:28,640 - logger.py:50 - Epoch: [104][499/500] loss: 0.90906, MAE: 0.44375, time/step=1040ms, lr=1.15e-05
2024-03-20 19:50:27,461 - logger.py:50 - Epoch: [104] train loss: 0.90906, val loss: 0.50535, test loss: 0.47569, Time: 578.95s
2024-03-20 19:50:27,461 - logger.py:50 - Best -- epoch=104, train loss: 0.90906, val loss: 0.50535, test loss: 0.47569

2024-03-20 19:51:25,234 - logger.py:50 - Epoch: [104]EMA val MAE: 0.44648, EMA test MAE: 0.43152, Time: 636.72s
2024-03-20 19:51:25,235 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 19:51:26,578 - logger.py:50 - Epoch: [105][0/500] loss: 0.42499, MAE: 0.48636, time/step=1341ms, lr=1.11e-05
2024-03-20 19:52:18,409 - logger.py:50 - Epoch: [105][50/500] loss: 0.49693, MAE: 0.43539, time/step=1043ms, lr=1.11e-05
2024-03-20 19:53:10,677 - logger.py:50 - Epoch: [105][100/500] loss: 0.50462, MAE: 0.44032, time/step=1044ms, lr=1.11e-05
2024-03-20 19:54:03,049 - logger.py:50 - Epoch: [105][150/500] loss: 0.53458, MAE: 0.44049, time/step=1045ms, lr=1.11e-05
2024-03-20 19:54:55,113 - logger.py:50 - Epoch: [105][200/500] loss: 0.51853, MAE: 0.43884, time/step=1044ms, lr=1.11e-05
2024-03-20 19:55:47,167 - logger.py:50 - Epoch: [105][250/500] loss: 0.51482, MAE: 0.43748, time/step=1044ms, lr=1.11e-05
2024-03-20 19:56:38,698 - logger.py:50 - Epoch: [105][300/500] loss: 0.51510, MAE: 0.43557, time/step=1041ms, lr=1.11e-05
2024-03-20 19:57:31,581 - logger.py:50 - Epoch: [105][350/500] loss: 0.52991, MAE: 0.43595, time/step=1044ms, lr=1.11e-05
2024-03-20 19:58:25,396 - logger.py:50 - Epoch: [105][400/500] loss: 0.70570, MAE: 0.43987, time/step=1048ms, lr=1.11e-05
2024-03-20 19:59:20,149 - logger.py:50 - Epoch: [105][450/500] loss: 0.68558, MAE: 0.44049, time/step=1053ms, lr=1.11e-05
2024-03-20 20:00:14,104 - logger.py:50 - Epoch: [105][499/500] loss: 0.90740, MAE: 0.44357, time/step=1058ms, lr=1.11e-05
2024-03-20 20:01:14,601 - logger.py:50 - Epoch: [105] train loss: 0.90740, val loss: 0.50779, test loss: 0.47754, Time: 589.37s
2024-03-20 20:01:14,601 - logger.py:50 - Best -- epoch=104, train loss: 0.90906, val loss: 0.50535, test loss: 0.47569

2024-03-20 20:02:14,194 - logger.py:50 - Epoch: [105]EMA val MAE: 0.44632, EMA test MAE: 0.43136, Time: 648.96s
2024-03-20 20:02:14,194 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 20:02:15,497 - logger.py:50 - Epoch: [106][0/500] loss: 0.49626, MAE: 0.45742, time/step=1301ms, lr=1.07e-05
2024-03-20 20:03:08,319 - logger.py:50 - Epoch: [106][50/500] loss: 0.61490, MAE: 0.43629, time/step=1061ms, lr=1.07e-05
2024-03-20 20:04:02,938 - logger.py:50 - Epoch: [106][100/500] loss: 0.59125, MAE: 0.44347, time/step=1077ms, lr=1.07e-05
2024-03-20 20:05:28,820 - logger.py:50 - Epoch: [106][150/500] loss: 1.78302, MAE: 0.46240, time/step=1289ms, lr=1.07e-05
2024-03-20 20:06:32,987 - logger.py:50 - Epoch: [106][200/500] loss: 1.45400, MAE: 0.45613, time/step=1287ms, lr=1.07e-05
2024-03-20 20:07:23,222 - logger.py:50 - Epoch: [106][250/500] loss: 1.28183, MAE: 0.45242, time/step=1231ms, lr=1.07e-05
2024-03-20 20:08:14,703 - logger.py:50 - Epoch: [106][300/500] loss: 1.14763, MAE: 0.45079, time/step=1198ms, lr=1.07e-05
2024-03-20 20:09:07,509 - logger.py:50 - Epoch: [106][350/500] loss: 1.04866, MAE: 0.44658, time/step=1178ms, lr=1.07e-05
2024-03-20 20:10:00,001 - logger.py:50 - Epoch: [106][400/500] loss: 0.99180, MAE: 0.44453, time/step=1162ms, lr=1.07e-05
2024-03-20 20:10:51,505 - logger.py:50 - Epoch: [106][450/500] loss: 0.94392, MAE: 0.44523, time/step=1147ms, lr=1.07e-05
2024-03-20 20:11:42,672 - logger.py:50 - Epoch: [106][499/500] loss: 0.89972, MAE: 0.44365, time/step=1137ms, lr=1.07e-05
2024-03-20 20:12:41,017 - logger.py:50 - Epoch: [106] train loss: 0.89972, val loss: 0.50440, test loss: 0.47519, Time: 626.82s
2024-03-20 20:12:41,017 - logger.py:50 - Best -- epoch=106, train loss: 0.89972, val loss: 0.50440, test loss: 0.47519

2024-03-20 20:13:38,555 - logger.py:50 - Epoch: [106]EMA val MAE: 0.44618, EMA test MAE: 0.43122, Time: 684.36s
2024-03-20 20:13:38,556 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 20:13:39,696 - logger.py:50 - Epoch: [107][0/500] loss: 0.68690, MAE: 0.42289, time/step=1138ms, lr=1.03e-05
2024-03-20 20:14:31,145 - logger.py:50 - Epoch: [107][50/500] loss: 1.79277, MAE: 0.45851, time/step=1031ms, lr=1.03e-05
2024-03-20 20:15:23,208 - logger.py:50 - Epoch: [107][100/500] loss: 1.16797, MAE: 0.44218, time/step=1036ms, lr=1.03e-05
2024-03-20 20:16:14,409 - logger.py:50 - Epoch: [107][150/500] loss: 0.95832, MAE: 0.44014, time/step=1032ms, lr=1.03e-05
2024-03-20 20:17:06,217 - logger.py:50 - Epoch: [107][200/500] loss: 0.83272, MAE: 0.43635, time/step=1033ms, lr=1.03e-05
2024-03-20 20:17:57,143 - logger.py:50 - Epoch: [107][250/500] loss: 0.77934, MAE: 0.43734, time/step=1030ms, lr=1.03e-05
2024-03-20 20:18:48,271 - logger.py:50 - Epoch: [107][300/500] loss: 0.73544, MAE: 0.43778, time/step=1029ms, lr=1.03e-05
2024-03-20 20:19:40,381 - logger.py:50 - Epoch: [107][350/500] loss: 0.69598, MAE: 0.43703, time/step=1031ms, lr=1.03e-05
2024-03-20 20:20:31,891 - logger.py:50 - Epoch: [107][400/500] loss: 0.98089, MAE: 0.44092, time/step=1031ms, lr=1.03e-05
2024-03-20 20:21:23,660 - logger.py:50 - Epoch: [107][450/500] loss: 0.92784, MAE: 0.44181, time/step=1031ms, lr=1.03e-05
2024-03-20 20:22:13,457 - logger.py:50 - Epoch: [107][499/500] loss: 0.89684, MAE: 0.44372, time/step=1030ms, lr=1.03e-05
2024-03-20 20:23:10,586 - logger.py:50 - Epoch: [107] train loss: 0.89684, val loss: 0.50547, test loss: 0.47357, Time: 572.03s
2024-03-20 20:23:10,586 - logger.py:50 - Best -- epoch=106, train loss: 0.89972, val loss: 0.50440, test loss: 0.47519

2024-03-20 20:24:07,211 - logger.py:50 - Epoch: [107]EMA val MAE: 0.44604, EMA test MAE: 0.43108, Time: 628.66s
2024-03-20 20:24:07,212 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 20:24:08,389 - logger.py:50 - Epoch: [108][0/500] loss: 0.58041, MAE: 0.39516, time/step=1175ms, lr=9.88e-06
2024-03-20 20:24:59,227 - logger.py:50 - Epoch: [108][50/500] loss: 0.49473, MAE: 0.42590, time/step=1020ms, lr=9.88e-06
2024-03-20 20:25:50,245 - logger.py:50 - Epoch: [108][100/500] loss: 0.49936, MAE: 0.43062, time/step=1020ms, lr=9.88e-06
2024-03-20 20:26:42,206 - logger.py:50 - Epoch: [108][150/500] loss: 0.49603, MAE: 0.43893, time/step=1026ms, lr=9.88e-06
2024-03-20 20:27:32,735 - logger.py:50 - Epoch: [108][200/500] loss: 0.51850, MAE: 0.43403, time/step=1022ms, lr=9.88e-06
2024-03-20 20:28:24,716 - logger.py:50 - Epoch: [108][250/500] loss: 0.51074, MAE: 0.43577, time/step=1026ms, lr=9.88e-06
2024-03-20 20:29:16,460 - logger.py:50 - Epoch: [108][300/500] loss: 0.73014, MAE: 0.43857, time/step=1027ms, lr=9.88e-06
2024-03-20 20:30:07,893 - logger.py:50 - Epoch: [108][350/500] loss: 0.70494, MAE: 0.43911, time/step=1028ms, lr=9.88e-06
2024-03-20 20:30:59,496 - logger.py:50 - Epoch: [108][400/500] loss: 0.68504, MAE: 0.43869, time/step=1028ms, lr=9.88e-06
2024-03-20 20:31:51,034 - logger.py:50 - Epoch: [108][450/500] loss: 0.94423, MAE: 0.44427, time/step=1028ms, lr=9.88e-06
2024-03-20 20:32:41,500 - logger.py:50 - Epoch: [108][499/500] loss: 0.90411, MAE: 0.44364, time/step=1029ms, lr=9.88e-06
2024-03-20 20:33:38,282 - logger.py:50 - Epoch: [108] train loss: 0.90411, val loss: 0.50580, test loss: 0.47749, Time: 571.07s
2024-03-20 20:33:38,283 - logger.py:50 - Best -- epoch=106, train loss: 0.89972, val loss: 0.50440, test loss: 0.47519

2024-03-20 20:34:35,047 - logger.py:50 - Epoch: [108]EMA val MAE: 0.44591, EMA test MAE: 0.43094, Time: 627.84s
2024-03-20 20:34:35,047 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 20:34:36,208 - logger.py:50 - Epoch: [109][0/500] loss: 0.77040, MAE: 0.31072, time/step=1158ms, lr=9.49e-06
2024-03-20 20:35:26,843 - logger.py:50 - Epoch: [109][50/500] loss: 0.50721, MAE: 0.44195, time/step=1016ms, lr=9.49e-06
2024-03-20 20:36:19,051 - logger.py:50 - Epoch: [109][100/500] loss: 1.70798, MAE: 0.45358, time/step=1030ms, lr=9.49e-06
2024-03-20 20:37:10,117 - logger.py:50 - Epoch: [109][150/500] loss: 1.32269, MAE: 0.45347, time/step=1027ms, lr=9.49e-06
2024-03-20 20:38:01,492 - logger.py:50 - Epoch: [109][200/500] loss: 1.11630, MAE: 0.44833, time/step=1027ms, lr=9.49e-06
2024-03-20 20:38:53,238 - logger.py:50 - Epoch: [109][250/500] loss: 1.00567, MAE: 0.44569, time/step=1029ms, lr=9.49e-06
2024-03-20 20:39:44,678 - logger.py:50 - Epoch: [109][300/500] loss: 1.15058, MAE: 0.45063, time/step=1029ms, lr=9.49e-06
2024-03-20 20:40:35,860 - logger.py:50 - Epoch: [109][350/500] loss: 1.05946, MAE: 0.44798, time/step=1028ms, lr=9.49e-06
2024-03-20 20:41:27,357 - logger.py:50 - Epoch: [109][400/500] loss: 0.98739, MAE: 0.44607, time/step=1028ms, lr=9.49e-06
2024-03-20 20:42:18,650 - logger.py:50 - Epoch: [109][450/500] loss: 0.94682, MAE: 0.44517, time/step=1028ms, lr=9.49e-06
2024-03-20 20:43:08,338 - logger.py:50 - Epoch: [109][499/500] loss: 0.90200, MAE: 0.44376, time/step=1027ms, lr=9.49e-06
2024-03-20 20:44:05,982 - logger.py:50 - Epoch: [109] train loss: 0.90200, val loss: 0.50418, test loss: 0.47234, Time: 570.93s
2024-03-20 20:44:05,983 - logger.py:50 - Best -- epoch=109, train loss: 0.90200, val loss: 0.50418, test loss: 0.47234

2024-03-20 20:45:02,736 - logger.py:50 - Epoch: [109]EMA val MAE: 0.44580, EMA test MAE: 0.43084, Time: 627.69s
2024-03-20 20:45:02,737 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 20:45:03,912 - logger.py:50 - Epoch: [110][0/500] loss: 0.41398, MAE: 0.33801, time/step=1172ms, lr=9.11e-06
2024-03-20 20:45:54,810 - logger.py:50 - Epoch: [110][50/500] loss: 0.57182, MAE: 0.43849, time/step=1021ms, lr=9.11e-06
2024-03-20 20:46:46,275 - logger.py:50 - Epoch: [110][100/500] loss: 1.72918, MAE: 0.45739, time/step=1025ms, lr=9.11e-06
2024-03-20 20:47:38,041 - logger.py:50 - Epoch: [110][150/500] loss: 1.30859, MAE: 0.45234, time/step=1028ms, lr=9.11e-06
2024-03-20 20:48:28,460 - logger.py:50 - Epoch: [110][200/500] loss: 1.14091, MAE: 0.45145, time/step=1023ms, lr=9.11e-06
2024-03-20 20:49:19,970 - logger.py:50 - Epoch: [110][250/500] loss: 1.30424, MAE: 0.45246, time/step=1025ms, lr=9.11e-06
2024-03-20 20:50:10,758 - logger.py:50 - Epoch: [110][300/500] loss: 1.17957, MAE: 0.44969, time/step=1023ms, lr=9.11e-06
2024-03-20 20:51:02,714 - logger.py:50 - Epoch: [110][350/500] loss: 1.07915, MAE: 0.44857, time/step=1026ms, lr=9.11e-06
2024-03-20 20:51:54,291 - logger.py:50 - Epoch: [110][400/500] loss: 1.00272, MAE: 0.44588, time/step=1026ms, lr=9.11e-06
2024-03-20 20:52:45,879 - logger.py:50 - Epoch: [110][450/500] loss: 0.94947, MAE: 0.44428, time/step=1027ms, lr=9.11e-06
2024-03-20 20:53:36,547 - logger.py:50 - Epoch: [110][499/500] loss: 0.90689, MAE: 0.44365, time/step=1028ms, lr=9.11e-06
2024-03-20 20:54:33,878 - logger.py:50 - Epoch: [110] train loss: 0.90689, val loss: 0.50363, test loss: 0.47529, Time: 571.14s
2024-03-20 20:54:33,878 - logger.py:50 - Best -- epoch=110, train loss: 0.90689, val loss: 0.50363, test loss: 0.47529

2024-03-20 20:55:30,618 - logger.py:50 - Epoch: [110]EMA val MAE: 0.44568, EMA test MAE: 0.43072, Time: 627.88s
2024-03-20 20:55:30,619 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 20:55:31,813 - logger.py:50 - Epoch: [111][0/500] loss: 0.70354, MAE: 0.43893, time/step=1191ms, lr=8.73e-06
2024-03-20 20:56:23,396 - logger.py:50 - Epoch: [111][50/500] loss: 0.51959, MAE: 0.44159, time/step=1035ms, lr=8.73e-06
2024-03-20 20:57:15,669 - logger.py:50 - Epoch: [111][100/500] loss: 1.72814, MAE: 0.45110, time/step=1040ms, lr=8.73e-06
2024-03-20 20:58:07,154 - logger.py:50 - Epoch: [111][150/500] loss: 1.33018, MAE: 0.44925, time/step=1037ms, lr=8.73e-06
2024-03-20 20:58:58,433 - logger.py:50 - Epoch: [111][200/500] loss: 1.12638, MAE: 0.44429, time/step=1034ms, lr=8.73e-06
2024-03-20 20:59:48,874 - logger.py:50 - Epoch: [111][250/500] loss: 1.00240, MAE: 0.44278, time/step=1029ms, lr=8.73e-06
2024-03-20 21:00:40,260 - logger.py:50 - Epoch: [111][300/500] loss: 0.92306, MAE: 0.44185, time/step=1029ms, lr=8.73e-06
2024-03-20 21:01:32,135 - logger.py:50 - Epoch: [111][350/500] loss: 0.86118, MAE: 0.44303, time/step=1030ms, lr=8.73e-06
2024-03-20 21:02:23,544 - logger.py:50 - Epoch: [111][400/500] loss: 0.98188, MAE: 0.44509, time/step=1030ms, lr=8.73e-06
2024-03-20 21:03:14,486 - logger.py:50 - Epoch: [111][450/500] loss: 0.93695, MAE: 0.44539, time/step=1029ms, lr=8.73e-06
2024-03-20 21:04:04,817 - logger.py:50 - Epoch: [111][499/500] loss: 0.89435, MAE: 0.44373, time/step=1028ms, lr=8.73e-06
2024-03-20 21:05:02,055 - logger.py:50 - Epoch: [111] train loss: 0.89435, val loss: 0.50401, test loss: 0.47385, Time: 571.44s
2024-03-20 21:05:02,056 - logger.py:50 - Best -- epoch=110, train loss: 0.90689, val loss: 0.50363, test loss: 0.47529

2024-03-20 21:05:58,850 - logger.py:50 - Epoch: [111]EMA val MAE: 0.44556, EMA test MAE: 0.43059, Time: 628.23s
2024-03-20 21:05:58,850 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 21:05:59,972 - logger.py:50 - Epoch: [112][0/500] loss: 1.01650, MAE: 0.70868, time/step=1120ms, lr=8.36e-06
2024-03-20 21:06:49,633 - logger.py:50 - Epoch: [112][50/500] loss: 0.53690, MAE: 0.45006, time/step=996ms, lr=8.36e-06
2024-03-20 21:07:41,925 - logger.py:50 - Epoch: [112][100/500] loss: 1.15247, MAE: 0.45754, time/step=1021ms, lr=8.36e-06
2024-03-20 21:08:32,573 - logger.py:50 - Epoch: [112][150/500] loss: 0.98458, MAE: 0.45455, time/step=1018ms, lr=8.36e-06
2024-03-20 21:09:24,744 - logger.py:50 - Epoch: [112][200/500] loss: 0.84493, MAE: 0.44802, time/step=1024ms, lr=8.36e-06
2024-03-20 21:10:16,895 - logger.py:50 - Epoch: [112][250/500] loss: 0.79818, MAE: 0.44757, time/step=1028ms, lr=8.36e-06
2024-03-20 21:11:07,887 - logger.py:50 - Epoch: [112][300/500] loss: 0.74147, MAE: 0.44587, time/step=1027ms, lr=8.36e-06
2024-03-20 21:11:59,339 - logger.py:50 - Epoch: [112][350/500] loss: 0.71650, MAE: 0.44364, time/step=1027ms, lr=8.36e-06
2024-03-20 21:12:51,234 - logger.py:50 - Epoch: [112][400/500] loss: 0.68251, MAE: 0.44135, time/step=1028ms, lr=8.36e-06
2024-03-20 21:13:42,849 - logger.py:50 - Epoch: [112][450/500] loss: 0.66355, MAE: 0.44134, time/step=1029ms, lr=8.36e-06
2024-03-20 21:14:32,493 - logger.py:50 - Epoch: [112][499/500] loss: 0.89172, MAE: 0.44372, time/step=1027ms, lr=8.36e-06
2024-03-20 21:15:30,001 - logger.py:50 - Epoch: [112] train loss: 0.89172, val loss: 0.50458, test loss: 0.47431, Time: 571.15s
2024-03-20 21:15:30,002 - logger.py:50 - Best -- epoch=110, train loss: 0.90689, val loss: 0.50363, test loss: 0.47529

2024-03-20 21:16:26,790 - logger.py:50 - Epoch: [112]EMA val MAE: 0.44546, EMA test MAE: 0.43049, Time: 627.94s
2024-03-20 21:16:26,790 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 21:16:27,481 - logger.py:50 - Epoch: [113][0/500] loss: 0.62080, MAE: 0.45527, time/step=689ms, lr=8.00e-06
2024-03-20 21:17:20,060 - logger.py:50 - Epoch: [113][50/500] loss: 2.92613, MAE: 0.48186, time/step=1044ms, lr=8.00e-06
2024-03-20 21:18:10,685 - logger.py:50 - Epoch: [113][100/500] loss: 1.71962, MAE: 0.45672, time/step=1029ms, lr=8.00e-06
2024-03-20 21:19:01,828 - logger.py:50 - Epoch: [113][150/500] loss: 1.30823, MAE: 0.44584, time/step=1027ms, lr=8.00e-06
2024-03-20 21:19:53,389 - logger.py:50 - Epoch: [113][200/500] loss: 1.12360, MAE: 0.44701, time/step=1028ms, lr=8.00e-06
2024-03-20 21:20:43,989 - logger.py:50 - Epoch: [113][250/500] loss: 1.00711, MAE: 0.44322, time/step=1025ms, lr=8.00e-06
2024-03-20 21:21:35,898 - logger.py:50 - Epoch: [113][300/500] loss: 0.92507, MAE: 0.44279, time/step=1027ms, lr=8.00e-06
2024-03-20 21:22:27,245 - logger.py:50 - Epoch: [113][350/500] loss: 1.03850, MAE: 0.44699, time/step=1027ms, lr=8.00e-06
2024-03-20 21:23:18,506 - logger.py:50 - Epoch: [113][400/500] loss: 0.97452, MAE: 0.44695, time/step=1027ms, lr=8.00e-06
2024-03-20 21:24:10,619 - logger.py:50 - Epoch: [113][450/500] loss: 0.92900, MAE: 0.44399, time/step=1028ms, lr=8.00e-06
2024-03-20 21:25:01,781 - logger.py:50 - Epoch: [113][499/500] loss: 0.88913, MAE: 0.44369, time/step=1030ms, lr=8.00e-06
2024-03-20 21:25:59,262 - logger.py:50 - Epoch: [113] train loss: 0.88913, val loss: 0.50307, test loss: 0.47331, Time: 572.47s
2024-03-20 21:25:59,262 - logger.py:50 - Best -- epoch=113, train loss: 0.88913, val loss: 0.50307, test loss: 0.47331

2024-03-20 21:26:56,002 - logger.py:50 - Epoch: [113]EMA val MAE: 0.44538, EMA test MAE: 0.43041, Time: 629.21s
2024-03-20 21:26:56,002 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 21:26:57,193 - logger.py:50 - Epoch: [114][0/500] loss: 0.84252, MAE: 0.47383, time/step=1189ms, lr=7.64e-06
2024-03-20 21:27:48,332 - logger.py:50 - Epoch: [114][50/500] loss: 0.58265, MAE: 0.43584, time/step=1026ms, lr=7.64e-06
2024-03-20 21:28:38,941 - logger.py:50 - Epoch: [114][100/500] loss: 0.56657, MAE: 0.43945, time/step=1019ms, lr=7.64e-06
2024-03-20 21:29:30,108 - logger.py:50 - Epoch: [114][150/500] loss: 0.55848, MAE: 0.44202, time/step=1021ms, lr=7.64e-06
2024-03-20 21:30:22,531 - logger.py:50 - Epoch: [114][200/500] loss: 0.53032, MAE: 0.44058, time/step=1027ms, lr=7.64e-06
2024-03-20 21:31:13,638 - logger.py:50 - Epoch: [114][250/500] loss: 0.54778, MAE: 0.44117, time/step=1026ms, lr=7.64e-06
2024-03-20 21:32:05,003 - logger.py:50 - Epoch: [114][300/500] loss: 0.52509, MAE: 0.44012, time/step=1027ms, lr=7.64e-06
2024-03-20 21:32:55,702 - logger.py:50 - Epoch: [114][350/500] loss: 0.70052, MAE: 0.44186, time/step=1025ms, lr=7.64e-06
2024-03-20 21:33:47,300 - logger.py:50 - Epoch: [114][400/500] loss: 0.98671, MAE: 0.44570, time/step=1026ms, lr=7.64e-06
2024-03-20 21:34:39,276 - logger.py:50 - Epoch: [114][450/500] loss: 0.93103, MAE: 0.44402, time/step=1027ms, lr=7.64e-06
2024-03-20 21:35:30,071 - logger.py:50 - Epoch: [114][499/500] loss: 0.88981, MAE: 0.44369, time/step=1028ms, lr=7.64e-06
2024-03-20 21:36:27,479 - logger.py:50 - Epoch: [114] train loss: 0.88981, val loss: 0.50472, test loss: 0.47449, Time: 571.48s
2024-03-20 21:36:27,479 - logger.py:50 - Best -- epoch=113, train loss: 0.88913, val loss: 0.50307, test loss: 0.47331

2024-03-20 21:37:24,633 - logger.py:50 - Epoch: [114]EMA val MAE: 0.44528, EMA test MAE: 0.43032, Time: 628.63s
2024-03-20 21:37:24,633 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 21:37:25,781 - logger.py:50 - Epoch: [115][0/500] loss: 0.38175, MAE: 0.43663, time/step=1146ms, lr=7.29e-06
2024-03-20 21:38:15,957 - logger.py:50 - Epoch: [115][50/500] loss: 1.75611, MAE: 0.46533, time/step=1006ms, lr=7.29e-06
2024-03-20 21:39:07,358 - logger.py:50 - Epoch: [115][100/500] loss: 1.12356, MAE: 0.45723, time/step=1017ms, lr=7.29e-06
2024-03-20 21:39:58,227 - logger.py:50 - Epoch: [115][150/500] loss: 0.91611, MAE: 0.44652, time/step=1017ms, lr=7.29e-06
2024-03-20 21:40:49,689 - logger.py:50 - Epoch: [115][200/500] loss: 0.84337, MAE: 0.44538, time/step=1020ms, lr=7.29e-06
2024-03-20 21:41:41,895 - logger.py:50 - Epoch: [115][250/500] loss: 0.77336, MAE: 0.44393, time/step=1025ms, lr=7.29e-06
2024-03-20 21:42:33,546 - logger.py:50 - Epoch: [115][300/500] loss: 0.72186, MAE: 0.44190, time/step=1026ms, lr=7.29e-06
2024-03-20 21:43:25,241 - logger.py:50 - Epoch: [115][350/500] loss: 0.68727, MAE: 0.44028, time/step=1027ms, lr=7.29e-06
2024-03-20 21:44:16,620 - logger.py:50 - Epoch: [115][400/500] loss: 0.66487, MAE: 0.43970, time/step=1027ms, lr=7.29e-06
2024-03-20 21:45:08,329 - logger.py:50 - Epoch: [115][450/500] loss: 0.92323, MAE: 0.44520, time/step=1028ms, lr=7.29e-06
2024-03-20 21:45:58,773 - logger.py:50 - Epoch: [115][499/500] loss: 0.88752, MAE: 0.44371, time/step=1028ms, lr=7.29e-06
2024-03-20 21:46:56,025 - logger.py:50 - Epoch: [115] train loss: 0.88752, val loss: 0.50421, test loss: 0.47343, Time: 571.39s
2024-03-20 21:46:56,025 - logger.py:50 - Best -- epoch=113, train loss: 0.88913, val loss: 0.50307, test loss: 0.47331

2024-03-20 21:47:52,853 - logger.py:50 - Epoch: [115]EMA val MAE: 0.44518, EMA test MAE: 0.43022, Time: 628.22s
2024-03-20 21:47:52,853 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 21:47:54,087 - logger.py:50 - Epoch: [116][0/500] loss: 0.29746, MAE: 0.47901, time/step=1232ms, lr=6.95e-06
2024-03-20 21:48:45,767 - logger.py:50 - Epoch: [116][50/500] loss: 0.45659, MAE: 0.44588, time/step=1037ms, lr=6.95e-06
2024-03-20 21:49:36,538 - logger.py:50 - Epoch: [116][100/500] loss: 0.49364, MAE: 0.43792, time/step=1027ms, lr=6.95e-06
2024-03-20 21:50:27,584 - logger.py:50 - Epoch: [116][150/500] loss: 0.54741, MAE: 0.43247, time/step=1025ms, lr=6.95e-06
2024-03-20 21:51:18,786 - logger.py:50 - Epoch: [116][200/500] loss: 0.54354, MAE: 0.43262, time/step=1025ms, lr=6.95e-06
2024-03-20 21:52:10,976 - logger.py:50 - Epoch: [116][250/500] loss: 1.27880, MAE: 0.45042, time/step=1028ms, lr=6.95e-06
2024-03-20 21:53:01,512 - logger.py:50 - Epoch: [116][300/500] loss: 1.15375, MAE: 0.44717, time/step=1025ms, lr=6.95e-06
2024-03-20 21:53:51,698 - logger.py:50 - Epoch: [116][350/500] loss: 1.06714, MAE: 0.44753, time/step=1022ms, lr=6.95e-06
2024-03-20 21:54:43,359 - logger.py:50 - Epoch: [116][400/500] loss: 0.99515, MAE: 0.44654, time/step=1024ms, lr=6.95e-06
2024-03-20 21:55:35,200 - logger.py:50 - Epoch: [116][450/500] loss: 0.93379, MAE: 0.44552, time/step=1025ms, lr=6.95e-06
2024-03-20 21:56:26,876 - logger.py:50 - Epoch: [116][499/500] loss: 0.89061, MAE: 0.44370, time/step=1028ms, lr=6.95e-06
2024-03-20 21:57:24,138 - logger.py:50 - Epoch: [116] train loss: 0.89061, val loss: 0.50259, test loss: 0.47218, Time: 571.28s
2024-03-20 21:57:24,138 - logger.py:50 - Best -- epoch=116, train loss: 0.89061, val loss: 0.50259, test loss: 0.47218

2024-03-20 21:58:20,874 - logger.py:50 - Epoch: [116]EMA val MAE: 0.44508, EMA test MAE: 0.43012, Time: 628.02s
2024-03-20 21:58:20,874 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 21:58:22,109 - logger.py:50 - Epoch: [117][0/500] loss: 0.31470, MAE: 0.40138, time/step=1233ms, lr=6.62e-06
2024-03-20 21:59:12,495 - logger.py:50 - Epoch: [117][50/500] loss: 0.52146, MAE: 0.44564, time/step=1012ms, lr=6.62e-06
2024-03-20 22:00:03,880 - logger.py:50 - Epoch: [117][100/500] loss: 0.48745, MAE: 0.43150, time/step=1020ms, lr=6.62e-06
2024-03-20 22:00:55,654 - logger.py:50 - Epoch: [117][150/500] loss: 0.50843, MAE: 0.43538, time/step=1025ms, lr=6.62e-06
2024-03-20 22:01:47,329 - logger.py:50 - Epoch: [117][200/500] loss: 0.50729, MAE: 0.43692, time/step=1027ms, lr=6.62e-06
2024-03-20 22:02:39,307 - logger.py:50 - Epoch: [117][250/500] loss: 0.51650, MAE: 0.43505, time/step=1030ms, lr=6.62e-06
2024-03-20 22:03:31,404 - logger.py:50 - Epoch: [117][300/500] loss: 0.90688, MAE: 0.44108, time/step=1032ms, lr=6.62e-06
2024-03-20 22:04:21,694 - logger.py:50 - Epoch: [117][350/500] loss: 1.03356, MAE: 0.44457, time/step=1028ms, lr=6.62e-06
2024-03-20 22:05:13,477 - logger.py:50 - Epoch: [117][400/500] loss: 0.96923, MAE: 0.44329, time/step=1029ms, lr=6.62e-06
2024-03-20 22:06:04,650 - logger.py:50 - Epoch: [117][450/500] loss: 0.92576, MAE: 0.44340, time/step=1028ms, lr=6.62e-06
2024-03-20 22:06:55,438 - logger.py:50 - Epoch: [117][499/500] loss: 0.89272, MAE: 0.44375, time/step=1029ms, lr=6.62e-06
2024-03-20 22:07:52,804 - logger.py:50 - Epoch: [117] train loss: 0.89272, val loss: 0.50633, test loss: 0.47611, Time: 571.93s
2024-03-20 22:07:52,804 - logger.py:50 - Best -- epoch=116, train loss: 0.89061, val loss: 0.50259, test loss: 0.47218

2024-03-20 22:08:49,621 - logger.py:50 - Epoch: [117]EMA val MAE: 0.44496, EMA test MAE: 0.43000, Time: 628.75s
2024-03-20 22:08:49,621 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 22:08:50,865 - logger.py:50 - Epoch: [118][0/500] loss: 0.22243, MAE: 0.41487, time/step=1242ms, lr=6.30e-06
2024-03-20 22:09:41,820 - logger.py:50 - Epoch: [118][50/500] loss: 0.54353, MAE: 0.42827, time/step=1023ms, lr=6.30e-06
2024-03-20 22:10:32,968 - logger.py:50 - Epoch: [118][100/500] loss: 0.53233, MAE: 0.43390, time/step=1023ms, lr=6.30e-06
2024-03-20 22:11:24,408 - logger.py:50 - Epoch: [118][150/500] loss: 0.94238, MAE: 0.44203, time/step=1025ms, lr=6.30e-06
2024-03-20 22:12:15,538 - logger.py:50 - Epoch: [118][200/500] loss: 0.82913, MAE: 0.43992, time/step=1024ms, lr=6.30e-06
2024-03-20 22:13:07,259 - logger.py:50 - Epoch: [118][250/500] loss: 0.76704, MAE: 0.44195, time/step=1026ms, lr=6.30e-06
2024-03-20 22:13:58,680 - logger.py:50 - Epoch: [118][300/500] loss: 0.72305, MAE: 0.44193, time/step=1027ms, lr=6.30e-06
2024-03-20 22:14:50,124 - logger.py:50 - Epoch: [118][350/500] loss: 0.70378, MAE: 0.44102, time/step=1027ms, lr=6.30e-06
2024-03-20 22:15:41,458 - logger.py:50 - Epoch: [118][400/500] loss: 0.69061, MAE: 0.44164, time/step=1027ms, lr=6.30e-06
2024-03-20 22:16:33,835 - logger.py:50 - Epoch: [118][450/500] loss: 0.66679, MAE: 0.44021, time/step=1029ms, lr=6.30e-06
2024-03-20 22:17:24,221 - logger.py:50 - Epoch: [118][499/500] loss: 0.89110, MAE: 0.44369, time/step=1029ms, lr=6.30e-06
2024-03-20 22:18:21,647 - logger.py:50 - Epoch: [118] train loss: 0.89110, val loss: 0.50358, test loss: 0.47213, Time: 572.03s
2024-03-20 22:18:21,648 - logger.py:50 - Best -- epoch=116, train loss: 0.89061, val loss: 0.50259, test loss: 0.47218

2024-03-20 22:19:18,970 - logger.py:50 - Epoch: [118]EMA val MAE: 0.44487, EMA test MAE: 0.42991, Time: 629.35s
2024-03-20 22:19:18,972 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 22:19:19,737 - logger.py:50 - Epoch: [119][0/500] loss: 0.94210, MAE: 0.56017, time/step=761ms, lr=5.99e-06
2024-03-20 22:20:11,501 - logger.py:50 - Epoch: [119][50/500] loss: 2.85877, MAE: 0.48537, time/step=1030ms, lr=5.99e-06
2024-03-20 22:21:03,061 - logger.py:50 - Epoch: [119][100/500] loss: 1.68255, MAE: 0.46274, time/step=1031ms, lr=5.99e-06
2024-03-20 22:21:54,880 - logger.py:50 - Epoch: [119][150/500] loss: 1.29042, MAE: 0.45658, time/step=1032ms, lr=5.99e-06
2024-03-20 22:22:46,108 - logger.py:50 - Epoch: [119][200/500] loss: 1.08518, MAE: 0.44985, time/step=1031ms, lr=5.99e-06
2024-03-20 22:23:38,484 - logger.py:50 - Epoch: [119][250/500] loss: 0.99722, MAE: 0.44512, time/step=1034ms, lr=5.99e-06
2024-03-20 22:24:30,025 - logger.py:50 - Epoch: [119][300/500] loss: 0.91939, MAE: 0.44348, time/step=1033ms, lr=5.99e-06
2024-03-20 22:25:21,936 - logger.py:50 - Epoch: [119][350/500] loss: 0.86578, MAE: 0.44266, time/step=1034ms, lr=5.99e-06
2024-03-20 22:26:13,072 - logger.py:50 - Epoch: [119][400/500] loss: 0.82427, MAE: 0.44189, time/step=1033ms, lr=5.99e-06
2024-03-20 22:27:04,554 - logger.py:50 - Epoch: [119][450/500] loss: 0.79373, MAE: 0.44181, time/step=1032ms, lr=5.99e-06
2024-03-20 22:27:54,542 - logger.py:50 - Epoch: [119][499/500] loss: 0.88805, MAE: 0.44369, time/step=1031ms, lr=5.99e-06
2024-03-20 22:28:52,516 - logger.py:50 - Epoch: [119] train loss: 0.88805, val loss: 0.50549, test loss: 0.47811, Time: 573.54s
2024-03-20 22:28:52,516 - logger.py:50 - Best -- epoch=116, train loss: 0.89061, val loss: 0.50259, test loss: 0.47218

2024-03-20 22:29:00,910 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 22:29:49,575 - logger.py:50 - Epoch: [119]EMA val MAE: 0.44478, EMA test MAE: 0.42982, Time: 630.60s
2024-03-20 22:29:49,576 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 22:29:50,814 - logger.py:50 - Epoch: [120][0/500] loss: 0.29974, MAE: 0.44845, time/step=1236ms, lr=5.68e-06
2024-03-20 22:30:42,177 - logger.py:50 - Epoch: [120][50/500] loss: 0.54768, MAE: 0.44946, time/step=1031ms, lr=5.68e-06
2024-03-20 22:31:33,418 - logger.py:50 - Epoch: [120][100/500] loss: 1.73296, MAE: 0.45966, time/step=1028ms, lr=5.68e-06
2024-03-20 22:32:24,771 - logger.py:50 - Epoch: [120][150/500] loss: 1.33203, MAE: 0.45080, time/step=1028ms, lr=5.68e-06
2024-03-20 22:33:17,219 - logger.py:50 - Epoch: [120][200/500] loss: 1.12572, MAE: 0.44739, time/step=1033ms, lr=5.68e-06
2024-03-20 22:34:09,600 - logger.py:50 - Epoch: [120][250/500] loss: 1.00928, MAE: 0.44703, time/step=1036ms, lr=5.68e-06
2024-03-20 22:35:02,101 - logger.py:50 - Epoch: [120][300/500] loss: 1.13407, MAE: 0.44841, time/step=1038ms, lr=5.68e-06
2024-03-20 22:35:53,163 - logger.py:50 - Epoch: [120][350/500] loss: 1.04767, MAE: 0.44865, time/step=1036ms, lr=5.68e-06
2024-03-20 22:36:44,517 - logger.py:50 - Epoch: [120][400/500] loss: 0.99472, MAE: 0.44670, time/step=1035ms, lr=5.68e-06
2024-03-20 22:37:36,442 - logger.py:50 - Epoch: [120][450/500] loss: 0.93593, MAE: 0.44439, time/step=1035ms, lr=5.68e-06
2024-03-20 22:38:26,489 - logger.py:50 - Epoch: [120][499/500] loss: 0.89379, MAE: 0.44371, time/step=1034ms, lr=5.68e-06
2024-03-20 22:39:24,254 - logger.py:50 - Epoch: [120] train loss: 0.89379, val loss: 0.50205, test loss: 0.47109, Time: 574.68s
2024-03-20 22:39:24,254 - logger.py:50 - Best -- epoch=120, train loss: 0.89379, val loss: 0.50205, test loss: 0.47109

2024-03-20 22:40:21,448 - logger.py:50 - Epoch: [120]EMA val MAE: 0.44471, EMA test MAE: 0.42975, Time: 631.87s
2024-03-20 22:40:21,448 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 22:40:22,632 - logger.py:50 - Epoch: [121][0/500] loss: 0.41433, MAE: 0.49642, time/step=1182ms, lr=5.38e-06
2024-03-20 22:41:13,439 - logger.py:50 - Epoch: [121][50/500] loss: 0.63638, MAE: 0.45283, time/step=1019ms, lr=5.38e-06
2024-03-20 22:42:06,091 - logger.py:50 - Epoch: [121][100/500] loss: 1.82171, MAE: 0.47030, time/step=1036ms, lr=5.38e-06
2024-03-20 22:42:57,187 - logger.py:50 - Epoch: [121][150/500] loss: 1.38545, MAE: 0.45374, time/step=1031ms, lr=5.38e-06
2024-03-20 22:43:48,800 - logger.py:50 - Epoch: [121][200/500] loss: 1.16346, MAE: 0.44824, time/step=1032ms, lr=5.38e-06
2024-03-20 22:44:41,178 - logger.py:50 - Epoch: [121][250/500] loss: 1.29183, MAE: 0.44998, time/step=1035ms, lr=5.38e-06
2024-03-20 22:45:32,050 - logger.py:50 - Epoch: [121][300/500] loss: 1.16229, MAE: 0.44739, time/step=1032ms, lr=5.38e-06
2024-03-20 22:46:24,000 - logger.py:50 - Epoch: [121][350/500] loss: 1.06330, MAE: 0.44549, time/step=1033ms, lr=5.38e-06
2024-03-20 22:47:15,864 - logger.py:50 - Epoch: [121][400/500] loss: 0.99041, MAE: 0.44411, time/step=1033ms, lr=5.38e-06
2024-03-20 22:48:07,386 - logger.py:50 - Epoch: [121][450/500] loss: 0.93320, MAE: 0.44325, time/step=1033ms, lr=5.38e-06
2024-03-20 22:48:58,019 - logger.py:50 - Epoch: [121][499/500] loss: 0.89463, MAE: 0.44357, time/step=1033ms, lr=5.38e-06
2024-03-20 22:49:55,452 - logger.py:50 - Epoch: [121] train loss: 0.89463, val loss: 0.50205, test loss: 0.47106, Time: 574.00s
2024-03-20 22:49:55,452 - logger.py:50 - Best -- epoch=120, train loss: 0.89379, val loss: 0.50205, test loss: 0.47109

2024-03-20 22:50:52,487 - logger.py:50 - Epoch: [121]EMA val MAE: 0.44466, EMA test MAE: 0.42970, Time: 631.04s
2024-03-20 22:50:52,488 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 22:50:53,641 - logger.py:50 - Epoch: [122][0/500] loss: 0.32146, MAE: 0.51384, time/step=1151ms, lr=5.09e-06
2024-03-20 22:51:44,496 - logger.py:50 - Epoch: [122][50/500] loss: 0.48458, MAE: 0.43852, time/step=1020ms, lr=5.09e-06
2024-03-20 22:52:35,736 - logger.py:50 - Epoch: [122][100/500] loss: 0.48350, MAE: 0.43402, time/step=1022ms, lr=5.09e-06
2024-03-20 22:53:27,437 - logger.py:50 - Epoch: [122][150/500] loss: 0.50208, MAE: 0.43700, time/step=1026ms, lr=5.09e-06
2024-03-20 22:54:19,677 - logger.py:50 - Epoch: [122][200/500] loss: 1.11400, MAE: 0.44850, time/step=1031ms, lr=5.09e-06
2024-03-20 22:55:11,403 - logger.py:50 - Epoch: [122][250/500] loss: 0.99698, MAE: 0.44454, time/step=1032ms, lr=5.09e-06
2024-03-20 22:55:38,233 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-20 22:56:02,540 - logger.py:50 - Epoch: [122][300/500] loss: 1.14480, MAE: 0.44804, time/step=1030ms, lr=5.09e-06
2024-03-20 22:56:54,006 - logger.py:50 - Epoch: [122][350/500] loss: 1.05730, MAE: 0.44706, time/step=1030ms, lr=5.09e-06
2024-03-20 22:57:46,091 - logger.py:50 - Epoch: [122][400/500] loss: 0.98324, MAE: 0.44439, time/step=1031ms, lr=5.09e-06
2024-03-20 22:58:37,775 - logger.py:50 - Epoch: [122][450/500] loss: 0.93511, MAE: 0.44392, time/step=1032ms, lr=5.09e-06
2024-03-20 22:59:28,581 - logger.py:50 - Epoch: [122][499/500] loss: 0.89452, MAE: 0.44360, time/step=1032ms, lr=5.09e-06
2024-03-20 23:00:26,478 - logger.py:50 - Epoch: [122] train loss: 0.89452, val loss: 0.50225, test loss: 0.47326, Time: 573.99s
2024-03-20 23:00:26,478 - logger.py:50 - Best -- epoch=120, train loss: 0.89379, val loss: 0.50205, test loss: 0.47109

2024-03-20 23:01:23,042 - logger.py:50 - Epoch: [122]EMA val MAE: 0.44461, EMA test MAE: 0.42964, Time: 630.55s
2024-03-20 23:01:23,042 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 23:01:24,173 - logger.py:50 - Epoch: [123][0/500] loss: 0.37031, MAE: 0.42082, time/step=1129ms, lr=4.81e-06
2024-03-20 23:02:16,380 - logger.py:50 - Epoch: [123][50/500] loss: 0.43830, MAE: 0.43119, time/step=1046ms, lr=4.81e-06
2024-03-20 23:03:08,099 - logger.py:50 - Epoch: [123][100/500] loss: 0.45435, MAE: 0.42830, time/step=1040ms, lr=4.81e-06
2024-03-20 23:03:59,427 - logger.py:50 - Epoch: [123][150/500] loss: 0.45113, MAE: 0.42881, time/step=1036ms, lr=4.81e-06
2024-03-20 23:04:51,115 - logger.py:50 - Epoch: [123][200/500] loss: 0.47433, MAE: 0.42864, time/step=1035ms, lr=4.81e-06
2024-03-20 23:05:42,051 - logger.py:50 - Epoch: [123][250/500] loss: 0.47826, MAE: 0.43028, time/step=1032ms, lr=4.81e-06
2024-03-20 23:06:33,635 - logger.py:50 - Epoch: [123][300/500] loss: 0.88875, MAE: 0.43866, time/step=1032ms, lr=4.81e-06
2024-03-20 23:07:24,855 - logger.py:50 - Epoch: [123][350/500] loss: 1.01592, MAE: 0.44365, time/step=1031ms, lr=4.81e-06
2024-03-20 23:08:16,550 - logger.py:50 - Epoch: [123][400/500] loss: 0.96175, MAE: 0.44369, time/step=1031ms, lr=4.81e-06
2024-03-20 23:09:07,831 - logger.py:50 - Epoch: [123][450/500] loss: 0.91714, MAE: 0.44380, time/step=1031ms, lr=4.81e-06
2024-03-20 23:09:58,907 - logger.py:50 - Epoch: [123][499/500] loss: 0.88720, MAE: 0.44374, time/step=1032ms, lr=4.81e-06
2024-03-20 23:10:56,503 - logger.py:50 - Epoch: [123] train loss: 0.88720, val loss: 0.50134, test loss: 0.47194, Time: 573.46s
2024-03-20 23:10:56,504 - logger.py:50 - Best -- epoch=123, train loss: 0.88720, val loss: 0.50134, test loss: 0.47194

2024-03-20 23:11:53,567 - logger.py:50 - Epoch: [123]EMA val MAE: 0.44456, EMA test MAE: 0.42960, Time: 630.52s
2024-03-20 23:11:53,567 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 23:11:54,787 - logger.py:50 - Epoch: [124][0/500] loss: 0.24363, MAE: 0.46035, time/step=1218ms, lr=4.54e-06
2024-03-20 23:12:46,371 - logger.py:50 - Epoch: [124][50/500] loss: 1.69003, MAE: 0.46918, time/step=1035ms, lr=4.54e-06
2024-03-20 23:13:37,655 - logger.py:50 - Epoch: [124][100/500] loss: 2.27982, MAE: 0.46662, time/step=1031ms, lr=4.54e-06
2024-03-20 23:14:28,885 - logger.py:50 - Epoch: [124][150/500] loss: 1.70381, MAE: 0.45841, time/step=1029ms, lr=4.54e-06
2024-03-20 23:15:20,293 - logger.py:50 - Epoch: [124][200/500] loss: 1.42453, MAE: 0.45384, time/step=1028ms, lr=4.54e-06
2024-03-20 23:16:11,611 - logger.py:50 - Epoch: [124][250/500] loss: 1.23879, MAE: 0.44955, time/step=1028ms, lr=4.54e-06
2024-03-20 23:17:02,985 - logger.py:50 - Epoch: [124][300/500] loss: 1.12447, MAE: 0.44733, time/step=1028ms, lr=4.54e-06
2024-03-20 23:17:54,897 - logger.py:50 - Epoch: [124][350/500] loss: 1.03286, MAE: 0.44470, time/step=1029ms, lr=4.54e-06
2024-03-20 23:18:46,732 - logger.py:50 - Epoch: [124][400/500] loss: 0.96851, MAE: 0.44356, time/step=1030ms, lr=4.54e-06
2024-03-20 23:19:38,351 - logger.py:50 - Epoch: [124][450/500] loss: 0.92490, MAE: 0.44521, time/step=1031ms, lr=4.54e-06
2024-03-20 23:20:29,656 - logger.py:50 - Epoch: [124][499/500] loss: 0.88378, MAE: 0.44370, time/step=1032ms, lr=4.54e-06
2024-03-20 23:21:27,176 - logger.py:50 - Epoch: [124] train loss: 0.88378, val loss: 0.50520, test loss: 0.47414, Time: 573.61s
2024-03-20 23:21:27,177 - logger.py:50 - Best -- epoch=123, train loss: 0.88720, val loss: 0.50134, test loss: 0.47194

2024-03-20 23:22:25,446 - logger.py:50 - Epoch: [124]EMA val MAE: 0.44453, EMA test MAE: 0.42956, Time: 631.88s
2024-03-20 23:22:25,446 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 23:22:26,646 - logger.py:50 - Epoch: [125][0/500] loss: 0.33422, MAE: 0.34585, time/step=1197ms, lr=4.28e-06
2024-03-20 23:23:19,739 - logger.py:50 - Epoch: [125][50/500] loss: 0.51219, MAE: 0.42242, time/step=1065ms, lr=4.28e-06
2024-03-20 23:24:12,708 - logger.py:50 - Epoch: [125][100/500] loss: 0.51364, MAE: 0.43507, time/step=1062ms, lr=4.28e-06
2024-03-20 23:25:04,669 - logger.py:50 - Epoch: [125][150/500] loss: 0.51836, MAE: 0.43662, time/step=1054ms, lr=4.28e-06
2024-03-20 23:25:56,770 - logger.py:50 - Epoch: [125][200/500] loss: 0.52619, MAE: 0.43625, time/step=1051ms, lr=4.28e-06
2024-03-20 23:26:49,372 - logger.py:50 - Epoch: [125][250/500] loss: 0.51007, MAE: 0.43789, time/step=1051ms, lr=4.28e-06
2024-03-20 23:27:42,001 - logger.py:50 - Epoch: [125][300/500] loss: 0.50785, MAE: 0.43886, time/step=1052ms, lr=4.28e-06
2024-03-20 23:28:34,835 - logger.py:50 - Epoch: [125][350/500] loss: 0.68781, MAE: 0.44297, time/step=1052ms, lr=4.28e-06
2024-03-20 23:29:27,653 - logger.py:50 - Epoch: [125][400/500] loss: 0.67186, MAE: 0.44068, time/step=1053ms, lr=4.28e-06
2024-03-20 23:30:19,731 - logger.py:50 - Epoch: [125][450/500] loss: 0.92167, MAE: 0.44444, time/step=1052ms, lr=4.28e-06
2024-03-20 23:31:11,134 - logger.py:50 - Epoch: [125][499/500] loss: 0.88646, MAE: 0.44365, time/step=1051ms, lr=4.28e-06
2024-03-20 23:32:09,984 - logger.py:50 - Epoch: [125] train loss: 0.88646, val loss: 0.50126, test loss: 0.47126, Time: 584.54s
2024-03-20 23:32:09,985 - logger.py:50 - Best -- epoch=125, train loss: 0.88646, val loss: 0.50126, test loss: 0.47126

2024-03-20 23:33:08,260 - logger.py:50 - Epoch: [125]EMA val MAE: 0.44449, EMA test MAE: 0.42952, Time: 642.81s
2024-03-20 23:33:08,260 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 23:33:09,454 - logger.py:50 - Epoch: [126][0/500] loss: 0.39683, MAE: 0.45288, time/step=1192ms, lr=4.03e-06
2024-03-20 23:34:01,730 - logger.py:50 - Epoch: [126][50/500] loss: 0.47392, MAE: 0.42945, time/step=1048ms, lr=4.03e-06
2024-03-20 23:34:53,367 - logger.py:50 - Epoch: [126][100/500] loss: 0.51305, MAE: 0.43039, time/step=1041ms, lr=4.03e-06
2024-03-20 23:35:46,754 - logger.py:50 - Epoch: [126][150/500] loss: 1.31036, MAE: 0.44759, time/step=1050ms, lr=4.03e-06
2024-03-20 23:36:38,443 - logger.py:50 - Epoch: [126][200/500] loss: 1.11976, MAE: 0.44563, time/step=1046ms, lr=4.03e-06
2024-03-20 23:37:30,918 - logger.py:50 - Epoch: [126][250/500] loss: 0.99904, MAE: 0.44264, time/step=1046ms, lr=4.03e-06
2024-03-20 23:38:24,249 - logger.py:50 - Epoch: [126][300/500] loss: 1.11592, MAE: 0.44555, time/step=1050ms, lr=4.03e-06
2024-03-20 23:39:15,680 - logger.py:50 - Epoch: [126][350/500] loss: 1.03363, MAE: 0.44442, time/step=1047ms, lr=4.03e-06
2024-03-20 23:40:09,048 - logger.py:50 - Epoch: [126][400/500] loss: 0.97010, MAE: 0.44462, time/step=1049ms, lr=4.03e-06
2024-03-20 23:41:01,970 - logger.py:50 - Epoch: [126][450/500] loss: 0.92695, MAE: 0.44352, time/step=1050ms, lr=4.03e-06
2024-03-20 23:41:53,405 - logger.py:50 - Epoch: [126][499/500] loss: 0.88486, MAE: 0.44369, time/step=1050ms, lr=4.03e-06
2024-03-20 23:42:52,172 - logger.py:50 - Epoch: [126] train loss: 0.88486, val loss: 0.50167, test loss: 0.47087, Time: 583.91s
2024-03-20 23:42:52,172 - logger.py:50 - Best -- epoch=125, train loss: 0.88646, val loss: 0.50126, test loss: 0.47126

2024-03-20 23:43:50,429 - logger.py:50 - Epoch: [126]EMA val MAE: 0.44446, EMA test MAE: 0.42950, Time: 642.17s
2024-03-20 23:43:50,429 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 23:43:51,572 - logger.py:50 - Epoch: [127][0/500] loss: 0.85907, MAE: 0.35454, time/step=1141ms, lr=3.79e-06
2024-03-20 23:44:43,455 - logger.py:50 - Epoch: [127][50/500] loss: 0.54460, MAE: 0.44741, time/step=1040ms, lr=3.79e-06
2024-03-20 23:45:35,444 - logger.py:50 - Epoch: [127][100/500] loss: 0.51391, MAE: 0.44934, time/step=1040ms, lr=3.79e-06
2024-03-20 23:46:27,640 - logger.py:50 - Epoch: [127][150/500] loss: 1.31450, MAE: 0.46028, time/step=1041ms, lr=3.79e-06
2024-03-20 23:47:19,346 - logger.py:50 - Epoch: [127][200/500] loss: 1.10445, MAE: 0.45235, time/step=1039ms, lr=3.79e-06
2024-03-20 23:48:11,080 - logger.py:50 - Epoch: [127][250/500] loss: 0.99086, MAE: 0.44632, time/step=1038ms, lr=3.79e-06
2024-03-20 23:49:04,365 - logger.py:50 - Epoch: [127][300/500] loss: 0.91129, MAE: 0.44665, time/step=1043ms, lr=3.79e-06
2024-03-20 23:49:55,748 - logger.py:50 - Epoch: [127][350/500] loss: 0.87116, MAE: 0.44495, time/step=1041ms, lr=3.79e-06
2024-03-20 23:50:46,795 - logger.py:50 - Epoch: [127][400/500] loss: 0.83128, MAE: 0.44314, time/step=1038ms, lr=3.79e-06
2024-03-20 23:51:39,444 - logger.py:50 - Epoch: [127][450/500] loss: 0.79389, MAE: 0.44206, time/step=1040ms, lr=3.79e-06
2024-03-20 23:52:31,543 - logger.py:50 - Epoch: [127][499/500] loss: 0.88770, MAE: 0.44376, time/step=1042ms, lr=3.79e-06
2024-03-20 23:53:29,552 - logger.py:50 - Epoch: [127] train loss: 0.88770, val loss: 0.50282, test loss: 0.47133, Time: 579.12s
2024-03-20 23:53:29,552 - logger.py:50 - Best -- epoch=125, train loss: 0.88646, val loss: 0.50126, test loss: 0.47126

2024-03-20 23:54:27,221 - logger.py:50 - Epoch: [127]EMA val MAE: 0.44446, EMA test MAE: 0.42949, Time: 636.79s
2024-03-20 23:54:27,221 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-20 23:54:28,459 - logger.py:50 - Epoch: [128][0/500] loss: 0.39619, MAE: 0.53733, time/step=1236ms, lr=3.56e-06
2024-03-20 23:55:20,166 - logger.py:50 - Epoch: [128][50/500] loss: 1.75261, MAE: 0.46092, time/step=1038ms, lr=3.56e-06
2024-03-20 23:56:12,493 - logger.py:50 - Epoch: [128][100/500] loss: 1.17421, MAE: 0.44797, time/step=1042ms, lr=3.56e-06
2024-03-20 23:57:03,676 - logger.py:50 - Epoch: [128][150/500] loss: 0.96144, MAE: 0.45190, time/step=1036ms, lr=3.56e-06
2024-03-20 23:57:56,226 - logger.py:50 - Epoch: [128][200/500] loss: 1.45040, MAE: 0.45615, time/step=1040ms, lr=3.56e-06
2024-03-20 23:58:48,888 - logger.py:50 - Epoch: [128][250/500] loss: 1.25176, MAE: 0.44973, time/step=1042ms, lr=3.56e-06
2024-03-20 23:59:40,385 - logger.py:50 - Epoch: [128][300/500] loss: 1.12458, MAE: 0.44776, time/step=1040ms, lr=3.56e-06
2024-03-21 00:00:33,041 - logger.py:50 - Epoch: [128][350/500] loss: 1.03494, MAE: 0.44873, time/step=1042ms, lr=3.56e-06
2024-03-21 00:01:25,191 - logger.py:50 - Epoch: [128][400/500] loss: 0.98436, MAE: 0.44616, time/step=1042ms, lr=3.56e-06
2024-03-21 00:02:17,446 - logger.py:50 - Epoch: [128][450/500] loss: 0.92791, MAE: 0.44452, time/step=1043ms, lr=3.56e-06
2024-03-21 00:03:07,957 - logger.py:50 - Epoch: [128][499/500] loss: 0.88662, MAE: 0.44366, time/step=1041ms, lr=3.56e-06
2024-03-21 00:04:06,138 - logger.py:50 - Epoch: [128] train loss: 0.88662, val loss: 0.50065, test loss: 0.47054, Time: 578.92s
2024-03-21 00:04:06,138 - logger.py:50 - Best -- epoch=128, train loss: 0.88662, val loss: 0.50065, test loss: 0.47054

2024-03-21 00:05:03,592 - logger.py:50 - Epoch: [128]EMA val MAE: 0.44443, EMA test MAE: 0.42946, Time: 636.37s
2024-03-21 00:05:03,592 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 00:05:04,787 - logger.py:50 - Epoch: [129][0/500] loss: 0.60919, MAE: 0.52176, time/step=1193ms, lr=3.33e-06
2024-03-21 00:05:57,471 - logger.py:50 - Epoch: [129][50/500] loss: 0.67623, MAE: 0.43825, time/step=1056ms, lr=3.33e-06
2024-03-21 00:06:49,561 - logger.py:50 - Epoch: [129][100/500] loss: 0.56778, MAE: 0.43342, time/step=1049ms, lr=3.33e-06
2024-03-21 00:07:42,047 - logger.py:50 - Epoch: [129][150/500] loss: 0.54376, MAE: 0.43744, time/step=1049ms, lr=3.33e-06
2024-03-21 00:08:34,220 - logger.py:50 - Epoch: [129][200/500] loss: 0.54272, MAE: 0.43735, time/step=1048ms, lr=3.33e-06
2024-03-21 00:09:26,060 - logger.py:50 - Epoch: [129][250/500] loss: 0.53875, MAE: 0.43795, time/step=1046ms, lr=3.33e-06
2024-03-21 00:10:17,127 - logger.py:50 - Epoch: [129][300/500] loss: 0.74532, MAE: 0.44335, time/step=1042ms, lr=3.33e-06
2024-03-21 00:11:09,039 - logger.py:50 - Epoch: [129][350/500] loss: 0.70961, MAE: 0.44291, time/step=1041ms, lr=3.33e-06
2024-03-21 00:12:00,370 - logger.py:50 - Epoch: [129][400/500] loss: 0.98075, MAE: 0.44619, time/step=1039ms, lr=3.33e-06
2024-03-21 00:12:52,646 - logger.py:50 - Epoch: [129][450/500] loss: 0.93022, MAE: 0.44463, time/step=1040ms, lr=3.33e-06
2024-03-21 00:13:43,859 - logger.py:50 - Epoch: [129][499/500] loss: 0.88280, MAE: 0.44369, time/step=1041ms, lr=3.33e-06
2024-03-21 00:14:41,842 - logger.py:50 - Epoch: [129] train loss: 0.88280, val loss: 0.50081, test loss: 0.47047, Time: 578.25s
2024-03-21 00:14:41,843 - logger.py:50 - Best -- epoch=128, train loss: 0.88662, val loss: 0.50065, test loss: 0.47054

2024-03-21 00:15:39,500 - logger.py:50 - Epoch: [129]EMA val MAE: 0.44442, EMA test MAE: 0.42945, Time: 635.91s
2024-03-21 00:15:39,500 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 00:15:40,737 - logger.py:50 - Epoch: [130][0/500] loss: 0.51323, MAE: 0.43159, time/step=1235ms, lr=3.12e-06
2024-03-21 00:16:32,415 - logger.py:50 - Epoch: [130][50/500] loss: 0.46724, MAE: 0.44105, time/step=1038ms, lr=3.12e-06
2024-03-21 00:17:24,026 - logger.py:50 - Epoch: [130][100/500] loss: 0.52585, MAE: 0.44389, time/step=1035ms, lr=3.12e-06
2024-03-21 00:18:16,391 - logger.py:50 - Epoch: [130][150/500] loss: 0.49851, MAE: 0.44108, time/step=1039ms, lr=3.12e-06
2024-03-21 00:19:07,842 - logger.py:50 - Epoch: [130][200/500] loss: 0.80089, MAE: 0.44809, time/step=1037ms, lr=3.12e-06
2024-03-21 00:20:00,544 - logger.py:50 - Epoch: [130][250/500] loss: 0.75361, MAE: 0.44805, time/step=1040ms, lr=3.12e-06
2024-03-21 00:20:52,718 - logger.py:50 - Epoch: [130][300/500] loss: 0.71784, MAE: 0.44268, time/step=1041ms, lr=3.12e-06
2024-03-21 00:21:44,934 - logger.py:50 - Epoch: [130][350/500] loss: 0.70644, MAE: 0.44244, time/step=1041ms, lr=3.12e-06
2024-03-21 00:22:36,149 - logger.py:50 - Epoch: [130][400/500] loss: 0.98141, MAE: 0.44587, time/step=1039ms, lr=3.12e-06
2024-03-21 00:23:29,090 - logger.py:50 - Epoch: [130][450/500] loss: 0.92399, MAE: 0.44547, time/step=1041ms, lr=3.12e-06
2024-03-21 00:24:19,716 - logger.py:50 - Epoch: [130][499/500] loss: 0.88461, MAE: 0.44367, time/step=1040ms, lr=3.12e-06
2024-03-21 00:25:17,698 - logger.py:50 - Epoch: [130] train loss: 0.88461, val loss: 0.50082, test loss: 0.46987, Time: 578.20s
2024-03-21 00:25:17,698 - logger.py:50 - Best -- epoch=128, train loss: 0.88662, val loss: 0.50065, test loss: 0.47054

2024-03-21 00:26:15,153 - logger.py:50 - Epoch: [130]EMA val MAE: 0.44440, EMA test MAE: 0.42943, Time: 635.65s
2024-03-21 00:26:15,153 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 00:26:15,793 - logger.py:50 - Epoch: [131][0/500] loss: 0.55330, MAE: 0.41510, time/step=637ms, lr=2.91e-06
2024-03-21 00:27:06,885 - logger.py:50 - Epoch: [131][50/500] loss: 0.53868, MAE: 0.43467, time/step=1014ms, lr=2.91e-06
2024-03-21 00:27:58,893 - logger.py:50 - Epoch: [131][100/500] loss: 0.54615, MAE: 0.44089, time/step=1027ms, lr=2.91e-06
2024-03-21 00:28:50,650 - logger.py:50 - Epoch: [131][150/500] loss: 0.52732, MAE: 0.43830, time/step=1030ms, lr=2.91e-06
2024-03-21 00:29:42,026 - logger.py:50 - Epoch: [131][200/500] loss: 0.53030, MAE: 0.44318, time/step=1029ms, lr=2.91e-06
2024-03-21 00:30:32,886 - logger.py:50 - Epoch: [131][250/500] loss: 0.75770, MAE: 0.44220, time/step=1027ms, lr=2.91e-06
2024-03-21 00:31:26,163 - logger.py:50 - Epoch: [131][300/500] loss: 0.71369, MAE: 0.44504, time/step=1033ms, lr=2.91e-06
2024-03-21 00:32:16,436 - logger.py:50 - Epoch: [131][350/500] loss: 0.68237, MAE: 0.44282, time/step=1029ms, lr=2.91e-06
2024-03-21 00:33:07,558 - logger.py:50 - Epoch: [131][400/500] loss: 0.65800, MAE: 0.44230, time/step=1028ms, lr=2.91e-06
2024-03-21 00:33:58,898 - logger.py:50 - Epoch: [131][450/500] loss: 0.65853, MAE: 0.44104, time/step=1028ms, lr=2.91e-06
2024-03-21 00:34:48,300 - logger.py:50 - Epoch: [131][499/500] loss: 0.88589, MAE: 0.44368, time/step=1026ms, lr=2.91e-06
2024-03-21 00:35:45,855 - logger.py:50 - Epoch: [131] train loss: 0.88589, val loss: 0.50088, test loss: 0.47121, Time: 570.70s
2024-03-21 00:35:45,855 - logger.py:50 - Best -- epoch=128, train loss: 0.88662, val loss: 0.50065, test loss: 0.47054

2024-03-21 00:36:42,585 - logger.py:50 - Epoch: [131]EMA val MAE: 0.44439, EMA test MAE: 0.42941, Time: 627.43s
2024-03-21 00:36:42,585 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 00:36:43,704 - logger.py:50 - Epoch: [132][0/500] loss: 0.29542, MAE: 0.41696, time/step=1117ms, lr=2.72e-06
2024-03-21 00:37:35,445 - logger.py:50 - Epoch: [132][50/500] loss: 0.58209, MAE: 0.43798, time/step=1036ms, lr=2.72e-06
2024-03-21 00:38:26,197 - logger.py:50 - Epoch: [132][100/500] loss: 2.34089, MAE: 0.46941, time/step=1026ms, lr=2.72e-06
2024-03-21 00:39:17,572 - logger.py:50 - Epoch: [132][150/500] loss: 1.72852, MAE: 0.45640, time/step=1026ms, lr=2.72e-06
2024-03-21 00:40:08,193 - logger.py:50 - Epoch: [132][200/500] loss: 1.42670, MAE: 0.45166, time/step=1023ms, lr=2.72e-06
2024-03-21 00:40:59,873 - logger.py:50 - Epoch: [132][250/500] loss: 1.23413, MAE: 0.44919, time/step=1025ms, lr=2.72e-06
2024-03-21 00:41:51,853 - logger.py:50 - Epoch: [132][300/500] loss: 1.11196, MAE: 0.44639, time/step=1027ms, lr=2.72e-06
2024-03-21 00:42:43,377 - logger.py:50 - Epoch: [132][350/500] loss: 1.02640, MAE: 0.44483, time/step=1028ms, lr=2.72e-06
2024-03-21 00:43:34,193 - logger.py:50 - Epoch: [132][400/500] loss: 0.97348, MAE: 0.44416, time/step=1026ms, lr=2.72e-06
2024-03-21 00:44:25,556 - logger.py:50 - Epoch: [132][450/500] loss: 0.92092, MAE: 0.44239, time/step=1027ms, lr=2.72e-06
2024-03-21 00:45:16,040 - logger.py:50 - Epoch: [132][499/500] loss: 0.88133, MAE: 0.44370, time/step=1027ms, lr=2.72e-06
2024-03-21 00:46:13,165 - logger.py:50 - Epoch: [132] train loss: 0.88133, val loss: 0.50096, test loss: 0.47016, Time: 570.58s
2024-03-21 00:46:13,165 - logger.py:50 - Best -- epoch=128, train loss: 0.88662, val loss: 0.50065, test loss: 0.47054

2024-03-21 00:47:09,761 - logger.py:50 - Epoch: [132]EMA val MAE: 0.44437, EMA test MAE: 0.42940, Time: 627.18s
2024-03-21 00:47:09,761 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 00:47:11,020 - logger.py:50 - Epoch: [133][0/500] loss: 0.22760, MAE: 0.37815, time/step=1257ms, lr=2.54e-06
2024-03-21 00:48:02,128 - logger.py:50 - Epoch: [133][50/500] loss: 2.85187, MAE: 0.47794, time/step=1027ms, lr=2.54e-06
2024-03-21 00:48:53,842 - logger.py:50 - Epoch: [133][100/500] loss: 1.71066, MAE: 0.46320, time/step=1030ms, lr=2.54e-06
2024-03-21 00:49:44,479 - logger.py:50 - Epoch: [133][150/500] loss: 1.75343, MAE: 0.46518, time/step=1025ms, lr=2.54e-06
2024-03-21 00:50:36,165 - logger.py:50 - Epoch: [133][200/500] loss: 1.42772, MAE: 0.45851, time/step=1027ms, lr=2.54e-06
2024-03-21 00:51:27,529 - logger.py:50 - Epoch: [133][250/500] loss: 1.23572, MAE: 0.44872, time/step=1027ms, lr=2.54e-06
2024-03-21 00:52:18,484 - logger.py:50 - Epoch: [133][300/500] loss: 1.11339, MAE: 0.44796, time/step=1026ms, lr=2.54e-06
2024-03-21 00:53:10,180 - logger.py:50 - Epoch: [133][350/500] loss: 1.02508, MAE: 0.44532, time/step=1027ms, lr=2.54e-06
2024-03-21 00:54:02,104 - logger.py:50 - Epoch: [133][400/500] loss: 0.95883, MAE: 0.44389, time/step=1028ms, lr=2.54e-06
2024-03-21 00:54:53,706 - logger.py:50 - Epoch: [133][450/500] loss: 0.92631, MAE: 0.44509, time/step=1029ms, lr=2.54e-06
2024-03-21 00:55:43,363 - logger.py:50 - Epoch: [133][499/500] loss: 0.88337, MAE: 0.44372, time/step=1027ms, lr=2.54e-06
2024-03-21 00:56:40,026 - logger.py:50 - Epoch: [133] train loss: 0.88337, val loss: 0.50075, test loss: 0.47002, Time: 570.26s
2024-03-21 00:56:40,026 - logger.py:50 - Best -- epoch=128, train loss: 0.88662, val loss: 0.50065, test loss: 0.47054

2024-03-21 00:57:36,672 - logger.py:50 - Epoch: [133]EMA val MAE: 0.44438, EMA test MAE: 0.42941, Time: 626.91s
2024-03-21 00:57:36,672 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 00:57:37,856 - logger.py:50 - Epoch: [134][0/500] loss: 0.25686, MAE: 0.32276, time/step=1182ms, lr=2.36e-06
2024-03-21 00:58:28,803 - logger.py:50 - Epoch: [134][50/500] loss: 0.57186, MAE: 0.43934, time/step=1022ms, lr=2.36e-06
2024-03-21 00:59:19,715 - logger.py:50 - Epoch: [134][100/500] loss: 0.54033, MAE: 0.43677, time/step=1020ms, lr=2.36e-06
2024-03-21 01:00:11,584 - logger.py:50 - Epoch: [134][150/500] loss: 0.51548, MAE: 0.43949, time/step=1026ms, lr=2.36e-06
2024-03-21 01:01:03,192 - logger.py:50 - Epoch: [134][200/500] loss: 0.51569, MAE: 0.44066, time/step=1027ms, lr=2.36e-06
2024-03-21 01:01:53,806 - logger.py:50 - Epoch: [134][250/500] loss: 0.51507, MAE: 0.43926, time/step=1024ms, lr=2.36e-06
2024-03-21 01:02:45,208 - logger.py:50 - Epoch: [134][300/500] loss: 0.52767, MAE: 0.43795, time/step=1025ms, lr=2.36e-06
2024-03-21 01:03:37,010 - logger.py:50 - Epoch: [134][350/500] loss: 0.51983, MAE: 0.43731, time/step=1027ms, lr=2.36e-06
2024-03-21 01:04:28,615 - logger.py:50 - Epoch: [134][400/500] loss: 0.66560, MAE: 0.44002, time/step=1027ms, lr=2.36e-06
2024-03-21 01:05:19,469 - logger.py:50 - Epoch: [134][450/500] loss: 0.65268, MAE: 0.43893, time/step=1026ms, lr=2.36e-06
2024-03-21 01:06:09,687 - logger.py:50 - Epoch: [134][499/500] loss: 0.88377, MAE: 0.44365, time/step=1026ms, lr=2.36e-06
2024-03-21 01:07:07,232 - logger.py:50 - Epoch: [134] train loss: 0.88377, val loss: 0.50070, test loss: 0.46991, Time: 570.56s
2024-03-21 01:07:07,232 - logger.py:50 - Best -- epoch=128, train loss: 0.88662, val loss: 0.50065, test loss: 0.47054

2024-03-21 01:08:03,957 - logger.py:50 - Epoch: [134]EMA val MAE: 0.44436, EMA test MAE: 0.42939, Time: 627.28s
2024-03-21 01:08:03,957 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 01:08:05,164 - logger.py:50 - Epoch: [135][0/500] loss: 0.35793, MAE: 0.42662, time/step=1205ms, lr=2.20e-06
2024-03-21 01:08:56,179 - logger.py:50 - Epoch: [135][50/500] loss: 0.55687, MAE: 0.44261, time/step=1024ms, lr=2.20e-06
2024-03-21 01:09:47,076 - logger.py:50 - Epoch: [135][100/500] loss: 0.52738, MAE: 0.43447, time/step=1021ms, lr=2.20e-06
2024-03-21 01:10:39,194 - logger.py:50 - Epoch: [135][150/500] loss: 0.51784, MAE: 0.43686, time/step=1028ms, lr=2.20e-06
2024-03-21 01:11:29,929 - logger.py:50 - Epoch: [135][200/500] loss: 0.51872, MAE: 0.43951, time/step=1025ms, lr=2.20e-06
2024-03-21 01:12:22,053 - logger.py:50 - Epoch: [135][250/500] loss: 0.75878, MAE: 0.44483, time/step=1028ms, lr=2.20e-06
2024-03-21 01:13:13,091 - logger.py:50 - Epoch: [135][300/500] loss: 0.72378, MAE: 0.44230, time/step=1027ms, lr=2.20e-06
2024-03-21 01:14:04,152 - logger.py:50 - Epoch: [135][350/500] loss: 0.69679, MAE: 0.44183, time/step=1026ms, lr=2.20e-06
2024-03-21 01:14:55,819 - logger.py:50 - Epoch: [135][400/500] loss: 0.68264, MAE: 0.43908, time/step=1027ms, lr=2.20e-06
2024-03-21 01:15:47,024 - logger.py:50 - Epoch: [135][450/500] loss: 0.92580, MAE: 0.44346, time/step=1027ms, lr=2.20e-06
2024-03-21 01:16:37,973 - logger.py:50 - Epoch: [135][499/500] loss: 0.88292, MAE: 0.44368, time/step=1028ms, lr=2.20e-06
2024-03-21 01:17:36,280 - logger.py:50 - Epoch: [135] train loss: 0.88292, val loss: 0.50061, test loss: 0.47029, Time: 572.32s
2024-03-21 01:17:36,280 - logger.py:50 - Best -- epoch=135, train loss: 0.88292, val loss: 0.50061, test loss: 0.47029

2024-03-21 01:18:34,064 - logger.py:50 - Epoch: [135]EMA val MAE: 0.44436, EMA test MAE: 0.42938, Time: 630.11s
2024-03-21 01:18:34,065 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 01:18:34,868 - logger.py:50 - Epoch: [136][0/500] loss: 0.26437, MAE: 0.49394, time/step=801ms, lr=2.05e-06
2024-03-21 01:19:28,073 - logger.py:50 - Epoch: [136][50/500] loss: 0.49967, MAE: 0.44328, time/step=1059ms, lr=2.05e-06
2024-03-21 01:20:20,141 - logger.py:50 - Epoch: [136][100/500] loss: 0.48240, MAE: 0.44131, time/step=1050ms, lr=2.05e-06
2024-03-21 01:21:12,121 - logger.py:50 - Epoch: [136][150/500] loss: 0.50511, MAE: 0.43953, time/step=1047ms, lr=2.05e-06
2024-03-21 01:22:04,877 - logger.py:50 - Epoch: [136][200/500] loss: 0.49903, MAE: 0.44093, time/step=1049ms, lr=2.05e-06
2024-03-21 01:22:56,056 - logger.py:50 - Epoch: [136][250/500] loss: 1.00278, MAE: 0.44849, time/step=1044ms, lr=2.05e-06
2024-03-21 01:23:48,667 - logger.py:50 - Epoch: [136][300/500] loss: 0.92143, MAE: 0.44658, time/step=1045ms, lr=2.05e-06
2024-03-21 01:24:40,564 - logger.py:50 - Epoch: [136][350/500] loss: 1.04176, MAE: 0.44996, time/step=1044ms, lr=2.05e-06
2024-03-21 01:25:32,716 - logger.py:50 - Epoch: [136][400/500] loss: 0.97448, MAE: 0.44832, time/step=1044ms, lr=2.05e-06
2024-03-21 01:26:24,451 - logger.py:50 - Epoch: [136][450/500] loss: 0.92417, MAE: 0.44493, time/step=1043ms, lr=2.05e-06
2024-03-21 01:27:15,427 - logger.py:50 - Epoch: [136][499/500] loss: 0.88224, MAE: 0.44372, time/step=1043ms, lr=2.05e-06
2024-03-21 01:28:13,590 - logger.py:50 - Epoch: [136] train loss: 0.88224, val loss: 0.50096, test loss: 0.47046, Time: 579.53s
2024-03-21 01:28:13,590 - logger.py:50 - Best -- epoch=135, train loss: 0.88292, val loss: 0.50061, test loss: 0.47029

2024-03-21 01:29:11,356 - logger.py:50 - Epoch: [136]EMA val MAE: 0.44435, EMA test MAE: 0.42937, Time: 637.29s
2024-03-21 01:29:11,356 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 01:29:12,527 - logger.py:50 - Epoch: [137][0/500] loss: 0.22225, MAE: 0.40819, time/step=1169ms, lr=1.90e-06
2024-03-21 01:30:04,247 - logger.py:50 - Epoch: [137][50/500] loss: 0.51234, MAE: 0.42767, time/step=1037ms, lr=1.90e-06
2024-03-21 01:30:56,448 - logger.py:50 - Epoch: [137][100/500] loss: 0.47797, MAE: 0.43634, time/step=1040ms, lr=1.90e-06
2024-03-21 01:31:48,008 - logger.py:50 - Epoch: [137][150/500] loss: 0.50744, MAE: 0.43335, time/step=1037ms, lr=1.90e-06
2024-03-21 01:32:40,790 - logger.py:50 - Epoch: [137][200/500] loss: 0.49970, MAE: 0.43898, time/step=1042ms, lr=1.90e-06
2024-03-21 01:33:32,537 - logger.py:50 - Epoch: [137][250/500] loss: 0.49689, MAE: 0.43832, time/step=1041ms, lr=1.90e-06
2024-03-21 01:34:26,175 - logger.py:50 - Epoch: [137][300/500] loss: 0.69533, MAE: 0.44188, time/step=1046ms, lr=1.90e-06
2024-03-21 01:35:17,802 - logger.py:50 - Epoch: [137][350/500] loss: 0.66733, MAE: 0.44000, time/step=1044ms, lr=1.90e-06
2024-03-21 01:36:09,595 - logger.py:50 - Epoch: [137][400/500] loss: 0.64280, MAE: 0.43954, time/step=1043ms, lr=1.90e-06
2024-03-21 01:37:02,064 - logger.py:50 - Epoch: [137][450/500] loss: 0.89927, MAE: 0.44224, time/step=1044ms, lr=1.90e-06
2024-03-21 01:37:53,057 - logger.py:50 - Epoch: [137][499/500] loss: 0.88270, MAE: 0.44365, time/step=1043ms, lr=1.90e-06
2024-03-21 01:38:50,937 - logger.py:50 - Epoch: [137] train loss: 0.88270, val loss: 0.50094, test loss: 0.47039, Time: 579.58s
2024-03-21 01:38:50,938 - logger.py:50 - Best -- epoch=135, train loss: 0.88292, val loss: 0.50061, test loss: 0.47029

2024-03-21 01:39:48,643 - logger.py:50 - Epoch: [137]EMA val MAE: 0.44433, EMA test MAE: 0.42935, Time: 637.29s
2024-03-21 01:39:48,643 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 01:39:49,928 - logger.py:50 - Epoch: [138][0/500] loss: 0.42323, MAE: 0.51349, time/step=1283ms, lr=1.77e-06
2024-03-21 01:40:42,433 - logger.py:50 - Epoch: [138][50/500] loss: 0.52514, MAE: 0.44424, time/step=1055ms, lr=1.77e-06
2024-03-21 01:41:33,855 - logger.py:50 - Epoch: [138][100/500] loss: 1.13021, MAE: 0.45593, time/step=1042ms, lr=1.77e-06
2024-03-21 01:42:26,999 - logger.py:50 - Epoch: [138][150/500] loss: 0.94200, MAE: 0.45402, time/step=1049ms, lr=1.77e-06
2024-03-21 01:43:18,437 - logger.py:50 - Epoch: [138][200/500] loss: 0.82552, MAE: 0.44661, time/step=1044ms, lr=1.77e-06
2024-03-21 01:44:10,460 - logger.py:50 - Epoch: [138][250/500] loss: 0.75419, MAE: 0.44128, time/step=1043ms, lr=1.77e-06
2024-03-21 01:45:02,087 - logger.py:50 - Epoch: [138][300/500] loss: 0.70041, MAE: 0.44050, time/step=1041ms, lr=1.77e-06
2024-03-21 01:45:53,544 - logger.py:50 - Epoch: [138][350/500] loss: 0.68525, MAE: 0.43958, time/step=1040ms, lr=1.77e-06
2024-03-21 01:46:44,638 - logger.py:50 - Epoch: [138][400/500] loss: 0.65826, MAE: 0.43918, time/step=1037ms, lr=1.77e-06
2024-03-21 01:47:36,146 - logger.py:50 - Epoch: [138][450/500] loss: 0.90929, MAE: 0.44351, time/step=1037ms, lr=1.77e-06
2024-03-21 01:48:27,115 - logger.py:50 - Epoch: [138][499/500] loss: 0.88277, MAE: 0.44372, time/step=1037ms, lr=1.77e-06
2024-03-21 01:49:24,980 - logger.py:50 - Epoch: [138] train loss: 0.88277, val loss: 0.50039, test loss: 0.46963, Time: 576.34s
2024-03-21 01:49:24,980 - logger.py:50 - Best -- epoch=138, train loss: 0.88277, val loss: 0.50039, test loss: 0.46963

2024-03-21 01:50:22,305 - logger.py:50 - Epoch: [138]EMA val MAE: 0.44433, EMA test MAE: 0.42935, Time: 633.66s
2024-03-21 01:50:22,305 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 01:50:23,467 - logger.py:50 - Epoch: [139][0/500] loss: 0.52341, MAE: 0.43892, time/step=1160ms, lr=1.65e-06
2024-03-21 01:51:15,761 - logger.py:50 - Epoch: [139][50/500] loss: 1.77387, MAE: 0.44979, time/step=1048ms, lr=1.65e-06
2024-03-21 01:52:06,903 - logger.py:50 - Epoch: [139][100/500] loss: 1.14197, MAE: 0.43591, time/step=1036ms, lr=1.65e-06
2024-03-21 01:52:58,536 - logger.py:50 - Epoch: [139][150/500] loss: 0.93062, MAE: 0.43812, time/step=1035ms, lr=1.65e-06
2024-03-21 01:53:50,100 - logger.py:50 - Epoch: [139][200/500] loss: 0.82929, MAE: 0.43796, time/step=1034ms, lr=1.65e-06
2024-03-21 01:54:42,193 - logger.py:50 - Epoch: [139][250/500] loss: 0.76422, MAE: 0.43888, time/step=1035ms, lr=1.65e-06
2024-03-21 01:55:33,332 - logger.py:50 - Epoch: [139][300/500] loss: 0.71201, MAE: 0.43675, time/step=1033ms, lr=1.65e-06
2024-03-21 01:56:25,026 - logger.py:50 - Epoch: [139][350/500] loss: 0.69087, MAE: 0.43880, time/step=1033ms, lr=1.65e-06
2024-03-21 01:57:17,716 - logger.py:50 - Epoch: [139][400/500] loss: 0.66351, MAE: 0.43774, time/step=1036ms, lr=1.65e-06
2024-03-21 01:58:09,990 - logger.py:50 - Epoch: [139][450/500] loss: 0.64796, MAE: 0.43765, time/step=1037ms, lr=1.65e-06
2024-03-21 01:59:00,471 - logger.py:50 - Epoch: [139][499/500] loss: 0.88035, MAE: 0.44369, time/step=1036ms, lr=1.65e-06
2024-03-21 01:59:58,714 - logger.py:50 - Epoch: [139] train loss: 0.88035, val loss: 0.50018, test loss: 0.46958, Time: 576.41s
2024-03-21 01:59:58,714 - logger.py:50 - Best -- epoch=139, train loss: 0.88035, val loss: 0.50018, test loss: 0.46958

2024-03-21 02:00:55,850 - logger.py:50 - Epoch: [139]EMA val MAE: 0.44433, EMA test MAE: 0.42935, Time: 633.54s
2024-03-21 02:00:55,850 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 02:00:57,160 - logger.py:50 - Epoch: [140][0/500] loss: 0.38426, MAE: 0.36959, time/step=1308ms, lr=1.54e-06
2024-03-21 02:01:48,334 - logger.py:50 - Epoch: [140][50/500] loss: 0.49519, MAE: 0.43046, time/step=1029ms, lr=1.54e-06
2024-03-21 02:02:39,994 - logger.py:50 - Epoch: [140][100/500] loss: 0.49116, MAE: 0.43304, time/step=1031ms, lr=1.54e-06
2024-03-21 02:03:32,260 - logger.py:50 - Epoch: [140][150/500] loss: 0.53404, MAE: 0.43179, time/step=1036ms, lr=1.54e-06
2024-03-21 02:04:23,054 - logger.py:50 - Epoch: [140][200/500] loss: 0.53023, MAE: 0.43094, time/step=1031ms, lr=1.54e-06
2024-03-21 02:05:15,215 - logger.py:50 - Epoch: [140][250/500] loss: 0.51817, MAE: 0.43494, time/step=1033ms, lr=1.54e-06
2024-03-21 02:06:06,985 - logger.py:50 - Epoch: [140][300/500] loss: 0.91894, MAE: 0.44217, time/step=1034ms, lr=1.54e-06
2024-03-21 02:06:57,946 - logger.py:50 - Epoch: [140][350/500] loss: 1.04228, MAE: 0.44352, time/step=1032ms, lr=1.54e-06
2024-03-21 02:07:49,722 - logger.py:50 - Epoch: [140][400/500] loss: 0.97457, MAE: 0.44365, time/step=1032ms, lr=1.54e-06
2024-03-21 02:08:41,593 - logger.py:50 - Epoch: [140][450/500] loss: 0.92882, MAE: 0.44404, time/step=1033ms, lr=1.54e-06
2024-03-21 02:09:32,536 - logger.py:50 - Epoch: [140][499/500] loss: 0.88355, MAE: 0.44368, time/step=1033ms, lr=1.54e-06
2024-03-21 02:10:30,329 - logger.py:50 - Epoch: [140] train loss: 0.88355, val loss: 0.50026, test loss: 0.46959, Time: 574.48s
2024-03-21 02:10:30,329 - logger.py:50 - Best -- epoch=139, train loss: 0.88035, val loss: 0.50018, test loss: 0.46958

2024-03-21 02:11:27,430 - logger.py:50 - Epoch: [140]EMA val MAE: 0.44426, EMA test MAE: 0.42928, Time: 631.58s
2024-03-21 02:11:27,430 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 02:11:28,673 - logger.py:50 - Epoch: [141][0/500] loss: 0.28077, MAE: 0.44154, time/step=1240ms, lr=1.43e-06
2024-03-21 02:12:20,732 - logger.py:50 - Epoch: [141][50/500] loss: 1.73085, MAE: 0.45571, time/step=1045ms, lr=1.43e-06
2024-03-21 02:13:12,649 - logger.py:50 - Epoch: [141][100/500] loss: 1.11357, MAE: 0.44675, time/step=1042ms, lr=1.43e-06
2024-03-21 02:14:05,031 - logger.py:50 - Epoch: [141][150/500] loss: 0.91107, MAE: 0.44567, time/step=1044ms, lr=1.43e-06
2024-03-21 02:14:56,430 - logger.py:50 - Epoch: [141][200/500] loss: 0.81634, MAE: 0.44022, time/step=1040ms, lr=1.43e-06
2024-03-21 02:15:48,347 - logger.py:50 - Epoch: [141][250/500] loss: 1.22302, MAE: 0.44425, time/step=1040ms, lr=1.43e-06
2024-03-21 02:16:41,277 - logger.py:50 - Epoch: [141][300/500] loss: 1.11637, MAE: 0.44431, time/step=1043ms, lr=1.43e-06
2024-03-21 02:17:33,799 - logger.py:50 - Epoch: [141][350/500] loss: 1.02406, MAE: 0.44212, time/step=1044ms, lr=1.43e-06
2024-03-21 02:18:26,954 - logger.py:50 - Epoch: [141][400/500] loss: 0.96022, MAE: 0.44185, time/step=1046ms, lr=1.43e-06
2024-03-21 02:19:19,395 - logger.py:50 - Epoch: [141][450/500] loss: 0.91595, MAE: 0.44249, time/step=1046ms, lr=1.43e-06
2024-03-21 02:20:09,418 - logger.py:50 - Epoch: [141][499/500] loss: 0.88078, MAE: 0.44374, time/step=1044ms, lr=1.43e-06
2024-03-21 02:21:07,672 - logger.py:50 - Epoch: [141] train loss: 0.88078, val loss: 0.50090, test loss: 0.47033, Time: 580.24s
2024-03-21 02:21:07,673 - logger.py:50 - Best -- epoch=139, train loss: 0.88035, val loss: 0.50018, test loss: 0.46958

2024-03-21 02:22:05,522 - logger.py:50 - Epoch: [141]EMA val MAE: 0.44423, EMA test MAE: 0.42925, Time: 638.09s
2024-03-21 02:22:05,522 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 02:22:06,867 - logger.py:50 - Epoch: [142][0/500] loss: 0.35875, MAE: 0.48489, time/step=1342ms, lr=1.34e-06
2024-03-21 02:22:59,479 - logger.py:50 - Epoch: [142][50/500] loss: 0.52522, MAE: 0.44153, time/step=1058ms, lr=1.34e-06
2024-03-21 02:23:52,082 - logger.py:50 - Epoch: [142][100/500] loss: 1.69902, MAE: 0.45917, time/step=1055ms, lr=1.34e-06
2024-03-21 02:24:44,235 - logger.py:50 - Epoch: [142][150/500] loss: 1.31905, MAE: 0.45077, time/step=1051ms, lr=1.34e-06
2024-03-21 02:25:36,486 - logger.py:50 - Epoch: [142][200/500] loss: 1.11914, MAE: 0.44836, time/step=1050ms, lr=1.34e-06
2024-03-21 02:26:29,297 - logger.py:50 - Epoch: [142][250/500] loss: 0.99075, MAE: 0.44658, time/step=1051ms, lr=1.34e-06
2024-03-21 02:27:20,733 - logger.py:50 - Epoch: [142][300/500] loss: 1.12170, MAE: 0.44916, time/step=1047ms, lr=1.34e-06
2024-03-21 02:28:13,287 - logger.py:50 - Epoch: [142][350/500] loss: 1.04323, MAE: 0.44980, time/step=1048ms, lr=1.34e-06
2024-03-21 02:29:04,939 - logger.py:50 - Epoch: [142][400/500] loss: 0.97274, MAE: 0.44722, time/step=1046ms, lr=1.34e-06
2024-03-21 02:29:56,399 - logger.py:50 - Epoch: [142][450/500] loss: 0.92419, MAE: 0.44450, time/step=1044ms, lr=1.34e-06
2024-03-21 02:30:47,031 - logger.py:50 - Epoch: [142][499/500] loss: 0.88196, MAE: 0.44363, time/step=1043ms, lr=1.34e-06
2024-03-21 02:31:45,472 - logger.py:50 - Epoch: [142] train loss: 0.88196, val loss: 0.49995, test loss: 0.46967, Time: 579.95s
2024-03-21 02:31:45,472 - logger.py:50 - Best -- epoch=142, train loss: 0.88196, val loss: 0.49995, test loss: 0.46967

2024-03-21 02:32:43,263 - logger.py:50 - Epoch: [142]EMA val MAE: 0.44419, EMA test MAE: 0.42921, Time: 637.74s
2024-03-21 02:32:43,263 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 02:32:44,440 - logger.py:50 - Epoch: [143][0/500] loss: 0.28700, MAE: 0.44745, time/step=1175ms, lr=1.26e-06
2024-03-21 02:33:36,002 - logger.py:50 - Epoch: [143][50/500] loss: 0.56708, MAE: 0.43358, time/step=1034ms, lr=1.26e-06
2024-03-21 02:34:27,422 - logger.py:50 - Epoch: [143][100/500] loss: 1.75029, MAE: 0.45680, time/step=1031ms, lr=1.26e-06
2024-03-21 02:35:19,913 - logger.py:50 - Epoch: [143][150/500] loss: 1.31509, MAE: 0.44845, time/step=1037ms, lr=1.26e-06
2024-03-21 02:36:11,942 - logger.py:50 - Epoch: [143][200/500] loss: 1.40588, MAE: 0.45069, time/step=1038ms, lr=1.26e-06
2024-03-21 02:37:04,617 - logger.py:50 - Epoch: [143][250/500] loss: 1.24193, MAE: 0.44795, time/step=1041ms, lr=1.26e-06
2024-03-21 02:37:56,841 - logger.py:50 - Epoch: [143][300/500] loss: 1.11994, MAE: 0.44714, time/step=1042ms, lr=1.26e-06
2024-03-21 02:38:49,389 - logger.py:50 - Epoch: [143][350/500] loss: 1.03272, MAE: 0.44663, time/step=1043ms, lr=1.26e-06
2024-03-21 02:39:40,886 - logger.py:50 - Epoch: [143][400/500] loss: 0.97634, MAE: 0.44458, time/step=1041ms, lr=1.26e-06
2024-03-21 02:40:34,318 - logger.py:50 - Epoch: [143][450/500] loss: 0.91917, MAE: 0.44377, time/step=1044ms, lr=1.26e-06
2024-03-21 02:41:25,012 - logger.py:50 - Epoch: [143][499/500] loss: 0.88179, MAE: 0.44374, time/step=1043ms, lr=1.26e-06
2024-03-21 02:42:23,244 - logger.py:50 - Epoch: [143] train loss: 0.88179, val loss: 0.50006, test loss: 0.46932, Time: 579.98s
2024-03-21 02:42:23,244 - logger.py:50 - Best -- epoch=142, train loss: 0.88196, val loss: 0.49995, test loss: 0.46967

2024-03-21 02:43:20,911 - logger.py:50 - Epoch: [143]EMA val MAE: 0.44416, EMA test MAE: 0.42918, Time: 637.65s
2024-03-21 02:43:20,911 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 02:43:21,640 - logger.py:50 - Epoch: [144][0/500] loss: 0.14789, MAE: 0.33290, time/step=726ms, lr=1.19e-06
2024-03-21 02:44:13,613 - logger.py:50 - Epoch: [144][50/500] loss: 0.51064, MAE: 0.44330, time/step=1033ms, lr=1.19e-06
2024-03-21 02:45:05,864 - logger.py:50 - Epoch: [144][100/500] loss: 0.47901, MAE: 0.44136, time/step=1039ms, lr=1.19e-06
2024-03-21 02:45:57,523 - logger.py:50 - Epoch: [144][150/500] loss: 0.50345, MAE: 0.43866, time/step=1037ms, lr=1.19e-06
2024-03-21 02:46:49,705 - logger.py:50 - Epoch: [144][200/500] loss: 0.53991, MAE: 0.43865, time/step=1039ms, lr=1.19e-06
2024-03-21 02:47:41,240 - logger.py:50 - Epoch: [144][250/500] loss: 1.01461, MAE: 0.44547, time/step=1037ms, lr=1.19e-06
2024-03-21 02:48:32,939 - logger.py:50 - Epoch: [144][300/500] loss: 0.92093, MAE: 0.44259, time/step=1037ms, lr=1.19e-06
2024-03-21 02:49:25,158 - logger.py:50 - Epoch: [144][350/500] loss: 0.85807, MAE: 0.44187, time/step=1038ms, lr=1.19e-06
2024-03-21 02:50:17,027 - logger.py:50 - Epoch: [144][400/500] loss: 0.81291, MAE: 0.44042, time/step=1038ms, lr=1.19e-06
2024-03-21 02:51:08,591 - logger.py:50 - Epoch: [144][450/500] loss: 0.78426, MAE: 0.44002, time/step=1037ms, lr=1.19e-06
2024-03-21 02:51:59,603 - logger.py:50 - Epoch: [144][499/500] loss: 0.88119, MAE: 0.44368, time/step=1037ms, lr=1.19e-06
2024-03-21 02:52:57,108 - logger.py:50 - Epoch: [144] train loss: 0.88119, val loss: 0.50015, test loss: 0.46959, Time: 576.20s
2024-03-21 02:52:57,108 - logger.py:50 - Best -- epoch=142, train loss: 0.88196, val loss: 0.49995, test loss: 0.46967

2024-03-21 02:53:54,666 - logger.py:50 - Epoch: [144]EMA val MAE: 0.44414, EMA test MAE: 0.42916, Time: 633.75s
2024-03-21 02:53:54,666 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 02:53:55,917 - logger.py:50 - Epoch: [145][0/500] loss: 0.24993, MAE: 0.46099, time/step=1248ms, lr=1.13e-06
2024-03-21 02:54:47,350 - logger.py:50 - Epoch: [145][50/500] loss: 0.51068, MAE: 0.43540, time/step=1033ms, lr=1.13e-06
2024-03-21 02:55:39,792 - logger.py:50 - Epoch: [145][100/500] loss: 0.48899, MAE: 0.44245, time/step=1041ms, lr=1.13e-06
2024-03-21 02:56:31,969 - logger.py:50 - Epoch: [145][150/500] loss: 0.49360, MAE: 0.44232, time/step=1042ms, lr=1.13e-06
2024-03-21 02:57:23,600 - logger.py:50 - Epoch: [145][200/500] loss: 1.09630, MAE: 0.44870, time/step=1039ms, lr=1.13e-06
2024-03-21 02:58:15,464 - logger.py:50 - Epoch: [145][250/500] loss: 0.96723, MAE: 0.44519, time/step=1039ms, lr=1.13e-06
2024-03-21 02:59:07,784 - logger.py:50 - Epoch: [145][300/500] loss: 1.08850, MAE: 0.44793, time/step=1040ms, lr=1.13e-06
2024-03-21 03:00:00,040 - logger.py:50 - Epoch: [145][350/500] loss: 1.01846, MAE: 0.44609, time/step=1041ms, lr=1.13e-06
2024-03-21 03:00:52,442 - logger.py:50 - Epoch: [145][400/500] loss: 0.95927, MAE: 0.44581, time/step=1042ms, lr=1.13e-06
2024-03-21 03:01:44,468 - logger.py:50 - Epoch: [145][450/500] loss: 0.91800, MAE: 0.44454, time/step=1042ms, lr=1.13e-06
2024-03-21 03:02:34,528 - logger.py:50 - Epoch: [145][499/500] loss: 0.88123, MAE: 0.44369, time/step=1040ms, lr=1.13e-06
2024-03-21 03:03:32,605 - logger.py:50 - Epoch: [145] train loss: 0.88123, val loss: 0.49988, test loss: 0.46919, Time: 577.94s
2024-03-21 03:03:32,605 - logger.py:50 - Best -- epoch=145, train loss: 0.88123, val loss: 0.49988, test loss: 0.46919

2024-03-21 03:04:30,052 - logger.py:50 - Epoch: [145]EMA val MAE: 0.44409, EMA test MAE: 0.42910, Time: 635.39s
2024-03-21 03:04:30,053 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 03:04:31,200 - logger.py:50 - Epoch: [146][0/500] loss: 0.39091, MAE: 0.39340, time/step=1145ms, lr=1.09e-06
2024-03-21 03:05:22,597 - logger.py:50 - Epoch: [146][50/500] loss: 0.56746, MAE: 0.43289, time/step=1030ms, lr=1.09e-06
2024-03-21 03:06:14,126 - logger.py:50 - Epoch: [146][100/500] loss: 0.55274, MAE: 0.43756, time/step=1030ms, lr=1.09e-06
2024-03-21 03:07:06,033 - logger.py:50 - Epoch: [146][150/500] loss: 0.53232, MAE: 0.43783, time/step=1033ms, lr=1.09e-06
2024-03-21 03:07:57,244 - logger.py:50 - Epoch: [146][200/500] loss: 1.13086, MAE: 0.44516, time/step=1031ms, lr=1.09e-06
2024-03-21 03:08:49,354 - logger.py:50 - Epoch: [146][250/500] loss: 1.24887, MAE: 0.44815, time/step=1033ms, lr=1.09e-06
2024-03-21 03:09:36,625 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 3x0e+3x1o | 1536 paths | 1536 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 3])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-21 03:09:37,615 - logger.py:50 - Number of params: 2979831
2024-03-21 03:09:40,939 - logger.py:50 - Epoch: [146][300/500] loss: 1.12458, MAE: 0.44772, time/step=1033ms, lr=1.09e-06
2024-03-21 03:10:32,048 - logger.py:50 - Epoch: [146][350/500] loss: 1.03848, MAE: 0.44440, time/step=1031ms, lr=1.09e-06
2024-03-21 03:11:24,211 - logger.py:50 - Epoch: [146][400/500] loss: 0.97906, MAE: 0.44408, time/step=1033ms, lr=1.09e-06
2024-03-21 03:12:15,531 - logger.py:50 - Epoch: [146][450/500] loss: 0.92847, MAE: 0.44453, time/step=1032ms, lr=1.09e-06
2024-03-21 03:13:07,521 - logger.py:50 - Epoch: [146][499/500] loss: 0.88058, MAE: 0.44367, time/step=1035ms, lr=1.09e-06
2024-03-21 03:14:05,516 - logger.py:50 - Epoch: [146] train loss: 0.88058, val loss: 0.49952, test loss: 0.46928, Time: 575.46s
2024-03-21 03:14:05,516 - logger.py:50 - Best -- epoch=146, train loss: 0.88058, val loss: 0.49952, test loss: 0.46928

2024-03-21 03:15:02,833 - logger.py:50 - Epoch: [146]EMA val MAE: 0.44404, EMA test MAE: 0.42906, Time: 632.78s
2024-03-21 03:15:02,833 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 03:15:04,019 - logger.py:50 - Epoch: [147][0/500] loss: 0.75725, MAE: 0.40155, time/step=1184ms, lr=1.05e-06
2024-03-21 03:15:55,103 - logger.py:50 - Epoch: [147][50/500] loss: 0.52832, MAE: 0.44810, time/step=1025ms, lr=1.05e-06
2024-03-21 03:16:46,844 - logger.py:50 - Epoch: [147][100/500] loss: 1.72094, MAE: 0.46049, time/step=1030ms, lr=1.05e-06
2024-03-21 03:17:39,178 - logger.py:50 - Epoch: [147][150/500] loss: 1.71116, MAE: 0.46340, time/step=1035ms, lr=1.05e-06
2024-03-21 03:18:30,619 - logger.py:50 - Epoch: [147][200/500] loss: 1.43056, MAE: 0.45566, time/step=1034ms, lr=1.05e-06
2024-03-21 03:19:22,822 - logger.py:50 - Epoch: [147][250/500] loss: 1.25629, MAE: 0.45324, time/step=1036ms, lr=1.05e-06
2024-03-21 03:20:14,749 - logger.py:50 - Epoch: [147][300/500] loss: 1.12063, MAE: 0.44929, time/step=1036ms, lr=1.05e-06
2024-03-21 03:21:06,625 - logger.py:50 - Epoch: [147][350/500] loss: 1.03708, MAE: 0.44729, time/step=1036ms, lr=1.05e-06
2024-03-21 03:21:58,221 - logger.py:50 - Epoch: [147][400/500] loss: 0.97056, MAE: 0.44513, time/step=1036ms, lr=1.05e-06
2024-03-21 03:22:50,277 - logger.py:50 - Epoch: [147][450/500] loss: 0.92089, MAE: 0.44382, time/step=1036ms, lr=1.05e-06
2024-03-21 03:23:40,607 - logger.py:50 - Epoch: [147][499/500] loss: 0.88059, MAE: 0.44375, time/step=1036ms, lr=1.05e-06
2024-03-21 03:24:38,068 - logger.py:50 - Epoch: [147] train loss: 0.88059, val loss: 0.49973, test loss: 0.46951, Time: 575.23s
2024-03-21 03:24:38,068 - logger.py:50 - Best -- epoch=146, train loss: 0.88058, val loss: 0.49952, test loss: 0.46928

2024-03-21 03:25:35,026 - logger.py:50 - Epoch: [147]EMA val MAE: 0.44403, EMA test MAE: 0.42904, Time: 632.19s
2024-03-21 03:25:35,027 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 03:25:35,747 - logger.py:50 - Epoch: [148][0/500] loss: 0.75226, MAE: 0.57554, time/step=718ms, lr=1.02e-06
2024-03-21 03:26:27,377 - logger.py:50 - Epoch: [148][50/500] loss: 0.46389, MAE: 0.43930, time/step=1026ms, lr=1.02e-06
2024-03-21 03:27:18,577 - logger.py:50 - Epoch: [148][100/500] loss: 0.47823, MAE: 0.44410, time/step=1025ms, lr=1.02e-06
2024-03-21 03:28:10,436 - logger.py:50 - Epoch: [148][150/500] loss: 0.49352, MAE: 0.43919, time/step=1029ms, lr=1.02e-06
2024-03-21 03:29:02,824 - logger.py:50 - Epoch: [148][200/500] loss: 0.50128, MAE: 0.44243, time/step=1034ms, lr=1.02e-06
2024-03-21 03:29:54,788 - logger.py:50 - Epoch: [148][250/500] loss: 0.49807, MAE: 0.43945, time/step=1035ms, lr=1.02e-06
2024-03-21 03:30:46,044 - logger.py:50 - Epoch: [148][300/500] loss: 0.90279, MAE: 0.44820, time/step=1033ms, lr=1.02e-06
2024-03-21 03:31:37,758 - logger.py:50 - Epoch: [148][350/500] loss: 1.03088, MAE: 0.44797, time/step=1033ms, lr=1.02e-06
2024-03-21 03:32:29,296 - logger.py:50 - Epoch: [148][400/500] loss: 0.97123, MAE: 0.44660, time/step=1033ms, lr=1.02e-06
2024-03-21 03:33:21,655 - logger.py:50 - Epoch: [148][450/500] loss: 0.92065, MAE: 0.44573, time/step=1035ms, lr=1.02e-06
2024-03-21 03:34:12,768 - logger.py:50 - Epoch: [148][499/500] loss: 0.88186, MAE: 0.44369, time/step=1035ms, lr=1.02e-06
2024-03-21 03:35:10,499 - logger.py:50 - Epoch: [148] train loss: 0.88186, val loss: 0.49965, test loss: 0.46910, Time: 575.47s
2024-03-21 03:35:10,499 - logger.py:50 - Best -- epoch=146, train loss: 0.88058, val loss: 0.49952, test loss: 0.46928

2024-03-21 03:36:07,715 - logger.py:50 - Epoch: [148]EMA val MAE: 0.44400, EMA test MAE: 0.42902, Time: 632.69s
2024-03-21 03:36:07,716 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 03:36:08,457 - logger.py:50 - Epoch: [149][0/500] loss: 0.31263, MAE: 0.50644, time/step=739ms, lr=1.01e-06
2024-03-21 03:36:59,913 - logger.py:50 - Epoch: [149][50/500] loss: 0.45620, MAE: 0.43059, time/step=1023ms, lr=1.01e-06
2024-03-21 03:37:51,551 - logger.py:50 - Epoch: [149][100/500] loss: 1.09558, MAE: 0.44271, time/step=1028ms, lr=1.01e-06
2024-03-21 03:38:43,584 - logger.py:50 - Epoch: [149][150/500] loss: 0.89089, MAE: 0.43945, time/step=1032ms, lr=1.01e-06
2024-03-21 03:39:35,832 - logger.py:50 - Epoch: [149][200/500] loss: 0.80409, MAE: 0.43991, time/step=1035ms, lr=1.01e-06
2024-03-21 03:40:28,285 - logger.py:50 - Epoch: [149][250/500] loss: 0.75392, MAE: 0.44149, time/step=1038ms, lr=1.01e-06
2024-03-21 03:41:19,434 - logger.py:50 - Epoch: [149][300/500] loss: 0.71437, MAE: 0.44169, time/step=1036ms, lr=1.01e-06
2024-03-21 03:42:11,489 - logger.py:50 - Epoch: [149][350/500] loss: 0.67639, MAE: 0.44304, time/step=1036ms, lr=1.01e-06
2024-03-21 03:43:02,826 - logger.py:50 - Epoch: [149][400/500] loss: 0.96868, MAE: 0.44600, time/step=1035ms, lr=1.01e-06
2024-03-21 03:43:54,534 - logger.py:50 - Epoch: [149][450/500] loss: 0.91930, MAE: 0.44434, time/step=1035ms, lr=1.01e-06
2024-03-21 03:44:45,818 - logger.py:50 - Epoch: [149][499/500] loss: 0.88405, MAE: 0.44367, time/step=1036ms, lr=1.01e-06
2024-03-21 03:45:43,257 - logger.py:50 - Epoch: [149] train loss: 0.88405, val loss: 0.50006, test loss: 0.46980, Time: 575.54s
2024-03-21 03:45:43,257 - logger.py:50 - Best -- epoch=146, train loss: 0.88058, val loss: 0.49952, test loss: 0.46928

2024-03-21 03:46:40,250 - logger.py:50 - Epoch: [149]EMA val MAE: 0.44396, EMA test MAE: 0.42898, Time: 632.53s
2024-03-21 03:46:40,250 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 03:46:40,250 - logger.py:50 - fold_10 test LOSS:0.46928
2024-03-21 09:02:06,124 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=True, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=True, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-03-21 09:02:27,692 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 3x0e+3x1o | 1536 paths | 1536 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 3])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-03-21 09:02:28,564 - logger.py:50 - Number of params: 2979831
2024-03-21 09:02:31,508 - logger.py:50 - Epoch: [0][0/500] loss: 13.25269, MAE: 1.81579, time/step=2940ms, lr=1.00e-06
2024-03-21 09:03:44,464 - logger.py:50 - Epoch: [0][50/500] loss: 13.07160, MAE: 1.59377, time/step=1488ms, lr=1.00e-06
2024-03-21 09:04:43,742 - logger.py:50 - Epoch: [0][100/500] loss: 11.58274, MAE: 1.53376, time/step=1338ms, lr=1.00e-06
2024-03-21 09:05:43,275 - logger.py:50 - Epoch: [0][150/500] loss: 10.95468, MAE: 1.49379, time/step=1289ms, lr=1.00e-06
2024-03-21 09:06:43,351 - logger.py:50 - Epoch: [0][200/500] loss: 10.63111, MAE: 1.46324, time/step=1268ms, lr=1.00e-06
2024-03-21 09:07:42,523 - logger.py:50 - Epoch: [0][250/500] loss: 10.29560, MAE: 1.42963, time/step=1251ms, lr=1.00e-06
2024-03-21 09:08:40,452 - logger.py:50 - Epoch: [0][300/500] loss: 10.00348, MAE: 1.40170, time/step=1235ms, lr=1.00e-06
2024-03-21 09:09:38,464 - logger.py:50 - Epoch: [0][350/500] loss: 9.79984, MAE: 1.37462, time/step=1225ms, lr=1.00e-06
2024-03-21 09:10:35,894 - logger.py:50 - Epoch: [0][400/500] loss: 9.64789, MAE: 1.35096, time/step=1215ms, lr=1.00e-06
2024-03-21 09:11:32,710 - logger.py:50 - Epoch: [0][450/500] loss: 9.58596, MAE: 1.32939, time/step=1207ms, lr=1.00e-06
2024-03-21 09:12:27,618 - logger.py:50 - Epoch: [0][499/500] loss: 9.43588, MAE: 1.30957, time/step=1198ms, lr=1.00e-06
2024-03-21 09:13:33,679 - logger.py:50 - Epoch: [0] train loss: 9.43588, train MAE: 1.30957,val loss: 7.50225, val MAE: 1.08132,test loss: 7.93163, test MAE: 1.10118,Time: 665.11s
2024-03-21 09:13:33,679 - logger.py:50 - Best -- epoch=0, train loss: 9.43588, val loss: 7.50225, test loss: 7.93163

2024-03-21 09:14:43,847 - logger.py:50 - Epoch: [0]EMA val MAE: 1.58975, EMA test MAE: 1.61553, Time: 735.28s
2024-03-21 09:14:43,847 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 09:14:45,068 - logger.py:50 - Epoch: [1][0/500] loss: 6.20390, MAE: 1.09998, time/step=1218ms, lr=1.08e-05
2024-03-21 09:15:39,978 - logger.py:50 - Epoch: [1][50/500] loss: 7.63171, MAE: 0.99716, time/step=1101ms, lr=1.08e-05
2024-03-21 09:16:35,232 - logger.py:50 - Epoch: [1][100/500] loss: 7.23902, MAE: 0.93041, time/step=1103ms, lr=1.08e-05
2024-03-21 09:17:30,203 - logger.py:50 - Epoch: [1][150/500] loss: 6.90624, MAE: 0.88435, time/step=1102ms, lr=1.08e-05
2024-03-21 09:18:28,453 - logger.py:50 - Epoch: [1][200/500] loss: 6.75658, MAE: 0.85090, time/step=1117ms, lr=1.08e-05
2024-03-21 09:19:24,747 - logger.py:50 - Epoch: [1][250/500] loss: 6.61390, MAE: 0.82262, time/step=1119ms, lr=1.08e-05
2024-03-21 09:20:22,300 - logger.py:50 - Epoch: [1][300/500] loss: 6.50589, MAE: 0.80316, time/step=1124ms, lr=1.08e-05
2024-03-21 09:21:18,695 - logger.py:50 - Epoch: [1][350/500] loss: 6.34938, MAE: 0.78452, time/step=1125ms, lr=1.08e-05
2024-03-21 09:22:14,002 - logger.py:50 - Epoch: [1][400/500] loss: 6.37467, MAE: 0.77063, time/step=1123ms, lr=1.08e-05
2024-03-21 09:23:09,743 - logger.py:50 - Epoch: [1][450/500] loss: 6.27175, MAE: 0.75592, time/step=1122ms, lr=1.08e-05
2024-03-21 09:24:03,747 - logger.py:50 - Epoch: [1][499/500] loss: 6.36027, MAE: 0.74453, time/step=1120ms, lr=1.08e-05
2024-03-21 09:25:07,012 - logger.py:50 - Epoch: [1] train loss: 6.36027, train MAE: 0.74453,val loss: 4.89975, val MAE: 0.59926,test loss: 5.11005, test MAE: 0.62196,Time: 623.16s
2024-03-21 09:25:07,012 - logger.py:50 - Best -- epoch=1, train loss: 6.36027, val loss: 4.89975, test loss: 5.11005

2024-03-21 09:26:10,092 - logger.py:50 - Epoch: [1]EMA val MAE: 1.52988, EMA test MAE: 1.55491, Time: 686.24s
2024-03-21 09:26:10,092 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 09:26:11,579 - logger.py:50 - Epoch: [2][0/500] loss: 4.38311, MAE: 0.60713, time/step=1484ms, lr=2.06e-05
2024-03-21 09:27:08,108 - logger.py:50 - Epoch: [2][50/500] loss: 4.88016, MAE: 0.59457, time/step=1138ms, lr=2.06e-05
2024-03-21 09:28:04,168 - logger.py:50 - Epoch: [2][100/500] loss: 4.82665, MAE: 0.58237, time/step=1129ms, lr=2.06e-05
2024-03-21 09:28:59,095 - logger.py:50 - Epoch: [2][150/500] loss: 4.81708, MAE: 0.57125, time/step=1119ms, lr=2.06e-05
2024-03-21 09:29:54,717 - logger.py:50 - Epoch: [2][200/500] loss: 5.40394, MAE: 0.57253, time/step=1118ms, lr=2.06e-05
2024-03-21 09:30:51,495 - logger.py:50 - Epoch: [2][250/500] loss: 5.32118, MAE: 0.56473, time/step=1121ms, lr=2.06e-05
2024-03-21 09:31:48,134 - logger.py:50 - Epoch: [2][300/500] loss: 5.34709, MAE: 0.55840, time/step=1123ms, lr=2.06e-05
2024-03-21 09:32:49,018 - logger.py:50 - Epoch: [2][350/500] loss: 5.22620, MAE: 0.55179, time/step=1137ms, lr=2.06e-05
2024-03-21 09:33:50,903 - logger.py:50 - Epoch: [2][400/500] loss: 5.12042, MAE: 0.54388, time/step=1149ms, lr=2.06e-05
2024-03-21 09:34:54,276 - logger.py:50 - Epoch: [2][450/500] loss: 5.02665, MAE: 0.53603, time/step=1162ms, lr=2.06e-05
2024-03-21 09:35:57,602 - logger.py:50 - Epoch: [2][499/500] loss: 4.93758, MAE: 0.52847, time/step=1175ms, lr=2.06e-05
2024-03-21 09:37:10,475 - logger.py:50 - Epoch: [2] train loss: 4.93758, train MAE: 0.52847,val loss: 4.01897, val MAE: 0.44644,test loss: 4.12105, test MAE: 0.46187,Time: 660.38s
2024-03-21 09:37:10,475 - logger.py:50 - Best -- epoch=2, train loss: 4.93758, val loss: 4.01897, test loss: 4.12105

2024-03-21 09:38:23,786 - logger.py:50 - Epoch: [2]EMA val MAE: 1.46285, EMA test MAE: 1.48688, Time: 733.69s
2024-03-21 09:38:23,787 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 09:38:25,127 - logger.py:50 - Epoch: [3][0/500] loss: 3.75939, MAE: 0.44113, time/step=1338ms, lr=3.04e-05
2024-03-21 09:39:25,444 - logger.py:50 - Epoch: [3][50/500] loss: 4.34387, MAE: 0.45569, time/step=1209ms, lr=3.04e-05
2024-03-21 09:40:28,015 - logger.py:50 - Epoch: [3][100/500] loss: 4.23793, MAE: 0.44841, time/step=1230ms, lr=3.04e-05
2024-03-21 09:41:29,557 - logger.py:50 - Epoch: [3][150/500] loss: 4.48118, MAE: 0.44820, time/step=1230ms, lr=3.04e-05
2024-03-21 09:42:31,461 - logger.py:50 - Epoch: [3][200/500] loss: 4.35326, MAE: 0.44318, time/step=1232ms, lr=3.04e-05
2024-03-21 09:43:30,489 - logger.py:50 - Epoch: [3][250/500] loss: 4.27548, MAE: 0.43690, time/step=1222ms, lr=3.04e-05
2024-03-21 09:44:33,131 - logger.py:50 - Epoch: [3][300/500] loss: 4.19169, MAE: 0.43026, time/step=1227ms, lr=3.04e-05
2024-03-21 09:45:34,472 - logger.py:50 - Epoch: [3][350/500] loss: 4.12941, MAE: 0.42258, time/step=1227ms, lr=3.04e-05
2024-03-21 09:46:31,498 - logger.py:50 - Epoch: [3][400/500] loss: 4.09518, MAE: 0.41854, time/step=1216ms, lr=3.04e-05
2024-03-21 09:47:26,588 - logger.py:50 - Epoch: [3][450/500] loss: 4.33827, MAE: 0.41991, time/step=1204ms, lr=3.04e-05
2024-03-21 09:48:22,273 - logger.py:50 - Epoch: [3][499/500] loss: 4.27754, MAE: 0.41520, time/step=1197ms, lr=3.04e-05
2024-03-21 09:49:27,969 - logger.py:50 - Epoch: [3] train loss: 4.27754, train MAE: 0.41520,val loss: 3.64053, val MAE: 0.36065,test loss: 3.71051, test MAE: 0.37154,Time: 664.18s
2024-03-21 09:49:27,969 - logger.py:50 - Best -- epoch=3, train loss: 4.27754, val loss: 3.64053, test loss: 3.71051

2024-03-21 09:50:41,066 - logger.py:50 - Epoch: [3]EMA val MAE: 1.39425, EMA test MAE: 1.41698, Time: 737.28s
2024-03-21 09:50:41,066 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 09:50:41,953 - logger.py:50 - Epoch: [4][0/500] loss: 4.10043, MAE: 0.44865, time/step=885ms, lr=4.02e-05
2024-03-21 09:51:44,720 - logger.py:50 - Epoch: [4][50/500] loss: 5.95867, MAE: 0.42237, time/step=1248ms, lr=4.02e-05
2024-03-21 09:52:46,085 - logger.py:50 - Epoch: [4][100/500] loss: 4.83984, MAE: 0.39619, time/step=1238ms, lr=4.02e-05
2024-03-21 09:53:44,476 - logger.py:50 - Epoch: [4][150/500] loss: 4.80865, MAE: 0.39036, time/step=1215ms, lr=4.02e-05
2024-03-21 09:54:42,187 - logger.py:50 - Epoch: [4][200/500] loss: 4.51654, MAE: 0.38363, time/step=1200ms, lr=4.02e-05
2024-03-21 09:55:38,529 - logger.py:50 - Epoch: [4][250/500] loss: 4.35377, MAE: 0.37430, time/step=1185ms, lr=4.02e-05
2024-03-21 09:56:34,448 - logger.py:50 - Epoch: [4][300/500] loss: 4.23523, MAE: 0.36745, time/step=1174ms, lr=4.02e-05
2024-03-21 09:57:30,583 - logger.py:50 - Epoch: [4][350/500] loss: 4.15219, MAE: 0.36134, time/step=1167ms, lr=4.02e-05
2024-03-21 09:58:27,143 - logger.py:50 - Epoch: [4][400/500] loss: 4.09362, MAE: 0.35771, time/step=1162ms, lr=4.02e-05
2024-03-21 09:59:22,667 - logger.py:50 - Epoch: [4][450/500] loss: 4.03897, MAE: 0.35384, time/step=1157ms, lr=4.02e-05
2024-03-21 10:00:16,874 - logger.py:50 - Epoch: [4][499/500] loss: 4.00812, MAE: 0.35067, time/step=1152ms, lr=4.02e-05
2024-03-21 10:01:20,508 - logger.py:50 - Epoch: [4] train loss: 4.00812, train MAE: 0.35067,val loss: 3.49229, val MAE: 0.31632,test loss: 3.56195, test MAE: 0.32394,Time: 639.44s
2024-03-21 10:01:20,508 - logger.py:50 - Best -- epoch=4, train loss: 4.00812, val loss: 3.49229, test loss: 3.56195

2024-03-21 10:02:24,331 - logger.py:50 - Epoch: [4]EMA val MAE: 1.32553, EMA test MAE: 1.34688, Time: 703.26s
2024-03-21 10:02:24,331 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 10:02:25,659 - logger.py:50 - Epoch: [5][0/500] loss: 3.66291, MAE: 0.33285, time/step=1325ms, lr=4.99e-05
2024-03-21 10:03:22,207 - logger.py:50 - Epoch: [5][50/500] loss: 3.58448, MAE: 0.31892, time/step=1135ms, lr=4.99e-05
2024-03-21 10:04:18,575 - logger.py:50 - Epoch: [5][100/500] loss: 3.56629, MAE: 0.31196, time/step=1131ms, lr=4.99e-05
2024-03-21 10:05:13,100 - logger.py:50 - Epoch: [5][150/500] loss: 3.59014, MAE: 0.30940, time/step=1118ms, lr=4.99e-05
2024-03-21 10:06:08,184 - logger.py:50 - Epoch: [5][200/500] loss: 3.56122, MAE: 0.30652, time/step=1114ms, lr=4.99e-05
2024-03-21 10:07:03,325 - logger.py:50 - Epoch: [5][250/500] loss: 4.03342, MAE: 0.32000, time/step=1112ms, lr=4.99e-05
2024-03-21 10:07:59,011 - logger.py:50 - Epoch: [5][300/500] loss: 3.94725, MAE: 0.32161, time/step=1112ms, lr=4.99e-05
2024-03-21 10:08:55,654 - logger.py:50 - Epoch: [5][350/500] loss: 3.88581, MAE: 0.31786, time/step=1115ms, lr=4.99e-05
2024-03-21 10:09:51,956 - logger.py:50 - Epoch: [5][400/500] loss: 3.84035, MAE: 0.31439, time/step=1116ms, lr=4.99e-05
2024-03-21 10:10:49,927 - logger.py:50 - Epoch: [5][450/500] loss: 3.93629, MAE: 0.31827, time/step=1121ms, lr=4.99e-05
2024-03-21 10:11:45,219 - logger.py:50 - Epoch: [5][499/500] loss: 3.89665, MAE: 0.31588, time/step=1122ms, lr=4.99e-05
2024-03-21 10:12:52,904 - logger.py:50 - Epoch: [5] train loss: 3.89665, train MAE: 0.31588,val loss: 3.42481, val MAE: 0.28623,test loss: 3.49924, test MAE: 0.29400,Time: 628.57s
2024-03-21 10:12:52,905 - logger.py:50 - Best -- epoch=5, train loss: 3.89665, val loss: 3.42481, test loss: 3.49924

2024-03-21 10:13:57,805 - logger.py:50 - Epoch: [5]EMA val MAE: 1.25827, EMA test MAE: 1.27834, Time: 693.47s
2024-03-21 10:13:57,805 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 10:13:59,077 - logger.py:50 - Epoch: [6][0/500] loss: 3.55265, MAE: 0.36359, time/step=1269ms, lr=4.98e-05
2024-03-21 10:14:55,368 - logger.py:50 - Epoch: [6][50/500] loss: 3.51281, MAE: 0.28271, time/step=1129ms, lr=4.98e-05
2024-03-21 10:15:57,746 - logger.py:50 - Epoch: [6][100/500] loss: 3.52957, MAE: 0.28456, time/step=1188ms, lr=4.98e-05
2024-03-21 10:16:55,356 - logger.py:50 - Epoch: [6][150/500] loss: 3.52730, MAE: 0.28352, time/step=1176ms, lr=4.98e-05
2024-03-21 10:17:51,235 - logger.py:50 - Epoch: [6][200/500] loss: 3.51398, MAE: 0.28099, time/step=1161ms, lr=4.98e-05
2024-03-21 10:18:47,396 - logger.py:50 - Epoch: [6][250/500] loss: 3.50755, MAE: 0.27921, time/step=1154ms, lr=4.98e-05
2024-03-21 10:19:43,899 - logger.py:50 - Epoch: [6][300/500] loss: 3.50645, MAE: 0.27905, time/step=1150ms, lr=4.98e-05
2024-03-21 10:20:41,132 - logger.py:50 - Epoch: [6][350/500] loss: 3.64651, MAE: 0.28566, time/step=1149ms, lr=4.98e-05
2024-03-21 10:21:36,420 - logger.py:50 - Epoch: [6][400/500] loss: 3.90869, MAE: 0.29305, time/step=1144ms, lr=4.98e-05
2024-03-21 10:22:33,586 - logger.py:50 - Epoch: [6][450/500] loss: 3.86450, MAE: 0.29276, time/step=1144ms, lr=4.98e-05
2024-03-21 10:23:31,381 - logger.py:50 - Epoch: [6][499/500] loss: 3.83314, MAE: 0.29053, time/step=1147ms, lr=4.98e-05
2024-03-21 10:24:35,798 - logger.py:50 - Epoch: [6] train loss: 3.83314, train MAE: 0.29053,val loss: 3.38853, val MAE: 0.26459,test loss: 3.46124, test MAE: 0.27345,Time: 637.99s
2024-03-21 10:24:35,799 - logger.py:50 - Best -- epoch=6, train loss: 3.83314, val loss: 3.38853, test loss: 3.46124

2024-03-21 10:25:42,736 - logger.py:50 - Epoch: [6]EMA val MAE: 1.19336, EMA test MAE: 1.21234, Time: 704.93s
2024-03-21 10:25:42,736 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 10:25:44,058 - logger.py:50 - Epoch: [7][0/500] loss: 3.43744, MAE: 0.28003, time/step=1319ms, lr=4.97e-05
2024-03-21 10:26:39,208 - logger.py:50 - Epoch: [7][50/500] loss: 5.66311, MAE: 0.30040, time/step=1107ms, lr=4.97e-05
2024-03-21 10:27:34,114 - logger.py:50 - Epoch: [7][100/500] loss: 4.61102, MAE: 0.31001, time/step=1103ms, lr=4.97e-05
2024-03-21 10:28:29,119 - logger.py:50 - Epoch: [7][150/500] loss: 4.22692, MAE: 0.29554, time/step=1102ms, lr=4.97e-05
2024-03-21 10:29:25,858 - logger.py:50 - Epoch: [7][200/500] loss: 4.03946, MAE: 0.28898, time/step=1110ms, lr=4.97e-05
2024-03-21 10:30:21,874 - logger.py:50 - Epoch: [7][250/500] loss: 3.91555, MAE: 0.28287, time/step=1112ms, lr=4.97e-05
2024-03-21 10:31:17,117 - logger.py:50 - Epoch: [7][300/500] loss: 3.83984, MAE: 0.27932, time/step=1111ms, lr=4.97e-05
2024-03-21 10:32:13,218 - logger.py:50 - Epoch: [7][350/500] loss: 3.77708, MAE: 0.27594, time/step=1112ms, lr=4.97e-05
2024-03-21 10:33:13,148 - logger.py:50 - Epoch: [7][400/500] loss: 3.87205, MAE: 0.28125, time/step=1123ms, lr=4.97e-05
2024-03-21 10:34:13,401 - logger.py:50 - Epoch: [7][450/500] loss: 3.82441, MAE: 0.27891, time/step=1132ms, lr=4.97e-05
2024-03-21 10:35:09,440 - logger.py:50 - Epoch: [7][499/500] loss: 3.79560, MAE: 0.27702, time/step=1133ms, lr=4.97e-05
2024-03-21 10:36:16,690 - logger.py:50 - Epoch: [7] train loss: 3.79560, train MAE: 0.27702,val loss: 3.36245, val MAE: 0.25207,test loss: 3.43498, test MAE: 0.26123,Time: 633.95s
2024-03-21 10:36:16,690 - logger.py:50 - Best -- epoch=7, train loss: 3.79560, val loss: 3.36245, test loss: 3.43498

2024-03-21 10:37:24,251 - logger.py:50 - Epoch: [7]EMA val MAE: 1.13148, EMA test MAE: 1.14955, Time: 701.51s
2024-03-21 10:37:24,251 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 10:37:25,022 - logger.py:50 - Epoch: [8][0/500] loss: 3.28673, MAE: 0.23382, time/step=768ms, lr=4.97e-05
2024-03-21 10:38:21,392 - logger.py:50 - Epoch: [8][50/500] loss: 3.42174, MAE: 0.25610, time/step=1120ms, lr=4.97e-05
2024-03-21 10:39:17,110 - logger.py:50 - Epoch: [8][100/500] loss: 3.41894, MAE: 0.25484, time/step=1117ms, lr=4.97e-05
2024-03-21 10:40:13,401 - logger.py:50 - Epoch: [8][150/500] loss: 3.76994, MAE: 0.26863, time/step=1120ms, lr=4.97e-05
2024-03-21 10:41:10,581 - logger.py:50 - Epoch: [8][200/500] loss: 3.68196, MAE: 0.26535, time/step=1126ms, lr=4.97e-05
2024-03-21 10:42:09,782 - logger.py:50 - Epoch: [8][250/500] loss: 4.08058, MAE: 0.27857, time/step=1138ms, lr=4.97e-05
2024-03-21 10:43:12,259 - logger.py:50 - Epoch: [8][300/500] loss: 3.96687, MAE: 0.27441, time/step=1156ms, lr=4.97e-05
2024-03-21 10:44:13,207 - logger.py:50 - Epoch: [8][350/500] loss: 3.89799, MAE: 0.27142, time/step=1165ms, lr=4.97e-05
2024-03-21 10:45:10,690 - logger.py:50 - Epoch: [8][400/500] loss: 3.84408, MAE: 0.26855, time/step=1163ms, lr=4.97e-05
2024-03-21 10:46:06,653 - logger.py:50 - Epoch: [8][450/500] loss: 3.79465, MAE: 0.26617, time/step=1158ms, lr=4.97e-05
2024-03-21 10:47:01,214 - logger.py:50 - Epoch: [8][499/500] loss: 3.75979, MAE: 0.26407, time/step=1154ms, lr=4.97e-05
2024-03-21 10:48:06,337 - logger.py:50 - Epoch: [8] train loss: 3.75979, train MAE: 0.26407,val loss: 3.33727, val MAE: 0.24226,test loss: 3.41033, test MAE: 0.25184,Time: 642.09s
2024-03-21 10:48:06,338 - logger.py:50 - Best -- epoch=8, train loss: 3.75979, val loss: 3.33727, test loss: 3.41033

2024-03-21 10:49:11,350 - logger.py:50 - Epoch: [8]EMA val MAE: 1.07336, EMA test MAE: 1.09069, Time: 707.10s
2024-03-21 10:49:11,351 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 10:49:12,137 - logger.py:50 - Epoch: [9][0/500] loss: 3.26437, MAE: 0.23885, time/step=784ms, lr=4.96e-05
2024-03-21 10:50:08,790 - logger.py:50 - Epoch: [9][50/500] loss: 3.40993, MAE: 0.25087, time/step=1126ms, lr=4.96e-05
2024-03-21 10:51:04,348 - logger.py:50 - Epoch: [9][100/500] loss: 3.39331, MAE: 0.24692, time/step=1119ms, lr=4.96e-05
2024-03-21 10:52:00,500 - logger.py:50 - Epoch: [9][150/500] loss: 3.38619, MAE: 0.24360, time/step=1120ms, lr=4.96e-05
2024-03-21 10:52:55,951 - logger.py:50 - Epoch: [9][200/500] loss: 3.41308, MAE: 0.24550, time/step=1117ms, lr=4.96e-05
2024-03-21 10:53:51,893 - logger.py:50 - Epoch: [9][250/500] loss: 3.42279, MAE: 0.24594, time/step=1118ms, lr=4.96e-05
2024-03-21 10:54:47,059 - logger.py:50 - Epoch: [9][300/500] loss: 3.43133, MAE: 0.24633, time/step=1115ms, lr=4.96e-05
2024-03-21 10:55:42,982 - logger.py:50 - Epoch: [9][350/500] loss: 3.56858, MAE: 0.25140, time/step=1116ms, lr=4.96e-05
2024-03-21 10:56:38,071 - logger.py:50 - Epoch: [9][400/500] loss: 3.82698, MAE: 0.26223, time/step=1114ms, lr=4.96e-05
2024-03-21 10:57:33,711 - logger.py:50 - Epoch: [9][450/500] loss: 3.77291, MAE: 0.25969, time/step=1114ms, lr=4.96e-05
2024-03-21 10:58:28,554 - logger.py:50 - Epoch: [9][499/500] loss: 3.73459, MAE: 0.25739, time/step=1114ms, lr=4.96e-05
2024-03-21 10:59:32,005 - logger.py:50 - Epoch: [9] train loss: 3.73459, train MAE: 0.25739,val loss: 3.31605, val MAE: 0.23015,test loss: 3.37403, test MAE: 0.23895,Time: 620.65s
2024-03-21 10:59:32,005 - logger.py:50 - Best -- epoch=9, train loss: 3.73459, val loss: 3.31605, test loss: 3.37403

2024-03-21 11:00:35,569 - logger.py:50 - Epoch: [9]EMA val MAE: 1.01910, EMA test MAE: 1.03574, Time: 684.22s
2024-03-21 11:00:35,570 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 11:00:36,862 - logger.py:50 - Epoch: [10][0/500] loss: 3.59498, MAE: 0.27943, time/step=1290ms, lr=4.95e-05
2024-03-21 11:01:32,710 - logger.py:50 - Epoch: [10][50/500] loss: 3.41164, MAE: 0.23876, time/step=1120ms, lr=4.95e-05
2024-03-21 11:02:32,242 - logger.py:50 - Epoch: [10][100/500] loss: 3.39860, MAE: 0.23779, time/step=1155ms, lr=4.95e-05
2024-03-21 11:03:34,052 - logger.py:50 - Epoch: [10][150/500] loss: 3.40413, MAE: 0.23719, time/step=1182ms, lr=4.95e-05
2024-03-21 11:04:37,501 - logger.py:50 - Epoch: [10][200/500] loss: 3.40329, MAE: 0.23691, time/step=1204ms, lr=4.95e-05
2024-03-21 11:05:38,305 - logger.py:50 - Epoch: [10][250/500] loss: 3.39517, MAE: 0.23681, time/step=1206ms, lr=4.95e-05
2024-03-21 11:06:39,573 - logger.py:50 - Epoch: [10][300/500] loss: 3.39273, MAE: 0.23777, time/step=1209ms, lr=4.95e-05
2024-03-21 11:07:37,443 - logger.py:50 - Epoch: [10][350/500] loss: 3.38770, MAE: 0.23748, time/step=1202ms, lr=4.95e-05
2024-03-21 11:08:37,996 - logger.py:50 - Epoch: [10][400/500] loss: 3.66632, MAE: 0.24504, time/step=1203ms, lr=4.95e-05
2024-03-21 11:09:35,784 - logger.py:50 - Epoch: [10][450/500] loss: 3.63159, MAE: 0.24493, time/step=1198ms, lr=4.95e-05
2024-03-21 11:10:31,368 - logger.py:50 - Epoch: [10][499/500] loss: 3.71099, MAE: 0.24989, time/step=1192ms, lr=4.95e-05
2024-03-21 11:11:35,293 - logger.py:50 - Epoch: [10] train loss: 3.71099, train MAE: 0.24989,val loss: 3.31545, val MAE: 0.23862,test loss: 3.37037, test MAE: 0.24712,Time: 659.72s
2024-03-21 11:11:35,294 - logger.py:50 - Best -- epoch=10, train loss: 3.71099, val loss: 3.31545, test loss: 3.37037

2024-03-21 11:12:38,363 - logger.py:50 - Epoch: [10]EMA val MAE: 0.96844, EMA test MAE: 0.98452, Time: 722.79s
2024-03-21 11:12:38,363 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 11:12:39,180 - logger.py:50 - Epoch: [11][0/500] loss: 3.18438, MAE: 0.22785, time/step=814ms, lr=4.94e-05
2024-03-21 11:13:35,451 - logger.py:50 - Epoch: [11][50/500] loss: 3.40896, MAE: 0.23449, time/step=1119ms, lr=4.94e-05
2024-03-21 11:14:31,907 - logger.py:50 - Epoch: [11][100/500] loss: 3.36329, MAE: 0.23112, time/step=1124ms, lr=4.94e-05
2024-03-21 11:15:27,662 - logger.py:50 - Epoch: [11][150/500] loss: 3.36126, MAE: 0.23342, time/step=1121ms, lr=4.94e-05
2024-03-21 11:16:23,625 - logger.py:50 - Epoch: [11][200/500] loss: 4.18748, MAE: 0.25790, time/step=1121ms, lr=4.94e-05
2024-03-21 11:17:18,994 - logger.py:50 - Epoch: [11][250/500] loss: 4.02156, MAE: 0.25744, time/step=1118ms, lr=4.94e-05
2024-03-21 11:18:14,663 - logger.py:50 - Epoch: [11][300/500] loss: 3.91867, MAE: 0.25231, time/step=1117ms, lr=4.94e-05
2024-03-21 11:19:11,068 - logger.py:50 - Epoch: [11][350/500] loss: 3.83274, MAE: 0.24891, time/step=1119ms, lr=4.94e-05
2024-03-21 11:20:08,221 - logger.py:50 - Epoch: [11][400/500] loss: 3.77346, MAE: 0.24657, time/step=1122ms, lr=4.94e-05
2024-03-21 11:21:08,746 - logger.py:50 - Epoch: [11][450/500] loss: 3.72569, MAE: 0.24526, time/step=1132ms, lr=4.94e-05
2024-03-21 11:22:04,645 - logger.py:50 - Epoch: [11][499/500] loss: 3.68645, MAE: 0.24284, time/step=1133ms, lr=4.94e-05
2024-03-21 11:23:16,698 - logger.py:50 - Epoch: [11] train loss: 3.68645, train MAE: 0.24284,val loss: 3.28345, val MAE: 0.21723,test loss: 3.33209, test MAE: 0.22559,Time: 638.33s
2024-03-21 11:23:16,699 - logger.py:50 - Best -- epoch=11, train loss: 3.68645, val loss: 3.28345, test loss: 3.33209

2024-03-21 11:24:27,426 - logger.py:50 - Epoch: [11]EMA val MAE: 0.92107, EMA test MAE: 0.93672, Time: 709.06s
2024-03-21 11:24:27,426 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 11:24:28,263 - logger.py:50 - Epoch: [12][0/500] loss: 3.30143, MAE: 0.23822, time/step=835ms, lr=4.92e-05
2024-03-21 11:25:30,786 - logger.py:50 - Epoch: [12][50/500] loss: 3.37192, MAE: 0.21989, time/step=1242ms, lr=4.92e-05
2024-03-21 11:26:32,929 - logger.py:50 - Epoch: [12][100/500] loss: 4.48765, MAE: 0.26327, time/step=1243ms, lr=4.92e-05
2024-03-21 11:27:34,065 - logger.py:50 - Epoch: [12][150/500] loss: 4.09985, MAE: 0.25452, time/step=1236ms, lr=4.92e-05
2024-03-21 11:28:36,777 - logger.py:50 - Epoch: [12][200/500] loss: 3.91433, MAE: 0.24675, time/step=1241ms, lr=4.92e-05
2024-03-21 11:29:39,282 - logger.py:50 - Epoch: [12][250/500] loss: 3.79553, MAE: 0.24188, time/step=1242ms, lr=4.92e-05
2024-03-21 11:30:42,130 - logger.py:50 - Epoch: [12][300/500] loss: 3.89109, MAE: 0.24754, time/step=1245ms, lr=4.92e-05
2024-03-21 11:31:43,689 - logger.py:50 - Epoch: [12][350/500] loss: 3.81604, MAE: 0.24560, time/step=1243ms, lr=4.92e-05
2024-03-21 11:32:46,564 - logger.py:50 - Epoch: [12][400/500] loss: 3.75100, MAE: 0.24290, time/step=1245ms, lr=4.92e-05
2024-03-21 11:33:47,977 - logger.py:50 - Epoch: [12][450/500] loss: 3.70372, MAE: 0.24088, time/step=1243ms, lr=4.92e-05
2024-03-21 11:34:48,827 - logger.py:50 - Epoch: [12][499/500] loss: 3.67221, MAE: 0.23902, time/step=1243ms, lr=4.92e-05
2024-03-21 11:36:06,640 - logger.py:50 - Epoch: [12] train loss: 3.67221, train MAE: 0.23902,val loss: 3.27677, val MAE: 0.21214,test loss: 3.33471, test MAE: 0.22191,Time: 699.21s
2024-03-21 11:36:06,640 - logger.py:50 - Best -- epoch=12, train loss: 3.67221, val loss: 3.27677, test loss: 3.33471

2024-03-21 11:37:17,152 - logger.py:50 - Epoch: [12]EMA val MAE: 0.87670, EMA test MAE: 0.89212, Time: 769.73s
2024-03-21 11:37:17,152 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 11:37:18,417 - logger.py:50 - Epoch: [13][0/500] loss: 3.23836, MAE: 0.22033, time/step=1262ms, lr=4.91e-05
2024-03-21 11:38:16,139 - logger.py:50 - Epoch: [13][50/500] loss: 3.31671, MAE: 0.21886, time/step=1157ms, lr=4.91e-05
2024-03-21 11:39:20,607 - logger.py:50 - Epoch: [13][100/500] loss: 3.31841, MAE: 0.21967, time/step=1222ms, lr=4.91e-05
2024-03-21 11:40:23,227 - logger.py:50 - Epoch: [13][150/500] loss: 3.31519, MAE: 0.21946, time/step=1232ms, lr=4.91e-05
2024-03-21 11:41:25,551 - logger.py:50 - Epoch: [13][200/500] loss: 3.30928, MAE: 0.22000, time/step=1236ms, lr=4.91e-05
2024-03-21 11:42:27,328 - logger.py:50 - Epoch: [13][250/500] loss: 3.31380, MAE: 0.21961, time/step=1236ms, lr=4.91e-05
2024-03-21 11:43:25,687 - logger.py:50 - Epoch: [13][300/500] loss: 3.30788, MAE: 0.21935, time/step=1224ms, lr=4.91e-05
2024-03-21 11:44:23,455 - logger.py:50 - Epoch: [13][350/500] loss: 3.31171, MAE: 0.22006, time/step=1215ms, lr=4.91e-05
2024-03-21 11:45:26,539 - logger.py:50 - Epoch: [13][400/500] loss: 3.31138, MAE: 0.21910, time/step=1220ms, lr=4.91e-05
2024-03-21 11:46:29,841 - logger.py:50 - Epoch: [13][450/500] loss: 3.67698, MAE: 0.23213, time/step=1225ms, lr=4.91e-05
2024-03-21 11:47:31,707 - logger.py:50 - Epoch: [13][499/500] loss: 3.65216, MAE: 0.23250, time/step=1229ms, lr=4.91e-05
2024-03-21 11:48:44,623 - logger.py:50 - Epoch: [13] train loss: 3.65216, train MAE: 0.23250,val loss: 3.26744, val MAE: 0.22773,test loss: 3.31509, test MAE: 0.23651,Time: 687.47s
2024-03-21 11:48:44,623 - logger.py:50 - Best -- epoch=13, train loss: 3.65216, val loss: 3.26744, test loss: 3.31509

2024-03-21 11:49:51,751 - logger.py:50 - Epoch: [13]EMA val MAE: 0.83559, EMA test MAE: 0.85082, Time: 754.60s
2024-03-21 11:49:51,751 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 11:49:53,055 - logger.py:50 - Epoch: [14][0/500] loss: 3.18704, MAE: 0.22407, time/step=1301ms, lr=4.90e-05
2024-03-21 11:50:50,038 - logger.py:50 - Epoch: [14][50/500] loss: 3.35821, MAE: 0.22338, time/step=1143ms, lr=4.90e-05
2024-03-21 11:51:47,036 - logger.py:50 - Epoch: [14][100/500] loss: 3.34070, MAE: 0.22712, time/step=1141ms, lr=4.90e-05
2024-03-21 11:52:44,923 - logger.py:50 - Epoch: [14][150/500] loss: 3.33048, MAE: 0.22250, time/step=1147ms, lr=4.90e-05
2024-03-21 11:53:41,726 - logger.py:50 - Epoch: [14][200/500] loss: 3.57753, MAE: 0.22870, time/step=1144ms, lr=4.90e-05
2024-03-21 11:54:39,626 - logger.py:50 - Epoch: [14][250/500] loss: 3.52813, MAE: 0.23095, time/step=1147ms, lr=4.90e-05
2024-03-21 11:55:36,489 - logger.py:50 - Epoch: [14][300/500] loss: 3.49463, MAE: 0.22858, time/step=1145ms, lr=4.90e-05
2024-03-21 11:56:33,300 - logger.py:50 - Epoch: [14][350/500] loss: 3.79421, MAE: 0.23905, time/step=1144ms, lr=4.90e-05
2024-03-21 11:57:30,625 - logger.py:50 - Epoch: [14][400/500] loss: 3.73475, MAE: 0.23665, time/step=1144ms, lr=4.90e-05
2024-03-21 11:58:29,320 - logger.py:50 - Epoch: [14][450/500] loss: 3.68108, MAE: 0.23332, time/step=1148ms, lr=4.90e-05
2024-03-21 11:59:29,901 - logger.py:50 - Epoch: [14][499/500] loss: 3.64248, MAE: 0.23182, time/step=1156ms, lr=4.90e-05
2024-03-21 12:00:44,677 - logger.py:50 - Epoch: [14] train loss: 3.64248, train MAE: 0.23182,val loss: 3.25015, val MAE: 0.20746,test loss: 3.29418, test MAE: 0.21586,Time: 652.93s
2024-03-21 12:00:44,677 - logger.py:50 - Best -- epoch=14, train loss: 3.64248, val loss: 3.25015, test loss: 3.29418

2024-03-21 12:02:02,048 - logger.py:50 - Epoch: [14]EMA val MAE: 0.79763, EMA test MAE: 0.81277, Time: 730.30s
2024-03-21 12:02:02,048 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 12:02:02,951 - logger.py:50 - Epoch: [15][0/500] loss: 3.28536, MAE: 0.21011, time/step=901ms, lr=4.88e-05
2024-03-21 12:03:04,394 - logger.py:50 - Epoch: [15][50/500] loss: 3.34060, MAE: 0.21737, time/step=1222ms, lr=4.88e-05
2024-03-21 12:04:05,088 - logger.py:50 - Epoch: [15][100/500] loss: 3.31949, MAE: 0.21460, time/step=1218ms, lr=4.88e-05
2024-03-21 12:05:07,211 - logger.py:50 - Epoch: [15][150/500] loss: 3.30964, MAE: 0.21397, time/step=1226ms, lr=4.88e-05
2024-03-21 12:06:07,151 - logger.py:50 - Epoch: [15][200/500] loss: 3.31944, MAE: 0.21487, time/step=1219ms, lr=4.88e-05
2024-03-21 12:07:09,537 - logger.py:50 - Epoch: [15][250/500] loss: 3.31725, MAE: 0.21407, time/step=1225ms, lr=4.88e-05
2024-03-21 12:08:11,114 - logger.py:50 - Epoch: [15][300/500] loss: 3.30811, MAE: 0.21397, time/step=1226ms, lr=4.88e-05
2024-03-21 12:09:13,040 - logger.py:50 - Epoch: [15][350/500] loss: 3.29941, MAE: 0.21302, time/step=1228ms, lr=4.88e-05
2024-03-21 12:10:14,482 - logger.py:50 - Epoch: [15][400/500] loss: 3.30495, MAE: 0.21474, time/step=1228ms, lr=4.88e-05
2024-03-21 12:11:15,777 - logger.py:50 - Epoch: [15][450/500] loss: 3.66363, MAE: 0.22313, time/step=1228ms, lr=4.88e-05
2024-03-21 12:12:15,450 - logger.py:50 - Epoch: [15][499/500] loss: 3.62845, MAE: 0.22587, time/step=1227ms, lr=4.88e-05
2024-03-21 12:13:27,066 - logger.py:50 - Epoch: [15] train loss: 3.62845, train MAE: 0.22587,val loss: 3.24142, val MAE: 0.21161,test loss: 3.28824, test MAE: 0.22121,Time: 685.02s
2024-03-21 12:13:27,067 - logger.py:50 - Best -- epoch=15, train loss: 3.62845, val loss: 3.24142, test loss: 3.28824

2024-03-21 12:14:37,464 - logger.py:50 - Epoch: [15]EMA val MAE: 0.76249, EMA test MAE: 0.77774, Time: 755.42s
2024-03-21 12:14:37,465 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 12:14:39,025 - logger.py:50 - Epoch: [16][0/500] loss: 3.21449, MAE: 0.22596, time/step=1558ms, lr=4.86e-05
2024-03-21 12:15:38,409 - logger.py:50 - Epoch: [16][50/500] loss: 3.26164, MAE: 0.20734, time/step=1195ms, lr=4.86e-05
2024-03-21 12:16:38,925 - logger.py:50 - Epoch: [16][100/500] loss: 3.29305, MAE: 0.20921, time/step=1203ms, lr=4.86e-05
2024-03-21 12:17:40,159 - logger.py:50 - Epoch: [16][150/500] loss: 3.28415, MAE: 0.20831, time/step=1210ms, lr=4.86e-05
2024-03-21 12:18:40,256 - logger.py:50 - Epoch: [16][200/500] loss: 3.28515, MAE: 0.21072, time/step=1208ms, lr=4.86e-05
2024-03-21 12:19:42,358 - logger.py:50 - Epoch: [16][250/500] loss: 3.28457, MAE: 0.21051, time/step=1215ms, lr=4.86e-05
2024-03-21 12:20:43,690 - logger.py:50 - Epoch: [16][300/500] loss: 3.28648, MAE: 0.21038, time/step=1217ms, lr=4.86e-05
2024-03-21 12:21:43,135 - logger.py:50 - Epoch: [16][350/500] loss: 3.43702, MAE: 0.21801, time/step=1213ms, lr=4.86e-05
2024-03-21 12:22:41,632 - logger.py:50 - Epoch: [16][400/500] loss: 3.42393, MAE: 0.21818, time/step=1207ms, lr=4.86e-05
2024-03-21 12:23:37,237 - logger.py:50 - Epoch: [16][450/500] loss: 3.65983, MAE: 0.22591, time/step=1197ms, lr=4.86e-05
2024-03-21 12:24:30,945 - logger.py:50 - Epoch: [16][499/500] loss: 3.62074, MAE: 0.22525, time/step=1187ms, lr=4.86e-05
2024-03-21 12:25:35,320 - logger.py:50 - Epoch: [16] train loss: 3.62074, train MAE: 0.22525,val loss: 3.23738, val MAE: 0.20254,test loss: 3.27646, test MAE: 0.21148,Time: 657.85s
2024-03-21 12:25:35,320 - logger.py:50 - Best -- epoch=16, train loss: 3.62074, val loss: 3.23738, test loss: 3.27646

2024-03-21 12:26:38,042 - logger.py:50 - Epoch: [16]EMA val MAE: 0.73013, EMA test MAE: 0.74554, Time: 720.58s
2024-03-21 12:26:38,042 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 12:26:39,298 - logger.py:50 - Epoch: [17][0/500] loss: 3.35099, MAE: 0.20577, time/step=1253ms, lr=4.85e-05
2024-03-21 12:27:33,436 - logger.py:50 - Epoch: [17][50/500] loss: 4.28801, MAE: 0.22939, time/step=1086ms, lr=4.85e-05
2024-03-21 12:28:30,644 - logger.py:50 - Epoch: [17][100/500] loss: 4.90050, MAE: 0.25681, time/step=1115ms, lr=4.85e-05
2024-03-21 12:29:29,433 - logger.py:50 - Epoch: [17][150/500] loss: 4.38813, MAE: 0.24756, time/step=1135ms, lr=4.85e-05
2024-03-21 12:30:27,191 - logger.py:50 - Epoch: [17][200/500] loss: 4.11478, MAE: 0.23906, time/step=1140ms, lr=4.85e-05
2024-03-21 12:31:28,429 - logger.py:50 - Epoch: [17][250/500] loss: 3.94696, MAE: 0.23279, time/step=1157ms, lr=4.85e-05
2024-03-21 12:32:29,763 - logger.py:50 - Epoch: [17][300/500] loss: 3.83151, MAE: 0.22850, time/step=1168ms, lr=4.85e-05
2024-03-21 12:33:31,348 - logger.py:50 - Epoch: [17][350/500] loss: 3.74606, MAE: 0.22509, time/step=1178ms, lr=4.85e-05
2024-03-21 12:34:30,816 - logger.py:50 - Epoch: [17][400/500] loss: 3.68501, MAE: 0.22283, time/step=1179ms, lr=4.85e-05
2024-03-21 12:35:27,142 - logger.py:50 - Epoch: [17][450/500] loss: 3.64179, MAE: 0.22072, time/step=1173ms, lr=4.85e-05
2024-03-21 12:36:22,694 - logger.py:50 - Epoch: [17][499/500] loss: 3.60759, MAE: 0.21912, time/step=1169ms, lr=4.85e-05
2024-03-21 12:37:26,309 - logger.py:50 - Epoch: [17] train loss: 3.60759, train MAE: 0.21912,val loss: 3.22657, val MAE: 0.19556,test loss: 3.26705, test MAE: 0.20357,Time: 648.27s
2024-03-21 12:37:26,310 - logger.py:50 - Best -- epoch=17, train loss: 3.60759, val loss: 3.22657, test loss: 3.26705

2024-03-21 12:38:32,711 - logger.py:50 - Epoch: [17]EMA val MAE: 0.70049, EMA test MAE: 0.71605, Time: 714.67s
2024-03-21 12:38:32,711 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 12:38:34,085 - logger.py:50 - Epoch: [18][0/500] loss: 3.26130, MAE: 0.22954, time/step=1371ms, lr=4.83e-05
2024-03-21 12:39:37,153 - logger.py:50 - Epoch: [18][50/500] loss: 5.55507, MAE: 0.27905, time/step=1264ms, lr=4.83e-05
2024-03-21 12:40:34,690 - logger.py:50 - Epoch: [18][100/500] loss: 4.42781, MAE: 0.24710, time/step=1208ms, lr=4.83e-05
2024-03-21 12:41:38,396 - logger.py:50 - Epoch: [18][150/500] loss: 4.40530, MAE: 0.24864, time/step=1230ms, lr=4.83e-05
2024-03-21 12:42:39,369 - logger.py:50 - Epoch: [18][200/500] loss: 4.12283, MAE: 0.23945, time/step=1227ms, lr=4.83e-05
2024-03-21 12:43:42,395 - logger.py:50 - Epoch: [18][250/500] loss: 3.94642, MAE: 0.23188, time/step=1234ms, lr=4.83e-05
2024-03-21 12:44:39,554 - logger.py:50 - Epoch: [18][300/500] loss: 3.83448, MAE: 0.22785, time/step=1219ms, lr=4.83e-05
2024-03-21 12:45:43,142 - logger.py:50 - Epoch: [18][350/500] loss: 3.74682, MAE: 0.22371, time/step=1226ms, lr=4.83e-05
2024-03-21 12:47:13,189 - logger.py:50 - Epoch: [18][400/500] loss: 3.68360, MAE: 0.22042, time/step=1298ms, lr=4.83e-05
2024-03-21 12:48:44,360 - logger.py:50 - Epoch: [18][450/500] loss: 3.63978, MAE: 0.21873, time/step=1356ms, lr=4.83e-05
2024-03-21 12:50:18,544 - logger.py:50 - Epoch: [18][499/500] loss: 3.60152, MAE: 0.21732, time/step=1412ms, lr=4.83e-05
2024-03-21 12:52:07,378 - logger.py:50 - Epoch: [18] train loss: 3.60152, train MAE: 0.21732,val loss: 3.22143, val MAE: 0.19720,test loss: 3.25841, test MAE: 0.20511,Time: 814.67s
2024-03-21 12:52:07,378 - logger.py:50 - Best -- epoch=18, train loss: 3.60152, val loss: 3.22143, test loss: 3.25841

2024-03-21 12:53:56,773 - logger.py:50 - Epoch: [18]EMA val MAE: 0.67324, EMA test MAE: 0.68877, Time: 924.06s
2024-03-21 12:53:56,773 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 12:53:58,514 - logger.py:50 - Epoch: [19][0/500] loss: 3.31279, MAE: 0.21476, time/step=1738ms, lr=4.81e-05
2024-03-21 12:55:19,370 - logger.py:50 - Epoch: [19][50/500] loss: 3.26208, MAE: 0.19985, time/step=1620ms, lr=4.81e-05
2024-03-21 12:56:14,438 - logger.py:50 - Epoch: [19][100/500] loss: 3.25170, MAE: 0.20126, time/step=1363ms, lr=4.81e-05
2024-03-21 12:57:11,853 - logger.py:50 - Epoch: [19][150/500] loss: 3.26916, MAE: 0.20414, time/step=1292ms, lr=4.81e-05
2024-03-21 12:58:07,273 - logger.py:50 - Epoch: [19][200/500] loss: 3.27020, MAE: 0.20440, time/step=1246ms, lr=4.81e-05
2024-03-21 12:59:05,527 - logger.py:50 - Epoch: [19][250/500] loss: 3.47994, MAE: 0.21415, time/step=1230ms, lr=4.81e-05
2024-03-21 13:00:14,033 - logger.py:50 - Epoch: [19][300/500] loss: 3.44863, MAE: 0.21589, time/step=1253ms, lr=4.81e-05
2024-03-21 13:01:34,458 - logger.py:50 - Epoch: [19][350/500] loss: 3.74366, MAE: 0.22299, time/step=1304ms, lr=4.81e-05
2024-03-21 13:02:55,052 - logger.py:50 - Epoch: [19][400/500] loss: 3.68027, MAE: 0.22011, time/step=1342ms, lr=4.81e-05
2024-03-21 13:04:16,464 - logger.py:50 - Epoch: [19][450/500] loss: 3.63364, MAE: 0.21813, time/step=1374ms, lr=4.81e-05
2024-03-21 13:05:34,893 - logger.py:50 - Epoch: [19][499/500] loss: 3.59250, MAE: 0.21548, time/step=1396ms, lr=4.81e-05
2024-03-21 13:07:13,713 - logger.py:50 - Epoch: [19] train loss: 3.59250, train MAE: 0.21548,val loss: 3.21335, val MAE: 0.19083,test loss: 3.25103, test MAE: 0.19926,Time: 796.94s
2024-03-21 13:07:13,713 - logger.py:50 - Best -- epoch=19, train loss: 3.59250, val loss: 3.21335, test loss: 3.25103

2024-03-21 13:08:50,153 - logger.py:50 - Epoch: [19]EMA val MAE: 0.64834, EMA test MAE: 0.66378, Time: 893.38s
2024-03-21 13:08:50,154 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 13:08:51,841 - logger.py:50 - Epoch: [20][0/500] loss: 3.23371, MAE: 0.20547, time/step=1685ms, lr=4.79e-05
2024-03-21 13:10:12,269 - logger.py:50 - Epoch: [20][50/500] loss: 3.24958, MAE: 0.20093, time/step=1610ms, lr=4.79e-05
2024-03-21 13:11:32,887 - logger.py:50 - Epoch: [20][100/500] loss: 4.34577, MAE: 0.22360, time/step=1611ms, lr=4.79e-05
2024-03-21 13:12:51,616 - logger.py:50 - Epoch: [20][150/500] loss: 4.33484, MAE: 0.23200, time/step=1599ms, lr=4.79e-05
2024-03-21 13:14:09,330 - logger.py:50 - Epoch: [20][200/500] loss: 4.06382, MAE: 0.22510, time/step=1588ms, lr=4.79e-05
2024-03-21 13:15:27,187 - logger.py:50 - Epoch: [20][250/500] loss: 3.90743, MAE: 0.22144, time/step=1582ms, lr=4.79e-05
2024-03-21 13:16:46,372 - logger.py:50 - Epoch: [20][300/500] loss: 3.79669, MAE: 0.21680, time/step=1582ms, lr=4.79e-05
2024-03-21 13:18:03,828 - logger.py:50 - Epoch: [20][350/500] loss: 3.73232, MAE: 0.21560, time/step=1577ms, lr=4.79e-05
2024-03-21 13:19:23,459 - logger.py:50 - Epoch: [20][400/500] loss: 3.67104, MAE: 0.21371, time/step=1579ms, lr=4.79e-05
2024-03-21 13:20:45,039 - logger.py:50 - Epoch: [20][450/500] loss: 3.62427, MAE: 0.21258, time/step=1585ms, lr=4.79e-05
2024-03-21 13:21:54,045 - logger.py:50 - Epoch: [20][499/500] loss: 3.58381, MAE: 0.21090, time/step=1568ms, lr=4.79e-05
2024-03-21 13:23:06,438 - logger.py:50 - Epoch: [20] train loss: 3.58381, train MAE: 0.21090,val loss: 3.20970, val MAE: 0.18728,test loss: 3.24698, test MAE: 0.19578,Time: 856.28s
2024-03-21 13:23:06,438 - logger.py:50 - Best -- epoch=20, train loss: 3.58381, val loss: 3.20970, test loss: 3.24698

2024-03-21 13:24:17,475 - logger.py:50 - Epoch: [20]EMA val MAE: 0.62561, EMA test MAE: 0.64084, Time: 927.32s
2024-03-21 13:24:17,475 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 13:24:18,784 - logger.py:50 - Epoch: [21][0/500] loss: 3.88911, MAE: 0.20596, time/step=1307ms, lr=4.77e-05
2024-03-21 13:25:21,049 - logger.py:50 - Epoch: [21][50/500] loss: 3.23572, MAE: 0.19538, time/step=1247ms, lr=4.77e-05
2024-03-21 13:26:17,143 - logger.py:50 - Epoch: [21][100/500] loss: 3.23425, MAE: 0.19512, time/step=1185ms, lr=4.77e-05
2024-03-21 13:27:12,590 - logger.py:50 - Epoch: [21][150/500] loss: 3.24289, MAE: 0.19690, time/step=1160ms, lr=4.77e-05
2024-03-21 13:28:08,672 - logger.py:50 - Epoch: [21][200/500] loss: 3.23946, MAE: 0.19652, time/step=1150ms, lr=4.77e-05
2024-03-21 13:29:04,893 - logger.py:50 - Epoch: [21][250/500] loss: 3.89158, MAE: 0.21916, time/step=1145ms, lr=4.77e-05
2024-03-21 13:29:59,629 - logger.py:50 - Epoch: [21][300/500] loss: 3.78830, MAE: 0.21855, time/step=1137ms, lr=4.77e-05
2024-03-21 13:30:55,275 - logger.py:50 - Epoch: [21][350/500] loss: 3.71753, MAE: 0.21642, time/step=1133ms, lr=4.77e-05
2024-03-21 13:31:51,657 - logger.py:50 - Epoch: [21][400/500] loss: 3.66543, MAE: 0.21494, time/step=1133ms, lr=4.77e-05
2024-03-21 13:32:47,821 - logger.py:50 - Epoch: [21][450/500] loss: 3.61735, MAE: 0.21281, time/step=1132ms, lr=4.77e-05
2024-03-21 13:33:46,551 - logger.py:50 - Epoch: [21][499/500] loss: 3.58227, MAE: 0.21165, time/step=1138ms, lr=4.77e-05
2024-03-21 13:34:50,895 - logger.py:50 - Epoch: [21] train loss: 3.58227, train MAE: 0.21165,val loss: 3.21048, val MAE: 0.19004,test loss: 3.24762, test MAE: 0.19824,Time: 633.42s
2024-03-21 13:34:50,895 - logger.py:50 - Best -- epoch=20, train loss: 3.58381, val loss: 3.20970, test loss: 3.24698

2024-03-21 13:35:53,340 - logger.py:50 - Epoch: [21]EMA val MAE: 0.60501, EMA test MAE: 0.62004, Time: 695.86s
2024-03-21 13:35:53,340 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 13:35:54,734 - logger.py:50 - Epoch: [22][0/500] loss: 3.21111, MAE: 0.17978, time/step=1391ms, lr=4.74e-05
2024-03-21 13:37:04,194 - logger.py:50 - Epoch: [22][50/500] loss: 3.32445, MAE: 0.19851, time/step=1389ms, lr=4.74e-05
2024-03-21 13:38:11,835 - logger.py:50 - Epoch: [22][100/500] loss: 4.40898, MAE: 0.22902, time/step=1371ms, lr=4.74e-05
2024-03-21 13:39:10,018 - logger.py:50 - Epoch: [22][150/500] loss: 4.02437, MAE: 0.22103, time/step=1302ms, lr=4.74e-05
2024-03-21 13:40:07,274 - logger.py:50 - Epoch: [22][200/500] loss: 3.83106, MAE: 0.21625, time/step=1263ms, lr=4.74e-05
2024-03-21 13:41:05,357 - logger.py:50 - Epoch: [22][250/500] loss: 3.71294, MAE: 0.21296, time/step=1243ms, lr=4.74e-05
2024-03-21 13:42:04,302 - logger.py:50 - Epoch: [22][300/500] loss: 3.63358, MAE: 0.20928, time/step=1232ms, lr=4.74e-05
2024-03-21 13:43:04,557 - logger.py:50 - Epoch: [22][350/500] loss: 3.72703, MAE: 0.21387, time/step=1229ms, lr=4.74e-05
2024-03-21 13:44:07,015 - logger.py:50 - Epoch: [22][400/500] loss: 3.66569, MAE: 0.21182, time/step=1231ms, lr=4.74e-05
2024-03-21 13:45:08,714 - logger.py:50 - Epoch: [22][450/500] loss: 3.61420, MAE: 0.20957, time/step=1231ms, lr=4.74e-05
2024-03-21 13:46:08,354 - logger.py:50 - Epoch: [22][499/500] loss: 3.57674, MAE: 0.20879, time/step=1230ms, lr=4.74e-05
2024-03-21 13:47:19,509 - logger.py:50 - Epoch: [22] train loss: 3.57674, train MAE: 0.20879,val loss: 3.20490, val MAE: 0.18752,test loss: 3.23807, test MAE: 0.19505,Time: 686.17s
2024-03-21 13:47:19,509 - logger.py:50 - Best -- epoch=22, train loss: 3.57674, val loss: 3.20490, test loss: 3.23807

2024-03-21 13:48:29,573 - logger.py:50 - Epoch: [22]EMA val MAE: 0.58614, EMA test MAE: 0.60096, Time: 756.23s
2024-03-21 13:48:29,574 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 13:48:30,521 - logger.py:50 - Epoch: [23][0/500] loss: 3.13920, MAE: 0.17085, time/step=945ms, lr=4.72e-05
2024-03-21 13:49:31,142 - logger.py:50 - Epoch: [23][50/500] loss: 3.25154, MAE: 0.19959, time/step=1207ms, lr=4.72e-05
2024-03-21 13:50:31,611 - logger.py:50 - Epoch: [23][100/500] loss: 3.78794, MAE: 0.22191, time/step=1208ms, lr=4.72e-05
2024-03-21 13:51:34,662 - logger.py:50 - Epoch: [23][150/500] loss: 3.60892, MAE: 0.21504, time/step=1226ms, lr=4.72e-05
2024-03-21 13:52:38,821 - logger.py:50 - Epoch: [23][200/500] loss: 4.07216, MAE: 0.22376, time/step=1240ms, lr=4.72e-05
2024-03-21 13:53:42,268 - logger.py:50 - Epoch: [23][250/500] loss: 3.90433, MAE: 0.21857, time/step=1246ms, lr=4.72e-05
2024-03-21 13:54:45,985 - logger.py:50 - Epoch: [23][300/500] loss: 3.79578, MAE: 0.21541, time/step=1251ms, lr=4.72e-05
2024-03-21 13:55:49,746 - logger.py:50 - Epoch: [23][350/500] loss: 3.71452, MAE: 0.21199, time/step=1254ms, lr=4.72e-05
2024-03-21 13:56:52,813 - logger.py:50 - Epoch: [23][400/500] loss: 3.65401, MAE: 0.20956, time/step=1255ms, lr=4.72e-05
2024-03-21 13:57:57,327 - logger.py:50 - Epoch: [23][450/500] loss: 3.60934, MAE: 0.20792, time/step=1259ms, lr=4.72e-05
2024-03-21 13:58:59,119 - logger.py:50 - Epoch: [23][499/500] loss: 3.57301, MAE: 0.20702, time/step=1259ms, lr=4.72e-05
2024-03-21 14:00:18,218 - logger.py:50 - Epoch: [23] train loss: 3.57301, train MAE: 0.20702,val loss: 3.20543, val MAE: 0.18974,test loss: 3.23597, test MAE: 0.19675,Time: 708.64s
2024-03-21 14:00:18,218 - logger.py:50 - Best -- epoch=22, train loss: 3.57674, val loss: 3.20490, test loss: 3.23807

2024-03-21 14:01:35,657 - logger.py:50 - Epoch: [23]EMA val MAE: 0.56916, EMA test MAE: 0.58369, Time: 786.08s
2024-03-21 14:01:35,657 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 14:01:37,133 - logger.py:50 - Epoch: [24][0/500] loss: 3.11596, MAE: 0.17470, time/step=1473ms, lr=4.70e-05
2024-03-21 14:02:43,917 - logger.py:50 - Epoch: [24][50/500] loss: 3.23588, MAE: 0.19468, time/step=1338ms, lr=4.70e-05
2024-03-21 14:03:47,890 - logger.py:50 - Epoch: [24][100/500] loss: 3.24669, MAE: 0.19466, time/step=1309ms, lr=4.70e-05
2024-03-21 14:04:52,919 - logger.py:50 - Epoch: [24][150/500] loss: 3.23839, MAE: 0.19441, time/step=1306ms, lr=4.70e-05
2024-03-21 14:05:57,374 - logger.py:50 - Epoch: [24][200/500] loss: 3.24211, MAE: 0.19430, time/step=1302ms, lr=4.70e-05
2024-03-21 14:07:01,652 - logger.py:50 - Epoch: [24][250/500] loss: 3.23674, MAE: 0.19344, time/step=1299ms, lr=4.70e-05
2024-03-21 14:08:06,222 - logger.py:50 - Epoch: [24][300/500] loss: 3.23522, MAE: 0.19293, time/step=1298ms, lr=4.70e-05
2024-03-21 14:09:09,599 - logger.py:50 - Epoch: [24][350/500] loss: 3.23484, MAE: 0.19262, time/step=1293ms, lr=4.70e-05
2024-03-21 14:10:15,004 - logger.py:50 - Epoch: [24][400/500] loss: 3.64643, MAE: 0.20503, time/step=1295ms, lr=4.70e-05
2024-03-21 14:11:19,663 - logger.py:50 - Epoch: [24][450/500] loss: 3.60632, MAE: 0.20618, time/step=1295ms, lr=4.70e-05
2024-03-21 14:12:23,661 - logger.py:50 - Epoch: [24][499/500] loss: 3.56653, MAE: 0.20494, time/step=1296ms, lr=4.70e-05
2024-03-21 14:13:40,533 - logger.py:50 - Epoch: [24] train loss: 3.56653, train MAE: 0.20494,val loss: 3.20150, val MAE: 0.19388,test loss: 3.22954, test MAE: 0.20044,Time: 724.88s
2024-03-21 14:13:40,533 - logger.py:50 - Best -- epoch=24, train loss: 3.56653, val loss: 3.20150, test loss: 3.22954

2024-03-21 14:14:56,215 - logger.py:50 - Epoch: [24]EMA val MAE: 0.55372, EMA test MAE: 0.56789, Time: 800.56s
2024-03-21 14:14:56,215 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 14:14:57,665 - logger.py:50 - Epoch: [25][0/500] loss: 3.18378, MAE: 0.19602, time/step=1448ms, lr=4.67e-05
2024-03-21 14:16:01,049 - logger.py:50 - Epoch: [25][50/500] loss: 3.23891, MAE: 0.19261, time/step=1271ms, lr=4.67e-05
2024-03-21 14:17:04,685 - logger.py:50 - Epoch: [25][100/500] loss: 3.26494, MAE: 0.19668, time/step=1272ms, lr=4.67e-05
2024-03-21 14:18:07,775 - logger.py:50 - Epoch: [25][150/500] loss: 3.24099, MAE: 0.19297, time/step=1269ms, lr=4.67e-05
2024-03-21 14:19:12,372 - logger.py:50 - Epoch: [25][200/500] loss: 3.23851, MAE: 0.19337, time/step=1274ms, lr=4.67e-05
2024-03-21 14:20:16,975 - logger.py:50 - Epoch: [25][250/500] loss: 3.44865, MAE: 0.20027, time/step=1278ms, lr=4.67e-05
2024-03-21 14:21:22,834 - logger.py:50 - Epoch: [25][300/500] loss: 3.41576, MAE: 0.20012, time/step=1284ms, lr=4.67e-05
2024-03-21 14:22:24,349 - logger.py:50 - Epoch: [25][350/500] loss: 3.70451, MAE: 0.20477, time/step=1277ms, lr=4.67e-05
2024-03-21 14:23:28,847 - logger.py:50 - Epoch: [25][400/500] loss: 3.64483, MAE: 0.20606, time/step=1278ms, lr=4.67e-05
2024-03-21 14:24:31,367 - logger.py:50 - Epoch: [25][450/500] loss: 3.60147, MAE: 0.20476, time/step=1275ms, lr=4.67e-05
2024-03-21 14:25:36,199 - logger.py:50 - Epoch: [25][499/500] loss: 3.56389, MAE: 0.20376, time/step=1280ms, lr=4.67e-05
2024-03-21 14:26:52,653 - logger.py:50 - Epoch: [25] train loss: 3.56389, train MAE: 0.20376,val loss: 3.20057, val MAE: 0.18751,test loss: 3.22795, test MAE: 0.19448,Time: 716.44s
2024-03-21 14:26:52,653 - logger.py:50 - Best -- epoch=25, train loss: 3.56389, val loss: 3.20057, test loss: 3.22795

2024-03-21 14:28:08,845 - logger.py:50 - Epoch: [25]EMA val MAE: 0.53997, EMA test MAE: 0.55376, Time: 792.63s
2024-03-21 14:28:08,845 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 14:28:10,281 - logger.py:50 - Epoch: [26][0/500] loss: 3.05294, MAE: 0.15850, time/step=1434ms, lr=4.65e-05
2024-03-21 14:29:14,201 - logger.py:50 - Epoch: [26][50/500] loss: 5.40631, MAE: 0.23608, time/step=1281ms, lr=4.65e-05
2024-03-21 14:30:17,271 - logger.py:50 - Epoch: [26][100/500] loss: 4.35996, MAE: 0.22179, time/step=1272ms, lr=4.65e-05
2024-03-21 14:31:22,920 - logger.py:50 - Epoch: [26][150/500] loss: 4.00399, MAE: 0.21240, time/step=1285ms, lr=4.65e-05
2024-03-21 14:32:27,978 - logger.py:50 - Epoch: [26][200/500] loss: 3.80450, MAE: 0.20741, time/step=1289ms, lr=4.65e-05
2024-03-21 14:33:32,022 - logger.py:50 - Epoch: [26][250/500] loss: 3.69328, MAE: 0.20464, time/step=1288ms, lr=4.65e-05
2024-03-21 14:34:33,944 - logger.py:50 - Epoch: [26][300/500] loss: 3.61474, MAE: 0.20179, time/step=1279ms, lr=4.65e-05
2024-03-21 14:35:38,098 - logger.py:50 - Epoch: [26][350/500] loss: 3.70521, MAE: 0.20402, time/step=1280ms, lr=4.65e-05
2024-03-21 14:36:42,257 - logger.py:50 - Epoch: [26][400/500] loss: 3.64532, MAE: 0.20417, time/step=1280ms, lr=4.65e-05
2024-03-21 14:37:46,247 - logger.py:50 - Epoch: [26][450/500] loss: 3.59759, MAE: 0.20251, time/step=1280ms, lr=4.65e-05
2024-03-21 14:38:50,031 - logger.py:50 - Epoch: [26][499/500] loss: 3.55880, MAE: 0.20123, time/step=1282ms, lr=4.65e-05
2024-03-21 14:40:12,920 - logger.py:50 - Epoch: [26] train loss: 3.55880, train MAE: 0.20123,val loss: 3.19375, val MAE: 0.18460,test loss: 3.22161, test MAE: 0.19184,Time: 724.08s
2024-03-21 14:40:12,920 - logger.py:50 - Best -- epoch=26, train loss: 3.55880, val loss: 3.19375, test loss: 3.22161

2024-03-21 14:41:32,044 - logger.py:50 - Epoch: [26]EMA val MAE: 0.52746, EMA test MAE: 0.54087, Time: 803.20s
2024-03-21 14:41:32,044 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 14:41:33,630 - logger.py:50 - Epoch: [27][0/500] loss: 3.25556, MAE: 0.20231, time/step=1584ms, lr=4.62e-05
2024-03-21 14:42:38,075 - logger.py:50 - Epoch: [27][50/500] loss: 3.19611, MAE: 0.18666, time/step=1295ms, lr=4.62e-05
2024-03-21 14:43:42,612 - logger.py:50 - Epoch: [27][100/500] loss: 3.71582, MAE: 0.20137, time/step=1293ms, lr=4.62e-05
2024-03-21 14:44:48,831 - logger.py:50 - Epoch: [27][150/500] loss: 4.28637, MAE: 0.21868, time/step=1303ms, lr=4.62e-05
2024-03-21 14:45:52,223 - logger.py:50 - Epoch: [27][200/500] loss: 4.02489, MAE: 0.21211, time/step=1294ms, lr=4.62e-05
2024-03-21 14:46:55,603 - logger.py:50 - Epoch: [27][250/500] loss: 3.86713, MAE: 0.20660, time/step=1289ms, lr=4.62e-05
2024-03-21 14:47:56,024 - logger.py:50 - Epoch: [27][300/500] loss: 3.75895, MAE: 0.20343, time/step=1276ms, lr=4.62e-05
2024-03-21 14:48:59,286 - logger.py:50 - Epoch: [27][350/500] loss: 3.69627, MAE: 0.20301, time/step=1274ms, lr=4.62e-05
2024-03-21 14:50:00,953 - logger.py:50 - Epoch: [27][400/500] loss: 3.63638, MAE: 0.20152, time/step=1269ms, lr=4.62e-05
2024-03-21 14:51:03,708 - logger.py:50 - Epoch: [27][450/500] loss: 3.59260, MAE: 0.20037, time/step=1268ms, lr=4.62e-05
2024-03-21 14:52:04,870 - logger.py:50 - Epoch: [27][499/500] loss: 3.55576, MAE: 0.19958, time/step=1266ms, lr=4.62e-05
2024-03-21 14:53:19,157 - logger.py:50 - Epoch: [27] train loss: 3.55576, train MAE: 0.19958,val loss: 3.19198, val MAE: 0.18015,test loss: 3.22129, test MAE: 0.18792,Time: 707.11s
2024-03-21 14:53:19,161 - logger.py:50 - Best -- epoch=27, train loss: 3.55576, val loss: 3.19198, test loss: 3.22129

2024-03-21 14:54:28,355 - logger.py:50 - Epoch: [27]EMA val MAE: 0.51615, EMA test MAE: 0.52919, Time: 776.31s
2024-03-21 14:54:28,355 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 14:54:29,286 - logger.py:50 - Epoch: [28][0/500] loss: 3.15353, MAE: 0.18230, time/step=927ms, lr=4.59e-05
2024-03-21 14:55:29,753 - logger.py:50 - Epoch: [28][50/500] loss: 3.21931, MAE: 0.18600, time/step=1204ms, lr=4.59e-05
2024-03-21 14:56:28,411 - logger.py:50 - Epoch: [28][100/500] loss: 3.23393, MAE: 0.18987, time/step=1189ms, lr=4.59e-05
2024-03-21 14:57:28,227 - logger.py:50 - Epoch: [28][150/500] loss: 3.23221, MAE: 0.18955, time/step=1191ms, lr=4.59e-05
2024-03-21 14:58:27,383 - logger.py:50 - Epoch: [28][200/500] loss: 3.49322, MAE: 0.20158, time/step=1189ms, lr=4.59e-05
2024-03-21 14:59:25,428 - logger.py:50 - Epoch: [28][250/500] loss: 3.43662, MAE: 0.19924, time/step=1184ms, lr=4.59e-05
2024-03-21 15:00:23,285 - logger.py:50 - Epoch: [28][300/500] loss: 3.39830, MAE: 0.19736, time/step=1179ms, lr=4.59e-05
2024-03-21 15:01:20,025 - logger.py:50 - Epoch: [28][350/500] loss: 3.36965, MAE: 0.19582, time/step=1173ms, lr=4.59e-05
2024-03-21 15:02:17,241 - logger.py:50 - Epoch: [28][400/500] loss: 3.35201, MAE: 0.19466, time/step=1169ms, lr=4.59e-05
2024-03-21 15:03:15,395 - logger.py:50 - Epoch: [28][450/500] loss: 3.33743, MAE: 0.19417, time/step=1169ms, lr=4.59e-05
2024-03-21 15:04:12,504 - logger.py:50 - Epoch: [28][499/500] loss: 3.55284, MAE: 0.19740, time/step=1168ms, lr=4.59e-05
2024-03-21 15:05:18,587 - logger.py:50 - Epoch: [28] train loss: 3.55284, train MAE: 0.19740,val loss: 3.29880, val MAE: 0.27363,test loss: 3.33503, test MAE: 0.28349,Time: 650.23s
2024-03-21 15:05:18,587 - logger.py:50 - Best -- epoch=27, train loss: 3.55576, val loss: 3.19198, test loss: 3.22129

2024-03-21 15:06:23,737 - logger.py:50 - Epoch: [28]EMA val MAE: 0.50574, EMA test MAE: 0.51848, Time: 715.38s
2024-03-21 15:06:23,738 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 15:06:25,093 - logger.py:50 - Epoch: [29][0/500] loss: 3.26440, MAE: 0.26333, time/step=1353ms, lr=4.56e-05
2024-03-21 15:07:23,401 - logger.py:50 - Epoch: [29][50/500] loss: 3.24198, MAE: 0.22487, time/step=1170ms, lr=4.56e-05
2024-03-21 15:08:20,773 - logger.py:50 - Epoch: [29][100/500] loss: 3.22050, MAE: 0.20757, time/step=1159ms, lr=4.56e-05
2024-03-21 15:09:17,786 - logger.py:50 - Epoch: [29][150/500] loss: 3.94970, MAE: 0.21768, time/step=1153ms, lr=4.56e-05
2024-03-21 15:10:15,364 - logger.py:50 - Epoch: [29][200/500] loss: 3.77439, MAE: 0.21129, time/step=1152ms, lr=4.56e-05
2024-03-21 15:11:11,502 - logger.py:50 - Epoch: [29][250/500] loss: 3.65928, MAE: 0.20711, time/step=1146ms, lr=4.56e-05
2024-03-21 15:12:08,575 - logger.py:50 - Epoch: [29][300/500] loss: 3.58646, MAE: 0.20384, time/step=1146ms, lr=4.56e-05
2024-03-21 15:13:04,654 - logger.py:50 - Epoch: [29][350/500] loss: 3.68533, MAE: 0.20568, time/step=1142ms, lr=4.56e-05
2024-03-21 15:14:00,140 - logger.py:50 - Epoch: [29][400/500] loss: 3.62692, MAE: 0.20448, time/step=1138ms, lr=4.56e-05
2024-03-21 15:14:56,474 - logger.py:50 - Epoch: [29][450/500] loss: 3.59113, MAE: 0.20313, time/step=1137ms, lr=4.56e-05
2024-03-21 15:15:52,341 - logger.py:50 - Epoch: [29][499/500] loss: 3.55649, MAE: 0.20261, time/step=1137ms, lr=4.56e-05
2024-03-21 15:16:54,847 - logger.py:50 - Epoch: [29] train loss: 3.55649, train MAE: 0.20261,val loss: 3.19636, val MAE: 0.19886,test loss: 3.22300, test MAE: 0.20532,Time: 631.11s
2024-03-21 15:16:54,847 - logger.py:50 - Best -- epoch=27, train loss: 3.55576, val loss: 3.19198, test loss: 3.22129

2024-03-21 15:17:58,701 - logger.py:50 - Epoch: [29]EMA val MAE: 0.49656, EMA test MAE: 0.50911, Time: 694.96s
2024-03-21 15:17:58,701 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 15:17:59,370 - logger.py:50 - Epoch: [30][0/500] loss: 3.08935, MAE: 0.17076, time/step=667ms, lr=4.53e-05
2024-03-21 15:18:57,497 - logger.py:50 - Epoch: [30][50/500] loss: 3.22358, MAE: 0.18917, time/step=1153ms, lr=4.53e-05
2024-03-21 15:19:55,755 - logger.py:50 - Epoch: [30][100/500] loss: 3.21953, MAE: 0.18766, time/step=1159ms, lr=4.53e-05
2024-03-21 15:20:52,226 - logger.py:50 - Epoch: [30][150/500] loss: 3.96367, MAE: 0.20766, time/step=1149ms, lr=4.53e-05
2024-03-21 15:21:50,202 - logger.py:50 - Epoch: [30][200/500] loss: 3.79266, MAE: 0.20481, time/step=1152ms, lr=4.53e-05
2024-03-21 15:22:45,766 - logger.py:50 - Epoch: [30][250/500] loss: 3.68057, MAE: 0.20134, time/step=1144ms, lr=4.53e-05
2024-03-21 15:23:42,487 - logger.py:50 - Epoch: [30][300/500] loss: 3.60230, MAE: 0.19997, time/step=1142ms, lr=4.53e-05
2024-03-21 15:24:39,187 - logger.py:50 - Epoch: [30][350/500] loss: 3.54737, MAE: 0.19807, time/step=1141ms, lr=4.53e-05
2024-03-21 15:25:38,242 - logger.py:50 - Epoch: [30][400/500] loss: 3.50344, MAE: 0.19647, time/step=1146ms, lr=4.53e-05
2024-03-21 15:26:34,937 - logger.py:50 - Epoch: [30][450/500] loss: 3.47093, MAE: 0.19556, time/step=1145ms, lr=4.53e-05
2024-03-21 15:27:29,606 - logger.py:50 - Epoch: [30][499/500] loss: 3.55009, MAE: 0.19726, time/step=1142ms, lr=4.53e-05
2024-03-21 15:28:34,779 - logger.py:50 - Epoch: [30] train loss: 3.55009, train MAE: 0.19726,val loss: 3.22229, val MAE: 0.23761,test loss: 3.24729, test MAE: 0.24293,Time: 636.08s
2024-03-21 15:28:34,779 - logger.py:50 - Best -- epoch=27, train loss: 3.55576, val loss: 3.19198, test loss: 3.22129

2024-03-21 15:29:38,755 - logger.py:50 - Epoch: [30]EMA val MAE: 0.48780, EMA test MAE: 0.50010, Time: 700.05s
2024-03-21 15:29:38,755 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 15:29:40,019 - logger.py:50 - Epoch: [31][0/500] loss: 3.24006, MAE: 0.26118, time/step=1261ms, lr=4.50e-05
2024-03-21 15:30:36,534 - logger.py:50 - Epoch: [31][50/500] loss: 3.20044, MAE: 0.19850, time/step=1133ms, lr=4.50e-05
2024-03-21 15:31:36,285 - logger.py:50 - Epoch: [31][100/500] loss: 3.72011, MAE: 0.20487, time/step=1164ms, lr=4.50e-05
2024-03-21 15:32:34,065 - logger.py:50 - Epoch: [31][150/500] loss: 3.57574, MAE: 0.20422, time/step=1161ms, lr=4.50e-05
2024-03-21 15:33:31,634 - logger.py:50 - Epoch: [31][200/500] loss: 3.48922, MAE: 0.20156, time/step=1159ms, lr=4.50e-05
2024-03-21 15:34:28,998 - logger.py:50 - Epoch: [31][250/500] loss: 3.43799, MAE: 0.19875, time/step=1156ms, lr=4.50e-05
2024-03-21 15:35:26,544 - logger.py:50 - Epoch: [31][300/500] loss: 3.40565, MAE: 0.19804, time/step=1155ms, lr=4.50e-05
2024-03-21 15:36:24,033 - logger.py:50 - Epoch: [31][350/500] loss: 3.37704, MAE: 0.19638, time/step=1155ms, lr=4.50e-05
2024-03-21 15:37:22,132 - logger.py:50 - Epoch: [31][400/500] loss: 3.63329, MAE: 0.20039, time/step=1156ms, lr=4.50e-05
2024-03-21 15:38:21,298 - logger.py:50 - Epoch: [31][450/500] loss: 3.58589, MAE: 0.20071, time/step=1159ms, lr=4.50e-05
2024-03-21 15:39:18,072 - logger.py:50 - Epoch: [31][499/500] loss: 3.55037, MAE: 0.19934, time/step=1159ms, lr=4.50e-05
2024-03-21 15:40:24,305 - logger.py:50 - Epoch: [31] train loss: 3.55037, train MAE: 0.19934,val loss: 3.18674, val MAE: 0.18180,test loss: 3.21202, test MAE: 0.18873,Time: 645.55s
2024-03-21 15:40:24,305 - logger.py:50 - Best -- epoch=31, train loss: 3.55037, val loss: 3.18674, test loss: 3.21202

2024-03-21 15:41:29,475 - logger.py:50 - Epoch: [31]EMA val MAE: 0.47952, EMA test MAE: 0.49156, Time: 710.72s
2024-03-21 15:41:29,475 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 15:41:30,253 - logger.py:50 - Epoch: [32][0/500] loss: 3.09949, MAE: 0.17919, time/step=776ms, lr=4.47e-05
2024-03-21 15:42:29,943 - logger.py:50 - Epoch: [32][50/500] loss: 3.22838, MAE: 0.18824, time/step=1186ms, lr=4.47e-05
2024-03-21 15:43:26,509 - logger.py:50 - Epoch: [32][100/500] loss: 3.23635, MAE: 0.19125, time/step=1159ms, lr=4.47e-05
2024-03-21 15:44:24,908 - logger.py:50 - Epoch: [32][150/500] loss: 3.57104, MAE: 0.19718, time/step=1162ms, lr=4.47e-05
2024-03-21 15:45:28,232 - logger.py:50 - Epoch: [32][200/500] loss: 3.48511, MAE: 0.19942, time/step=1188ms, lr=4.47e-05
2024-03-21 15:46:25,144 - logger.py:50 - Epoch: [32][250/500] loss: 3.43615, MAE: 0.19725, time/step=1178ms, lr=4.47e-05
2024-03-21 15:47:21,193 - logger.py:50 - Epoch: [32][300/500] loss: 3.39646, MAE: 0.19525, time/step=1168ms, lr=4.47e-05
2024-03-21 15:48:22,956 - logger.py:50 - Epoch: [32][350/500] loss: 3.36648, MAE: 0.19345, time/step=1178ms, lr=4.47e-05
2024-03-21 15:49:18,280 - logger.py:50 - Epoch: [32][400/500] loss: 3.35118, MAE: 0.19346, time/step=1169ms, lr=4.47e-05
2024-03-21 15:50:15,031 - logger.py:50 - Epoch: [32][450/500] loss: 3.33568, MAE: 0.19247, time/step=1165ms, lr=4.47e-05
2024-03-21 15:51:14,367 - logger.py:50 - Epoch: [32][499/500] loss: 3.54683, MAE: 0.19516, time/step=1170ms, lr=4.47e-05
2024-03-21 15:52:21,684 - logger.py:50 - Epoch: [32] train loss: 3.54683, train MAE: 0.19516,val loss: 3.24026, val MAE: 0.24017,test loss: 3.26435, test MAE: 0.24832,Time: 652.21s
2024-03-21 15:52:21,685 - logger.py:50 - Best -- epoch=31, train loss: 3.55037, val loss: 3.18674, test loss: 3.21202

2024-03-21 15:53:32,043 - logger.py:50 - Epoch: [32]EMA val MAE: 0.47152, EMA test MAE: 0.48331, Time: 722.57s
2024-03-21 15:53:32,043 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 15:53:33,547 - logger.py:50 - Epoch: [33][0/500] loss: 3.24034, MAE: 0.25089, time/step=1501ms, lr=4.44e-05
2024-03-21 15:54:37,267 - logger.py:50 - Epoch: [33][50/500] loss: 3.25071, MAE: 0.21114, time/step=1279ms, lr=4.44e-05
2024-03-21 15:55:38,588 - logger.py:50 - Epoch: [33][100/500] loss: 3.21866, MAE: 0.19732, time/step=1253ms, lr=4.44e-05
2024-03-21 15:56:40,120 - logger.py:50 - Epoch: [33][150/500] loss: 3.20926, MAE: 0.19257, time/step=1246ms, lr=4.44e-05
2024-03-21 15:57:42,061 - logger.py:50 - Epoch: [33][200/500] loss: 3.21096, MAE: 0.19106, time/step=1244ms, lr=4.44e-05
2024-03-21 15:58:43,700 - logger.py:50 - Epoch: [33][250/500] loss: 3.20842, MAE: 0.18939, time/step=1242ms, lr=4.44e-05
2024-03-21 15:59:42,632 - logger.py:50 - Epoch: [33][300/500] loss: 3.21591, MAE: 0.19005, time/step=1231ms, lr=4.44e-05
2024-03-21 16:00:38,347 - logger.py:50 - Epoch: [33][350/500] loss: 3.22007, MAE: 0.19029, time/step=1215ms, lr=4.44e-05
2024-03-21 16:01:37,304 - logger.py:50 - Epoch: [33][400/500] loss: 3.22323, MAE: 0.18981, time/step=1210ms, lr=4.44e-05
2024-03-21 16:02:37,033 - logger.py:50 - Epoch: [33][450/500] loss: 3.47031, MAE: 0.19585, time/step=1208ms, lr=4.44e-05
2024-03-21 16:03:36,260 - logger.py:50 - Epoch: [33][499/500] loss: 3.54902, MAE: 0.19819, time/step=1208ms, lr=4.44e-05
2024-03-21 16:04:42,930 - logger.py:50 - Epoch: [33] train loss: 3.54902, train MAE: 0.19819,val loss: 3.21160, val MAE: 0.21055,test loss: 3.23500, test MAE: 0.21638,Time: 670.89s
2024-03-21 16:04:42,930 - logger.py:50 - Best -- epoch=31, train loss: 3.55037, val loss: 3.18674, test loss: 3.21202

2024-03-21 16:05:48,563 - logger.py:50 - Epoch: [33]EMA val MAE: 0.46362, EMA test MAE: 0.47521, Time: 736.52s
2024-03-21 16:05:48,564 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 16:05:49,443 - logger.py:50 - Epoch: [34][0/500] loss: 3.62001, MAE: 0.28709, time/step=877ms, lr=4.40e-05
2024-03-21 16:06:48,322 - logger.py:50 - Epoch: [34][50/500] loss: 3.20045, MAE: 0.19389, time/step=1172ms, lr=4.40e-05
2024-03-21 16:07:47,203 - logger.py:50 - Epoch: [34][100/500] loss: 3.19939, MAE: 0.19114, time/step=1175ms, lr=4.40e-05
2024-03-21 16:08:43,646 - logger.py:50 - Epoch: [34][150/500] loss: 3.20049, MAE: 0.18871, time/step=1159ms, lr=4.40e-05
2024-03-21 16:09:41,535 - logger.py:50 - Epoch: [34][200/500] loss: 3.21715, MAE: 0.18917, time/step=1159ms, lr=4.40e-05
2024-03-21 16:10:38,944 - logger.py:50 - Epoch: [34][250/500] loss: 3.66263, MAE: 0.19971, time/step=1157ms, lr=4.40e-05
2024-03-21 16:11:36,014 - logger.py:50 - Epoch: [34][300/500] loss: 3.76120, MAE: 0.20341, time/step=1154ms, lr=4.40e-05
2024-03-21 16:12:32,884 - logger.py:50 - Epoch: [34][350/500] loss: 3.68701, MAE: 0.20149, time/step=1152ms, lr=4.40e-05
2024-03-21 16:13:28,620 - logger.py:50 - Epoch: [34][400/500] loss: 3.62999, MAE: 0.20001, time/step=1147ms, lr=4.40e-05
2024-03-21 16:14:26,219 - logger.py:50 - Epoch: [34][450/500] loss: 3.58463, MAE: 0.19858, time/step=1148ms, lr=4.40e-05
2024-03-21 16:15:22,183 - logger.py:50 - Epoch: [34][499/500] loss: 3.54548, MAE: 0.19692, time/step=1147ms, lr=4.40e-05
2024-03-21 16:16:26,897 - logger.py:50 - Epoch: [34] train loss: 3.54548, train MAE: 0.19692,val loss: 3.18336, val MAE: 0.17749,test loss: 3.20700, test MAE: 0.18460,Time: 638.33s
2024-03-21 16:16:26,897 - logger.py:50 - Best -- epoch=34, train loss: 3.54548, val loss: 3.18336, test loss: 3.20700

2024-03-21 16:17:33,142 - logger.py:50 - Epoch: [34]EMA val MAE: 0.45609, EMA test MAE: 0.46751, Time: 704.58s
2024-03-21 16:17:33,142 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 16:17:34,698 - logger.py:50 - Epoch: [35][0/500] loss: 3.16008, MAE: 0.19123, time/step=1552ms, lr=4.37e-05
2024-03-21 16:18:33,804 - logger.py:50 - Epoch: [35][50/500] loss: 3.26374, MAE: 0.18947, time/step=1189ms, lr=4.37e-05
2024-03-21 16:19:30,139 - logger.py:50 - Epoch: [35][100/500] loss: 3.25434, MAE: 0.19005, time/step=1158ms, lr=4.37e-05
2024-03-21 16:20:29,521 - logger.py:50 - Epoch: [35][150/500] loss: 3.23156, MAE: 0.18845, time/step=1168ms, lr=4.37e-05
2024-03-21 16:21:26,574 - logger.py:50 - Epoch: [35][200/500] loss: 3.78343, MAE: 0.20082, time/step=1161ms, lr=4.37e-05
2024-03-21 16:22:24,259 - logger.py:50 - Epoch: [35][250/500] loss: 3.66846, MAE: 0.19983, time/step=1160ms, lr=4.37e-05
2024-03-21 16:23:23,595 - logger.py:50 - Epoch: [35][300/500] loss: 3.58794, MAE: 0.19673, time/step=1164ms, lr=4.37e-05
2024-03-21 16:24:19,635 - logger.py:50 - Epoch: [35][350/500] loss: 3.53558, MAE: 0.19502, time/step=1158ms, lr=4.37e-05
2024-03-21 16:25:18,114 - logger.py:50 - Epoch: [35][400/500] loss: 3.62570, MAE: 0.19864, time/step=1160ms, lr=4.37e-05
2024-03-21 16:26:16,164 - logger.py:50 - Epoch: [35][450/500] loss: 3.57783, MAE: 0.19695, time/step=1160ms, lr=4.37e-05
2024-03-21 16:27:10,103 - logger.py:50 - Epoch: [35][499/500] loss: 3.54377, MAE: 0.19583, time/step=1154ms, lr=4.37e-05
2024-03-21 16:28:16,763 - logger.py:50 - Epoch: [35] train loss: 3.54377, train MAE: 0.19583,val loss: 3.18615, val MAE: 0.17915,test loss: 3.21113, test MAE: 0.18635,Time: 643.62s
2024-03-21 16:28:16,763 - logger.py:50 - Best -- epoch=34, train loss: 3.54548, val loss: 3.18336, test loss: 3.20700

2024-03-21 16:29:24,492 - logger.py:50 - Epoch: [35]EMA val MAE: 0.44863, EMA test MAE: 0.45988, Time: 711.35s
2024-03-21 16:29:24,492 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 16:29:25,298 - logger.py:50 - Epoch: [36][0/500] loss: 3.21833, MAE: 0.17916, time/step=804ms, lr=4.34e-05
2024-03-21 16:30:21,304 - logger.py:50 - Epoch: [36][50/500] loss: 3.20244, MAE: 0.18945, time/step=1114ms, lr=4.34e-05
2024-03-21 16:31:16,049 - logger.py:50 - Epoch: [36][100/500] loss: 3.72827, MAE: 0.19768, time/step=1104ms, lr=4.34e-05
2024-03-21 16:32:11,571 - logger.py:50 - Epoch: [36][150/500] loss: 3.55038, MAE: 0.19528, time/step=1106ms, lr=4.34e-05
2024-03-21 16:33:08,046 - logger.py:50 - Epoch: [36][200/500] loss: 3.46996, MAE: 0.19314, time/step=1112ms, lr=4.34e-05
2024-03-21 16:34:06,361 - logger.py:50 - Epoch: [36][250/500] loss: 3.41912, MAE: 0.19039, time/step=1123ms, lr=4.34e-05
2024-03-21 16:35:03,009 - logger.py:50 - Epoch: [36][300/500] loss: 3.38317, MAE: 0.18961, time/step=1125ms, lr=4.34e-05
2024-03-21 16:36:00,547 - logger.py:50 - Epoch: [36][350/500] loss: 3.35812, MAE: 0.18945, time/step=1128ms, lr=4.34e-05
2024-03-21 16:36:55,418 - logger.py:50 - Epoch: [36][400/500] loss: 3.62169, MAE: 0.19457, time/step=1124ms, lr=4.34e-05
2024-03-21 16:37:53,221 - logger.py:50 - Epoch: [36][450/500] loss: 3.57414, MAE: 0.19465, time/step=1128ms, lr=4.34e-05
2024-03-21 16:38:48,621 - logger.py:50 - Epoch: [36][499/500] loss: 3.54021, MAE: 0.19353, time/step=1128ms, lr=4.34e-05
2024-03-21 16:39:55,266 - logger.py:50 - Epoch: [36] train loss: 3.54021, train MAE: 0.19353,val loss: 3.20662, val MAE: 0.17959,test loss: 3.23247, test MAE: 0.18741,Time: 630.77s
2024-03-21 16:39:55,266 - logger.py:50 - Best -- epoch=34, train loss: 3.54548, val loss: 3.18336, test loss: 3.20700

2024-03-21 16:40:59,758 - logger.py:50 - Epoch: [36]EMA val MAE: 0.44105, EMA test MAE: 0.45215, Time: 695.27s
2024-03-21 16:40:59,759 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 16:41:01,111 - logger.py:50 - Epoch: [37][0/500] loss: 3.17267, MAE: 0.16811, time/step=1350ms, lr=4.30e-05
2024-03-21 16:41:58,125 - logger.py:50 - Epoch: [37][50/500] loss: 3.21121, MAE: 0.17661, time/step=1144ms, lr=4.30e-05
2024-03-21 16:42:53,333 - logger.py:50 - Epoch: [37][100/500] loss: 3.23790, MAE: 0.18395, time/step=1124ms, lr=4.30e-05
2024-03-21 16:43:49,971 - logger.py:50 - Epoch: [37][150/500] loss: 3.21677, MAE: 0.18079, time/step=1127ms, lr=4.30e-05
2024-03-21 16:44:44,598 - logger.py:50 - Epoch: [37][200/500] loss: 3.22205, MAE: 0.18260, time/step=1119ms, lr=4.30e-05
2024-03-21 16:45:41,602 - logger.py:50 - Epoch: [37][250/500] loss: 3.21598, MAE: 0.18245, time/step=1123ms, lr=4.30e-05
2024-03-21 16:46:36,964 - logger.py:50 - Epoch: [37][300/500] loss: 3.21488, MAE: 0.18376, time/step=1120ms, lr=4.30e-05
2024-03-21 16:47:32,614 - logger.py:50 - Epoch: [37][350/500] loss: 3.53868, MAE: 0.19156, time/step=1119ms, lr=4.30e-05
2024-03-21 16:48:28,293 - logger.py:50 - Epoch: [37][400/500] loss: 3.49713, MAE: 0.19294, time/step=1119ms, lr=4.30e-05
2024-03-21 16:49:22,391 - logger.py:50 - Epoch: [37][450/500] loss: 3.57825, MAE: 0.19469, time/step=1114ms, lr=4.30e-05
2024-03-21 16:50:18,144 - logger.py:50 - Epoch: [37][499/500] loss: 3.54263, MAE: 0.19531, time/step=1117ms, lr=4.30e-05
2024-03-21 16:51:24,726 - logger.py:50 - Epoch: [37] train loss: 3.54263, train MAE: 0.19531,val loss: 3.18345, val MAE: 0.17817,test loss: 3.20470, test MAE: 0.18493,Time: 624.97s
2024-03-21 16:51:24,726 - logger.py:50 - Best -- epoch=34, train loss: 3.54548, val loss: 3.18336, test loss: 3.20700

2024-03-21 16:52:28,569 - logger.py:50 - Epoch: [37]EMA val MAE: 0.43309, EMA test MAE: 0.44405, Time: 688.81s
2024-03-21 16:52:28,570 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 16:52:29,266 - logger.py:50 - Epoch: [38][0/500] loss: 3.17656, MAE: 0.17361, time/step=694ms, lr=4.26e-05
2024-03-21 16:53:26,581 - logger.py:50 - Epoch: [38][50/500] loss: 3.17600, MAE: 0.18071, time/step=1137ms, lr=4.26e-05
2024-03-21 16:54:22,124 - logger.py:50 - Epoch: [38][100/500] loss: 3.19526, MAE: 0.18281, time/step=1124ms, lr=4.26e-05
2024-03-21 16:55:18,690 - logger.py:50 - Epoch: [38][150/500] loss: 3.94830, MAE: 0.19327, time/step=1127ms, lr=4.26e-05
2024-03-21 16:56:15,367 - logger.py:50 - Epoch: [38][200/500] loss: 3.76386, MAE: 0.19553, time/step=1128ms, lr=4.26e-05
2024-03-21 16:57:12,379 - logger.py:50 - Epoch: [38][250/500] loss: 3.65322, MAE: 0.19366, time/step=1131ms, lr=4.26e-05
2024-03-21 16:58:12,609 - logger.py:50 - Epoch: [38][300/500] loss: 3.57496, MAE: 0.19149, time/step=1143ms, lr=4.26e-05
2024-03-21 16:59:13,975 - logger.py:50 - Epoch: [38][350/500] loss: 3.52980, MAE: 0.19052, time/step=1155ms, lr=4.26e-05
2024-03-21 17:00:15,369 - logger.py:50 - Epoch: [38][400/500] loss: 3.61733, MAE: 0.19391, time/step=1164ms, lr=4.26e-05
2024-03-21 17:01:18,845 - logger.py:50 - Epoch: [38][450/500] loss: 3.57728, MAE: 0.19423, time/step=1176ms, lr=4.26e-05
2024-03-21 17:02:19,260 - logger.py:50 - Epoch: [38][499/500] loss: 3.53839, MAE: 0.19274, time/step=1181ms, lr=4.26e-05
2024-03-21 17:03:28,352 - logger.py:50 - Epoch: [38] train loss: 3.53839, train MAE: 0.19274,val loss: 3.18253, val MAE: 0.17857,test loss: 3.20168, test MAE: 0.18565,Time: 659.78s
2024-03-21 17:03:28,352 - logger.py:50 - Best -- epoch=38, train loss: 3.53839, val loss: 3.18253, test loss: 3.20168

2024-03-21 17:04:43,399 - logger.py:50 - Epoch: [38]EMA val MAE: 0.42528, EMA test MAE: 0.43608, Time: 734.83s
2024-03-21 17:04:43,400 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 17:04:44,766 - logger.py:50 - Epoch: [39][0/500] loss: 3.14817, MAE: 0.17848, time/step=1364ms, lr=4.23e-05
2024-03-21 17:05:46,187 - logger.py:50 - Epoch: [39][50/500] loss: 3.21456, MAE: 0.17992, time/step=1231ms, lr=4.23e-05
2024-03-21 17:06:47,222 - logger.py:50 - Epoch: [39][100/500] loss: 4.32338, MAE: 0.20778, time/step=1226ms, lr=4.23e-05
2024-03-21 17:07:47,337 - logger.py:50 - Epoch: [39][150/500] loss: 3.95289, MAE: 0.20095, time/step=1218ms, lr=4.23e-05
2024-03-21 17:08:49,113 - logger.py:50 - Epoch: [39][200/500] loss: 3.76658, MAE: 0.19637, time/step=1222ms, lr=4.23e-05
2024-03-21 17:09:50,364 - logger.py:50 - Epoch: [39][250/500] loss: 3.64947, MAE: 0.19358, time/step=1223ms, lr=4.23e-05
2024-03-21 17:10:51,537 - logger.py:50 - Epoch: [39][300/500] loss: 3.74727, MAE: 0.19749, time/step=1223ms, lr=4.23e-05
2024-03-21 17:11:53,761 - logger.py:50 - Epoch: [39][350/500] loss: 3.67479, MAE: 0.19685, time/step=1226ms, lr=4.23e-05
2024-03-21 17:12:53,729 - logger.py:50 - Epoch: [39][400/500] loss: 3.61493, MAE: 0.19511, time/step=1223ms, lr=4.23e-05
2024-03-21 17:13:54,065 - logger.py:50 - Epoch: [39][450/500] loss: 3.57290, MAE: 0.19375, time/step=1221ms, lr=4.23e-05
2024-03-21 17:14:55,498 - logger.py:50 - Epoch: [39][499/500] loss: 3.53825, MAE: 0.19243, time/step=1224ms, lr=4.23e-05
2024-03-21 17:16:06,240 - logger.py:50 - Epoch: [39] train loss: 3.53825, train MAE: 0.19243,val loss: 3.19119, val MAE: 0.17885,test loss: 3.21529, test MAE: 0.18627,Time: 682.84s
2024-03-21 17:16:06,240 - logger.py:50 - Best -- epoch=38, train loss: 3.53839, val loss: 3.18253, test loss: 3.20168

2024-03-21 17:17:11,416 - logger.py:50 - Epoch: [39]EMA val MAE: 0.41741, EMA test MAE: 0.42801, Time: 748.02s
2024-03-21 17:17:11,416 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 17:17:12,827 - logger.py:50 - Epoch: [40][0/500] loss: 3.27288, MAE: 0.22389, time/step=1408ms, lr=4.19e-05
2024-03-21 17:18:11,231 - logger.py:50 - Epoch: [40][50/500] loss: 3.21524, MAE: 0.18383, time/step=1173ms, lr=4.19e-05
2024-03-21 17:19:08,815 - logger.py:50 - Epoch: [40][100/500] loss: 3.20518, MAE: 0.18313, time/step=1162ms, lr=4.19e-05
2024-03-21 17:20:08,857 - logger.py:50 - Epoch: [40][150/500] loss: 3.95394, MAE: 0.19754, time/step=1175ms, lr=4.19e-05
2024-03-21 17:21:10,438 - logger.py:50 - Epoch: [40][200/500] loss: 3.77100, MAE: 0.19740, time/step=1189ms, lr=4.19e-05
2024-03-21 17:22:11,323 - logger.py:50 - Epoch: [40][250/500] loss: 3.65061, MAE: 0.19344, time/step=1195ms, lr=4.19e-05
2024-03-21 17:23:13,639 - logger.py:50 - Epoch: [40][300/500] loss: 3.58013, MAE: 0.19312, time/step=1203ms, lr=4.19e-05
2024-03-21 17:24:15,015 - logger.py:50 - Epoch: [40][350/500] loss: 3.67184, MAE: 0.19469, time/step=1207ms, lr=4.19e-05
2024-03-21 17:25:15,688 - logger.py:50 - Epoch: [40][400/500] loss: 3.61928, MAE: 0.19424, time/step=1208ms, lr=4.19e-05
2024-03-21 17:26:15,747 - logger.py:50 - Epoch: [40][450/500] loss: 3.57606, MAE: 0.19329, time/step=1207ms, lr=4.19e-05
2024-03-21 17:27:17,363 - logger.py:50 - Epoch: [40][499/500] loss: 3.53637, MAE: 0.19186, time/step=1212ms, lr=4.19e-05
2024-03-21 17:28:30,925 - logger.py:50 - Epoch: [40] train loss: 3.53637, train MAE: 0.19186,val loss: 3.18254, val MAE: 0.17788,test loss: 3.20257, test MAE: 0.18478,Time: 679.51s
2024-03-21 17:28:30,925 - logger.py:50 - Best -- epoch=38, train loss: 3.53839, val loss: 3.18253, test loss: 3.20168

2024-03-21 17:29:42,118 - logger.py:50 - Epoch: [40]EMA val MAE: 0.40940, EMA test MAE: 0.41975, Time: 750.70s
2024-03-21 17:29:42,119 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 17:29:43,426 - logger.py:50 - Epoch: [41][0/500] loss: 3.20848, MAE: 0.17665, time/step=1305ms, lr=4.15e-05
2024-03-21 17:30:43,404 - logger.py:50 - Epoch: [41][50/500] loss: 3.20058, MAE: 0.18647, time/step=1202ms, lr=4.15e-05
2024-03-21 17:31:43,539 - logger.py:50 - Epoch: [41][100/500] loss: 3.19900, MAE: 0.18204, time/step=1202ms, lr=4.15e-05
2024-03-21 17:32:44,221 - logger.py:50 - Epoch: [41][150/500] loss: 3.94705, MAE: 0.20122, time/step=1206ms, lr=4.15e-05
2024-03-21 17:33:42,926 - logger.py:50 - Epoch: [41][200/500] loss: 3.76734, MAE: 0.19899, time/step=1198ms, lr=4.15e-05
2024-03-21 17:34:40,956 - logger.py:50 - Epoch: [41][250/500] loss: 3.65549, MAE: 0.19587, time/step=1191ms, lr=4.15e-05
2024-03-21 17:35:38,436 - logger.py:50 - Epoch: [41][300/500] loss: 3.57916, MAE: 0.19245, time/step=1184ms, lr=4.15e-05
2024-03-21 17:36:33,090 - logger.py:50 - Epoch: [41][350/500] loss: 3.52463, MAE: 0.19042, time/step=1171ms, lr=4.15e-05
2024-03-21 17:37:30,631 - logger.py:50 - Epoch: [41][400/500] loss: 3.48788, MAE: 0.18987, time/step=1168ms, lr=4.15e-05
2024-03-21 17:38:27,520 - logger.py:50 - Epoch: [41][450/500] loss: 3.45701, MAE: 0.18914, time/step=1165ms, lr=4.15e-05
2024-03-21 17:39:24,460 - logger.py:50 - Epoch: [41][499/500] loss: 3.53485, MAE: 0.19168, time/step=1165ms, lr=4.15e-05
2024-03-21 17:40:27,915 - logger.py:50 - Epoch: [41] train loss: 3.53485, train MAE: 0.19168,val loss: 3.18537, val MAE: 0.18104,test loss: 3.20210, test MAE: 0.18703,Time: 645.80s
2024-03-21 17:40:27,915 - logger.py:50 - Best -- epoch=38, train loss: 3.53839, val loss: 3.18253, test loss: 3.20168

2024-03-21 17:41:32,413 - logger.py:50 - Epoch: [41]EMA val MAE: 0.40151, EMA test MAE: 0.41159, Time: 710.29s
2024-03-21 17:41:32,413 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 17:41:33,165 - logger.py:50 - Epoch: [42][0/500] loss: 3.35420, MAE: 0.18757, time/step=750ms, lr=4.11e-05
2024-03-21 17:42:29,283 - logger.py:50 - Epoch: [42][50/500] loss: 3.21136, MAE: 0.18345, time/step=1115ms, lr=4.11e-05
2024-03-21 17:43:25,823 - logger.py:50 - Epoch: [42][100/500] loss: 3.21865, MAE: 0.18485, time/step=1123ms, lr=4.11e-05
2024-03-21 17:44:22,237 - logger.py:50 - Epoch: [42][150/500] loss: 3.20627, MAE: 0.18273, time/step=1125ms, lr=4.11e-05
2024-03-21 17:45:18,167 - logger.py:50 - Epoch: [42][200/500] loss: 3.20048, MAE: 0.18180, time/step=1123ms, lr=4.11e-05
2024-03-21 17:46:16,767 - logger.py:50 - Epoch: [42][250/500] loss: 3.20732, MAE: 0.18299, time/step=1133ms, lr=4.11e-05
2024-03-21 17:47:21,144 - logger.py:50 - Epoch: [42][300/500] loss: 3.20766, MAE: 0.18286, time/step=1159ms, lr=4.11e-05
2024-03-21 17:48:24,511 - logger.py:50 - Epoch: [42][350/500] loss: 3.20610, MAE: 0.18272, time/step=1174ms, lr=4.11e-05
2024-03-21 17:49:23,536 - logger.py:50 - Epoch: [42][400/500] loss: 3.33621, MAE: 0.18610, time/step=1175ms, lr=4.11e-05
2024-03-21 17:50:28,693 - logger.py:50 - Epoch: [42][450/500] loss: 3.56929, MAE: 0.18904, time/step=1189ms, lr=4.11e-05
2024-03-21 17:51:21,852 - logger.py:50 - Epoch: [42][499/500] loss: 3.53376, MAE: 0.19147, time/step=1179ms, lr=4.11e-05
2024-03-21 17:52:24,988 - logger.py:50 - Epoch: [42] train loss: 3.53376, train MAE: 0.19147,val loss: 3.18067, val MAE: 0.18547,test loss: 3.20109, test MAE: 0.19176,Time: 652.57s
2024-03-21 17:52:24,988 - logger.py:50 - Best -- epoch=42, train loss: 3.53376, val loss: 3.18067, test loss: 3.20109

2024-03-21 17:53:28,318 - logger.py:50 - Epoch: [42]EMA val MAE: 0.39341, EMA test MAE: 0.40321, Time: 715.90s
2024-03-21 17:53:28,318 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 17:53:29,600 - logger.py:50 - Epoch: [43][0/500] loss: 3.23690, MAE: 0.18361, time/step=1280ms, lr=4.07e-05
2024-03-21 17:54:25,512 - logger.py:50 - Epoch: [43][50/500] loss: 3.20916, MAE: 0.18051, time/step=1121ms, lr=4.07e-05
2024-03-21 17:55:21,145 - logger.py:50 - Epoch: [43][100/500] loss: 3.20134, MAE: 0.18058, time/step=1117ms, lr=4.07e-05
2024-03-21 17:56:14,449 - logger.py:50 - Epoch: [43][150/500] loss: 3.20926, MAE: 0.18004, time/step=1100ms, lr=4.07e-05
2024-03-21 17:57:11,531 - logger.py:50 - Epoch: [43][200/500] loss: 3.21542, MAE: 0.18257, time/step=1110ms, lr=4.07e-05
2024-03-21 17:58:08,871 - logger.py:50 - Epoch: [43][250/500] loss: 3.21021, MAE: 0.18251, time/step=1118ms, lr=4.07e-05
2024-03-21 17:59:06,510 - logger.py:50 - Epoch: [43][300/500] loss: 3.38109, MAE: 0.18701, time/step=1124ms, lr=4.07e-05
2024-03-21 18:00:04,047 - logger.py:50 - Epoch: [43][350/500] loss: 3.35851, MAE: 0.18791, time/step=1127ms, lr=4.07e-05
2024-03-21 18:01:03,078 - logger.py:50 - Epoch: [43][400/500] loss: 3.33974, MAE: 0.18778, time/step=1134ms, lr=4.07e-05
2024-03-21 18:02:03,036 - logger.py:50 - Epoch: [43][450/500] loss: 3.32286, MAE: 0.18680, time/step=1141ms, lr=4.07e-05
2024-03-21 18:03:01,946 - logger.py:50 - Epoch: [43][499/500] loss: 3.53436, MAE: 0.19143, time/step=1147ms, lr=4.07e-05
2024-03-21 18:04:08,396 - logger.py:50 - Epoch: [43] train loss: 3.53436, train MAE: 0.19143,val loss: 3.20212, val MAE: 0.20984,test loss: 3.21899, test MAE: 0.21591,Time: 640.08s
2024-03-21 18:04:08,396 - logger.py:50 - Best -- epoch=42, train loss: 3.53376, val loss: 3.18067, test loss: 3.20109

2024-03-21 18:05:14,795 - logger.py:50 - Epoch: [43]EMA val MAE: 0.38548, EMA test MAE: 0.39497, Time: 706.48s
2024-03-21 18:05:14,796 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 18:05:15,551 - logger.py:50 - Epoch: [44][0/500] loss: 3.21254, MAE: 0.21520, time/step=753ms, lr=4.03e-05
2024-03-21 18:06:15,626 - logger.py:50 - Epoch: [44][50/500] loss: 3.20968, MAE: 0.19480, time/step=1193ms, lr=4.03e-05
2024-03-21 18:07:14,099 - logger.py:50 - Epoch: [44][100/500] loss: 3.71730, MAE: 0.20605, time/step=1181ms, lr=4.03e-05
2024-03-21 18:08:10,643 - logger.py:50 - Epoch: [44][150/500] loss: 3.55974, MAE: 0.20030, time/step=1165ms, lr=4.03e-05
2024-03-21 18:09:11,435 - logger.py:50 - Epoch: [44][200/500] loss: 3.46896, MAE: 0.19502, time/step=1177ms, lr=4.03e-05
2024-03-21 18:10:11,076 - logger.py:50 - Epoch: [44][250/500] loss: 3.41097, MAE: 0.19161, time/step=1180ms, lr=4.03e-05
2024-03-21 18:11:10,819 - logger.py:50 - Epoch: [44][300/500] loss: 3.37331, MAE: 0.18927, time/step=1183ms, lr=4.03e-05
2024-03-21 18:12:09,768 - logger.py:50 - Epoch: [44][350/500] loss: 3.35094, MAE: 0.18814, time/step=1182ms, lr=4.03e-05
2024-03-21 18:13:06,966 - logger.py:50 - Epoch: [44][400/500] loss: 3.33367, MAE: 0.18770, time/step=1177ms, lr=4.03e-05
2024-03-21 18:14:04,424 - logger.py:50 - Epoch: [44][450/500] loss: 3.31918, MAE: 0.18720, time/step=1174ms, lr=4.03e-05
2024-03-21 18:14:58,582 - logger.py:50 - Epoch: [44][499/500] loss: 3.53218, MAE: 0.18949, time/step=1168ms, lr=4.03e-05
2024-03-21 18:16:00,797 - logger.py:50 - Epoch: [44] train loss: 3.53218, train MAE: 0.18949,val loss: 3.21584, val MAE: 0.25987,test loss: 3.23556, test MAE: 0.26587,Time: 646.00s
2024-03-21 18:16:00,798 - logger.py:50 - Best -- epoch=42, train loss: 3.53376, val loss: 3.18067, test loss: 3.20109

2024-03-21 18:17:01,255 - logger.py:50 - Epoch: [44]EMA val MAE: 0.37783, EMA test MAE: 0.38697, Time: 706.46s
2024-03-21 18:17:01,255 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 18:17:02,455 - logger.py:50 - Epoch: [45][0/500] loss: 3.14636, MAE: 0.24933, time/step=1197ms, lr=3.99e-05
2024-03-21 18:17:57,313 - logger.py:50 - Epoch: [45][50/500] loss: 4.20970, MAE: 0.23584, time/step=1099ms, lr=3.99e-05
2024-03-21 18:18:52,904 - logger.py:50 - Epoch: [45][100/500] loss: 3.70456, MAE: 0.21047, time/step=1105ms, lr=3.99e-05
2024-03-21 18:19:49,387 - logger.py:50 - Epoch: [45][150/500] loss: 3.52494, MAE: 0.19954, time/step=1113ms, lr=3.99e-05
2024-03-21 18:20:43,499 - logger.py:50 - Epoch: [45][200/500] loss: 3.45764, MAE: 0.19718, time/step=1106ms, lr=3.99e-05
2024-03-21 18:21:39,630 - logger.py:50 - Epoch: [45][250/500] loss: 3.40543, MAE: 0.19297, time/step=1109ms, lr=3.99e-05
2024-03-21 18:22:34,318 - logger.py:50 - Epoch: [45][300/500] loss: 3.37221, MAE: 0.19143, time/step=1107ms, lr=3.99e-05
2024-03-21 18:23:28,425 - logger.py:50 - Epoch: [45][350/500] loss: 3.34565, MAE: 0.18966, time/step=1103ms, lr=3.99e-05
2024-03-21 18:24:23,429 - logger.py:50 - Epoch: [45][400/500] loss: 3.60534, MAE: 0.19270, time/step=1103ms, lr=3.99e-05
2024-03-21 18:25:17,987 - logger.py:50 - Epoch: [45][450/500] loss: 3.56278, MAE: 0.19321, time/step=1101ms, lr=3.99e-05
2024-03-21 18:26:11,201 - logger.py:50 - Epoch: [45][499/500] loss: 3.53165, MAE: 0.19280, time/step=1100ms, lr=3.99e-05
2024-03-21 18:27:13,687 - logger.py:50 - Epoch: [45] train loss: 3.53165, train MAE: 0.19280,val loss: 3.18424, val MAE: 0.17351,test loss: 3.19896, test MAE: 0.18050,Time: 612.43s
2024-03-21 18:27:13,687 - logger.py:50 - Best -- epoch=42, train loss: 3.53376, val loss: 3.18067, test loss: 3.20109

2024-03-21 18:28:15,505 - logger.py:50 - Epoch: [45]EMA val MAE: 0.37031, EMA test MAE: 0.37912, Time: 674.25s
2024-03-21 18:28:15,505 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 18:28:16,732 - logger.py:50 - Epoch: [46][0/500] loss: 3.20478, MAE: 0.17592, time/step=1225ms, lr=3.95e-05
2024-03-21 18:29:12,523 - logger.py:50 - Epoch: [46][50/500] loss: 3.20453, MAE: 0.18010, time/step=1118ms, lr=3.95e-05
2024-03-21 18:30:08,143 - logger.py:50 - Epoch: [46][100/500] loss: 3.22332, MAE: 0.18321, time/step=1115ms, lr=3.95e-05
2024-03-21 18:31:03,513 - logger.py:50 - Epoch: [46][150/500] loss: 3.55274, MAE: 0.19308, time/step=1113ms, lr=3.95e-05
2024-03-21 18:31:59,243 - logger.py:50 - Epoch: [46][200/500] loss: 3.46185, MAE: 0.19077, time/step=1113ms, lr=3.95e-05
2024-03-21 18:32:54,634 - logger.py:50 - Epoch: [46][250/500] loss: 3.40805, MAE: 0.18799, time/step=1112ms, lr=3.95e-05
2024-03-21 18:33:49,088 - logger.py:50 - Epoch: [46][300/500] loss: 3.37526, MAE: 0.18705, time/step=1108ms, lr=3.95e-05
2024-03-21 18:34:44,229 - logger.py:50 - Epoch: [46][350/500] loss: 3.35095, MAE: 0.18590, time/step=1107ms, lr=3.95e-05
2024-03-21 18:35:39,143 - logger.py:50 - Epoch: [46][400/500] loss: 3.32753, MAE: 0.18470, time/step=1106ms, lr=3.95e-05
2024-03-21 18:36:33,310 - logger.py:50 - Epoch: [46][450/500] loss: 3.31488, MAE: 0.18465, time/step=1104ms, lr=3.95e-05
2024-03-21 18:37:27,484 - logger.py:50 - Epoch: [46][499/500] loss: 3.52911, MAE: 0.18806, time/step=1104ms, lr=3.95e-05
2024-03-21 18:38:29,582 - logger.py:50 - Epoch: [46] train loss: 3.52911, train MAE: 0.18806,val loss: 3.21078, val MAE: 0.22866,test loss: 3.22950, test MAE: 0.23608,Time: 614.08s
2024-03-21 18:38:29,582 - logger.py:50 - Best -- epoch=42, train loss: 3.53376, val loss: 3.18067, test loss: 3.20109

2024-03-21 18:39:32,152 - logger.py:50 - Epoch: [46]EMA val MAE: 0.36288, EMA test MAE: 0.37133, Time: 676.65s
2024-03-21 18:39:32,152 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 18:39:33,422 - logger.py:50 - Epoch: [47][0/500] loss: 3.37201, MAE: 0.24614, time/step=1268ms, lr=3.91e-05
2024-03-21 18:40:26,484 - logger.py:50 - Epoch: [47][50/500] loss: 4.24064, MAE: 0.21705, time/step=1065ms, lr=3.91e-05
2024-03-21 18:41:20,812 - logger.py:50 - Epoch: [47][100/500] loss: 3.73413, MAE: 0.21060, time/step=1076ms, lr=3.91e-05
2024-03-21 18:42:15,602 - logger.py:50 - Epoch: [47][150/500] loss: 3.55997, MAE: 0.20184, time/step=1082ms, lr=3.91e-05
2024-03-21 18:43:10,077 - logger.py:50 - Epoch: [47][200/500] loss: 3.46964, MAE: 0.19672, time/step=1084ms, lr=3.91e-05
2024-03-21 18:44:05,080 - logger.py:50 - Epoch: [47][250/500] loss: 3.41683, MAE: 0.19403, time/step=1087ms, lr=3.91e-05
2024-03-21 18:44:59,746 - logger.py:50 - Epoch: [47][300/500] loss: 3.38500, MAE: 0.19225, time/step=1088ms, lr=3.91e-05
2024-03-21 18:45:54,021 - logger.py:50 - Epoch: [47][350/500] loss: 3.35775, MAE: 0.19092, time/step=1088ms, lr=3.91e-05
2024-03-21 18:46:50,621 - logger.py:50 - Epoch: [47][400/500] loss: 3.33514, MAE: 0.18911, time/step=1093ms, lr=3.91e-05
2024-03-21 18:47:46,246 - logger.py:50 - Epoch: [47][450/500] loss: 3.56738, MAE: 0.19248, time/step=1096ms, lr=3.91e-05
2024-03-21 18:48:40,122 - logger.py:50 - Epoch: [47][499/500] loss: 3.53062, MAE: 0.19204, time/step=1096ms, lr=3.91e-05
2024-03-21 18:49:41,811 - logger.py:50 - Epoch: [47] train loss: 3.53062, train MAE: 0.19204,val loss: 3.18148, val MAE: 0.17821,test loss: 3.19935, test MAE: 0.18475,Time: 609.66s
2024-03-21 18:49:41,811 - logger.py:50 - Best -- epoch=42, train loss: 3.53376, val loss: 3.18067, test loss: 3.20109

2024-03-21 18:50:43,265 - logger.py:50 - Epoch: [47]EMA val MAE: 0.35566, EMA test MAE: 0.36374, Time: 671.11s
2024-03-21 18:50:43,265 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 18:50:44,608 - logger.py:50 - Epoch: [48][0/500] loss: 3.13044, MAE: 0.14912, time/step=1340ms, lr=3.86e-05
2024-03-21 18:51:40,200 - logger.py:50 - Epoch: [48][50/500] loss: 3.21046, MAE: 0.18354, time/step=1116ms, lr=3.86e-05
2024-03-21 18:52:35,968 - logger.py:50 - Epoch: [48][100/500] loss: 3.19772, MAE: 0.18010, time/step=1116ms, lr=3.86e-05
2024-03-21 18:53:31,509 - logger.py:50 - Epoch: [48][150/500] loss: 3.19123, MAE: 0.17897, time/step=1114ms, lr=3.86e-05
2024-03-21 18:54:25,915 - logger.py:50 - Epoch: [48][200/500] loss: 3.19620, MAE: 0.18008, time/step=1108ms, lr=3.86e-05
2024-03-21 18:55:20,365 - logger.py:50 - Epoch: [48][250/500] loss: 3.19814, MAE: 0.18074, time/step=1104ms, lr=3.86e-05
2024-03-21 18:56:13,991 - logger.py:50 - Epoch: [48][300/500] loss: 3.19806, MAE: 0.18105, time/step=1099ms, lr=3.86e-05
2024-03-21 18:57:08,968 - logger.py:50 - Epoch: [48][350/500] loss: 3.20453, MAE: 0.18156, time/step=1099ms, lr=3.86e-05
2024-03-21 18:58:04,352 - logger.py:50 - Epoch: [48][400/500] loss: 3.33293, MAE: 0.18583, time/step=1100ms, lr=3.86e-05
2024-03-21 18:59:00,492 - logger.py:50 - Epoch: [48][450/500] loss: 3.56451, MAE: 0.18948, time/step=1102ms, lr=3.86e-05
2024-03-21 18:59:53,400 - logger.py:50 - Epoch: [48][499/500] loss: 3.53005, MAE: 0.18950, time/step=1100ms, lr=3.86e-05
2024-03-21 19:00:56,282 - logger.py:50 - Epoch: [48] train loss: 3.53005, train MAE: 0.18950,val loss: 3.17921, val MAE: 0.17902,test loss: 3.19795, test MAE: 0.18631,Time: 613.02s
2024-03-21 19:00:56,282 - logger.py:50 - Best -- epoch=48, train loss: 3.53005, val loss: 3.17921, test loss: 3.19795

2024-03-21 19:01:59,118 - logger.py:50 - Epoch: [48]EMA val MAE: 0.34876, EMA test MAE: 0.35646, Time: 675.85s
2024-03-21 19:01:59,118 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 19:02:00,359 - logger.py:50 - Epoch: [49][0/500] loss: 3.15342, MAE: 0.19661, time/step=1239ms, lr=3.82e-05
2024-03-21 19:02:57,210 - logger.py:50 - Epoch: [49][50/500] loss: 3.17753, MAE: 0.17721, time/step=1139ms, lr=3.82e-05
2024-03-21 19:03:52,778 - logger.py:50 - Epoch: [49][100/500] loss: 3.19452, MAE: 0.17907, time/step=1125ms, lr=3.82e-05
2024-03-21 19:04:48,681 - logger.py:50 - Epoch: [49][150/500] loss: 3.20259, MAE: 0.18078, time/step=1123ms, lr=3.82e-05
2024-03-21 19:05:43,750 - logger.py:50 - Epoch: [49][200/500] loss: 3.19825, MAE: 0.18060, time/step=1118ms, lr=3.82e-05
2024-03-21 19:06:37,975 - logger.py:50 - Epoch: [49][250/500] loss: 3.65046, MAE: 0.19248, time/step=1111ms, lr=3.82e-05
2024-03-21 19:07:34,239 - logger.py:50 - Epoch: [49][300/500] loss: 3.57173, MAE: 0.19031, time/step=1113ms, lr=3.82e-05
2024-03-21 19:08:28,994 - logger.py:50 - Epoch: [49][350/500] loss: 3.51979, MAE: 0.18932, time/step=1111ms, lr=3.82e-05
2024-03-21 19:09:23,498 - logger.py:50 - Epoch: [49][400/500] loss: 3.48290, MAE: 0.18897, time/step=1108ms, lr=3.82e-05
2024-03-21 19:10:17,998 - logger.py:50 - Epoch: [49][450/500] loss: 3.44900, MAE: 0.18736, time/step=1106ms, lr=3.82e-05
2024-03-21 19:11:11,691 - logger.py:50 - Epoch: [49][499/500] loss: 3.52844, MAE: 0.18916, time/step=1105ms, lr=3.82e-05
2024-03-21 19:12:13,931 - logger.py:50 - Epoch: [49] train loss: 3.52844, train MAE: 0.18916,val loss: 3.18697, val MAE: 0.18499,test loss: 3.20431, test MAE: 0.19132,Time: 614.81s
2024-03-21 19:12:13,932 - logger.py:50 - Best -- epoch=48, train loss: 3.53005, val loss: 3.17921, test loss: 3.19795

2024-03-21 19:13:16,532 - logger.py:50 - Epoch: [49]EMA val MAE: 0.34218, EMA test MAE: 0.34952, Time: 677.41s
2024-03-21 19:13:16,532 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 19:13:17,339 - logger.py:50 - Epoch: [50][0/500] loss: 3.10146, MAE: 0.17391, time/step=805ms, lr=3.78e-05
2024-03-21 19:14:10,825 - logger.py:50 - Epoch: [50][50/500] loss: 3.17322, MAE: 0.18073, time/step=1065ms, lr=3.78e-05
2024-03-21 19:15:03,777 - logger.py:50 - Epoch: [50][100/500] loss: 3.19235, MAE: 0.17987, time/step=1062ms, lr=3.78e-05
2024-03-21 19:15:57,197 - logger.py:50 - Epoch: [50][150/500] loss: 3.18037, MAE: 0.17854, time/step=1064ms, lr=3.78e-05
2024-03-21 19:16:50,106 - logger.py:50 - Epoch: [50][200/500] loss: 3.18620, MAE: 0.17972, time/step=1063ms, lr=3.78e-05
2024-03-21 19:17:44,417 - logger.py:50 - Epoch: [50][250/500] loss: 3.63847, MAE: 0.18808, time/step=1067ms, lr=3.78e-05
2024-03-21 19:18:37,331 - logger.py:50 - Epoch: [50][300/500] loss: 3.57455, MAE: 0.18825, time/step=1066ms, lr=3.78e-05
2024-03-21 19:19:30,920 - logger.py:50 - Epoch: [50][350/500] loss: 3.51843, MAE: 0.18700, time/step=1067ms, lr=3.78e-05
2024-03-21 19:20:24,658 - logger.py:50 - Epoch: [50][400/500] loss: 3.60935, MAE: 0.19083, time/step=1068ms, lr=3.78e-05
2024-03-21 19:21:18,247 - logger.py:50 - Epoch: [50][450/500] loss: 3.56357, MAE: 0.18941, time/step=1068ms, lr=3.78e-05
2024-03-21 19:22:10,746 - logger.py:50 - Epoch: [50][499/500] loss: 3.52830, MAE: 0.18904, time/step=1068ms, lr=3.78e-05
2024-03-21 19:23:11,498 - logger.py:50 - Epoch: [50] train loss: 3.52830, train MAE: 0.18904,val loss: 3.17956, val MAE: 0.17458,test loss: 3.19607, test MAE: 0.18175,Time: 594.97s
2024-03-21 19:23:11,498 - logger.py:50 - Best -- epoch=48, train loss: 3.53005, val loss: 3.17921, test loss: 3.19795

2024-03-21 19:24:11,259 - logger.py:50 - Epoch: [50]EMA val MAE: 0.33589, EMA test MAE: 0.34291, Time: 654.73s
2024-03-21 19:24:11,259 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 19:24:12,056 - logger.py:50 - Epoch: [51][0/500] loss: 3.11371, MAE: 0.14683, time/step=795ms, lr=3.73e-05
2024-03-21 19:25:04,016 - logger.py:50 - Epoch: [51][50/500] loss: 3.20912, MAE: 0.18334, time/step=1034ms, lr=3.73e-05
2024-03-21 19:25:57,799 - logger.py:50 - Epoch: [51][100/500] loss: 3.20356, MAE: 0.18210, time/step=1055ms, lr=3.73e-05
2024-03-21 19:26:50,738 - logger.py:50 - Epoch: [51][150/500] loss: 3.20062, MAE: 0.18126, time/step=1056ms, lr=3.73e-05
2024-03-21 19:27:43,592 - logger.py:50 - Epoch: [51][200/500] loss: 3.20025, MAE: 0.17958, time/step=1056ms, lr=3.73e-05
2024-03-21 19:28:36,279 - logger.py:50 - Epoch: [51][250/500] loss: 3.65472, MAE: 0.19087, time/step=1056ms, lr=3.73e-05
2024-03-21 19:29:30,453 - logger.py:50 - Epoch: [51][300/500] loss: 3.74966, MAE: 0.19520, time/step=1060ms, lr=3.73e-05
2024-03-21 19:30:24,740 - logger.py:50 - Epoch: [51][350/500] loss: 3.67146, MAE: 0.19389, time/step=1064ms, lr=3.73e-05
2024-03-21 19:31:17,272 - logger.py:50 - Epoch: [51][400/500] loss: 3.61227, MAE: 0.19256, time/step=1062ms, lr=3.73e-05
2024-03-21 19:32:11,271 - logger.py:50 - Epoch: [51][450/500] loss: 3.56586, MAE: 0.19112, time/step=1064ms, lr=3.73e-05
2024-03-21 19:33:03,446 - logger.py:50 - Epoch: [51][499/500] loss: 3.52781, MAE: 0.18968, time/step=1064ms, lr=3.73e-05
2024-03-21 19:34:03,342 - logger.py:50 - Epoch: [51] train loss: 3.52781, train MAE: 0.18968,val loss: 3.17750, val MAE: 0.17466,test loss: 3.19385, test MAE: 0.18160,Time: 592.08s
2024-03-21 19:34:03,342 - logger.py:50 - Best -- epoch=51, train loss: 3.52781, val loss: 3.17750, test loss: 3.19385

2024-03-21 19:35:03,642 - logger.py:50 - Epoch: [51]EMA val MAE: 0.32980, EMA test MAE: 0.33651, Time: 652.38s
2024-03-21 19:35:03,642 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 19:35:04,868 - logger.py:50 - Epoch: [52][0/500] loss: 3.04831, MAE: 0.15425, time/step=1224ms, lr=3.69e-05
2024-03-21 19:35:58,837 - logger.py:50 - Epoch: [52][50/500] loss: 3.20133, MAE: 0.18324, time/step=1082ms, lr=3.69e-05
2024-03-21 19:36:52,377 - logger.py:50 - Epoch: [52][100/500] loss: 3.19162, MAE: 0.17962, time/step=1077ms, lr=3.69e-05
2024-03-21 19:37:44,897 - logger.py:50 - Epoch: [52][150/500] loss: 3.19447, MAE: 0.18051, time/step=1068ms, lr=3.69e-05
2024-03-21 19:38:39,408 - logger.py:50 - Epoch: [52][200/500] loss: 3.45296, MAE: 0.18722, time/step=1073ms, lr=3.69e-05
2024-03-21 19:39:33,947 - logger.py:50 - Epoch: [52][250/500] loss: 3.40901, MAE: 0.18591, time/step=1077ms, lr=3.69e-05
2024-03-21 19:40:28,006 - logger.py:50 - Epoch: [52][300/500] loss: 3.37862, MAE: 0.18556, time/step=1078ms, lr=3.69e-05
2024-03-21 19:41:25,483 - logger.py:50 - Epoch: [52][350/500] loss: 3.35097, MAE: 0.18403, time/step=1088ms, lr=3.69e-05
2024-03-21 19:42:20,155 - logger.py:50 - Epoch: [52][400/500] loss: 3.33119, MAE: 0.18354, time/step=1089ms, lr=3.69e-05
2024-03-21 19:43:13,361 - logger.py:50 - Epoch: [52][450/500] loss: 3.56093, MAE: 0.18632, time/step=1086ms, lr=3.69e-05
2024-03-21 19:44:05,681 - logger.py:50 - Epoch: [52][499/500] loss: 3.52632, MAE: 0.18775, time/step=1084ms, lr=3.69e-05
2024-03-21 19:45:06,257 - logger.py:50 - Epoch: [52] train loss: 3.52632, train MAE: 0.18775,val loss: 3.18037, val MAE: 0.17721,test loss: 3.19349, test MAE: 0.18357,Time: 602.62s
2024-03-21 19:45:06,257 - logger.py:50 - Best -- epoch=51, train loss: 3.52781, val loss: 3.17750, test loss: 3.19385

2024-03-21 19:46:07,224 - logger.py:50 - Epoch: [52]EMA val MAE: 0.32386, EMA test MAE: 0.33031, Time: 663.58s
2024-03-21 19:46:07,224 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 19:46:07,949 - logger.py:50 - Epoch: [53][0/500] loss: 3.19590, MAE: 0.20227, time/step=723ms, lr=3.64e-05
2024-03-21 19:47:02,379 - logger.py:50 - Epoch: [53][50/500] loss: 3.19166, MAE: 0.18172, time/step=1081ms, lr=3.64e-05
2024-03-21 19:47:54,824 - logger.py:50 - Epoch: [53][100/500] loss: 4.28860, MAE: 0.19645, time/step=1065ms, lr=3.64e-05
2024-03-21 19:48:49,534 - logger.py:50 - Epoch: [53][150/500] loss: 3.91511, MAE: 0.19119, time/step=1075ms, lr=3.64e-05
2024-03-21 19:49:43,342 - logger.py:50 - Epoch: [53][200/500] loss: 3.74772, MAE: 0.18899, time/step=1075ms, lr=3.64e-05
2024-03-21 19:50:37,352 - logger.py:50 - Epoch: [53][250/500] loss: 3.64078, MAE: 0.18789, time/step=1076ms, lr=3.64e-05
2024-03-21 19:51:30,797 - logger.py:50 - Epoch: [53][300/500] loss: 3.74001, MAE: 0.19152, time/step=1075ms, lr=3.64e-05
2024-03-21 19:52:25,122 - logger.py:50 - Epoch: [53][350/500] loss: 3.66275, MAE: 0.19096, time/step=1077ms, lr=3.64e-05
2024-03-21 19:53:19,616 - logger.py:50 - Epoch: [53][400/500] loss: 3.60349, MAE: 0.18965, time/step=1078ms, lr=3.64e-05
2024-03-21 19:54:11,780 - logger.py:50 - Epoch: [53][450/500] loss: 3.56058, MAE: 0.18895, time/step=1074ms, lr=3.64e-05
2024-03-21 19:55:05,179 - logger.py:50 - Epoch: [53][499/500] loss: 3.52650, MAE: 0.18851, time/step=1076ms, lr=3.64e-05
2024-03-21 19:56:06,836 - logger.py:50 - Epoch: [53] train loss: 3.52650, train MAE: 0.18851,val loss: 3.17825, val MAE: 0.17417,test loss: 3.19471, test MAE: 0.18130,Time: 599.61s
2024-03-21 19:56:06,837 - logger.py:50 - Best -- epoch=51, train loss: 3.52781, val loss: 3.17750, test loss: 3.19385

2024-03-21 19:57:07,613 - logger.py:50 - Epoch: [53]EMA val MAE: 0.31799, EMA test MAE: 0.32421, Time: 660.39s
2024-03-21 19:57:07,613 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 19:57:08,573 - logger.py:50 - Epoch: [54][0/500] loss: 3.13281, MAE: 0.17249, time/step=957ms, lr=3.59e-05
2024-03-21 19:58:01,459 - logger.py:50 - Epoch: [54][50/500] loss: 4.19690, MAE: 0.21140, time/step=1056ms, lr=3.59e-05
2024-03-21 19:58:56,260 - logger.py:50 - Epoch: [54][100/500] loss: 4.80116, MAE: 0.21856, time/step=1076ms, lr=3.59e-05
2024-03-21 19:59:48,270 - logger.py:50 - Epoch: [54][150/500] loss: 4.28832, MAE: 0.20811, time/step=1064ms, lr=3.59e-05
2024-03-21 20:00:41,804 - logger.py:50 - Epoch: [54][200/500] loss: 4.01197, MAE: 0.19981, time/step=1066ms, lr=3.59e-05
2024-03-21 20:01:35,264 - logger.py:50 - Epoch: [54][250/500] loss: 3.85225, MAE: 0.19624, time/step=1066ms, lr=3.59e-05
2024-03-21 20:02:29,317 - logger.py:50 - Epoch: [54][300/500] loss: 3.74530, MAE: 0.19487, time/step=1069ms, lr=3.59e-05
2024-03-21 20:03:23,275 - logger.py:50 - Epoch: [54][350/500] loss: 3.66577, MAE: 0.19275, time/step=1070ms, lr=3.59e-05
2024-03-21 20:04:17,445 - logger.py:50 - Epoch: [54][400/500] loss: 3.60687, MAE: 0.19083, time/step=1072ms, lr=3.59e-05
2024-03-21 20:05:12,569 - logger.py:50 - Epoch: [54][450/500] loss: 3.56023, MAE: 0.18936, time/step=1075ms, lr=3.59e-05
2024-03-21 20:06:05,169 - logger.py:50 - Epoch: [54][499/500] loss: 3.52510, MAE: 0.18825, time/step=1075ms, lr=3.59e-05
2024-03-21 20:07:05,320 - logger.py:50 - Epoch: [54] train loss: 3.52510, train MAE: 0.18825,val loss: 3.18130, val MAE: 0.17486,test loss: 3.19776, test MAE: 0.18178,Time: 597.71s
2024-03-21 20:07:05,321 - logger.py:50 - Best -- epoch=51, train loss: 3.52781, val loss: 3.17750, test loss: 3.19385

2024-03-21 20:08:05,315 - logger.py:50 - Epoch: [54]EMA val MAE: 0.31231, EMA test MAE: 0.31832, Time: 657.70s
2024-03-21 20:08:05,316 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 20:08:05,976 - logger.py:50 - Epoch: [55][0/500] loss: 3.23032, MAE: 0.21697, time/step=658ms, lr=3.55e-05
2024-03-21 20:08:59,924 - logger.py:50 - Epoch: [55][50/500] loss: 5.40005, MAE: 0.22793, time/step=1071ms, lr=3.55e-05
2024-03-21 20:09:53,419 - logger.py:50 - Epoch: [55][100/500] loss: 4.31044, MAE: 0.20472, time/step=1070ms, lr=3.55e-05
2024-03-21 20:10:46,938 - logger.py:50 - Epoch: [55][150/500] loss: 3.94115, MAE: 0.19728, time/step=1070ms, lr=3.55e-05
2024-03-21 20:11:41,176 - logger.py:50 - Epoch: [55][200/500] loss: 3.75018, MAE: 0.19304, time/step=1074ms, lr=3.55e-05
2024-03-21 20:12:35,001 - logger.py:50 - Epoch: [55][250/500] loss: 3.63795, MAE: 0.19009, time/step=1074ms, lr=3.55e-05
2024-03-21 20:13:28,645 - logger.py:50 - Epoch: [55][300/500] loss: 3.73494, MAE: 0.19054, time/step=1074ms, lr=3.55e-05
2024-03-21 20:14:22,731 - logger.py:50 - Epoch: [55][350/500] loss: 3.66086, MAE: 0.19066, time/step=1075ms, lr=3.55e-05
2024-03-21 20:15:17,629 - logger.py:50 - Epoch: [55][400/500] loss: 3.60440, MAE: 0.18940, time/step=1078ms, lr=3.55e-05
2024-03-21 20:16:11,473 - logger.py:50 - Epoch: [55][450/500] loss: 3.56082, MAE: 0.18877, time/step=1078ms, lr=3.55e-05
2024-03-21 20:17:02,569 - logger.py:50 - Epoch: [55][499/500] loss: 3.52603, MAE: 0.18809, time/step=1075ms, lr=3.55e-05
2024-03-21 20:18:01,733 - logger.py:50 - Epoch: [55] train loss: 3.52603, train MAE: 0.18809,val loss: 3.18877, val MAE: 0.17509,test loss: 3.20675, test MAE: 0.18264,Time: 596.42s
2024-03-21 20:18:01,734 - logger.py:50 - Best -- epoch=51, train loss: 3.52781, val loss: 3.17750, test loss: 3.19385

2024-03-21 20:19:00,599 - logger.py:50 - Epoch: [55]EMA val MAE: 0.30684, EMA test MAE: 0.31267, Time: 655.28s
2024-03-21 20:19:00,600 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 20:19:01,803 - logger.py:50 - Epoch: [56][0/500] loss: 3.17493, MAE: 0.15077, time/step=1200ms, lr=3.50e-05
2024-03-21 20:19:54,123 - logger.py:50 - Epoch: [56][50/500] loss: 6.44318, MAE: 0.25959, time/step=1049ms, lr=3.50e-05
2024-03-21 20:20:46,026 - logger.py:50 - Epoch: [56][100/500] loss: 4.83699, MAE: 0.22175, time/step=1044ms, lr=3.50e-05
2024-03-21 20:21:41,688 - logger.py:50 - Epoch: [56][150/500] loss: 4.27989, MAE: 0.20691, time/step=1067ms, lr=3.50e-05
2024-03-21 20:22:34,466 - logger.py:50 - Epoch: [56][200/500] loss: 4.01160, MAE: 0.20034, time/step=1064ms, lr=3.50e-05
2024-03-21 20:23:28,469 - logger.py:50 - Epoch: [56][250/500] loss: 3.84382, MAE: 0.19560, time/step=1067ms, lr=3.50e-05
2024-03-21 20:24:26,995 - logger.py:50 - Epoch: [56][300/500] loss: 3.73498, MAE: 0.19300, time/step=1084ms, lr=3.50e-05
2024-03-21 20:25:25,969 - logger.py:50 - Epoch: [56][350/500] loss: 3.65662, MAE: 0.19159, time/step=1098ms, lr=3.50e-05
2024-03-21 20:26:25,314 - logger.py:50 - Epoch: [56][400/500] loss: 3.59916, MAE: 0.18952, time/step=1109ms, lr=3.50e-05
2024-03-21 20:27:20,404 - logger.py:50 - Epoch: [56][450/500] loss: 3.55767, MAE: 0.18908, time/step=1108ms, lr=3.50e-05
2024-03-21 20:28:17,073 - logger.py:50 - Epoch: [56][499/500] loss: 3.52594, MAE: 0.18870, time/step=1113ms, lr=3.50e-05
2024-03-21 20:29:29,671 - logger.py:50 - Epoch: [56] train loss: 3.52594, train MAE: 0.18870,val loss: 3.19279, val MAE: 0.17868,test loss: 3.21017, test MAE: 0.18660,Time: 629.07s
2024-03-21 20:29:29,672 - logger.py:50 - Best -- epoch=51, train loss: 3.52781, val loss: 3.17750, test loss: 3.19385

2024-03-21 20:30:39,337 - logger.py:50 - Epoch: [56]EMA val MAE: 0.30150, EMA test MAE: 0.30719, Time: 698.74s
2024-03-21 20:30:39,337 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 20:30:40,168 - logger.py:50 - Epoch: [57][0/500] loss: 3.21295, MAE: 0.18765, time/step=828ms, lr=3.45e-05
2024-03-21 20:31:38,786 - logger.py:50 - Epoch: [57][50/500] loss: 3.20238, MAE: 0.18555, time/step=1166ms, lr=3.45e-05
2024-03-21 20:32:39,030 - logger.py:50 - Epoch: [57][100/500] loss: 3.19667, MAE: 0.18420, time/step=1185ms, lr=3.45e-05
2024-03-21 20:33:36,789 - logger.py:50 - Epoch: [57][150/500] loss: 3.19862, MAE: 0.18333, time/step=1175ms, lr=3.45e-05
2024-03-21 20:34:35,353 - logger.py:50 - Epoch: [57][200/500] loss: 3.19297, MAE: 0.18041, time/step=1174ms, lr=3.45e-05
2024-03-21 20:35:36,768 - logger.py:50 - Epoch: [57][250/500] loss: 3.19402, MAE: 0.18058, time/step=1185ms, lr=3.45e-05
2024-03-21 20:36:36,177 - logger.py:50 - Epoch: [57][300/500] loss: 3.19422, MAE: 0.17986, time/step=1186ms, lr=3.45e-05
2024-03-21 20:37:32,985 - logger.py:50 - Epoch: [57][350/500] loss: 3.19587, MAE: 0.17998, time/step=1178ms, lr=3.45e-05
2024-03-21 20:38:32,253 - logger.py:50 - Epoch: [57][400/500] loss: 3.19750, MAE: 0.17951, time/step=1179ms, lr=3.45e-05
2024-03-21 20:39:29,993 - logger.py:50 - Epoch: [57][450/500] loss: 3.31193, MAE: 0.18266, time/step=1177ms, lr=3.45e-05
2024-03-21 20:40:26,916 - logger.py:50 - Epoch: [57][499/500] loss: 3.52460, MAE: 0.18788, time/step=1175ms, lr=3.45e-05
2024-03-21 20:41:36,985 - logger.py:50 - Epoch: [57] train loss: 3.52460, train MAE: 0.18788,val loss: 3.18764, val MAE: 0.19625,test loss: 3.20226, test MAE: 0.20336,Time: 657.65s
2024-03-21 20:41:36,985 - logger.py:50 - Best -- epoch=51, train loss: 3.52781, val loss: 3.17750, test loss: 3.19385

2024-03-21 20:42:44,195 - logger.py:50 - Epoch: [57]EMA val MAE: 0.29624, EMA test MAE: 0.30180, Time: 724.86s
2024-03-21 20:42:44,196 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 20:42:45,529 - logger.py:50 - Epoch: [58][0/500] loss: 3.31030, MAE: 0.23737, time/step=1332ms, lr=3.40e-05
2024-03-21 20:43:43,356 - logger.py:50 - Epoch: [58][50/500] loss: 3.20742, MAE: 0.18499, time/step=1160ms, lr=3.40e-05
2024-03-21 20:44:41,763 - logger.py:50 - Epoch: [58][100/500] loss: 3.20234, MAE: 0.18178, time/step=1164ms, lr=3.40e-05
2024-03-21 20:45:40,778 - logger.py:50 - Epoch: [58][150/500] loss: 3.19763, MAE: 0.18164, time/step=1169ms, lr=3.40e-05
2024-03-21 20:46:41,037 - logger.py:50 - Epoch: [58][200/500] loss: 3.19527, MAE: 0.17985, time/step=1178ms, lr=3.40e-05
2024-03-21 20:47:40,574 - logger.py:50 - Epoch: [58][250/500] loss: 3.20276, MAE: 0.18035, time/step=1181ms, lr=3.40e-05
2024-03-21 20:48:38,545 - logger.py:50 - Epoch: [58][300/500] loss: 3.19783, MAE: 0.17990, time/step=1177ms, lr=3.40e-05
2024-03-21 20:49:36,800 - logger.py:50 - Epoch: [58][350/500] loss: 3.20054, MAE: 0.18041, time/step=1176ms, lr=3.40e-05
2024-03-21 20:50:36,739 - logger.py:50 - Epoch: [58][400/500] loss: 3.19898, MAE: 0.18045, time/step=1178ms, lr=3.40e-05
2024-03-21 20:51:36,796 - logger.py:50 - Epoch: [58][450/500] loss: 3.56135, MAE: 0.18723, time/step=1181ms, lr=3.40e-05
2024-03-21 20:52:33,660 - logger.py:50 - Epoch: [58][499/500] loss: 3.52534, MAE: 0.18900, time/step=1179ms, lr=3.40e-05
2024-03-21 20:53:44,323 - logger.py:50 - Epoch: [58] train loss: 3.52534, train MAE: 0.18900,val loss: 3.18014, val MAE: 0.18286,test loss: 3.19554, test MAE: 0.18960,Time: 660.13s
2024-03-21 20:53:44,323 - logger.py:50 - Best -- epoch=51, train loss: 3.52781, val loss: 3.17750, test loss: 3.19385

2024-03-21 20:54:55,310 - logger.py:50 - Epoch: [58]EMA val MAE: 0.29117, EMA test MAE: 0.29664, Time: 731.11s
2024-03-21 20:54:55,310 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 20:54:56,580 - logger.py:50 - Epoch: [59][0/500] loss: 3.60157, MAE: 0.22615, time/step=1267ms, lr=3.36e-05
2024-03-21 20:55:55,165 - logger.py:50 - Epoch: [59][50/500] loss: 3.22228, MAE: 0.18546, time/step=1174ms, lr=3.36e-05
2024-03-21 20:56:53,243 - logger.py:50 - Epoch: [59][100/500] loss: 3.20313, MAE: 0.17906, time/step=1168ms, lr=3.36e-05
2024-03-21 20:57:52,585 - logger.py:50 - Epoch: [59][150/500] loss: 3.19794, MAE: 0.18002, time/step=1174ms, lr=3.36e-05
2024-03-21 20:58:51,760 - logger.py:50 - Epoch: [59][200/500] loss: 3.20022, MAE: 0.18078, time/step=1176ms, lr=3.36e-05
2024-03-21 20:59:52,810 - logger.py:50 - Epoch: [59][250/500] loss: 3.39972, MAE: 0.18257, time/step=1185ms, lr=3.36e-05
2024-03-21 21:00:51,697 - logger.py:50 - Epoch: [59][300/500] loss: 3.36634, MAE: 0.18478, time/step=1184ms, lr=3.36e-05
2024-03-21 21:01:50,213 - logger.py:50 - Epoch: [59][350/500] loss: 3.34289, MAE: 0.18409, time/step=1182ms, lr=3.36e-05
2024-03-21 21:02:49,469 - logger.py:50 - Epoch: [59][400/500] loss: 3.32316, MAE: 0.18353, time/step=1182ms, lr=3.36e-05
2024-03-21 21:03:47,821 - logger.py:50 - Epoch: [59][450/500] loss: 3.55803, MAE: 0.18723, time/step=1181ms, lr=3.36e-05
2024-03-21 21:04:44,461 - logger.py:50 - Epoch: [59][499/500] loss: 3.52309, MAE: 0.18765, time/step=1178ms, lr=3.36e-05
2024-03-21 21:05:56,644 - logger.py:50 - Epoch: [59] train loss: 3.52309, train MAE: 0.18765,val loss: 3.19524, val MAE: 0.17977,test loss: 3.21862, test MAE: 0.18801,Time: 661.33s
2024-03-21 21:05:56,644 - logger.py:50 - Best -- epoch=51, train loss: 3.52781, val loss: 3.17750, test loss: 3.19385

2024-03-21 21:07:07,684 - logger.py:50 - Epoch: [59]EMA val MAE: 0.28637, EMA test MAE: 0.29179, Time: 732.37s
2024-03-21 21:07:07,685 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 21:07:08,446 - logger.py:50 - Epoch: [60][0/500] loss: 3.26107, MAE: 0.19824, time/step=759ms, lr=3.31e-05
2024-03-21 21:08:07,572 - logger.py:50 - Epoch: [60][50/500] loss: 3.19058, MAE: 0.17941, time/step=1174ms, lr=3.31e-05
2024-03-21 21:09:07,834 - logger.py:50 - Epoch: [60][100/500] loss: 3.71430, MAE: 0.19538, time/step=1190ms, lr=3.31e-05
2024-03-21 21:10:07,587 - logger.py:50 - Epoch: [60][150/500] loss: 3.54289, MAE: 0.19213, time/step=1191ms, lr=3.31e-05
2024-03-21 21:11:08,756 - logger.py:50 - Epoch: [60][200/500] loss: 4.00604, MAE: 0.19629, time/step=1199ms, lr=3.31e-05
2024-03-21 21:12:07,831 - logger.py:50 - Epoch: [60][250/500] loss: 3.85126, MAE: 0.19580, time/step=1196ms, lr=3.31e-05
2024-03-21 21:13:08,035 - logger.py:50 - Epoch: [60][300/500] loss: 3.74291, MAE: 0.19411, time/step=1197ms, lr=3.31e-05
2024-03-21 21:14:09,386 - logger.py:50 - Epoch: [60][350/500] loss: 3.66047, MAE: 0.19168, time/step=1201ms, lr=3.31e-05
2024-03-21 21:15:08,100 - logger.py:50 - Epoch: [60][400/500] loss: 3.60340, MAE: 0.19083, time/step=1198ms, lr=3.31e-05
2024-03-21 21:16:06,830 - logger.py:50 - Epoch: [60][450/500] loss: 3.56017, MAE: 0.18915, time/step=1195ms, lr=3.31e-05
2024-03-21 21:17:03,709 - logger.py:50 - Epoch: [60][499/500] loss: 3.52387, MAE: 0.18781, time/step=1192ms, lr=3.31e-05
2024-03-21 21:18:12,382 - logger.py:50 - Epoch: [60] train loss: 3.52387, train MAE: 0.18781,val loss: 3.17567, val MAE: 0.17471,test loss: 3.19046, test MAE: 0.18147,Time: 664.70s
2024-03-21 21:18:12,382 - logger.py:50 - Best -- epoch=60, train loss: 3.52387, val loss: 3.17567, test loss: 3.19046

2024-03-21 21:19:20,469 - logger.py:50 - Epoch: [60]EMA val MAE: 0.28161, EMA test MAE: 0.28700, Time: 732.78s
2024-03-21 21:19:20,469 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 21:19:21,241 - logger.py:50 - Epoch: [61][0/500] loss: 3.18450, MAE: 0.17761, time/step=769ms, lr=3.26e-05
2024-03-21 21:20:20,788 - logger.py:50 - Epoch: [61][50/500] loss: 3.19680, MAE: 0.17928, time/step=1183ms, lr=3.26e-05
2024-03-21 21:21:19,004 - logger.py:50 - Epoch: [61][100/500] loss: 3.19038, MAE: 0.17896, time/step=1174ms, lr=3.26e-05
2024-03-21 21:22:15,932 - logger.py:50 - Epoch: [61][150/500] loss: 3.19943, MAE: 0.18070, time/step=1162ms, lr=3.26e-05
2024-03-21 21:23:14,878 - logger.py:50 - Epoch: [61][200/500] loss: 3.45936, MAE: 0.18898, time/step=1166ms, lr=3.26e-05
2024-03-21 21:24:15,886 - logger.py:50 - Epoch: [61][250/500] loss: 3.40149, MAE: 0.18732, time/step=1177ms, lr=3.26e-05
2024-03-21 21:25:14,051 - logger.py:50 - Epoch: [61][300/500] loss: 3.36816, MAE: 0.18586, time/step=1175ms, lr=3.26e-05
2024-03-21 21:26:13,061 - logger.py:50 - Epoch: [61][350/500] loss: 3.34256, MAE: 0.18432, time/step=1175ms, lr=3.26e-05
2024-03-21 21:27:11,203 - logger.py:50 - Epoch: [61][400/500] loss: 3.32468, MAE: 0.18392, time/step=1174ms, lr=3.26e-05
2024-03-21 21:28:08,389 - logger.py:50 - Epoch: [61][450/500] loss: 3.55812, MAE: 0.18739, time/step=1171ms, lr=3.26e-05
2024-03-21 21:29:07,745 - logger.py:50 - Epoch: [61][499/500] loss: 3.52387, MAE: 0.18669, time/step=1175ms, lr=3.26e-05
2024-03-21 21:30:18,294 - logger.py:50 - Epoch: [61] train loss: 3.52387, train MAE: 0.18669,val loss: 3.18004, val MAE: 0.17617,test loss: 3.19122, test MAE: 0.18263,Time: 657.82s
2024-03-21 21:30:18,294 - logger.py:50 - Best -- epoch=60, train loss: 3.52387, val loss: 3.17567, test loss: 3.19046

2024-03-21 21:31:27,112 - logger.py:50 - Epoch: [61]EMA val MAE: 0.27685, EMA test MAE: 0.28224, Time: 726.64s
2024-03-21 21:31:27,113 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 21:31:28,577 - logger.py:50 - Epoch: [62][0/500] loss: 3.24180, MAE: 0.20365, time/step=1462ms, lr=3.21e-05
2024-03-21 21:32:26,336 - logger.py:50 - Epoch: [62][50/500] loss: 4.17981, MAE: 0.20182, time/step=1161ms, lr=3.21e-05
2024-03-21 21:33:25,016 - logger.py:50 - Epoch: [62][100/500] loss: 3.69474, MAE: 0.19295, time/step=1167ms, lr=3.21e-05
2024-03-21 21:34:24,154 - logger.py:50 - Epoch: [62][150/500] loss: 3.52120, MAE: 0.18626, time/step=1172ms, lr=3.21e-05
2024-03-21 21:35:23,181 - logger.py:50 - Epoch: [62][200/500] loss: 3.43863, MAE: 0.18548, time/step=1174ms, lr=3.21e-05
2024-03-21 21:36:21,439 - logger.py:50 - Epoch: [62][250/500] loss: 3.39249, MAE: 0.18504, time/step=1173ms, lr=3.21e-05
2024-03-21 21:37:20,027 - logger.py:50 - Epoch: [62][300/500] loss: 3.73795, MAE: 0.19216, time/step=1172ms, lr=3.21e-05
2024-03-21 21:38:17,275 - logger.py:50 - Epoch: [62][350/500] loss: 3.66384, MAE: 0.19179, time/step=1169ms, lr=3.21e-05
2024-03-21 21:39:16,881 - logger.py:50 - Epoch: [62][400/500] loss: 3.60240, MAE: 0.18933, time/step=1171ms, lr=3.21e-05
2024-03-21 21:40:15,617 - logger.py:50 - Epoch: [62][450/500] loss: 3.55831, MAE: 0.18824, time/step=1172ms, lr=3.21e-05
2024-03-21 21:41:13,614 - logger.py:50 - Epoch: [62][499/500] loss: 3.52301, MAE: 0.18738, time/step=1173ms, lr=3.21e-05
2024-03-21 21:42:24,072 - logger.py:50 - Epoch: [62] train loss: 3.52301, train MAE: 0.18738,val loss: 3.17423, val MAE: 0.17584,test loss: 3.18859, test MAE: 0.18257,Time: 656.96s
2024-03-21 21:42:24,072 - logger.py:50 - Best -- epoch=62, train loss: 3.52301, val loss: 3.17423, test loss: 3.18859

2024-03-21 21:43:33,952 - logger.py:50 - Epoch: [62]EMA val MAE: 0.27221, EMA test MAE: 0.27762, Time: 726.84s
2024-03-21 21:43:33,952 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 21:43:34,722 - logger.py:50 - Epoch: [63][0/500] loss: 3.08696, MAE: 0.14025, time/step=767ms, lr=3.16e-05
2024-03-21 21:44:33,257 - logger.py:50 - Epoch: [63][50/500] loss: 3.19238, MAE: 0.17518, time/step=1163ms, lr=3.16e-05
2024-03-21 21:45:32,241 - logger.py:50 - Epoch: [63][100/500] loss: 3.20697, MAE: 0.17987, time/step=1171ms, lr=3.16e-05
2024-03-21 21:46:30,953 - logger.py:50 - Epoch: [63][150/500] loss: 3.20503, MAE: 0.17938, time/step=1172ms, lr=3.16e-05
2024-03-21 21:47:28,406 - logger.py:50 - Epoch: [63][200/500] loss: 3.20320, MAE: 0.17967, time/step=1166ms, lr=3.16e-05
2024-03-21 21:48:26,956 - logger.py:50 - Epoch: [63][250/500] loss: 3.20779, MAE: 0.18113, time/step=1167ms, lr=3.16e-05
2024-03-21 21:49:25,909 - logger.py:50 - Epoch: [63][300/500] loss: 3.20357, MAE: 0.18030, time/step=1169ms, lr=3.16e-05
2024-03-21 21:50:22,797 - logger.py:50 - Epoch: [63][350/500] loss: 3.20256, MAE: 0.18024, time/step=1165ms, lr=3.16e-05
2024-03-21 21:51:16,648 - logger.py:50 - Epoch: [63][400/500] loss: 3.20147, MAE: 0.18032, time/step=1154ms, lr=3.16e-05
2024-03-21 21:52:12,056 - logger.py:50 - Epoch: [63][450/500] loss: 3.56097, MAE: 0.18531, time/step=1149ms, lr=3.16e-05
2024-03-21 21:53:06,881 - logger.py:50 - Epoch: [63][499/500] loss: 3.52280, MAE: 0.18623, time/step=1146ms, lr=3.16e-05
2024-03-21 21:54:09,776 - logger.py:50 - Epoch: [63] train loss: 3.52280, train MAE: 0.18623,val loss: 3.17600, val MAE: 0.17663,test loss: 3.19052, test MAE: 0.18313,Time: 635.82s
2024-03-21 21:54:09,776 - logger.py:50 - Best -- epoch=62, train loss: 3.52301, val loss: 3.17423, test loss: 3.18859

2024-03-21 21:55:13,265 - logger.py:50 - Epoch: [63]EMA val MAE: 0.26753, EMA test MAE: 0.27299, Time: 699.31s
2024-03-21 21:55:13,265 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 21:55:14,067 - logger.py:50 - Epoch: [64][0/500] loss: 3.23333, MAE: 0.20644, time/step=799ms, lr=3.11e-05
2024-03-21 21:56:09,790 - logger.py:50 - Epoch: [64][50/500] loss: 3.19324, MAE: 0.18173, time/step=1108ms, lr=3.11e-05
2024-03-21 21:57:04,962 - logger.py:50 - Epoch: [64][100/500] loss: 3.18891, MAE: 0.18132, time/step=1106ms, lr=3.11e-05
2024-03-21 21:58:00,153 - logger.py:50 - Epoch: [64][150/500] loss: 3.53137, MAE: 0.18913, time/step=1105ms, lr=3.11e-05
2024-03-21 21:58:54,980 - logger.py:50 - Epoch: [64][200/500] loss: 3.45219, MAE: 0.18896, time/step=1103ms, lr=3.11e-05
2024-03-21 21:59:50,223 - logger.py:50 - Epoch: [64][250/500] loss: 3.40041, MAE: 0.18645, time/step=1103ms, lr=3.11e-05
2024-03-21 22:00:46,033 - logger.py:50 - Epoch: [64][300/500] loss: 3.36645, MAE: 0.18473, time/step=1106ms, lr=3.11e-05
2024-03-21 22:01:42,192 - logger.py:50 - Epoch: [64][350/500] loss: 3.66055, MAE: 0.18869, time/step=1108ms, lr=3.11e-05
2024-03-21 22:02:38,520 - logger.py:50 - Epoch: [64][400/500] loss: 3.59827, MAE: 0.18787, time/step=1110ms, lr=3.11e-05
2024-03-21 22:03:33,028 - logger.py:50 - Epoch: [64][450/500] loss: 3.55306, MAE: 0.18719, time/step=1108ms, lr=3.11e-05
2024-03-21 22:04:26,887 - logger.py:50 - Epoch: [64][499/500] loss: 3.52188, MAE: 0.18627, time/step=1107ms, lr=3.11e-05
2024-03-21 22:05:29,614 - logger.py:50 - Epoch: [64] train loss: 3.52188, train MAE: 0.18627,val loss: 3.17468, val MAE: 0.17549,test loss: 3.18775, test MAE: 0.18182,Time: 616.35s
2024-03-21 22:05:29,614 - logger.py:50 - Best -- epoch=62, train loss: 3.52301, val loss: 3.17423, test loss: 3.18859

2024-03-21 22:06:31,631 - logger.py:50 - Epoch: [64]EMA val MAE: 0.26306, EMA test MAE: 0.26858, Time: 678.37s
2024-03-21 22:06:31,631 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 22:06:32,884 - logger.py:50 - Epoch: [65][0/500] loss: 3.18203, MAE: 0.17315, time/step=1250ms, lr=3.06e-05
2024-03-21 22:07:27,048 - logger.py:50 - Epoch: [65][50/500] loss: 3.16949, MAE: 0.17405, time/step=1087ms, lr=3.06e-05
2024-03-21 22:08:20,827 - logger.py:50 - Epoch: [65][100/500] loss: 3.18779, MAE: 0.17789, time/step=1081ms, lr=3.06e-05
2024-03-21 22:09:14,676 - logger.py:50 - Epoch: [65][150/500] loss: 3.18975, MAE: 0.17908, time/step=1080ms, lr=3.06e-05
2024-03-21 22:10:09,280 - logger.py:50 - Epoch: [65][200/500] loss: 3.44560, MAE: 0.18192, time/step=1083ms, lr=3.06e-05
2024-03-21 22:11:04,803 - logger.py:50 - Epoch: [65][250/500] loss: 3.39847, MAE: 0.18474, time/step=1088ms, lr=3.06e-05
2024-03-21 22:11:59,513 - logger.py:50 - Epoch: [65][300/500] loss: 3.36304, MAE: 0.18359, time/step=1089ms, lr=3.06e-05
2024-03-21 22:12:53,160 - logger.py:50 - Epoch: [65][350/500] loss: 3.34288, MAE: 0.18325, time/step=1087ms, lr=3.06e-05
2024-03-21 22:13:51,854 - logger.py:50 - Epoch: [65][400/500] loss: 3.60057, MAE: 0.18747, time/step=1098ms, lr=3.06e-05
2024-03-21 22:14:50,400 - logger.py:50 - Epoch: [65][450/500] loss: 3.55770, MAE: 0.18776, time/step=1106ms, lr=3.06e-05
2024-03-21 22:15:47,849 - logger.py:50 - Epoch: [65][499/500] loss: 3.52251, MAE: 0.18678, time/step=1112ms, lr=3.06e-05
2024-03-21 22:16:57,571 - logger.py:50 - Epoch: [65] train loss: 3.52251, train MAE: 0.18678,val loss: 3.17529, val MAE: 0.17764,test loss: 3.18969, test MAE: 0.18459,Time: 625.94s
2024-03-21 22:16:57,571 - logger.py:50 - Best -- epoch=62, train loss: 3.52301, val loss: 3.17423, test loss: 3.18859

2024-03-21 22:18:06,116 - logger.py:50 - Epoch: [65]EMA val MAE: 0.25865, EMA test MAE: 0.26423, Time: 694.49s
2024-03-21 22:18:06,117 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 22:18:07,494 - logger.py:50 - Epoch: [66][0/500] loss: 3.12164, MAE: 0.16815, time/step=1375ms, lr=3.01e-05
2024-03-21 22:19:05,453 - logger.py:50 - Epoch: [66][50/500] loss: 3.19965, MAE: 0.17773, time/step=1163ms, lr=3.01e-05
2024-03-21 22:20:03,217 - logger.py:50 - Epoch: [66][100/500] loss: 3.20680, MAE: 0.18054, time/step=1159ms, lr=3.01e-05
2024-03-21 22:21:01,033 - logger.py:50 - Epoch: [66][150/500] loss: 3.20104, MAE: 0.17858, time/step=1158ms, lr=3.01e-05
2024-03-21 22:22:00,423 - logger.py:50 - Epoch: [66][200/500] loss: 3.19484, MAE: 0.17743, time/step=1166ms, lr=3.01e-05
2024-03-21 22:22:58,194 - logger.py:50 - Epoch: [66][250/500] loss: 3.19488, MAE: 0.17759, time/step=1164ms, lr=3.01e-05
2024-03-21 22:23:56,021 - logger.py:50 - Epoch: [66][300/500] loss: 3.19619, MAE: 0.17795, time/step=1162ms, lr=3.01e-05
2024-03-21 22:24:54,648 - logger.py:50 - Epoch: [66][350/500] loss: 3.19628, MAE: 0.17853, time/step=1164ms, lr=3.01e-05
2024-03-21 22:25:53,432 - logger.py:50 - Epoch: [66][400/500] loss: 3.32151, MAE: 0.18029, time/step=1165ms, lr=3.01e-05
2024-03-21 22:26:50,419 - logger.py:50 - Epoch: [66][450/500] loss: 3.55738, MAE: 0.18423, time/step=1163ms, lr=3.01e-05
2024-03-21 22:27:48,524 - logger.py:50 - Epoch: [66][499/500] loss: 3.52107, MAE: 0.18576, time/step=1165ms, lr=3.01e-05
2024-03-21 22:28:53,503 - logger.py:50 - Epoch: [66] train loss: 3.52107, train MAE: 0.18576,val loss: 3.17847, val MAE: 0.17859,test loss: 3.19328, test MAE: 0.18517,Time: 647.39s
2024-03-21 22:28:53,503 - logger.py:50 - Best -- epoch=62, train loss: 3.52301, val loss: 3.17423, test loss: 3.18859

2024-03-21 22:29:56,116 - logger.py:50 - Epoch: [66]EMA val MAE: 0.25427, EMA test MAE: 0.25994, Time: 710.00s
2024-03-21 22:29:56,117 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 22:29:56,804 - logger.py:50 - Epoch: [67][0/500] loss: 3.33704, MAE: 0.17351, time/step=685ms, lr=2.96e-05
2024-03-21 22:30:51,785 - logger.py:50 - Epoch: [67][50/500] loss: 3.20272, MAE: 0.18116, time/step=1091ms, lr=2.96e-05
2024-03-21 22:31:45,470 - logger.py:50 - Epoch: [67][100/500] loss: 3.20187, MAE: 0.17967, time/step=1083ms, lr=2.96e-05
2024-03-21 22:32:38,914 - logger.py:50 - Epoch: [67][150/500] loss: 3.53733, MAE: 0.18575, time/step=1078ms, lr=2.96e-05
2024-03-21 22:33:32,869 - logger.py:50 - Epoch: [67][200/500] loss: 3.44838, MAE: 0.18520, time/step=1078ms, lr=2.96e-05
2024-03-21 22:34:27,015 - logger.py:50 - Epoch: [67][250/500] loss: 3.84086, MAE: 0.18985, time/step=1079ms, lr=2.96e-05
2024-03-21 22:35:21,000 - logger.py:50 - Epoch: [67][300/500] loss: 3.73861, MAE: 0.19020, time/step=1079ms, lr=2.96e-05
2024-03-21 22:36:14,956 - logger.py:50 - Epoch: [67][350/500] loss: 3.66000, MAE: 0.18884, time/step=1079ms, lr=2.96e-05
2024-03-21 22:37:09,362 - logger.py:50 - Epoch: [67][400/500] loss: 3.60067, MAE: 0.18765, time/step=1080ms, lr=2.96e-05
2024-03-21 22:38:00,806 - logger.py:50 - Epoch: [67][450/500] loss: 3.55648, MAE: 0.18702, time/step=1075ms, lr=2.96e-05
2024-03-21 22:38:55,364 - logger.py:50 - Epoch: [67][499/500] loss: 3.52030, MAE: 0.18626, time/step=1078ms, lr=2.96e-05
2024-03-21 22:39:56,518 - logger.py:50 - Epoch: [67] train loss: 3.52030, train MAE: 0.18626,val loss: 3.17352, val MAE: 0.17454,test loss: 3.18828, test MAE: 0.18167,Time: 600.40s
2024-03-21 22:39:56,518 - logger.py:50 - Best -- epoch=67, train loss: 3.52030, val loss: 3.17352, test loss: 3.18828

2024-03-21 22:40:56,638 - logger.py:50 - Epoch: [67]EMA val MAE: 0.25007, EMA test MAE: 0.25580, Time: 660.52s
2024-03-21 22:40:56,638 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 22:40:57,361 - logger.py:50 - Epoch: [68][0/500] loss: 3.17565, MAE: 0.18997, time/step=721ms, lr=2.91e-05
2024-03-21 22:41:50,856 - logger.py:50 - Epoch: [68][50/500] loss: 4.20794, MAE: 0.20325, time/step=1063ms, lr=2.91e-05
2024-03-21 22:42:43,485 - logger.py:50 - Epoch: [68][100/500] loss: 4.80868, MAE: 0.20981, time/step=1058ms, lr=2.91e-05
2024-03-21 22:43:35,997 - logger.py:50 - Epoch: [68][150/500] loss: 4.27445, MAE: 0.20165, time/step=1055ms, lr=2.91e-05
2024-03-21 22:44:29,117 - logger.py:50 - Epoch: [68][200/500] loss: 4.00160, MAE: 0.19722, time/step=1057ms, lr=2.91e-05
2024-03-21 22:45:22,411 - logger.py:50 - Epoch: [68][250/500] loss: 3.84070, MAE: 0.19340, time/step=1059ms, lr=2.91e-05
2024-03-21 22:46:15,135 - logger.py:50 - Epoch: [68][300/500] loss: 3.73548, MAE: 0.19072, time/step=1058ms, lr=2.91e-05
2024-03-21 22:47:07,826 - logger.py:50 - Epoch: [68][350/500] loss: 3.65825, MAE: 0.18931, time/step=1058ms, lr=2.91e-05
2024-03-21 22:48:00,401 - logger.py:50 - Epoch: [68][400/500] loss: 3.60299, MAE: 0.18869, time/step=1057ms, lr=2.91e-05
2024-03-21 22:48:53,595 - logger.py:50 - Epoch: [68][450/500] loss: 3.55896, MAE: 0.18782, time/step=1058ms, lr=2.91e-05
2024-03-21 22:49:45,977 - logger.py:50 - Epoch: [68][499/500] loss: 3.52061, MAE: 0.18586, time/step=1059ms, lr=2.91e-05
2024-03-21 22:50:45,679 - logger.py:50 - Epoch: [68] train loss: 3.52061, train MAE: 0.18586,val loss: 3.17380, val MAE: 0.17326,test loss: 3.18884, test MAE: 0.17987,Time: 589.04s
2024-03-21 22:50:45,679 - logger.py:50 - Best -- epoch=67, train loss: 3.52030, val loss: 3.17352, test loss: 3.18828

2024-03-21 22:51:44,768 - logger.py:50 - Epoch: [68]EMA val MAE: 0.24589, EMA test MAE: 0.25170, Time: 648.13s
2024-03-21 22:51:44,768 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 22:51:45,966 - logger.py:50 - Epoch: [69][0/500] loss: 3.23013, MAE: 0.20494, time/step=1195ms, lr=2.86e-05
2024-03-21 22:52:39,199 - logger.py:50 - Epoch: [69][50/500] loss: 3.16423, MAE: 0.17047, time/step=1067ms, lr=2.86e-05
2024-03-21 22:53:32,349 - logger.py:50 - Epoch: [69][100/500] loss: 3.17312, MAE: 0.17368, time/step=1065ms, lr=2.86e-05
2024-03-21 22:54:25,189 - logger.py:50 - Epoch: [69][150/500] loss: 3.17980, MAE: 0.17576, time/step=1062ms, lr=2.86e-05
2024-03-21 22:55:19,493 - logger.py:50 - Epoch: [69][200/500] loss: 3.18581, MAE: 0.17779, time/step=1068ms, lr=2.86e-05
2024-03-21 22:56:12,816 - logger.py:50 - Epoch: [69][250/500] loss: 3.18375, MAE: 0.17739, time/step=1068ms, lr=2.86e-05
2024-03-21 22:57:05,418 - logger.py:50 - Epoch: [69][300/500] loss: 3.19379, MAE: 0.17893, time/step=1065ms, lr=2.86e-05
2024-03-21 22:57:58,479 - logger.py:50 - Epoch: [69][350/500] loss: 3.65795, MAE: 0.18712, time/step=1065ms, lr=2.86e-05
2024-03-21 22:58:51,333 - logger.py:50 - Epoch: [69][400/500] loss: 3.60181, MAE: 0.18748, time/step=1064ms, lr=2.86e-05
2024-03-21 22:59:48,117 - logger.py:50 - Epoch: [69][450/500] loss: 3.55411, MAE: 0.18613, time/step=1072ms, lr=2.86e-05
2024-03-21 23:00:46,417 - logger.py:50 - Epoch: [69][499/500] loss: 3.52031, MAE: 0.18560, time/step=1083ms, lr=2.86e-05
2024-03-21 23:01:51,411 - logger.py:50 - Epoch: [69] train loss: 3.52031, train MAE: 0.18560,val loss: 3.17434, val MAE: 0.17238,test loss: 3.18950, test MAE: 0.17922,Time: 606.64s
2024-03-21 23:01:51,411 - logger.py:50 - Best -- epoch=67, train loss: 3.52030, val loss: 3.17352, test loss: 3.18828

2024-03-21 23:02:53,371 - logger.py:50 - Epoch: [69]EMA val MAE: 0.24183, EMA test MAE: 0.24773, Time: 668.60s
2024-03-21 23:02:53,372 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 23:02:54,590 - logger.py:50 - Epoch: [70][0/500] loss: 3.12849, MAE: 0.18754, time/step=1216ms, lr=2.81e-05
2024-03-21 23:03:57,557 - logger.py:50 - Epoch: [70][50/500] loss: 3.20101, MAE: 0.18235, time/step=1258ms, lr=2.81e-05
2024-03-21 23:05:00,982 - logger.py:50 - Epoch: [70][100/500] loss: 4.79229, MAE: 0.21309, time/step=1263ms, lr=2.81e-05
2024-03-21 23:06:04,036 - logger.py:50 - Epoch: [70][150/500] loss: 4.27316, MAE: 0.20601, time/step=1263ms, lr=2.81e-05
2024-03-21 23:06:58,319 - logger.py:50 - Epoch: [70][200/500] loss: 4.00882, MAE: 0.19891, time/step=1219ms, lr=2.81e-05
2024-03-21 23:07:52,851 - logger.py:50 - Epoch: [70][250/500] loss: 3.84029, MAE: 0.19430, time/step=1193ms, lr=2.81e-05
2024-03-21 23:08:48,644 - logger.py:50 - Epoch: [70][300/500] loss: 3.73705, MAE: 0.19295, time/step=1180ms, lr=2.81e-05
2024-03-21 23:09:43,439 - logger.py:50 - Epoch: [70][350/500] loss: 3.65561, MAE: 0.19015, time/step=1168ms, lr=2.81e-05
2024-03-21 23:10:40,547 - logger.py:50 - Epoch: [70][400/500] loss: 3.60135, MAE: 0.18864, time/step=1165ms, lr=2.81e-05
2024-03-21 23:11:36,342 - logger.py:50 - Epoch: [70][450/500] loss: 3.55638, MAE: 0.18698, time/step=1160ms, lr=2.81e-05
2024-03-21 23:12:30,275 - logger.py:50 - Epoch: [70][499/500] loss: 3.51901, MAE: 0.18584, time/step=1154ms, lr=2.81e-05
2024-03-21 23:13:33,985 - logger.py:50 - Epoch: [70] train loss: 3.51901, train MAE: 0.18584,val loss: 3.17479, val MAE: 0.17205,test loss: 3.18938, test MAE: 0.17877,Time: 640.61s
2024-03-21 23:13:33,985 - logger.py:50 - Best -- epoch=67, train loss: 3.52030, val loss: 3.17352, test loss: 3.18828

2024-03-21 23:14:39,855 - logger.py:50 - Epoch: [70]EMA val MAE: 0.23795, EMA test MAE: 0.24394, Time: 706.48s
2024-03-21 23:14:39,855 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 23:14:41,132 - logger.py:50 - Epoch: [71][0/500] loss: 3.13181, MAE: 0.17787, time/step=1273ms, lr=2.76e-05
2024-03-21 23:15:37,880 - logger.py:50 - Epoch: [71][50/500] loss: 3.20948, MAE: 0.17740, time/step=1138ms, lr=2.76e-05
2024-03-21 23:16:34,196 - logger.py:50 - Epoch: [71][100/500] loss: 3.18172, MAE: 0.17603, time/step=1132ms, lr=2.76e-05
2024-03-21 23:17:30,224 - logger.py:50 - Epoch: [71][150/500] loss: 3.19025, MAE: 0.17671, time/step=1128ms, lr=2.76e-05
2024-03-21 23:18:25,564 - logger.py:50 - Epoch: [71][200/500] loss: 3.44442, MAE: 0.18383, time/step=1123ms, lr=2.76e-05
2024-03-21 23:19:24,291 - logger.py:50 - Epoch: [71][250/500] loss: 3.39379, MAE: 0.18325, time/step=1133ms, lr=2.76e-05
2024-03-21 23:20:20,953 - logger.py:50 - Epoch: [71][300/500] loss: 3.36422, MAE: 0.18311, time/step=1133ms, lr=2.76e-05
2024-03-21 23:21:19,611 - logger.py:50 - Epoch: [71][350/500] loss: 3.34220, MAE: 0.18284, time/step=1139ms, lr=2.76e-05
2024-03-21 23:22:17,573 - logger.py:50 - Epoch: [71][400/500] loss: 3.32120, MAE: 0.18142, time/step=1141ms, lr=2.76e-05
2024-03-21 23:23:16,458 - logger.py:50 - Epoch: [71][450/500] loss: 3.55246, MAE: 0.18516, time/step=1145ms, lr=2.76e-05
2024-03-21 23:24:13,975 - logger.py:50 - Epoch: [71][499/500] loss: 3.51941, MAE: 0.18523, time/step=1148ms, lr=2.76e-05
2024-03-21 23:25:20,789 - logger.py:50 - Epoch: [71] train loss: 3.51941, train MAE: 0.18523,val loss: 3.17421, val MAE: 0.17307,test loss: 3.19031, test MAE: 0.18006,Time: 640.93s
2024-03-21 23:25:20,790 - logger.py:50 - Best -- epoch=67, train loss: 3.52030, val loss: 3.17352, test loss: 3.18828

2024-03-21 23:26:24,281 - logger.py:50 - Epoch: [71]EMA val MAE: 0.23411, EMA test MAE: 0.24018, Time: 704.43s
2024-03-21 23:26:24,281 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 23:26:25,090 - logger.py:50 - Epoch: [72][0/500] loss: 3.14731, MAE: 0.15986, time/step=806ms, lr=2.70e-05
2024-03-21 23:27:17,909 - logger.py:50 - Epoch: [72][50/500] loss: 3.19877, MAE: 0.18110, time/step=1051ms, lr=2.70e-05
2024-03-21 23:28:10,317 - logger.py:50 - Epoch: [72][100/500] loss: 3.20953, MAE: 0.18147, time/step=1050ms, lr=2.70e-05
2024-03-21 23:29:03,323 - logger.py:50 - Epoch: [72][150/500] loss: 3.20059, MAE: 0.17983, time/step=1053ms, lr=2.70e-05
2024-03-21 23:29:56,000 - logger.py:50 - Epoch: [72][200/500] loss: 3.75669, MAE: 0.19085, time/step=1053ms, lr=2.70e-05
2024-03-21 23:30:49,517 - logger.py:50 - Epoch: [72][250/500] loss: 3.64486, MAE: 0.18939, time/step=1057ms, lr=2.70e-05
2024-03-21 23:31:43,238 - logger.py:50 - Epoch: [72][300/500] loss: 3.74058, MAE: 0.19081, time/step=1060ms, lr=2.70e-05
2024-03-21 23:32:37,259 - logger.py:50 - Epoch: [72][350/500] loss: 3.65565, MAE: 0.18860, time/step=1063ms, lr=2.70e-05
2024-03-21 23:33:28,744 - logger.py:50 - Epoch: [72][400/500] loss: 3.59899, MAE: 0.18693, time/step=1059ms, lr=2.70e-05
2024-03-21 23:34:21,572 - logger.py:50 - Epoch: [72][450/500] loss: 3.55706, MAE: 0.18699, time/step=1058ms, lr=2.70e-05
2024-03-21 23:35:13,451 - logger.py:50 - Epoch: [72][499/500] loss: 3.52046, MAE: 0.18590, time/step=1058ms, lr=2.70e-05
2024-03-21 23:36:12,478 - logger.py:50 - Epoch: [72] train loss: 3.52046, train MAE: 0.18590,val loss: 3.17605, val MAE: 0.17701,test loss: 3.19271, test MAE: 0.18409,Time: 588.20s
2024-03-21 23:36:12,478 - logger.py:50 - Best -- epoch=67, train loss: 3.52030, val loss: 3.17352, test loss: 3.18828

2024-03-21 23:37:11,896 - logger.py:50 - Epoch: [72]EMA val MAE: 0.23044, EMA test MAE: 0.23659, Time: 647.61s
2024-03-21 23:37:11,896 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 23:37:13,192 - logger.py:50 - Epoch: [73][0/500] loss: 3.13592, MAE: 0.18782, time/step=1293ms, lr=2.65e-05
2024-03-21 23:38:06,600 - logger.py:50 - Epoch: [73][50/500] loss: 3.21954, MAE: 0.18283, time/step=1073ms, lr=2.65e-05
2024-03-21 23:38:59,192 - logger.py:50 - Epoch: [73][100/500] loss: 3.69958, MAE: 0.18744, time/step=1062ms, lr=2.65e-05
2024-03-21 23:39:52,901 - logger.py:50 - Epoch: [73][150/500] loss: 3.53211, MAE: 0.18534, time/step=1066ms, lr=2.65e-05
2024-03-21 23:40:46,348 - logger.py:50 - Epoch: [73][200/500] loss: 4.00166, MAE: 0.19135, time/step=1067ms, lr=2.65e-05
2024-03-21 23:41:39,560 - logger.py:50 - Epoch: [73][250/500] loss: 3.83676, MAE: 0.19006, time/step=1066ms, lr=2.65e-05
2024-03-21 23:42:32,253 - logger.py:50 - Epoch: [73][300/500] loss: 3.72814, MAE: 0.18759, time/step=1064ms, lr=2.65e-05
2024-03-21 23:43:25,056 - logger.py:50 - Epoch: [73][350/500] loss: 3.65278, MAE: 0.18676, time/step=1063ms, lr=2.65e-05
2024-03-21 23:44:17,990 - logger.py:50 - Epoch: [73][400/500] loss: 3.60314, MAE: 0.18652, time/step=1063ms, lr=2.65e-05
2024-03-21 23:45:10,639 - logger.py:50 - Epoch: [73][450/500] loss: 3.55591, MAE: 0.18590, time/step=1062ms, lr=2.65e-05
2024-03-21 23:46:02,883 - logger.py:50 - Epoch: [73][499/500] loss: 3.51972, MAE: 0.18507, time/step=1062ms, lr=2.65e-05
2024-03-21 23:47:01,801 - logger.py:50 - Epoch: [73] train loss: 3.51972, train MAE: 0.18507,val loss: 3.17312, val MAE: 0.16981,test loss: 3.18691, test MAE: 0.17633,Time: 589.90s
2024-03-21 23:47:01,801 - logger.py:50 - Best -- epoch=73, train loss: 3.51972, val loss: 3.17312, test loss: 3.18691

2024-03-21 23:48:00,892 - logger.py:50 - Epoch: [73]EMA val MAE: 0.22689, EMA test MAE: 0.23313, Time: 649.00s
2024-03-21 23:48:00,892 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 23:48:02,053 - logger.py:50 - Epoch: [74][0/500] loss: 3.11092, MAE: 0.18578, time/step=1159ms, lr=2.60e-05
2024-03-21 23:48:55,062 - logger.py:50 - Epoch: [74][50/500] loss: 3.19639, MAE: 0.18011, time/step=1062ms, lr=2.60e-05
2024-03-21 23:49:48,197 - logger.py:50 - Epoch: [74][100/500] loss: 3.71883, MAE: 0.19414, time/step=1062ms, lr=2.60e-05
2024-03-21 23:50:40,951 - logger.py:50 - Epoch: [74][150/500] loss: 3.54125, MAE: 0.18938, time/step=1060ms, lr=2.60e-05
2024-03-21 23:51:33,668 - logger.py:50 - Epoch: [74][200/500] loss: 4.00715, MAE: 0.19440, time/step=1059ms, lr=2.60e-05
2024-03-21 23:52:25,935 - logger.py:50 - Epoch: [74][250/500] loss: 3.84687, MAE: 0.19384, time/step=1056ms, lr=2.60e-05
2024-03-21 23:53:19,695 - logger.py:50 - Epoch: [74][300/500] loss: 3.73237, MAE: 0.19090, time/step=1059ms, lr=2.60e-05
2024-03-21 23:54:12,430 - logger.py:50 - Epoch: [74][350/500] loss: 3.65812, MAE: 0.18964, time/step=1059ms, lr=2.60e-05
2024-03-21 23:55:05,186 - logger.py:50 - Epoch: [74][400/500] loss: 3.59801, MAE: 0.18794, time/step=1058ms, lr=2.60e-05
2024-03-21 23:55:58,024 - logger.py:50 - Epoch: [74][450/500] loss: 3.55457, MAE: 0.18689, time/step=1058ms, lr=2.60e-05
2024-03-21 23:56:49,942 - logger.py:50 - Epoch: [74][499/500] loss: 3.51877, MAE: 0.18566, time/step=1058ms, lr=2.60e-05
2024-03-21 23:57:49,994 - logger.py:50 - Epoch: [74] train loss: 3.51877, train MAE: 0.18566,val loss: 3.17211, val MAE: 0.17097,test loss: 3.18596, test MAE: 0.17762,Time: 589.10s
2024-03-21 23:57:49,995 - logger.py:50 - Best -- epoch=74, train loss: 3.51877, val loss: 3.17211, test loss: 3.18596

2024-03-21 23:58:50,068 - logger.py:50 - Epoch: [74]EMA val MAE: 0.22349, EMA test MAE: 0.22979, Time: 649.18s
2024-03-21 23:58:50,068 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-21 23:58:50,823 - logger.py:50 - Epoch: [75][0/500] loss: 3.18421, MAE: 0.15712, time/step=752ms, lr=2.55e-05
2024-03-21 23:59:42,868 - logger.py:50 - Epoch: [75][50/500] loss: 4.25003, MAE: 0.20584, time/step=1035ms, lr=2.55e-05
2024-03-22 00:00:35,469 - logger.py:50 - Epoch: [75][100/500] loss: 3.74162, MAE: 0.19347, time/step=1044ms, lr=2.55e-05
2024-03-22 00:01:28,928 - logger.py:50 - Epoch: [75][150/500] loss: 4.28738, MAE: 0.20002, time/step=1052ms, lr=2.55e-05
2024-03-22 00:02:21,289 - logger.py:50 - Epoch: [75][200/500] loss: 4.01787, MAE: 0.19622, time/step=1051ms, lr=2.55e-05
2024-03-22 00:03:14,141 - logger.py:50 - Epoch: [75][250/500] loss: 3.85034, MAE: 0.19363, time/step=1052ms, lr=2.55e-05
2024-03-22 00:04:06,509 - logger.py:50 - Epoch: [75][300/500] loss: 3.74060, MAE: 0.19139, time/step=1051ms, lr=2.55e-05
2024-03-22 00:04:59,466 - logger.py:50 - Epoch: [75][350/500] loss: 3.66082, MAE: 0.18879, time/step=1052ms, lr=2.55e-05
2024-03-22 00:05:51,905 - logger.py:50 - Epoch: [75][400/500] loss: 3.60308, MAE: 0.18794, time/step=1052ms, lr=2.55e-05
2024-03-22 00:06:45,242 - logger.py:50 - Epoch: [75][450/500] loss: 3.55426, MAE: 0.18634, time/step=1054ms, lr=2.55e-05
2024-03-22 00:07:37,639 - logger.py:50 - Epoch: [75][499/500] loss: 3.51891, MAE: 0.18520, time/step=1055ms, lr=2.55e-05
2024-03-22 00:08:36,763 - logger.py:50 - Epoch: [75] train loss: 3.51891, train MAE: 0.18520,val loss: 3.17392, val MAE: 0.17153,test loss: 3.18907, test MAE: 0.17828,Time: 586.69s
2024-03-22 00:08:36,763 - logger.py:50 - Best -- epoch=74, train loss: 3.51877, val loss: 3.17211, test loss: 3.18596

2024-03-22 00:09:35,539 - logger.py:50 - Epoch: [75]EMA val MAE: 0.22022, EMA test MAE: 0.22659, Time: 645.47s
2024-03-22 00:09:35,540 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 00:09:36,788 - logger.py:50 - Epoch: [76][0/500] loss: 3.12142, MAE: 0.15069, time/step=1246ms, lr=2.50e-05
2024-03-22 00:10:30,110 - logger.py:50 - Epoch: [76][50/500] loss: 3.20431, MAE: 0.18055, time/step=1070ms, lr=2.50e-05
2024-03-22 00:11:22,847 - logger.py:50 - Epoch: [76][100/500] loss: 3.19514, MAE: 0.18052, time/step=1062ms, lr=2.50e-05
2024-03-22 00:12:15,189 - logger.py:50 - Epoch: [76][150/500] loss: 3.20089, MAE: 0.18056, time/step=1057ms, lr=2.50e-05
2024-03-22 00:13:08,303 - logger.py:50 - Epoch: [76][200/500] loss: 3.20598, MAE: 0.17952, time/step=1059ms, lr=2.50e-05
2024-03-22 00:14:02,947 - logger.py:50 - Epoch: [76][250/500] loss: 3.20137, MAE: 0.17917, time/step=1065ms, lr=2.50e-05
2024-03-22 00:14:55,754 - logger.py:50 - Epoch: [76][300/500] loss: 3.19790, MAE: 0.17897, time/step=1064ms, lr=2.50e-05
2024-03-22 00:15:49,678 - logger.py:50 - Epoch: [76][350/500] loss: 3.19570, MAE: 0.17809, time/step=1066ms, lr=2.50e-05
2024-03-22 00:16:43,517 - logger.py:50 - Epoch: [76][400/500] loss: 3.59862, MAE: 0.18477, time/step=1067ms, lr=2.50e-05
2024-03-22 00:17:37,427 - logger.py:50 - Epoch: [76][450/500] loss: 3.55594, MAE: 0.18488, time/step=1068ms, lr=2.50e-05
2024-03-22 00:18:29,604 - logger.py:50 - Epoch: [76][499/500] loss: 3.51876, MAE: 0.18433, time/step=1068ms, lr=2.50e-05
2024-03-22 00:19:28,843 - logger.py:50 - Epoch: [76] train loss: 3.51876, train MAE: 0.18433,val loss: 3.17333, val MAE: 0.17372,test loss: 3.18703, test MAE: 0.18032,Time: 593.30s
2024-03-22 00:19:28,843 - logger.py:50 - Best -- epoch=74, train loss: 3.51877, val loss: 3.17211, test loss: 3.18596

2024-03-22 00:20:28,235 - logger.py:50 - Epoch: [76]EMA val MAE: 0.21704, EMA test MAE: 0.22348, Time: 652.70s
2024-03-22 00:20:28,235 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 00:20:29,049 - logger.py:50 - Epoch: [77][0/500] loss: 3.09295, MAE: 0.15832, time/step=812ms, lr=2.45e-05
2024-03-22 00:21:21,983 - logger.py:50 - Epoch: [77][50/500] loss: 3.18474, MAE: 0.17789, time/step=1054ms, lr=2.45e-05
2024-03-22 00:22:14,675 - logger.py:50 - Epoch: [77][100/500] loss: 3.18253, MAE: 0.17760, time/step=1054ms, lr=2.45e-05
2024-03-22 00:23:08,065 - logger.py:50 - Epoch: [77][150/500] loss: 4.27427, MAE: 0.19946, time/step=1058ms, lr=2.45e-05
2024-03-22 00:24:00,441 - logger.py:50 - Epoch: [77][200/500] loss: 4.00022, MAE: 0.19473, time/step=1056ms, lr=2.45e-05
2024-03-22 00:24:53,231 - logger.py:50 - Epoch: [77][250/500] loss: 3.83884, MAE: 0.19120, time/step=1056ms, lr=2.45e-05
2024-03-22 00:25:46,487 - logger.py:50 - Epoch: [77][300/500] loss: 3.72996, MAE: 0.18908, time/step=1057ms, lr=2.45e-05
2024-03-22 00:26:39,336 - logger.py:50 - Epoch: [77][350/500] loss: 3.65122, MAE: 0.18757, time/step=1057ms, lr=2.45e-05
2024-03-22 00:27:32,951 - logger.py:50 - Epoch: [77][400/500] loss: 3.59669, MAE: 0.18638, time/step=1059ms, lr=2.45e-05
2024-03-22 00:28:25,689 - logger.py:50 - Epoch: [77][450/500] loss: 3.55419, MAE: 0.18594, time/step=1059ms, lr=2.45e-05
2024-03-22 00:29:18,986 - logger.py:50 - Epoch: [77][499/500] loss: 3.51793, MAE: 0.18518, time/step=1061ms, lr=2.45e-05
2024-03-22 00:30:19,248 - logger.py:50 - Epoch: [77] train loss: 3.51793, train MAE: 0.18518,val loss: 3.17228, val MAE: 0.17070,test loss: 3.18579, test MAE: 0.17706,Time: 591.01s
2024-03-22 00:30:19,249 - logger.py:50 - Best -- epoch=74, train loss: 3.51877, val loss: 3.17211, test loss: 3.18596

2024-03-22 00:31:17,892 - logger.py:50 - Epoch: [77]EMA val MAE: 0.21414, EMA test MAE: 0.22063, Time: 649.66s
2024-03-22 00:31:17,892 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 00:31:18,600 - logger.py:50 - Epoch: [78][0/500] loss: 3.13111, MAE: 0.16468, time/step=706ms, lr=2.40e-05
2024-03-22 00:32:10,851 - logger.py:50 - Epoch: [78][50/500] loss: 5.37813, MAE: 0.21345, time/step=1038ms, lr=2.40e-05
2024-03-22 00:33:04,440 - logger.py:50 - Epoch: [78][100/500] loss: 4.30829, MAE: 0.20074, time/step=1055ms, lr=2.40e-05
2024-03-22 00:33:56,899 - logger.py:50 - Epoch: [78][150/500] loss: 3.93841, MAE: 0.19129, time/step=1053ms, lr=2.40e-05
2024-03-22 00:34:50,290 - logger.py:50 - Epoch: [78][200/500] loss: 3.74561, MAE: 0.18751, time/step=1057ms, lr=2.40e-05
2024-03-22 00:35:44,280 - logger.py:50 - Epoch: [78][250/500] loss: 3.63403, MAE: 0.18489, time/step=1061ms, lr=2.40e-05
2024-03-22 00:36:36,484 - logger.py:50 - Epoch: [78][300/500] loss: 3.55855, MAE: 0.18347, time/step=1058ms, lr=2.40e-05
2024-03-22 00:37:29,137 - logger.py:50 - Epoch: [78][350/500] loss: 3.50745, MAE: 0.18354, time/step=1058ms, lr=2.40e-05
2024-03-22 00:38:22,770 - logger.py:50 - Epoch: [78][400/500] loss: 3.47121, MAE: 0.18362, time/step=1060ms, lr=2.40e-05
2024-03-22 00:39:14,997 - logger.py:50 - Epoch: [78][450/500] loss: 3.44284, MAE: 0.18325, time/step=1058ms, lr=2.40e-05
2024-03-22 00:40:07,397 - logger.py:50 - Epoch: [78][499/500] loss: 3.51795, MAE: 0.18380, time/step=1059ms, lr=2.40e-05
2024-03-22 00:41:07,750 - logger.py:50 - Epoch: [78] train loss: 3.51795, train MAE: 0.18380,val loss: 3.17950, val MAE: 0.20110,test loss: 3.19381, test MAE: 0.20757,Time: 589.86s
2024-03-22 00:41:07,751 - logger.py:50 - Best -- epoch=74, train loss: 3.51877, val loss: 3.17211, test loss: 3.18596

2024-03-22 00:42:06,950 - logger.py:50 - Epoch: [78]EMA val MAE: 0.21133, EMA test MAE: 0.21786, Time: 649.06s
2024-03-22 00:42:06,950 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 00:42:08,176 - logger.py:50 - Epoch: [79][0/500] loss: 3.11784, MAE: 0.19635, time/step=1224ms, lr=2.34e-05
2024-03-22 00:43:01,334 - logger.py:50 - Epoch: [79][50/500] loss: 3.21180, MAE: 0.19043, time/step=1066ms, lr=2.34e-05
2024-03-22 00:43:55,431 - logger.py:50 - Epoch: [79][100/500] loss: 3.19518, MAE: 0.18448, time/step=1074ms, lr=2.34e-05
2024-03-22 00:44:49,192 - logger.py:50 - Epoch: [79][150/500] loss: 3.19433, MAE: 0.18345, time/step=1074ms, lr=2.34e-05
2024-03-22 00:45:42,660 - logger.py:50 - Epoch: [79][200/500] loss: 3.19940, MAE: 0.18326, time/step=1073ms, lr=2.34e-05
2024-03-22 00:46:35,695 - logger.py:50 - Epoch: [79][250/500] loss: 3.19714, MAE: 0.18208, time/step=1071ms, lr=2.34e-05
2024-03-22 00:47:28,737 - logger.py:50 - Epoch: [79][300/500] loss: 3.20047, MAE: 0.18200, time/step=1069ms, lr=2.34e-05
2024-03-22 00:48:21,587 - logger.py:50 - Epoch: [79][350/500] loss: 3.19557, MAE: 0.18086, time/step=1067ms, lr=2.34e-05
2024-03-22 00:49:14,798 - logger.py:50 - Epoch: [79][400/500] loss: 3.60249, MAE: 0.18644, time/step=1067ms, lr=2.34e-05
2024-03-22 00:50:09,009 - logger.py:50 - Epoch: [79][450/500] loss: 3.55564, MAE: 0.18639, time/step=1069ms, lr=2.34e-05
2024-03-22 00:51:00,969 - logger.py:50 - Epoch: [79][499/500] loss: 3.51763, MAE: 0.18538, time/step=1068ms, lr=2.34e-05
2024-03-22 00:52:01,540 - logger.py:50 - Epoch: [79] train loss: 3.51763, train MAE: 0.18538,val loss: 3.17086, val MAE: 0.17311,test loss: 3.18673, test MAE: 0.17989,Time: 594.59s
2024-03-22 00:52:01,541 - logger.py:50 - Best -- epoch=79, train loss: 3.51763, val loss: 3.17086, test loss: 3.18673

2024-03-22 00:53:01,289 - logger.py:50 - Epoch: [79]EMA val MAE: 0.20870, EMA test MAE: 0.21526, Time: 654.34s
2024-03-22 00:53:01,290 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 00:53:02,111 - logger.py:50 - Epoch: [80][0/500] loss: 3.18839, MAE: 0.15954, time/step=819ms, lr=2.29e-05
2024-03-22 00:53:54,561 - logger.py:50 - Epoch: [80][50/500] loss: 4.20951, MAE: 0.20208, time/step=1044ms, lr=2.29e-05
2024-03-22 00:54:47,775 - logger.py:50 - Epoch: [80][100/500] loss: 3.70050, MAE: 0.19003, time/step=1054ms, lr=2.29e-05
2024-03-22 00:55:40,992 - logger.py:50 - Epoch: [80][150/500] loss: 4.27369, MAE: 0.19531, time/step=1058ms, lr=2.29e-05
2024-03-22 00:56:35,166 - logger.py:50 - Epoch: [80][200/500] loss: 4.00222, MAE: 0.19304, time/step=1064ms, lr=2.29e-05
2024-03-22 00:57:28,670 - logger.py:50 - Epoch: [80][250/500] loss: 3.84067, MAE: 0.19084, time/step=1065ms, lr=2.29e-05
2024-03-22 00:58:21,928 - logger.py:50 - Epoch: [80][300/500] loss: 3.73366, MAE: 0.18891, time/step=1065ms, lr=2.29e-05
2024-03-22 00:59:14,996 - logger.py:50 - Epoch: [80][350/500] loss: 3.65501, MAE: 0.18692, time/step=1065ms, lr=2.29e-05
2024-03-22 01:00:08,885 - logger.py:50 - Epoch: [80][400/500] loss: 3.59401, MAE: 0.18525, time/step=1066ms, lr=2.29e-05
2024-03-22 01:01:01,771 - logger.py:50 - Epoch: [80][450/500] loss: 3.55342, MAE: 0.18513, time/step=1065ms, lr=2.29e-05
2024-03-22 01:01:53,405 - logger.py:50 - Epoch: [80][499/500] loss: 3.51684, MAE: 0.18424, time/step=1064ms, lr=2.29e-05
2024-03-22 01:02:52,935 - logger.py:50 - Epoch: [80] train loss: 3.51684, train MAE: 0.18424,val loss: 3.17119, val MAE: 0.17035,test loss: 3.18683, test MAE: 0.17727,Time: 591.65s
2024-03-22 01:02:52,935 - logger.py:50 - Best -- epoch=79, train loss: 3.51763, val loss: 3.17086, test loss: 3.18673

2024-03-22 01:03:52,868 - logger.py:50 - Epoch: [80]EMA val MAE: 0.20623, EMA test MAE: 0.21283, Time: 651.58s
2024-03-22 01:03:52,868 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 01:03:53,620 - logger.py:50 - Epoch: [81][0/500] loss: 3.14049, MAE: 0.17013, time/step=750ms, lr=2.24e-05
2024-03-22 01:04:47,748 - logger.py:50 - Epoch: [81][50/500] loss: 3.18462, MAE: 0.17763, time/step=1076ms, lr=2.24e-05
2024-03-22 01:05:41,239 - logger.py:50 - Epoch: [81][100/500] loss: 3.17826, MAE: 0.17559, time/step=1073ms, lr=2.24e-05
2024-03-22 01:06:34,277 - logger.py:50 - Epoch: [81][150/500] loss: 3.51821, MAE: 0.18395, time/step=1069ms, lr=2.24e-05
2024-03-22 01:07:28,018 - logger.py:50 - Epoch: [81][200/500] loss: 3.44680, MAE: 0.18394, time/step=1070ms, lr=2.24e-05
2024-03-22 01:08:19,744 - logger.py:50 - Epoch: [81][250/500] loss: 3.39537, MAE: 0.18279, time/step=1063ms, lr=2.24e-05
2024-03-22 01:09:13,374 - logger.py:50 - Epoch: [81][300/500] loss: 3.73273, MAE: 0.18848, time/step=1065ms, lr=2.24e-05
2024-03-22 01:10:05,456 - logger.py:50 - Epoch: [81][350/500] loss: 3.65946, MAE: 0.18768, time/step=1061ms, lr=2.24e-05
2024-03-22 01:10:57,832 - logger.py:50 - Epoch: [81][400/500] loss: 3.59917, MAE: 0.18592, time/step=1060ms, lr=2.24e-05
2024-03-22 01:11:50,359 - logger.py:50 - Epoch: [81][450/500] loss: 3.55592, MAE: 0.18505, time/step=1059ms, lr=2.24e-05
2024-03-22 01:12:43,958 - logger.py:50 - Epoch: [81][499/500] loss: 3.51720, MAE: 0.18430, time/step=1062ms, lr=2.24e-05
2024-03-22 01:13:44,013 - logger.py:50 - Epoch: [81] train loss: 3.51720, train MAE: 0.18430,val loss: 3.17185, val MAE: 0.17154,test loss: 3.18534, test MAE: 0.17794,Time: 591.14s
2024-03-22 01:13:44,013 - logger.py:50 - Best -- epoch=79, train loss: 3.51763, val loss: 3.17086, test loss: 3.18673

2024-03-22 01:14:43,491 - logger.py:50 - Epoch: [81]EMA val MAE: 0.20390, EMA test MAE: 0.21052, Time: 650.62s
2024-03-22 01:14:43,492 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 01:14:44,753 - logger.py:50 - Epoch: [82][0/500] loss: 3.22393, MAE: 0.21473, time/step=1259ms, lr=2.19e-05
2024-03-22 01:15:37,763 - logger.py:50 - Epoch: [82][50/500] loss: 3.16766, MAE: 0.17707, time/step=1064ms, lr=2.19e-05
2024-03-22 01:16:31,482 - logger.py:50 - Epoch: [82][100/500] loss: 3.17889, MAE: 0.17643, time/step=1069ms, lr=2.19e-05
2024-03-22 01:17:25,737 - logger.py:50 - Epoch: [82][150/500] loss: 3.18041, MAE: 0.17748, time/step=1074ms, lr=2.19e-05
2024-03-22 01:18:18,552 - logger.py:50 - Epoch: [82][200/500] loss: 3.44805, MAE: 0.18372, time/step=1070ms, lr=2.19e-05
2024-03-22 01:19:12,310 - logger.py:50 - Epoch: [82][250/500] loss: 3.39824, MAE: 0.18364, time/step=1071ms, lr=2.19e-05
2024-03-22 01:20:05,083 - logger.py:50 - Epoch: [82][300/500] loss: 3.35893, MAE: 0.18153, time/step=1068ms, lr=2.19e-05
2024-03-22 01:20:58,034 - logger.py:50 - Epoch: [82][350/500] loss: 3.33020, MAE: 0.17962, time/step=1067ms, lr=2.19e-05
2024-03-22 01:21:51,802 - logger.py:50 - Epoch: [82][400/500] loss: 3.31535, MAE: 0.17961, time/step=1068ms, lr=2.19e-05
2024-03-22 01:22:43,384 - logger.py:50 - Epoch: [82][450/500] loss: 3.55371, MAE: 0.18317, time/step=1064ms, lr=2.19e-05
2024-03-22 01:23:36,025 - logger.py:50 - Epoch: [82][499/500] loss: 3.51596, MAE: 0.18302, time/step=1065ms, lr=2.19e-05
2024-03-22 01:24:37,017 - logger.py:50 - Epoch: [82] train loss: 3.51596, train MAE: 0.18302,val loss: 3.17220, val MAE: 0.17247,test loss: 3.18646, test MAE: 0.17903,Time: 593.52s
2024-03-22 01:24:37,017 - logger.py:50 - Best -- epoch=79, train loss: 3.51763, val loss: 3.17086, test loss: 3.18673

2024-03-22 01:25:35,989 - logger.py:50 - Epoch: [82]EMA val MAE: 0.20163, EMA test MAE: 0.20828, Time: 652.50s
2024-03-22 01:25:35,990 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 01:25:37,352 - logger.py:50 - Epoch: [83][0/500] loss: 3.06727, MAE: 0.17283, time/step=1360ms, lr=2.14e-05
2024-03-22 01:26:30,492 - logger.py:50 - Epoch: [83][50/500] loss: 3.20887, MAE: 0.18462, time/step=1069ms, lr=2.14e-05
2024-03-22 01:27:23,490 - logger.py:50 - Epoch: [83][100/500] loss: 3.19541, MAE: 0.18192, time/step=1064ms, lr=2.14e-05
2024-03-22 01:28:16,298 - logger.py:50 - Epoch: [83][150/500] loss: 3.18472, MAE: 0.17836, time/step=1062ms, lr=2.14e-05
2024-03-22 01:29:09,244 - logger.py:50 - Epoch: [83][200/500] loss: 3.18565, MAE: 0.17824, time/step=1061ms, lr=2.14e-05
2024-03-22 01:30:02,150 - logger.py:50 - Epoch: [83][250/500] loss: 3.18675, MAE: 0.17836, time/step=1060ms, lr=2.14e-05
2024-03-22 01:30:54,996 - logger.py:50 - Epoch: [83][300/500] loss: 3.19457, MAE: 0.17924, time/step=1060ms, lr=2.14e-05
2024-03-22 01:31:48,183 - logger.py:50 - Epoch: [83][350/500] loss: 3.19697, MAE: 0.17838, time/step=1060ms, lr=2.14e-05
2024-03-22 01:32:41,194 - logger.py:50 - Epoch: [83][400/500] loss: 3.47274, MAE: 0.18251, time/step=1060ms, lr=2.14e-05
2024-03-22 01:33:33,006 - logger.py:50 - Epoch: [83][450/500] loss: 3.43939, MAE: 0.18213, time/step=1058ms, lr=2.14e-05
2024-03-22 01:34:24,429 - logger.py:50 - Epoch: [83][499/500] loss: 3.51667, MAE: 0.18349, time/step=1057ms, lr=2.14e-05
2024-03-22 01:35:24,930 - logger.py:50 - Epoch: [83] train loss: 3.51667, train MAE: 0.18349,val loss: 3.17567, val MAE: 0.18625,test loss: 3.18809, test MAE: 0.19264,Time: 588.94s
2024-03-22 01:35:24,930 - logger.py:50 - Best -- epoch=79, train loss: 3.51763, val loss: 3.17086, test loss: 3.18673

2024-03-22 01:36:24,077 - logger.py:50 - Epoch: [83]EMA val MAE: 0.19956, EMA test MAE: 0.20624, Time: 648.09s
2024-03-22 01:36:24,077 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 01:36:25,389 - logger.py:50 - Epoch: [84][0/500] loss: 3.10137, MAE: 0.17089, time/step=1309ms, lr=2.09e-05
2024-03-22 01:37:16,599 - logger.py:50 - Epoch: [84][50/500] loss: 3.20822, MAE: 0.18241, time/step=1030ms, lr=2.09e-05
2024-03-22 01:38:09,699 - logger.py:50 - Epoch: [84][100/500] loss: 3.21622, MAE: 0.18170, time/step=1046ms, lr=2.09e-05
2024-03-22 01:39:02,754 - logger.py:50 - Epoch: [84][150/500] loss: 3.21191, MAE: 0.18112, time/step=1051ms, lr=2.09e-05
2024-03-22 01:39:54,900 - logger.py:50 - Epoch: [84][200/500] loss: 3.20513, MAE: 0.18037, time/step=1049ms, lr=2.09e-05
2024-03-22 01:40:47,636 - logger.py:50 - Epoch: [84][250/500] loss: 3.20307, MAE: 0.18048, time/step=1050ms, lr=2.09e-05
2024-03-22 01:41:40,163 - logger.py:50 - Epoch: [84][300/500] loss: 3.20231, MAE: 0.17970, time/step=1050ms, lr=2.09e-05
2024-03-22 01:42:33,725 - logger.py:50 - Epoch: [84][350/500] loss: 3.19569, MAE: 0.17857, time/step=1053ms, lr=2.09e-05
2024-03-22 01:43:26,726 - logger.py:50 - Epoch: [84][400/500] loss: 3.19188, MAE: 0.17832, time/step=1054ms, lr=2.09e-05
2024-03-22 01:44:19,379 - logger.py:50 - Epoch: [84][450/500] loss: 3.43498, MAE: 0.18141, time/step=1054ms, lr=2.09e-05
2024-03-22 01:45:12,141 - logger.py:50 - Epoch: [84][499/500] loss: 3.51573, MAE: 0.18290, time/step=1056ms, lr=2.09e-05
2024-03-22 01:46:12,008 - logger.py:50 - Epoch: [84] train loss: 3.51573, train MAE: 0.18290,val loss: 3.17987, val MAE: 0.19587,test loss: 3.19546, test MAE: 0.20224,Time: 587.93s
2024-03-22 01:46:12,008 - logger.py:50 - Best -- epoch=79, train loss: 3.51763, val loss: 3.17086, test loss: 3.18673

2024-03-22 01:47:10,944 - logger.py:50 - Epoch: [84]EMA val MAE: 0.19760, EMA test MAE: 0.20430, Time: 646.87s
2024-03-22 01:47:10,944 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 01:47:12,182 - logger.py:50 - Epoch: [85][0/500] loss: 3.31102, MAE: 0.24772, time/step=1235ms, lr=2.04e-05
2024-03-22 01:48:05,623 - logger.py:50 - Epoch: [85][50/500] loss: 3.22045, MAE: 0.18697, time/step=1072ms, lr=2.04e-05
2024-03-22 01:48:59,009 - logger.py:50 - Epoch: [85][100/500] loss: 3.20784, MAE: 0.18099, time/step=1070ms, lr=2.04e-05
2024-03-22 01:49:52,293 - logger.py:50 - Epoch: [85][150/500] loss: 3.19316, MAE: 0.17989, time/step=1069ms, lr=2.04e-05
2024-03-22 01:50:44,896 - logger.py:50 - Epoch: [85][200/500] loss: 3.20488, MAE: 0.18207, time/step=1064ms, lr=2.04e-05
2024-03-22 01:51:37,399 - logger.py:50 - Epoch: [85][250/500] loss: 3.19620, MAE: 0.17936, time/step=1062ms, lr=2.04e-05
2024-03-22 01:52:30,017 - logger.py:50 - Epoch: [85][300/500] loss: 3.19316, MAE: 0.17906, time/step=1060ms, lr=2.04e-05
2024-03-22 01:53:22,880 - logger.py:50 - Epoch: [85][350/500] loss: 3.19208, MAE: 0.17874, time/step=1060ms, lr=2.04e-05
2024-03-22 01:54:16,336 - logger.py:50 - Epoch: [85][400/500] loss: 3.46898, MAE: 0.18192, time/step=1061ms, lr=2.04e-05
2024-03-22 01:55:09,016 - logger.py:50 - Epoch: [85][450/500] loss: 3.43955, MAE: 0.18297, time/step=1060ms, lr=2.04e-05
2024-03-22 01:56:01,169 - logger.py:50 - Epoch: [85][499/500] loss: 3.51665, MAE: 0.18494, time/step=1060ms, lr=2.04e-05
2024-03-22 01:57:01,030 - logger.py:50 - Epoch: [85] train loss: 3.51665, train MAE: 0.18494,val loss: 3.17233, val MAE: 0.17374,test loss: 3.18663, test MAE: 0.18049,Time: 590.09s
2024-03-22 01:57:01,030 - logger.py:50 - Best -- epoch=79, train loss: 3.51763, val loss: 3.17086, test loss: 3.18673

2024-03-22 01:57:59,801 - logger.py:50 - Epoch: [85]EMA val MAE: 0.19590, EMA test MAE: 0.20262, Time: 648.86s
2024-03-22 01:57:59,801 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 01:58:00,519 - logger.py:50 - Epoch: [86][0/500] loss: 3.10330, MAE: 0.17723, time/step=715ms, lr=1.99e-05
2024-03-22 01:58:53,727 - logger.py:50 - Epoch: [86][50/500] loss: 3.18766, MAE: 0.18127, time/step=1057ms, lr=1.99e-05
2024-03-22 01:59:46,334 - logger.py:50 - Epoch: [86][100/500] loss: 4.29456, MAE: 0.19516, time/step=1055ms, lr=1.99e-05
2024-03-22 02:00:38,945 - logger.py:50 - Epoch: [86][150/500] loss: 3.92652, MAE: 0.19119, time/step=1054ms, lr=1.99e-05
2024-03-22 02:01:32,815 - logger.py:50 - Epoch: [86][200/500] loss: 3.73887, MAE: 0.18707, time/step=1060ms, lr=1.99e-05
2024-03-22 02:02:25,928 - logger.py:50 - Epoch: [86][250/500] loss: 3.83142, MAE: 0.18913, time/step=1060ms, lr=1.99e-05
2024-03-22 02:03:18,310 - logger.py:50 - Epoch: [86][300/500] loss: 3.72235, MAE: 0.18658, time/step=1058ms, lr=1.99e-05
2024-03-22 02:04:11,053 - logger.py:50 - Epoch: [86][350/500] loss: 3.64566, MAE: 0.18494, time/step=1058ms, lr=1.99e-05
2024-03-22 02:05:03,375 - logger.py:50 - Epoch: [86][400/500] loss: 3.59542, MAE: 0.18502, time/step=1056ms, lr=1.99e-05
2024-03-22 02:05:56,112 - logger.py:50 - Epoch: [86][450/500] loss: 3.55108, MAE: 0.18433, time/step=1056ms, lr=1.99e-05
2024-03-22 02:06:48,108 - logger.py:50 - Epoch: [86][499/500] loss: 3.51548, MAE: 0.18397, time/step=1057ms, lr=1.99e-05
2024-03-22 02:07:47,813 - logger.py:50 - Epoch: [86] train loss: 3.51548, train MAE: 0.18397,val loss: 3.17021, val MAE: 0.17164,test loss: 3.18397, test MAE: 0.17822,Time: 588.01s
2024-03-22 02:07:47,813 - logger.py:50 - Best -- epoch=86, train loss: 3.51548, val loss: 3.17021, test loss: 3.18397

2024-03-22 02:08:46,983 - logger.py:50 - Epoch: [86]EMA val MAE: 0.19429, EMA test MAE: 0.20101, Time: 647.18s
2024-03-22 02:08:46,983 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 02:08:48,198 - logger.py:50 - Epoch: [87][0/500] loss: 3.15368, MAE: 0.17555, time/step=1212ms, lr=1.94e-05
2024-03-22 02:09:42,244 - logger.py:50 - Epoch: [87][50/500] loss: 5.32546, MAE: 0.19830, time/step=1083ms, lr=1.94e-05
2024-03-22 02:10:35,515 - logger.py:50 - Epoch: [87][100/500] loss: 4.26891, MAE: 0.19032, time/step=1075ms, lr=1.94e-05
2024-03-22 02:11:28,313 - logger.py:50 - Epoch: [87][150/500] loss: 3.91383, MAE: 0.18737, time/step=1068ms, lr=1.94e-05
2024-03-22 02:12:21,469 - logger.py:50 - Epoch: [87][200/500] loss: 3.73417, MAE: 0.18612, time/step=1067ms, lr=1.94e-05
2024-03-22 02:13:15,018 - logger.py:50 - Epoch: [87][250/500] loss: 3.62556, MAE: 0.18358, time/step=1068ms, lr=1.94e-05
2024-03-22 02:14:07,995 - logger.py:50 - Epoch: [87][300/500] loss: 3.55472, MAE: 0.18279, time/step=1066ms, lr=1.94e-05
2024-03-22 02:15:00,281 - logger.py:50 - Epoch: [87][350/500] loss: 3.64808, MAE: 0.18447, time/step=1064ms, lr=1.94e-05
2024-03-22 02:15:54,183 - logger.py:50 - Epoch: [87][400/500] loss: 3.59352, MAE: 0.18415, time/step=1065ms, lr=1.94e-05
2024-03-22 02:16:47,333 - logger.py:50 - Epoch: [87][450/500] loss: 3.55118, MAE: 0.18402, time/step=1065ms, lr=1.94e-05
2024-03-22 02:17:38,459 - logger.py:50 - Epoch: [87][499/500] loss: 3.51507, MAE: 0.18299, time/step=1063ms, lr=1.94e-05
2024-03-22 02:18:38,525 - logger.py:50 - Epoch: [87] train loss: 3.51507, train MAE: 0.18299,val loss: 3.17198, val MAE: 0.17202,test loss: 3.18561, test MAE: 0.17879,Time: 591.54s
2024-03-22 02:18:38,525 - logger.py:50 - Best -- epoch=86, train loss: 3.51548, val loss: 3.17021, test loss: 3.18397

2024-03-22 02:19:37,324 - logger.py:50 - Epoch: [87]EMA val MAE: 0.19275, EMA test MAE: 0.19949, Time: 650.34s
2024-03-22 02:19:37,324 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 02:19:38,012 - logger.py:50 - Epoch: [88][0/500] loss: 3.13758, MAE: 0.16546, time/step=685ms, lr=1.89e-05
2024-03-22 02:20:31,848 - logger.py:50 - Epoch: [88][50/500] loss: 3.17516, MAE: 0.17167, time/step=1069ms, lr=1.89e-05
2024-03-22 02:21:24,200 - logger.py:50 - Epoch: [88][100/500] loss: 3.17922, MAE: 0.17413, time/step=1058ms, lr=1.89e-05
2024-03-22 02:22:16,485 - logger.py:50 - Epoch: [88][150/500] loss: 3.19467, MAE: 0.17751, time/step=1054ms, lr=1.89e-05
2024-03-22 02:23:09,166 - logger.py:50 - Epoch: [88][200/500] loss: 3.19211, MAE: 0.17687, time/step=1054ms, lr=1.89e-05
2024-03-22 02:24:03,067 - logger.py:50 - Epoch: [88][250/500] loss: 3.63263, MAE: 0.18480, time/step=1059ms, lr=1.89e-05
2024-03-22 02:24:55,466 - logger.py:50 - Epoch: [88][300/500] loss: 3.56473, MAE: 0.18383, time/step=1057ms, lr=1.89e-05
2024-03-22 02:25:49,157 - logger.py:50 - Epoch: [88][350/500] loss: 3.50572, MAE: 0.18213, time/step=1059ms, lr=1.89e-05
2024-03-22 02:26:41,054 - logger.py:50 - Epoch: [88][400/500] loss: 3.46664, MAE: 0.18109, time/step=1057ms, lr=1.89e-05
2024-03-22 02:27:33,870 - logger.py:50 - Epoch: [88][450/500] loss: 3.43545, MAE: 0.18053, time/step=1057ms, lr=1.89e-05
2024-03-22 02:28:26,070 - logger.py:50 - Epoch: [88][499/500] loss: 3.51525, MAE: 0.18244, time/step=1057ms, lr=1.89e-05
2024-03-22 02:29:25,552 - logger.py:50 - Epoch: [88] train loss: 3.51525, train MAE: 0.18244,val loss: 3.18059, val MAE: 0.20515,test loss: 3.19379, test MAE: 0.21156,Time: 588.23s
2024-03-22 02:29:25,553 - logger.py:50 - Best -- epoch=86, train loss: 3.51548, val loss: 3.17021, test loss: 3.18397

2024-03-22 02:30:25,006 - logger.py:50 - Epoch: [88]EMA val MAE: 0.19128, EMA test MAE: 0.19802, Time: 647.68s
2024-03-22 02:30:25,006 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 02:30:25,771 - logger.py:50 - Epoch: [89][0/500] loss: 3.20394, MAE: 0.23120, time/step=763ms, lr=1.84e-05
2024-03-22 02:31:19,217 - logger.py:50 - Epoch: [89][50/500] loss: 3.21128, MAE: 0.18881, time/step=1063ms, lr=1.84e-05
2024-03-22 02:32:12,857 - logger.py:50 - Epoch: [89][100/500] loss: 3.19625, MAE: 0.18432, time/step=1068ms, lr=1.84e-05
2024-03-22 02:33:04,494 - logger.py:50 - Epoch: [89][150/500] loss: 3.19328, MAE: 0.18157, time/step=1056ms, lr=1.84e-05
2024-03-22 02:33:57,000 - logger.py:50 - Epoch: [89][200/500] loss: 3.75243, MAE: 0.18992, time/step=1055ms, lr=1.84e-05
2024-03-22 02:34:50,074 - logger.py:50 - Epoch: [89][250/500] loss: 3.64030, MAE: 0.18803, time/step=1056ms, lr=1.84e-05
2024-03-22 02:35:43,648 - logger.py:50 - Epoch: [89][300/500] loss: 3.55851, MAE: 0.18499, time/step=1059ms, lr=1.84e-05
2024-03-22 02:36:37,393 - logger.py:50 - Epoch: [89][350/500] loss: 3.65033, MAE: 0.18685, time/step=1061ms, lr=1.84e-05
2024-03-22 02:37:29,917 - logger.py:50 - Epoch: [89][400/500] loss: 3.59437, MAE: 0.18566, time/step=1060ms, lr=1.84e-05
2024-03-22 02:38:22,319 - logger.py:50 - Epoch: [89][450/500] loss: 3.54878, MAE: 0.18449, time/step=1058ms, lr=1.84e-05
2024-03-22 02:39:13,641 - logger.py:50 - Epoch: [89][499/500] loss: 3.51515, MAE: 0.18416, time/step=1057ms, lr=1.84e-05
2024-03-22 02:40:14,300 - logger.py:50 - Epoch: [89] train loss: 3.51515, train MAE: 0.18416,val loss: 3.17117, val MAE: 0.17219,test loss: 3.18462, test MAE: 0.17863,Time: 589.29s
2024-03-22 02:40:14,300 - logger.py:50 - Best -- epoch=86, train loss: 3.51548, val loss: 3.17021, test loss: 3.18397

2024-03-22 02:41:14,583 - logger.py:50 - Epoch: [89]EMA val MAE: 0.19003, EMA test MAE: 0.19675, Time: 649.58s
2024-03-22 02:41:14,583 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 02:41:15,290 - logger.py:50 - Epoch: [90][0/500] loss: 3.26999, MAE: 0.20132, time/step=705ms, lr=1.79e-05
2024-03-22 02:42:09,924 - logger.py:50 - Epoch: [90][50/500] loss: 3.19436, MAE: 0.17779, time/step=1085ms, lr=1.79e-05
2024-03-22 02:43:02,631 - logger.py:50 - Epoch: [90][100/500] loss: 4.29353, MAE: 0.19607, time/step=1070ms, lr=1.79e-05
2024-03-22 02:43:57,001 - logger.py:50 - Epoch: [90][150/500] loss: 3.92338, MAE: 0.18808, time/step=1076ms, lr=1.79e-05
2024-03-22 02:44:49,120 - logger.py:50 - Epoch: [90][200/500] loss: 3.73790, MAE: 0.18528, time/step=1067ms, lr=1.79e-05
2024-03-22 02:45:42,182 - logger.py:50 - Epoch: [90][250/500] loss: 3.62647, MAE: 0.18346, time/step=1066ms, lr=1.79e-05
2024-03-22 02:46:36,782 - logger.py:50 - Epoch: [90][300/500] loss: 3.55007, MAE: 0.18201, time/step=1070ms, lr=1.79e-05
2024-03-22 02:47:29,387 - logger.py:50 - Epoch: [90][350/500] loss: 3.64565, MAE: 0.18481, time/step=1068ms, lr=1.79e-05
2024-03-22 02:48:22,213 - logger.py:50 - Epoch: [90][400/500] loss: 3.58868, MAE: 0.18452, time/step=1066ms, lr=1.79e-05
2024-03-22 02:49:14,700 - logger.py:50 - Epoch: [90][450/500] loss: 3.54757, MAE: 0.18416, time/step=1065ms, lr=1.79e-05
2024-03-22 02:50:06,646 - logger.py:50 - Epoch: [90][499/500] loss: 3.51511, MAE: 0.18356, time/step=1064ms, lr=1.79e-05
2024-03-22 02:51:06,622 - logger.py:50 - Epoch: [90] train loss: 3.51511, train MAE: 0.18356,val loss: 3.17183, val MAE: 0.17257,test loss: 3.18545, test MAE: 0.17908,Time: 592.04s
2024-03-22 02:51:06,622 - logger.py:50 - Best -- epoch=86, train loss: 3.51548, val loss: 3.17021, test loss: 3.18397

2024-03-22 02:52:07,124 - logger.py:50 - Epoch: [90]EMA val MAE: 0.18884, EMA test MAE: 0.19555, Time: 652.54s
2024-03-22 02:52:07,124 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 02:52:07,824 - logger.py:50 - Epoch: [91][0/500] loss: 3.25787, MAE: 0.17960, time/step=697ms, lr=1.74e-05
2024-03-22 02:53:01,317 - logger.py:50 - Epoch: [91][50/500] loss: 3.24135, MAE: 0.18103, time/step=1063ms, lr=1.74e-05
2024-03-22 02:53:54,537 - logger.py:50 - Epoch: [91][100/500] loss: 3.21716, MAE: 0.17862, time/step=1063ms, lr=1.74e-05
2024-03-22 02:54:47,708 - logger.py:50 - Epoch: [91][150/500] loss: 3.21079, MAE: 0.17926, time/step=1063ms, lr=1.74e-05
2024-03-22 02:55:40,395 - logger.py:50 - Epoch: [91][200/500] loss: 3.20689, MAE: 0.17969, time/step=1061ms, lr=1.74e-05
2024-03-22 02:56:34,244 - logger.py:50 - Epoch: [91][250/500] loss: 3.19789, MAE: 0.17749, time/step=1064ms, lr=1.74e-05
2024-03-22 02:57:25,488 - logger.py:50 - Epoch: [91][300/500] loss: 3.19458, MAE: 0.17750, time/step=1058ms, lr=1.74e-05
2024-03-22 02:58:19,398 - logger.py:50 - Epoch: [91][350/500] loss: 3.19144, MAE: 0.17698, time/step=1061ms, lr=1.74e-05
2024-03-22 02:59:11,735 - logger.py:50 - Epoch: [91][400/500] loss: 3.19050, MAE: 0.17678, time/step=1059ms, lr=1.74e-05
2024-03-22 03:00:04,995 - logger.py:50 - Epoch: [91][450/500] loss: 3.30390, MAE: 0.17919, time/step=1060ms, lr=1.74e-05
2024-03-22 03:00:58,177 - logger.py:50 - Epoch: [91][499/500] loss: 3.51395, MAE: 0.18232, time/step=1062ms, lr=1.74e-05
2024-03-22 03:01:57,328 - logger.py:50 - Epoch: [91] train loss: 3.51395, train MAE: 0.18232,val loss: 3.17395, val MAE: 0.17550,test loss: 3.18848, test MAE: 0.18183,Time: 590.20s
2024-03-22 03:01:57,329 - logger.py:50 - Best -- epoch=86, train loss: 3.51548, val loss: 3.17021, test loss: 3.18397

2024-03-22 03:02:57,696 - logger.py:50 - Epoch: [91]EMA val MAE: 0.18766, EMA test MAE: 0.19435, Time: 650.57s
2024-03-22 03:02:57,696 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 03:02:58,984 - logger.py:50 - Epoch: [92][0/500] loss: 3.15338, MAE: 0.18632, time/step=1286ms, lr=1.70e-05
2024-03-22 03:03:51,000 - logger.py:50 - Epoch: [92][50/500] loss: 6.44190, MAE: 0.23678, time/step=1045ms, lr=1.70e-05
2024-03-22 03:04:43,802 - logger.py:50 - Epoch: [92][100/500] loss: 4.83499, MAE: 0.21276, time/step=1051ms, lr=1.70e-05
2024-03-22 03:05:35,950 - logger.py:50 - Epoch: [92][150/500] loss: 4.28407, MAE: 0.20127, time/step=1048ms, lr=1.70e-05
2024-03-22 03:06:28,213 - logger.py:50 - Epoch: [92][200/500] loss: 4.01694, MAE: 0.19658, time/step=1047ms, lr=1.70e-05
2024-03-22 03:07:21,302 - logger.py:50 - Epoch: [92][250/500] loss: 3.84561, MAE: 0.19212, time/step=1050ms, lr=1.70e-05
2024-03-22 03:08:15,469 - logger.py:50 - Epoch: [92][300/500] loss: 3.73414, MAE: 0.19018, time/step=1056ms, lr=1.70e-05
2024-03-22 03:09:08,778 - logger.py:50 - Epoch: [92][350/500] loss: 3.65390, MAE: 0.18798, time/step=1057ms, lr=1.70e-05
2024-03-22 03:10:01,759 - logger.py:50 - Epoch: [92][400/500] loss: 3.59438, MAE: 0.18607, time/step=1058ms, lr=1.70e-05
2024-03-22 03:10:54,293 - logger.py:50 - Epoch: [92][450/500] loss: 3.55104, MAE: 0.18556, time/step=1057ms, lr=1.70e-05
2024-03-22 03:11:47,743 - logger.py:50 - Epoch: [92][499/500] loss: 3.51386, MAE: 0.18434, time/step=1060ms, lr=1.70e-05
2024-03-22 03:12:48,588 - logger.py:50 - Epoch: [92] train loss: 3.51386, train MAE: 0.18434,val loss: 3.16941, val MAE: 0.17154,test loss: 3.18343, test MAE: 0.17816,Time: 590.89s
2024-03-22 03:12:48,589 - logger.py:50 - Best -- epoch=92, train loss: 3.51386, val loss: 3.16941, test loss: 3.18343

2024-03-22 03:13:47,182 - logger.py:50 - Epoch: [92]EMA val MAE: 0.18668, EMA test MAE: 0.19336, Time: 649.49s
2024-03-22 03:13:47,182 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 03:13:48,449 - logger.py:50 - Epoch: [93][0/500] loss: 3.12037, MAE: 0.16862, time/step=1264ms, lr=1.65e-05
2024-03-22 03:14:41,596 - logger.py:50 - Epoch: [93][50/500] loss: 3.14750, MAE: 0.16989, time/step=1067ms, lr=1.65e-05
2024-03-22 03:15:35,459 - logger.py:50 - Epoch: [93][100/500] loss: 3.17554, MAE: 0.17409, time/step=1072ms, lr=1.65e-05
2024-03-22 03:16:27,722 - logger.py:50 - Epoch: [93][150/500] loss: 3.17863, MAE: 0.17491, time/step=1063ms, lr=1.65e-05
2024-03-22 03:17:20,637 - logger.py:50 - Epoch: [93][200/500] loss: 3.18248, MAE: 0.17529, time/step=1062ms, lr=1.65e-05
2024-03-22 03:18:13,625 - logger.py:50 - Epoch: [93][250/500] loss: 3.62743, MAE: 0.18330, time/step=1062ms, lr=1.65e-05
2024-03-22 03:19:07,236 - logger.py:50 - Epoch: [93][300/500] loss: 3.55431, MAE: 0.18269, time/step=1063ms, lr=1.65e-05
2024-03-22 03:19:59,470 - logger.py:50 - Epoch: [93][350/500] loss: 3.50242, MAE: 0.18170, time/step=1061ms, lr=1.65e-05
2024-03-22 03:20:52,734 - logger.py:50 - Epoch: [93][400/500] loss: 3.46626, MAE: 0.18122, time/step=1061ms, lr=1.65e-05
2024-03-22 03:21:44,907 - logger.py:50 - Epoch: [93][450/500] loss: 3.43663, MAE: 0.18068, time/step=1059ms, lr=1.65e-05
2024-03-22 03:22:36,867 - logger.py:50 - Epoch: [93][499/500] loss: 3.51414, MAE: 0.18259, time/step=1059ms, lr=1.65e-05
2024-03-22 03:23:37,786 - logger.py:50 - Epoch: [93] train loss: 3.51414, train MAE: 0.18259,val loss: 3.17016, val MAE: 0.17168,test loss: 3.18447, test MAE: 0.17787,Time: 590.60s
2024-03-22 03:23:37,786 - logger.py:50 - Best -- epoch=92, train loss: 3.51386, val loss: 3.16941, test loss: 3.18343

2024-03-22 03:24:37,133 - logger.py:50 - Epoch: [93]EMA val MAE: 0.18569, EMA test MAE: 0.19235, Time: 649.95s
2024-03-22 03:24:37,133 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 03:24:38,312 - logger.py:50 - Epoch: [94][0/500] loss: 3.20960, MAE: 0.16796, time/step=1177ms, lr=1.60e-05
2024-03-22 03:25:31,513 - logger.py:50 - Epoch: [94][50/500] loss: 4.18328, MAE: 0.19732, time/step=1066ms, lr=1.60e-05
2024-03-22 03:26:23,677 - logger.py:50 - Epoch: [94][100/500] loss: 3.69669, MAE: 0.19147, time/step=1055ms, lr=1.60e-05
2024-03-22 03:27:15,695 - logger.py:50 - Epoch: [94][150/500] loss: 3.53283, MAE: 0.18715, time/step=1050ms, lr=1.60e-05
2024-03-22 03:28:08,581 - logger.py:50 - Epoch: [94][200/500] loss: 3.44217, MAE: 0.18376, time/step=1052ms, lr=1.60e-05
2024-03-22 03:29:01,956 - logger.py:50 - Epoch: [94][250/500] loss: 3.39430, MAE: 0.18219, time/step=1055ms, lr=1.60e-05
2024-03-22 03:29:55,274 - logger.py:50 - Epoch: [94][300/500] loss: 3.35980, MAE: 0.18105, time/step=1057ms, lr=1.60e-05
2024-03-22 03:30:48,434 - logger.py:50 - Epoch: [94][350/500] loss: 3.33243, MAE: 0.18011, time/step=1058ms, lr=1.60e-05
2024-03-22 03:31:40,061 - logger.py:50 - Epoch: [94][400/500] loss: 3.59529, MAE: 0.18329, time/step=1055ms, lr=1.60e-05
2024-03-22 03:32:32,400 - logger.py:50 - Epoch: [94][450/500] loss: 3.55133, MAE: 0.18400, time/step=1054ms, lr=1.60e-05
2024-03-22 03:33:24,718 - logger.py:50 - Epoch: [94][499/500] loss: 3.51354, MAE: 0.18293, time/step=1055ms, lr=1.60e-05
2024-03-22 03:34:24,148 - logger.py:50 - Epoch: [94] train loss: 3.51354, train MAE: 0.18293,val loss: 3.16972, val MAE: 0.17299,test loss: 3.18407, test MAE: 0.17938,Time: 587.01s
2024-03-22 03:34:24,148 - logger.py:50 - Best -- epoch=92, train loss: 3.51386, val loss: 3.16941, test loss: 3.18343

2024-03-22 03:35:23,945 - logger.py:50 - Epoch: [94]EMA val MAE: 0.18478, EMA test MAE: 0.19142, Time: 646.81s
2024-03-22 03:35:23,945 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 03:35:24,683 - logger.py:50 - Epoch: [95][0/500] loss: 3.22591, MAE: 0.18362, time/step=735ms, lr=1.55e-05
2024-03-22 03:36:16,877 - logger.py:50 - Epoch: [95][50/500] loss: 3.16289, MAE: 0.17179, time/step=1038ms, lr=1.55e-05
2024-03-22 03:37:09,877 - logger.py:50 - Epoch: [95][100/500] loss: 3.17439, MAE: 0.17272, time/step=1049ms, lr=1.55e-05
2024-03-22 03:38:02,758 - logger.py:50 - Epoch: [95][150/500] loss: 3.18102, MAE: 0.17411, time/step=1052ms, lr=1.55e-05
2024-03-22 03:38:56,838 - logger.py:50 - Epoch: [95][200/500] loss: 3.18783, MAE: 0.17417, time/step=1059ms, lr=1.55e-05
2024-03-22 03:39:49,587 - logger.py:50 - Epoch: [95][250/500] loss: 3.63283, MAE: 0.18172, time/step=1058ms, lr=1.55e-05
2024-03-22 03:40:42,086 - logger.py:50 - Epoch: [95][300/500] loss: 3.55745, MAE: 0.18084, time/step=1057ms, lr=1.55e-05
2024-03-22 03:41:35,130 - logger.py:50 - Epoch: [95][350/500] loss: 3.50499, MAE: 0.18074, time/step=1057ms, lr=1.55e-05
2024-03-22 03:42:28,859 - logger.py:50 - Epoch: [95][400/500] loss: 3.46442, MAE: 0.18047, time/step=1060ms, lr=1.55e-05
2024-03-22 03:43:20,579 - logger.py:50 - Epoch: [95][450/500] loss: 3.54907, MAE: 0.18263, time/step=1057ms, lr=1.55e-05
2024-03-22 03:44:13,638 - logger.py:50 - Epoch: [95][499/500] loss: 3.51375, MAE: 0.18230, time/step=1059ms, lr=1.55e-05
2024-03-22 03:45:14,538 - logger.py:50 - Epoch: [95] train loss: 3.51375, train MAE: 0.18230,val loss: 3.16903, val MAE: 0.17109,test loss: 3.18371, test MAE: 0.17769,Time: 590.59s
2024-03-22 03:45:14,538 - logger.py:50 - Best -- epoch=95, train loss: 3.51375, val loss: 3.16903, test loss: 3.18371

2024-03-22 03:46:14,275 - logger.py:50 - Epoch: [95]EMA val MAE: 0.18390, EMA test MAE: 0.19052, Time: 650.33s
2024-03-22 03:46:14,275 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 03:46:15,447 - logger.py:50 - Epoch: [96][0/500] loss: 3.13052, MAE: 0.17827, time/step=1169ms, lr=1.51e-05
2024-03-22 03:47:08,727 - logger.py:50 - Epoch: [96][50/500] loss: 3.19478, MAE: 0.17738, time/step=1068ms, lr=1.51e-05
2024-03-22 03:48:00,562 - logger.py:50 - Epoch: [96][100/500] loss: 3.21552, MAE: 0.18144, time/step=1052ms, lr=1.51e-05
2024-03-22 03:48:53,943 - logger.py:50 - Epoch: [96][150/500] loss: 3.20734, MAE: 0.17833, time/step=1057ms, lr=1.51e-05
2024-03-22 03:49:45,945 - logger.py:50 - Epoch: [96][200/500] loss: 3.20184, MAE: 0.17852, time/step=1053ms, lr=1.51e-05
2024-03-22 03:50:39,238 - logger.py:50 - Epoch: [96][250/500] loss: 3.19788, MAE: 0.17805, time/step=1056ms, lr=1.51e-05
2024-03-22 03:51:31,405 - logger.py:50 - Epoch: [96][300/500] loss: 3.36697, MAE: 0.18175, time/step=1054ms, lr=1.51e-05
2024-03-22 03:52:24,881 - logger.py:50 - Epoch: [96][350/500] loss: 3.33955, MAE: 0.18151, time/step=1056ms, lr=1.51e-05
2024-03-22 03:53:16,961 - logger.py:50 - Epoch: [96][400/500] loss: 3.59728, MAE: 0.18433, time/step=1054ms, lr=1.51e-05
2024-03-22 03:54:10,794 - logger.py:50 - Epoch: [96][450/500] loss: 3.54948, MAE: 0.18345, time/step=1057ms, lr=1.51e-05
2024-03-22 03:55:02,470 - logger.py:50 - Epoch: [96][499/500] loss: 3.51327, MAE: 0.18260, time/step=1056ms, lr=1.51e-05
2024-03-22 03:56:02,273 - logger.py:50 - Epoch: [96] train loss: 3.51327, train MAE: 0.18260,val loss: 3.16922, val MAE: 0.17183,test loss: 3.18357, test MAE: 0.17819,Time: 588.00s
2024-03-22 03:56:02,273 - logger.py:50 - Best -- epoch=95, train loss: 3.51375, val loss: 3.16903, test loss: 3.18371

2024-03-22 03:57:01,130 - logger.py:50 - Epoch: [96]EMA val MAE: 0.18312, EMA test MAE: 0.18972, Time: 646.85s
2024-03-22 03:57:01,131 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 03:57:02,367 - logger.py:50 - Epoch: [97][0/500] loss: 3.27378, MAE: 0.21798, time/step=1234ms, lr=1.46e-05
2024-03-22 03:57:54,903 - logger.py:50 - Epoch: [97][50/500] loss: 3.22144, MAE: 0.17752, time/step=1054ms, lr=1.46e-05
2024-03-22 03:58:48,464 - logger.py:50 - Epoch: [97][100/500] loss: 3.20608, MAE: 0.17749, time/step=1063ms, lr=1.46e-05
2024-03-22 03:59:41,975 - logger.py:50 - Epoch: [97][150/500] loss: 3.19733, MAE: 0.17700, time/step=1065ms, lr=1.46e-05
2024-03-22 04:00:34,422 - logger.py:50 - Epoch: [97][200/500] loss: 3.19815, MAE: 0.17816, time/step=1061ms, lr=1.46e-05
2024-03-22 04:01:27,918 - logger.py:50 - Epoch: [97][250/500] loss: 3.19590, MAE: 0.17778, time/step=1063ms, lr=1.46e-05
2024-03-22 04:02:21,239 - logger.py:50 - Epoch: [97][300/500] loss: 3.19055, MAE: 0.17713, time/step=1063ms, lr=1.46e-05
2024-03-22 04:03:14,053 - logger.py:50 - Epoch: [97][350/500] loss: 3.18969, MAE: 0.17734, time/step=1062ms, lr=1.46e-05
2024-03-22 04:04:06,355 - logger.py:50 - Epoch: [97][400/500] loss: 3.31823, MAE: 0.18035, time/step=1060ms, lr=1.46e-05
2024-03-22 04:04:59,169 - logger.py:50 - Epoch: [97][450/500] loss: 3.30272, MAE: 0.17950, time/step=1060ms, lr=1.46e-05
2024-03-22 04:05:51,149 - logger.py:50 - Epoch: [97][499/500] loss: 3.51362, MAE: 0.18227, time/step=1060ms, lr=1.46e-05
2024-03-22 04:06:50,950 - logger.py:50 - Epoch: [97] train loss: 3.51362, train MAE: 0.18227,val loss: 3.17146, val MAE: 0.17378,test loss: 3.18545, test MAE: 0.18010,Time: 589.82s
2024-03-22 04:06:50,950 - logger.py:50 - Best -- epoch=95, train loss: 3.51375, val loss: 3.16903, test loss: 3.18371

2024-03-22 04:07:49,434 - logger.py:50 - Epoch: [97]EMA val MAE: 0.18235, EMA test MAE: 0.18893, Time: 648.30s
2024-03-22 04:07:49,434 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 04:07:50,620 - logger.py:50 - Epoch: [98][0/500] loss: 3.14136, MAE: 0.17098, time/step=1184ms, lr=1.41e-05
2024-03-22 04:08:43,726 - logger.py:50 - Epoch: [98][50/500] loss: 3.16375, MAE: 0.17437, time/step=1065ms, lr=1.41e-05
2024-03-22 04:09:36,053 - logger.py:50 - Epoch: [98][100/500] loss: 3.17694, MAE: 0.17664, time/step=1056ms, lr=1.41e-05
2024-03-22 04:10:29,132 - logger.py:50 - Epoch: [98][150/500] loss: 3.52320, MAE: 0.18312, time/step=1058ms, lr=1.41e-05
2024-03-22 04:11:20,876 - logger.py:50 - Epoch: [98][200/500] loss: 3.44301, MAE: 0.18479, time/step=1052ms, lr=1.41e-05
2024-03-22 04:12:14,227 - logger.py:50 - Epoch: [98][250/500] loss: 3.39326, MAE: 0.18329, time/step=1055ms, lr=1.41e-05
2024-03-22 04:13:06,554 - logger.py:50 - Epoch: [98][300/500] loss: 3.36103, MAE: 0.18264, time/step=1054ms, lr=1.41e-05
2024-03-22 04:14:00,816 - logger.py:50 - Epoch: [98][350/500] loss: 3.33703, MAE: 0.18171, time/step=1058ms, lr=1.41e-05
2024-03-22 04:14:54,347 - logger.py:50 - Epoch: [98][400/500] loss: 3.31714, MAE: 0.17997, time/step=1060ms, lr=1.41e-05
2024-03-22 04:15:46,958 - logger.py:50 - Epoch: [98][450/500] loss: 3.54877, MAE: 0.18205, time/step=1059ms, lr=1.41e-05
2024-03-22 04:16:38,615 - logger.py:50 - Epoch: [98][499/500] loss: 3.51285, MAE: 0.18226, time/step=1058ms, lr=1.41e-05
2024-03-22 04:17:37,778 - logger.py:50 - Epoch: [98] train loss: 3.51285, train MAE: 0.18226,val loss: 3.16949, val MAE: 0.17455,test loss: 3.18361, test MAE: 0.18089,Time: 588.34s
2024-03-22 04:17:37,778 - logger.py:50 - Best -- epoch=95, train loss: 3.51375, val loss: 3.16903, test loss: 3.18371

2024-03-22 04:18:38,000 - logger.py:50 - Epoch: [98]EMA val MAE: 0.18167, EMA test MAE: 0.18823, Time: 648.57s
2024-03-22 04:18:38,003 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 04:18:39,476 - logger.py:50 - Epoch: [99][0/500] loss: 3.17163, MAE: 0.17251, time/step=1470ms, lr=1.37e-05
2024-03-22 04:19:32,635 - logger.py:50 - Epoch: [99][50/500] loss: 3.18036, MAE: 0.17509, time/step=1071ms, lr=1.37e-05
2024-03-22 04:20:25,048 - logger.py:50 - Epoch: [99][100/500] loss: 3.18086, MAE: 0.17618, time/step=1060ms, lr=1.37e-05
2024-03-22 04:21:18,184 - logger.py:50 - Epoch: [99][150/500] loss: 3.18558, MAE: 0.17878, time/step=1061ms, lr=1.37e-05
2024-03-22 04:22:10,369 - logger.py:50 - Epoch: [99][200/500] loss: 4.00413, MAE: 0.19240, time/step=1057ms, lr=1.37e-05
2024-03-22 04:23:03,061 - logger.py:50 - Epoch: [99][250/500] loss: 3.83732, MAE: 0.18948, time/step=1056ms, lr=1.37e-05
2024-03-22 04:23:55,800 - logger.py:50 - Epoch: [99][300/500] loss: 3.72961, MAE: 0.18741, time/step=1056ms, lr=1.37e-05
2024-03-22 04:24:48,347 - logger.py:50 - Epoch: [99][350/500] loss: 3.65288, MAE: 0.18542, time/step=1055ms, lr=1.37e-05
2024-03-22 04:25:41,209 - logger.py:50 - Epoch: [99][400/500] loss: 3.59576, MAE: 0.18456, time/step=1055ms, lr=1.37e-05
2024-03-22 04:26:33,768 - logger.py:50 - Epoch: [99][450/500] loss: 3.54785, MAE: 0.18369, time/step=1055ms, lr=1.37e-05
2024-03-22 04:27:25,775 - logger.py:50 - Epoch: [99][499/500] loss: 3.51291, MAE: 0.18266, time/step=1056ms, lr=1.37e-05
2024-03-22 04:28:26,268 - logger.py:50 - Epoch: [99] train loss: 3.51291, train MAE: 0.18266,val loss: 3.16960, val MAE: 0.17273,test loss: 3.18330, test MAE: 0.17913,Time: 588.26s
2024-03-22 04:28:26,269 - logger.py:50 - Best -- epoch=95, train loss: 3.51375, val loss: 3.16903, test loss: 3.18371

2024-03-22 04:29:25,932 - logger.py:50 - Epoch: [99]EMA val MAE: 0.18105, EMA test MAE: 0.18760, Time: 647.93s
2024-03-22 04:29:25,932 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 04:29:27,203 - logger.py:50 - Epoch: [100][0/500] loss: 3.17846, MAE: 0.18218, time/step=1269ms, lr=1.32e-05
2024-03-22 04:30:19,730 - logger.py:50 - Epoch: [100][50/500] loss: 3.17091, MAE: 0.16831, time/step=1055ms, lr=1.32e-05
2024-03-22 04:31:12,591 - logger.py:50 - Epoch: [100][100/500] loss: 3.17014, MAE: 0.16937, time/step=1056ms, lr=1.32e-05
2024-03-22 04:32:06,011 - logger.py:50 - Epoch: [100][150/500] loss: 3.18300, MAE: 0.17349, time/step=1060ms, lr=1.32e-05
2024-03-22 04:32:58,480 - logger.py:50 - Epoch: [100][200/500] loss: 3.99549, MAE: 0.18752, time/step=1057ms, lr=1.32e-05
2024-03-22 04:33:51,386 - logger.py:50 - Epoch: [100][250/500] loss: 3.83317, MAE: 0.18686, time/step=1058ms, lr=1.32e-05
2024-03-22 04:34:44,442 - logger.py:50 - Epoch: [100][300/500] loss: 3.72585, MAE: 0.18497, time/step=1058ms, lr=1.32e-05
2024-03-22 04:35:37,087 - logger.py:50 - Epoch: [100][350/500] loss: 3.64680, MAE: 0.18316, time/step=1057ms, lr=1.32e-05
2024-03-22 04:36:30,175 - logger.py:50 - Epoch: [100][400/500] loss: 3.59144, MAE: 0.18281, time/step=1058ms, lr=1.32e-05
2024-03-22 04:37:22,795 - logger.py:50 - Epoch: [100][450/500] loss: 3.54873, MAE: 0.18227, time/step=1057ms, lr=1.32e-05
2024-03-22 04:38:14,674 - logger.py:50 - Epoch: [100][499/500] loss: 3.51268, MAE: 0.18217, time/step=1057ms, lr=1.32e-05
2024-03-22 04:39:15,394 - logger.py:50 - Epoch: [100] train loss: 3.51268, train MAE: 0.18217,val loss: 3.16881, val MAE: 0.17045,test loss: 3.18328, test MAE: 0.17698,Time: 589.46s
2024-03-22 04:39:15,394 - logger.py:50 - Best -- epoch=100, train loss: 3.51268, val loss: 3.16881, test loss: 3.18328

2024-03-22 04:40:15,315 - logger.py:50 - Epoch: [100]EMA val MAE: 0.18043, EMA test MAE: 0.18696, Time: 649.38s
2024-03-22 04:40:15,315 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 04:40:15,966 - logger.py:50 - Epoch: [101][0/500] loss: 3.17635, MAE: 0.16321, time/step=649ms, lr=1.28e-05
2024-03-22 04:41:08,448 - logger.py:50 - Epoch: [101][50/500] loss: 4.18252, MAE: 0.19915, time/step=1042ms, lr=1.28e-05
2024-03-22 04:42:00,685 - logger.py:50 - Epoch: [101][100/500] loss: 3.70630, MAE: 0.18927, time/step=1043ms, lr=1.28e-05
2024-03-22 04:42:53,062 - logger.py:50 - Epoch: [101][150/500] loss: 4.27513, MAE: 0.19262, time/step=1045ms, lr=1.28e-05
2024-03-22 04:43:47,215 - logger.py:50 - Epoch: [101][200/500] loss: 3.99921, MAE: 0.19046, time/step=1054ms, lr=1.28e-05
2024-03-22 04:44:39,884 - logger.py:50 - Epoch: [101][250/500] loss: 3.84301, MAE: 0.18878, time/step=1054ms, lr=1.28e-05
2024-03-22 04:45:33,184 - logger.py:50 - Epoch: [101][300/500] loss: 3.73449, MAE: 0.18671, time/step=1056ms, lr=1.28e-05
2024-03-22 04:46:26,272 - logger.py:50 - Epoch: [101][350/500] loss: 3.65267, MAE: 0.18447, time/step=1057ms, lr=1.28e-05
2024-03-22 04:47:18,669 - logger.py:50 - Epoch: [101][400/500] loss: 3.59402, MAE: 0.18326, time/step=1056ms, lr=1.28e-05
2024-03-22 04:48:11,721 - logger.py:50 - Epoch: [101][450/500] loss: 3.54931, MAE: 0.18294, time/step=1056ms, lr=1.28e-05
2024-03-22 04:49:04,507 - logger.py:50 - Epoch: [101][499/500] loss: 3.51231, MAE: 0.18169, time/step=1058ms, lr=1.28e-05
2024-03-22 04:50:05,214 - logger.py:50 - Epoch: [101] train loss: 3.51231, train MAE: 0.18169,val loss: 3.16852, val MAE: 0.17015,test loss: 3.18215, test MAE: 0.17645,Time: 589.90s
2024-03-22 04:50:05,215 - logger.py:50 - Best -- epoch=101, train loss: 3.51231, val loss: 3.16852, test loss: 3.18215

2024-03-22 04:51:03,813 - logger.py:50 - Epoch: [101]EMA val MAE: 0.17985, EMA test MAE: 0.18636, Time: 648.50s
2024-03-22 04:51:03,813 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 04:51:04,604 - logger.py:50 - Epoch: [102][0/500] loss: 3.14994, MAE: 0.17332, time/step=788ms, lr=1.24e-05
2024-03-22 04:51:57,847 - logger.py:50 - Epoch: [102][50/500] loss: 3.16824, MAE: 0.17656, time/step=1059ms, lr=1.24e-05
2024-03-22 04:52:51,633 - logger.py:50 - Epoch: [102][100/500] loss: 3.18278, MAE: 0.17494, time/step=1068ms, lr=1.24e-05
2024-03-22 04:53:45,563 - logger.py:50 - Epoch: [102][150/500] loss: 3.18176, MAE: 0.17408, time/step=1071ms, lr=1.24e-05
2024-03-22 04:54:39,305 - logger.py:50 - Epoch: [102][200/500] loss: 3.18821, MAE: 0.17582, time/step=1072ms, lr=1.24e-05
2024-03-22 04:55:32,250 - logger.py:50 - Epoch: [102][250/500] loss: 3.39750, MAE: 0.18009, time/step=1069ms, lr=1.24e-05
2024-03-22 04:56:25,291 - logger.py:50 - Epoch: [102][300/500] loss: 3.35957, MAE: 0.18027, time/step=1068ms, lr=1.24e-05
2024-03-22 04:57:18,060 - logger.py:50 - Epoch: [102][350/500] loss: 3.33197, MAE: 0.17906, time/step=1066ms, lr=1.24e-05
2024-03-22 04:58:10,939 - logger.py:50 - Epoch: [102][400/500] loss: 3.31413, MAE: 0.17871, time/step=1065ms, lr=1.24e-05
2024-03-22 04:59:03,647 - logger.py:50 - Epoch: [102][450/500] loss: 3.54594, MAE: 0.18170, time/step=1064ms, lr=1.24e-05
2024-03-22 04:59:55,994 - logger.py:50 - Epoch: [102][499/500] loss: 3.51233, MAE: 0.18158, time/step=1064ms, lr=1.24e-05
2024-03-22 05:00:56,425 - logger.py:50 - Epoch: [102] train loss: 3.51233, train MAE: 0.18158,val loss: 3.16954, val MAE: 0.17041,test loss: 3.18416, test MAE: 0.17696,Time: 592.61s
2024-03-22 05:00:56,425 - logger.py:50 - Best -- epoch=101, train loss: 3.51231, val loss: 3.16852, test loss: 3.18215

2024-03-22 05:01:55,497 - logger.py:50 - Epoch: [102]EMA val MAE: 0.17926, EMA test MAE: 0.18576, Time: 651.68s
2024-03-22 05:01:55,497 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 05:01:56,669 - logger.py:50 - Epoch: [103][0/500] loss: 3.31102, MAE: 0.17268, time/step=1170ms, lr=1.19e-05
2024-03-22 05:02:50,182 - logger.py:50 - Epoch: [103][50/500] loss: 6.32302, MAE: 0.23077, time/step=1072ms, lr=1.19e-05
2024-03-22 05:03:42,836 - logger.py:50 - Epoch: [103][100/500] loss: 4.79419, MAE: 0.20370, time/step=1063ms, lr=1.19e-05
2024-03-22 05:04:35,744 - logger.py:50 - Epoch: [103][150/500] loss: 4.27246, MAE: 0.19613, time/step=1061ms, lr=1.19e-05
2024-03-22 05:05:28,385 - logger.py:50 - Epoch: [103][200/500] loss: 4.00253, MAE: 0.19185, time/step=1059ms, lr=1.19e-05
2024-03-22 05:06:21,034 - logger.py:50 - Epoch: [103][250/500] loss: 3.83830, MAE: 0.18926, time/step=1058ms, lr=1.19e-05
2024-03-22 05:07:14,735 - logger.py:50 - Epoch: [103][300/500] loss: 3.72702, MAE: 0.18651, time/step=1061ms, lr=1.19e-05
2024-03-22 05:08:06,799 - logger.py:50 - Epoch: [103][350/500] loss: 3.65320, MAE: 0.18555, time/step=1058ms, lr=1.19e-05
2024-03-22 05:08:58,944 - logger.py:50 - Epoch: [103][400/500] loss: 3.59174, MAE: 0.18371, time/step=1056ms, lr=1.19e-05
2024-03-22 05:09:52,075 - logger.py:50 - Epoch: [103][450/500] loss: 3.54737, MAE: 0.18321, time/step=1057ms, lr=1.19e-05
2024-03-22 05:10:44,676 - logger.py:50 - Epoch: [103][499/500] loss: 3.51176, MAE: 0.18263, time/step=1058ms, lr=1.19e-05
2024-03-22 05:11:43,470 - logger.py:50 - Epoch: [103] train loss: 3.51176, train MAE: 0.18263,val loss: 3.16979, val MAE: 0.16994,test loss: 3.18478, test MAE: 0.17649,Time: 587.97s
2024-03-22 05:11:43,470 - logger.py:50 - Best -- epoch=101, train loss: 3.51231, val loss: 3.16852, test loss: 3.18215

2024-03-22 05:12:43,028 - logger.py:50 - Epoch: [103]EMA val MAE: 0.17878, EMA test MAE: 0.18526, Time: 647.53s
2024-03-22 05:12:43,028 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 05:12:44,279 - logger.py:50 - Epoch: [104][0/500] loss: 3.14382, MAE: 0.18960, time/step=1249ms, lr=1.15e-05
2024-03-22 05:13:35,697 - logger.py:50 - Epoch: [104][50/500] loss: 3.19454, MAE: 0.17897, time/step=1033ms, lr=1.15e-05
2024-03-22 05:14:29,001 - logger.py:50 - Epoch: [104][100/500] loss: 3.18652, MAE: 0.17486, time/step=1049ms, lr=1.15e-05
2024-03-22 05:15:21,857 - logger.py:50 - Epoch: [104][150/500] loss: 3.19423, MAE: 0.17617, time/step=1052ms, lr=1.15e-05
2024-03-22 05:16:13,748 - logger.py:50 - Epoch: [104][200/500] loss: 3.19157, MAE: 0.17694, time/step=1048ms, lr=1.15e-05
2024-03-22 05:17:06,920 - logger.py:50 - Epoch: [104][250/500] loss: 3.19181, MAE: 0.17701, time/step=1051ms, lr=1.15e-05
2024-03-22 05:18:00,488 - logger.py:50 - Epoch: [104][300/500] loss: 3.19257, MAE: 0.17780, time/step=1055ms, lr=1.15e-05
2024-03-22 05:18:53,203 - logger.py:50 - Epoch: [104][350/500] loss: 3.18731, MAE: 0.17671, time/step=1055ms, lr=1.15e-05
2024-03-22 05:19:46,421 - logger.py:50 - Epoch: [104][400/500] loss: 3.46531, MAE: 0.17992, time/step=1056ms, lr=1.15e-05
2024-03-22 05:20:40,331 - logger.py:50 - Epoch: [104][450/500] loss: 3.43347, MAE: 0.17909, time/step=1058ms, lr=1.15e-05
2024-03-22 05:21:32,633 - logger.py:50 - Epoch: [104][499/500] loss: 3.51199, MAE: 0.18100, time/step=1059ms, lr=1.15e-05
2024-03-22 05:22:31,897 - logger.py:50 - Epoch: [104] train loss: 3.51199, train MAE: 0.18100,val loss: 3.16930, val MAE: 0.17670,test loss: 3.18377, test MAE: 0.18318,Time: 588.87s
2024-03-22 05:22:31,897 - logger.py:50 - Best -- epoch=101, train loss: 3.51231, val loss: 3.16852, test loss: 3.18215

2024-03-22 05:23:31,169 - logger.py:50 - Epoch: [104]EMA val MAE: 0.17823, EMA test MAE: 0.18471, Time: 648.14s
2024-03-22 05:23:31,170 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 05:23:32,397 - logger.py:50 - Epoch: [105][0/500] loss: 3.10315, MAE: 0.14549, time/step=1225ms, lr=1.11e-05
2024-03-22 05:24:24,820 - logger.py:50 - Epoch: [105][50/500] loss: 3.15804, MAE: 0.17761, time/step=1052ms, lr=1.11e-05
2024-03-22 05:25:17,152 - logger.py:50 - Epoch: [105][100/500] loss: 3.16486, MAE: 0.17648, time/step=1049ms, lr=1.11e-05
2024-03-22 05:26:10,193 - logger.py:50 - Epoch: [105][150/500] loss: 3.18679, MAE: 0.17760, time/step=1053ms, lr=1.11e-05
2024-03-22 05:27:02,662 - logger.py:50 - Epoch: [105][200/500] loss: 3.74565, MAE: 0.18644, time/step=1052ms, lr=1.11e-05
2024-03-22 05:27:56,096 - logger.py:50 - Epoch: [105][250/500] loss: 3.83557, MAE: 0.18886, time/step=1055ms, lr=1.11e-05
2024-03-22 05:28:48,928 - logger.py:50 - Epoch: [105][300/500] loss: 3.73005, MAE: 0.18788, time/step=1056ms, lr=1.11e-05
2024-03-22 05:29:41,774 - logger.py:50 - Epoch: [105][350/500] loss: 3.65202, MAE: 0.18574, time/step=1056ms, lr=1.11e-05
2024-03-22 05:30:34,823 - logger.py:50 - Epoch: [105][400/500] loss: 3.59363, MAE: 0.18496, time/step=1056ms, lr=1.11e-05
2024-03-22 05:31:28,231 - logger.py:50 - Epoch: [105][450/500] loss: 3.54706, MAE: 0.18371, time/step=1058ms, lr=1.11e-05
2024-03-22 05:32:19,790 - logger.py:50 - Epoch: [105][499/500] loss: 3.51197, MAE: 0.18287, time/step=1057ms, lr=1.11e-05
2024-03-22 05:33:19,581 - logger.py:50 - Epoch: [105] train loss: 3.51197, train MAE: 0.18287,val loss: 3.17059, val MAE: 0.17253,test loss: 3.18383, test MAE: 0.17900,Time: 588.41s
2024-03-22 05:33:19,581 - logger.py:50 - Best -- epoch=101, train loss: 3.51231, val loss: 3.16852, test loss: 3.18215

2024-03-22 05:34:18,983 - logger.py:50 - Epoch: [105]EMA val MAE: 0.17782, EMA test MAE: 0.18429, Time: 647.81s
2024-03-22 05:34:18,984 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 05:34:19,739 - logger.py:50 - Epoch: [106][0/500] loss: 3.17258, MAE: 0.17845, time/step=753ms, lr=1.07e-05
2024-03-22 05:35:13,122 - logger.py:50 - Epoch: [106][50/500] loss: 5.35402, MAE: 0.19971, time/step=1061ms, lr=1.07e-05
2024-03-22 05:36:05,716 - logger.py:50 - Epoch: [106][100/500] loss: 4.27642, MAE: 0.19021, time/step=1057ms, lr=1.07e-05
2024-03-22 05:36:58,407 - logger.py:50 - Epoch: [106][150/500] loss: 3.92164, MAE: 0.18554, time/step=1056ms, lr=1.07e-05
2024-03-22 05:37:50,195 - logger.py:50 - Epoch: [106][200/500] loss: 3.73481, MAE: 0.18246, time/step=1051ms, lr=1.07e-05
2024-03-22 05:38:43,978 - logger.py:50 - Epoch: [106][250/500] loss: 3.63331, MAE: 0.18280, time/step=1056ms, lr=1.07e-05
2024-03-22 05:39:37,593 - logger.py:50 - Epoch: [106][300/500] loss: 3.55864, MAE: 0.18147, time/step=1058ms, lr=1.07e-05
2024-03-22 05:40:31,698 - logger.py:50 - Epoch: [106][350/500] loss: 3.50220, MAE: 0.18026, time/step=1062ms, lr=1.07e-05
2024-03-22 05:41:24,059 - logger.py:50 - Epoch: [106][400/500] loss: 3.46158, MAE: 0.17953, time/step=1060ms, lr=1.07e-05
2024-03-22 05:42:16,062 - logger.py:50 - Epoch: [106][450/500] loss: 3.43340, MAE: 0.17967, time/step=1058ms, lr=1.07e-05
2024-03-22 05:43:08,279 - logger.py:50 - Epoch: [106][499/500] loss: 3.51172, MAE: 0.18134, time/step=1059ms, lr=1.07e-05
2024-03-22 05:44:08,052 - logger.py:50 - Epoch: [106] train loss: 3.51172, train MAE: 0.18134,val loss: 3.16852, val MAE: 0.17115,test loss: 3.18415, test MAE: 0.17775,Time: 589.07s
2024-03-22 05:44:08,053 - logger.py:50 - Best -- epoch=106, train loss: 3.51172, val loss: 3.16852, test loss: 3.18415

2024-03-22 05:45:07,582 - logger.py:50 - Epoch: [106]EMA val MAE: 0.17736, EMA test MAE: 0.18382, Time: 648.60s
2024-03-22 05:45:07,587 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 05:45:08,878 - logger.py:50 - Epoch: [107][0/500] loss: 3.24230, MAE: 0.19975, time/step=1289ms, lr=1.03e-05
2024-03-22 05:46:01,355 - logger.py:50 - Epoch: [107][50/500] loss: 3.18443, MAE: 0.17608, time/step=1054ms, lr=1.03e-05
2024-03-22 05:46:54,815 - logger.py:50 - Epoch: [107][100/500] loss: 3.18771, MAE: 0.17689, time/step=1062ms, lr=1.03e-05
2024-03-22 05:47:47,144 - logger.py:50 - Epoch: [107][150/500] loss: 3.18870, MAE: 0.17730, time/step=1057ms, lr=1.03e-05
2024-03-22 05:48:41,267 - logger.py:50 - Epoch: [107][200/500] loss: 3.18287, MAE: 0.17582, time/step=1063ms, lr=1.03e-05
2024-03-22 05:49:32,788 - logger.py:50 - Epoch: [107][250/500] loss: 3.19049, MAE: 0.17623, time/step=1057ms, lr=1.03e-05
2024-03-22 05:50:25,569 - logger.py:50 - Epoch: [107][300/500] loss: 3.18906, MAE: 0.17672, time/step=1056ms, lr=1.03e-05
2024-03-22 05:51:18,081 - logger.py:50 - Epoch: [107][350/500] loss: 3.50342, MAE: 0.18089, time/step=1056ms, lr=1.03e-05
2024-03-22 05:52:10,703 - logger.py:50 - Epoch: [107][400/500] loss: 3.46200, MAE: 0.17929, time/step=1055ms, lr=1.03e-05
2024-03-22 05:53:04,517 - logger.py:50 - Epoch: [107][450/500] loss: 3.54651, MAE: 0.18130, time/step=1057ms, lr=1.03e-05
2024-03-22 05:53:55,480 - logger.py:50 - Epoch: [107][499/500] loss: 3.51113, MAE: 0.18115, time/step=1056ms, lr=1.03e-05
2024-03-22 05:54:55,225 - logger.py:50 - Epoch: [107] train loss: 3.51113, train MAE: 0.18115,val loss: 3.16932, val MAE: 0.17271,test loss: 3.18393, test MAE: 0.17915,Time: 587.64s
2024-03-22 05:54:55,225 - logger.py:50 - Best -- epoch=106, train loss: 3.51172, val loss: 3.16852, test loss: 3.18415

2024-03-22 05:55:53,613 - logger.py:50 - Epoch: [107]EMA val MAE: 0.17693, EMA test MAE: 0.18338, Time: 646.03s
2024-03-22 05:55:53,614 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 05:55:54,898 - logger.py:50 - Epoch: [108][0/500] loss: 3.07607, MAE: 0.15077, time/step=1282ms, lr=9.88e-06
2024-03-22 05:56:47,125 - logger.py:50 - Epoch: [108][50/500] loss: 5.44881, MAE: 0.20746, time/step=1049ms, lr=9.88e-06
2024-03-22 05:57:40,222 - logger.py:50 - Epoch: [108][100/500] loss: 4.29612, MAE: 0.19076, time/step=1056ms, lr=9.88e-06
2024-03-22 05:58:34,481 - logger.py:50 - Epoch: [108][150/500] loss: 3.92889, MAE: 0.18674, time/step=1065ms, lr=9.88e-06
2024-03-22 05:59:27,315 - logger.py:50 - Epoch: [108][200/500] loss: 3.74513, MAE: 0.18469, time/step=1063ms, lr=9.88e-06
2024-03-22 06:00:20,147 - logger.py:50 - Epoch: [108][250/500] loss: 3.63625, MAE: 0.18315, time/step=1062ms, lr=9.88e-06
2024-03-22 06:01:12,115 - logger.py:50 - Epoch: [108][300/500] loss: 3.56516, MAE: 0.18294, time/step=1058ms, lr=9.88e-06
2024-03-22 06:02:05,623 - logger.py:50 - Epoch: [108][350/500] loss: 3.50982, MAE: 0.18199, time/step=1060ms, lr=9.88e-06
2024-03-22 06:02:58,640 - logger.py:50 - Epoch: [108][400/500] loss: 3.46891, MAE: 0.18124, time/step=1060ms, lr=9.88e-06
2024-03-22 06:03:52,911 - logger.py:50 - Epoch: [108][450/500] loss: 3.43411, MAE: 0.18019, time/step=1063ms, lr=9.88e-06
2024-03-22 06:04:45,432 - logger.py:50 - Epoch: [108][499/500] loss: 3.51095, MAE: 0.18126, time/step=1064ms, lr=9.88e-06
2024-03-22 06:05:44,517 - logger.py:50 - Epoch: [108] train loss: 3.51095, train MAE: 0.18126,val loss: 3.16936, val MAE: 0.18031,test loss: 3.18315, test MAE: 0.18657,Time: 590.90s
2024-03-22 06:05:44,517 - logger.py:50 - Best -- epoch=106, train loss: 3.51172, val loss: 3.16852, test loss: 3.18415

2024-03-22 06:06:44,068 - logger.py:50 - Epoch: [108]EMA val MAE: 0.17654, EMA test MAE: 0.18298, Time: 650.45s
2024-03-22 06:06:44,068 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 06:06:44,814 - logger.py:50 - Epoch: [109][0/500] loss: 3.15172, MAE: 0.19740, time/step=743ms, lr=9.49e-06
2024-03-22 06:07:37,177 - logger.py:50 - Epoch: [109][50/500] loss: 3.18852, MAE: 0.18202, time/step=1041ms, lr=9.49e-06
2024-03-22 06:08:29,894 - logger.py:50 - Epoch: [109][100/500] loss: 3.19019, MAE: 0.17936, time/step=1048ms, lr=9.49e-06
2024-03-22 06:09:23,404 - logger.py:50 - Epoch: [109][150/500] loss: 3.18284, MAE: 0.17671, time/step=1055ms, lr=9.49e-06
2024-03-22 06:10:15,343 - logger.py:50 - Epoch: [109][200/500] loss: 3.18093, MAE: 0.17617, time/step=1051ms, lr=9.49e-06
2024-03-22 06:11:08,211 - logger.py:50 - Epoch: [109][250/500] loss: 3.63352, MAE: 0.18207, time/step=1052ms, lr=9.49e-06
2024-03-22 06:12:01,482 - logger.py:50 - Epoch: [109][300/500] loss: 3.55658, MAE: 0.18164, time/step=1055ms, lr=9.49e-06
2024-03-22 06:12:54,940 - logger.py:50 - Epoch: [109][350/500] loss: 3.64696, MAE: 0.18283, time/step=1057ms, lr=9.49e-06
2024-03-22 06:13:48,573 - logger.py:50 - Epoch: [109][400/500] loss: 3.58670, MAE: 0.18215, time/step=1059ms, lr=9.49e-06
2024-03-22 06:14:42,682 - logger.py:50 - Epoch: [109][450/500] loss: 3.54742, MAE: 0.18215, time/step=1061ms, lr=9.49e-06
2024-03-22 06:15:35,847 - logger.py:50 - Epoch: [109][499/500] loss: 3.51120, MAE: 0.18131, time/step=1064ms, lr=9.49e-06
2024-03-22 06:16:36,160 - logger.py:50 - Epoch: [109] train loss: 3.51120, train MAE: 0.18131,val loss: 3.16826, val MAE: 0.17027,test loss: 3.18201, test MAE: 0.17655,Time: 592.09s
2024-03-22 06:16:36,160 - logger.py:50 - Best -- epoch=109, train loss: 3.51120, val loss: 3.16826, test loss: 3.18201

2024-03-22 06:17:34,824 - logger.py:50 - Epoch: [109]EMA val MAE: 0.17616, EMA test MAE: 0.18259, Time: 650.76s
2024-03-22 06:17:34,824 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 06:17:35,635 - logger.py:50 - Epoch: [110][0/500] loss: 3.23942, MAE: 0.19581, time/step=809ms, lr=9.11e-06
2024-03-22 06:18:29,575 - logger.py:50 - Epoch: [110][50/500] loss: 3.19501, MAE: 0.17727, time/step=1073ms, lr=9.11e-06
2024-03-22 06:19:21,720 - logger.py:50 - Epoch: [110][100/500] loss: 3.18978, MAE: 0.17536, time/step=1058ms, lr=9.11e-06
2024-03-22 06:20:15,399 - logger.py:50 - Epoch: [110][150/500] loss: 3.18089, MAE: 0.17434, time/step=1063ms, lr=9.11e-06
2024-03-22 06:21:07,606 - logger.py:50 - Epoch: [110][200/500] loss: 3.18523, MAE: 0.17447, time/step=1059ms, lr=9.11e-06
2024-03-22 06:22:00,595 - logger.py:50 - Epoch: [110][250/500] loss: 3.18377, MAE: 0.17526, time/step=1059ms, lr=9.11e-06
2024-03-22 06:22:53,623 - logger.py:50 - Epoch: [110][300/500] loss: 3.18429, MAE: 0.17561, time/step=1059ms, lr=9.11e-06
2024-03-22 06:23:47,557 - logger.py:50 - Epoch: [110][350/500] loss: 3.49933, MAE: 0.17956, time/step=1062ms, lr=9.11e-06
2024-03-22 06:24:40,617 - logger.py:50 - Epoch: [110][400/500] loss: 3.45968, MAE: 0.17890, time/step=1062ms, lr=9.11e-06
2024-03-22 06:25:33,528 - logger.py:50 - Epoch: [110][450/500] loss: 3.54318, MAE: 0.18080, time/step=1061ms, lr=9.11e-06
2024-03-22 06:26:25,700 - logger.py:50 - Epoch: [110][499/500] loss: 3.51097, MAE: 0.18077, time/step=1062ms, lr=9.11e-06
2024-03-22 06:27:25,618 - logger.py:50 - Epoch: [110] train loss: 3.51097, train MAE: 0.18077,val loss: 3.17154, val MAE: 0.17240,test loss: 3.18483, test MAE: 0.17872,Time: 590.79s
2024-03-22 06:27:25,618 - logger.py:50 - Best -- epoch=109, train loss: 3.51120, val loss: 3.16826, test loss: 3.18201

2024-03-22 06:28:26,615 - logger.py:50 - Epoch: [110]EMA val MAE: 0.17577, EMA test MAE: 0.18220, Time: 651.79s
2024-03-22 06:28:26,615 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 06:28:27,877 - logger.py:50 - Epoch: [111][0/500] loss: 3.06827, MAE: 0.15612, time/step=1260ms, lr=8.73e-06
2024-03-22 06:29:21,162 - logger.py:50 - Epoch: [111][50/500] loss: 3.18711, MAE: 0.17922, time/step=1070ms, lr=8.73e-06
2024-03-22 06:30:14,713 - logger.py:50 - Epoch: [111][100/500] loss: 4.76164, MAE: 0.19679, time/step=1070ms, lr=8.73e-06
2024-03-22 06:31:07,068 - logger.py:50 - Epoch: [111][150/500] loss: 4.24661, MAE: 0.19137, time/step=1063ms, lr=8.73e-06
2024-03-22 06:32:00,667 - logger.py:50 - Epoch: [111][200/500] loss: 3.98175, MAE: 0.18767, time/step=1065ms, lr=8.73e-06
2024-03-22 06:32:53,675 - logger.py:50 - Epoch: [111][250/500] loss: 3.82781, MAE: 0.18655, time/step=1064ms, lr=8.73e-06
2024-03-22 06:33:46,845 - logger.py:50 - Epoch: [111][300/500] loss: 3.72074, MAE: 0.18490, time/step=1064ms, lr=8.73e-06
2024-03-22 06:34:39,864 - logger.py:50 - Epoch: [111][350/500] loss: 3.64571, MAE: 0.18367, time/step=1063ms, lr=8.73e-06
2024-03-22 06:35:34,392 - logger.py:50 - Epoch: [111][400/500] loss: 3.59005, MAE: 0.18240, time/step=1067ms, lr=8.73e-06
2024-03-22 06:36:27,367 - logger.py:50 - Epoch: [111][450/500] loss: 3.54668, MAE: 0.18185, time/step=1066ms, lr=8.73e-06
2024-03-22 06:37:19,985 - logger.py:50 - Epoch: [111][499/500] loss: 3.51098, MAE: 0.18144, time/step=1067ms, lr=8.73e-06
2024-03-22 06:38:19,775 - logger.py:50 - Epoch: [111] train loss: 3.51098, train MAE: 0.18144,val loss: 3.16770, val MAE: 0.17068,test loss: 3.18149, test MAE: 0.17698,Time: 593.16s
2024-03-22 06:38:19,775 - logger.py:50 - Best -- epoch=111, train loss: 3.51098, val loss: 3.16770, test loss: 3.18149

2024-03-22 06:39:17,922 - logger.py:50 - Epoch: [111]EMA val MAE: 0.17546, EMA test MAE: 0.18187, Time: 651.31s
2024-03-22 06:39:17,923 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 06:39:19,169 - logger.py:50 - Epoch: [112][0/500] loss: 3.13931, MAE: 0.17957, time/step=1244ms, lr=8.36e-06
2024-03-22 06:40:12,864 - logger.py:50 - Epoch: [112][50/500] loss: 6.34525, MAE: 0.22884, time/step=1077ms, lr=8.36e-06
2024-03-22 06:41:05,471 - logger.py:50 - Epoch: [112][100/500] loss: 4.78580, MAE: 0.20291, time/step=1065ms, lr=8.36e-06
2024-03-22 06:41:59,096 - logger.py:50 - Epoch: [112][150/500] loss: 4.25677, MAE: 0.19411, time/step=1067ms, lr=8.36e-06
2024-03-22 06:42:52,859 - logger.py:50 - Epoch: [112][200/500] loss: 3.98622, MAE: 0.18860, time/step=1069ms, lr=8.36e-06
2024-03-22 06:43:46,487 - logger.py:50 - Epoch: [112][250/500] loss: 3.82674, MAE: 0.18711, time/step=1070ms, lr=8.36e-06
2024-03-22 06:44:39,103 - logger.py:50 - Epoch: [112][300/500] loss: 3.72131, MAE: 0.18533, time/step=1067ms, lr=8.36e-06
2024-03-22 06:45:31,582 - logger.py:50 - Epoch: [112][350/500] loss: 3.64528, MAE: 0.18418, time/step=1065ms, lr=8.36e-06
2024-03-22 06:46:23,852 - logger.py:50 - Epoch: [112][400/500] loss: 3.59063, MAE: 0.18290, time/step=1062ms, lr=8.36e-06
2024-03-22 06:47:16,760 - logger.py:50 - Epoch: [112][450/500] loss: 3.54598, MAE: 0.18249, time/step=1062ms, lr=8.36e-06
2024-03-22 06:48:09,225 - logger.py:50 - Epoch: [112][499/500] loss: 3.51103, MAE: 0.18178, time/step=1063ms, lr=8.36e-06
2024-03-22 06:49:09,607 - logger.py:50 - Epoch: [112] train loss: 3.51103, train MAE: 0.18178,val loss: 3.16738, val MAE: 0.16943,test loss: 3.18153, test MAE: 0.17576,Time: 591.68s
2024-03-22 06:49:09,607 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 06:50:08,659 - logger.py:50 - Epoch: [112]EMA val MAE: 0.17517, EMA test MAE: 0.18158, Time: 650.74s
2024-03-22 06:50:08,659 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 06:50:09,848 - logger.py:50 - Epoch: [113][0/500] loss: 3.26053, MAE: 0.17027, time/step=1187ms, lr=8.00e-06
2024-03-22 06:51:04,485 - logger.py:50 - Epoch: [113][50/500] loss: 3.18919, MAE: 0.17534, time/step=1095ms, lr=8.00e-06
2024-03-22 06:51:56,458 - logger.py:50 - Epoch: [113][100/500] loss: 3.18620, MAE: 0.17808, time/step=1067ms, lr=8.00e-06
2024-03-22 06:52:49,992 - logger.py:50 - Epoch: [113][150/500] loss: 3.18707, MAE: 0.17786, time/step=1068ms, lr=8.00e-06
2024-03-22 06:53:43,397 - logger.py:50 - Epoch: [113][200/500] loss: 3.43908, MAE: 0.18214, time/step=1068ms, lr=8.00e-06
2024-03-22 06:54:35,864 - logger.py:50 - Epoch: [113][250/500] loss: 3.38986, MAE: 0.18050, time/step=1065ms, lr=8.00e-06
2024-03-22 06:55:28,864 - logger.py:50 - Epoch: [113][300/500] loss: 3.72771, MAE: 0.18516, time/step=1064ms, lr=8.00e-06
2024-03-22 06:56:21,986 - logger.py:50 - Epoch: [113][350/500] loss: 3.65518, MAE: 0.18437, time/step=1064ms, lr=8.00e-06
2024-03-22 06:57:14,954 - logger.py:50 - Epoch: [113][400/500] loss: 3.59531, MAE: 0.18304, time/step=1063ms, lr=8.00e-06
2024-03-22 06:58:07,374 - logger.py:50 - Epoch: [113][450/500] loss: 3.54687, MAE: 0.18189, time/step=1061ms, lr=8.00e-06
2024-03-22 06:58:58,958 - logger.py:50 - Epoch: [113][499/500] loss: 3.51042, MAE: 0.18065, time/step=1061ms, lr=8.00e-06
2024-03-22 06:59:58,807 - logger.py:50 - Epoch: [113] train loss: 3.51042, train MAE: 0.18065,val loss: 3.16844, val MAE: 0.17019,test loss: 3.18218, test MAE: 0.17644,Time: 590.15s
2024-03-22 06:59:58,807 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 07:00:58,036 - logger.py:50 - Epoch: [113]EMA val MAE: 0.17485, EMA test MAE: 0.18126, Time: 649.38s
2024-03-22 07:00:58,036 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 07:00:58,866 - logger.py:50 - Epoch: [114][0/500] loss: 3.08761, MAE: 0.16437, time/step=827ms, lr=7.64e-06
2024-03-22 07:01:52,496 - logger.py:50 - Epoch: [114][50/500] loss: 3.16790, MAE: 0.17064, time/step=1068ms, lr=7.64e-06
2024-03-22 07:02:45,787 - logger.py:50 - Epoch: [114][100/500] loss: 3.17326, MAE: 0.17292, time/step=1067ms, lr=7.64e-06
2024-03-22 07:03:38,551 - logger.py:50 - Epoch: [114][150/500] loss: 3.18532, MAE: 0.17271, time/step=1063ms, lr=7.64e-06
2024-03-22 07:04:31,254 - logger.py:50 - Epoch: [114][200/500] loss: 3.18376, MAE: 0.17325, time/step=1061ms, lr=7.64e-06
2024-03-22 07:05:24,480 - logger.py:50 - Epoch: [114][250/500] loss: 3.38890, MAE: 0.17691, time/step=1062ms, lr=7.64e-06
2024-03-22 07:06:17,595 - logger.py:50 - Epoch: [114][300/500] loss: 3.35438, MAE: 0.17564, time/step=1062ms, lr=7.64e-06
2024-03-22 07:07:11,242 - logger.py:50 - Epoch: [114][350/500] loss: 3.32987, MAE: 0.17674, time/step=1063ms, lr=7.64e-06
2024-03-22 07:08:05,188 - logger.py:50 - Epoch: [114][400/500] loss: 3.31024, MAE: 0.17631, time/step=1065ms, lr=7.64e-06
2024-03-22 07:08:58,026 - logger.py:50 - Epoch: [114][450/500] loss: 3.54464, MAE: 0.18000, time/step=1064ms, lr=7.64e-06
2024-03-22 07:09:49,408 - logger.py:50 - Epoch: [114][499/500] loss: 3.51040, MAE: 0.18040, time/step=1063ms, lr=7.64e-06
2024-03-22 07:10:49,480 - logger.py:50 - Epoch: [114] train loss: 3.51040, train MAE: 0.18040,val loss: 3.16740, val MAE: 0.17171,test loss: 3.18125, test MAE: 0.17792,Time: 591.44s
2024-03-22 07:10:49,480 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 07:11:48,445 - logger.py:50 - Epoch: [114]EMA val MAE: 0.17453, EMA test MAE: 0.18093, Time: 650.41s
2024-03-22 07:11:48,445 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 07:11:49,682 - logger.py:50 - Epoch: [115][0/500] loss: 3.08163, MAE: 0.14260, time/step=1234ms, lr=7.29e-06
2024-03-22 07:12:42,615 - logger.py:50 - Epoch: [115][50/500] loss: 3.18691, MAE: 0.18033, time/step=1062ms, lr=7.29e-06
2024-03-22 07:13:36,256 - logger.py:50 - Epoch: [115][100/500] loss: 4.28655, MAE: 0.19448, time/step=1067ms, lr=7.29e-06
2024-03-22 07:14:30,654 - logger.py:50 - Epoch: [115][150/500] loss: 4.24747, MAE: 0.19380, time/step=1074ms, lr=7.29e-06
2024-03-22 07:15:22,524 - logger.py:50 - Epoch: [115][200/500] loss: 3.98646, MAE: 0.18990, time/step=1065ms, lr=7.29e-06
2024-03-22 07:16:16,362 - logger.py:50 - Epoch: [115][250/500] loss: 3.82489, MAE: 0.18667, time/step=1067ms, lr=7.29e-06
2024-03-22 07:17:10,019 - logger.py:50 - Epoch: [115][300/500] loss: 3.72383, MAE: 0.18537, time/step=1068ms, lr=7.29e-06
2024-03-22 07:18:04,529 - logger.py:50 - Epoch: [115][350/500] loss: 3.64420, MAE: 0.18337, time/step=1071ms, lr=7.29e-06
2024-03-22 07:18:57,503 - logger.py:50 - Epoch: [115][400/500] loss: 3.58632, MAE: 0.18219, time/step=1070ms, lr=7.29e-06
2024-03-22 07:19:49,509 - logger.py:50 - Epoch: [115][450/500] loss: 3.54322, MAE: 0.18192, time/step=1067ms, lr=7.29e-06
2024-03-22 07:20:40,737 - logger.py:50 - Epoch: [115][499/500] loss: 3.51005, MAE: 0.18102, time/step=1065ms, lr=7.29e-06
2024-03-22 07:21:40,079 - logger.py:50 - Epoch: [115] train loss: 3.51005, train MAE: 0.18102,val loss: 3.17126, val MAE: 0.17182,test loss: 3.18338, test MAE: 0.17815,Time: 591.63s
2024-03-22 07:21:40,079 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 07:22:38,806 - logger.py:50 - Epoch: [115]EMA val MAE: 0.17428, EMA test MAE: 0.18067, Time: 650.36s
2024-03-22 07:22:38,806 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 07:22:40,007 - logger.py:50 - Epoch: [116][0/500] loss: 3.60360, MAE: 0.25695, time/step=1199ms, lr=6.95e-06
2024-03-22 07:23:32,348 - logger.py:50 - Epoch: [116][50/500] loss: 4.21178, MAE: 0.19993, time/step=1050ms, lr=6.95e-06
2024-03-22 07:24:25,316 - logger.py:50 - Epoch: [116][100/500] loss: 4.80806, MAE: 0.20116, time/step=1055ms, lr=6.95e-06
2024-03-22 07:25:19,042 - logger.py:50 - Epoch: [116][150/500] loss: 4.26225, MAE: 0.19204, time/step=1061ms, lr=6.95e-06
2024-03-22 07:26:13,012 - logger.py:50 - Epoch: [116][200/500] loss: 3.98857, MAE: 0.18840, time/step=1066ms, lr=6.95e-06
2024-03-22 07:27:06,159 - logger.py:50 - Epoch: [116][250/500] loss: 3.82753, MAE: 0.18567, time/step=1065ms, lr=6.95e-06
2024-03-22 07:27:59,544 - logger.py:50 - Epoch: [116][300/500] loss: 3.72960, MAE: 0.18491, time/step=1066ms, lr=6.95e-06
2024-03-22 07:28:53,597 - logger.py:50 - Epoch: [116][350/500] loss: 3.65055, MAE: 0.18350, time/step=1068ms, lr=6.95e-06
2024-03-22 07:29:45,675 - logger.py:50 - Epoch: [116][400/500] loss: 3.59190, MAE: 0.18202, time/step=1065ms, lr=6.95e-06
2024-03-22 07:30:39,535 - logger.py:50 - Epoch: [116][450/500] loss: 3.54633, MAE: 0.18186, time/step=1066ms, lr=6.95e-06
2024-03-22 07:31:32,027 - logger.py:50 - Epoch: [116][499/500] loss: 3.50993, MAE: 0.18089, time/step=1066ms, lr=6.95e-06
2024-03-22 07:32:31,987 - logger.py:50 - Epoch: [116] train loss: 3.50993, train MAE: 0.18089,val loss: 3.16781, val MAE: 0.17006,test loss: 3.18150, test MAE: 0.17642,Time: 593.18s
2024-03-22 07:32:31,987 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 07:33:30,647 - logger.py:50 - Epoch: [116]EMA val MAE: 0.17403, EMA test MAE: 0.18041, Time: 651.84s
2024-03-22 07:33:30,647 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 07:33:31,840 - logger.py:50 - Epoch: [117][0/500] loss: 3.34363, MAE: 0.19955, time/step=1190ms, lr=6.62e-06
2024-03-22 07:34:24,806 - logger.py:50 - Epoch: [117][50/500] loss: 3.19132, MAE: 0.17754, time/step=1062ms, lr=6.62e-06
2024-03-22 07:35:17,336 - logger.py:50 - Epoch: [117][100/500] loss: 3.18583, MAE: 0.17752, time/step=1056ms, lr=6.62e-06
2024-03-22 07:36:10,052 - logger.py:50 - Epoch: [117][150/500] loss: 3.54030, MAE: 0.18700, time/step=1056ms, lr=6.62e-06
2024-03-22 07:37:03,761 - logger.py:50 - Epoch: [117][200/500] loss: 3.44459, MAE: 0.18326, time/step=1060ms, lr=6.62e-06
2024-03-22 07:37:57,554 - logger.py:50 - Epoch: [117][250/500] loss: 3.39040, MAE: 0.18120, time/step=1063ms, lr=6.62e-06
2024-03-22 07:38:51,034 - logger.py:50 - Epoch: [117][300/500] loss: 3.35504, MAE: 0.18060, time/step=1064ms, lr=6.62e-06
2024-03-22 07:39:44,270 - logger.py:50 - Epoch: [117][350/500] loss: 3.32734, MAE: 0.17884, time/step=1064ms, lr=6.62e-06
2024-03-22 07:40:37,502 - logger.py:50 - Epoch: [117][400/500] loss: 3.30905, MAE: 0.17877, time/step=1064ms, lr=6.62e-06
2024-03-22 07:41:31,126 - logger.py:50 - Epoch: [117][450/500] loss: 3.54580, MAE: 0.18128, time/step=1065ms, lr=6.62e-06
2024-03-22 07:42:23,364 - logger.py:50 - Epoch: [117][499/500] loss: 3.50975, MAE: 0.18036, time/step=1065ms, lr=6.62e-06
2024-03-22 07:43:22,718 - logger.py:50 - Epoch: [117] train loss: 3.50975, train MAE: 0.18036,val loss: 3.16746, val MAE: 0.17173,test loss: 3.18099, test MAE: 0.17800,Time: 592.07s
2024-03-22 07:43:22,718 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 07:44:21,921 - logger.py:50 - Epoch: [117]EMA val MAE: 0.17377, EMA test MAE: 0.18015, Time: 651.27s
2024-03-22 07:44:21,921 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 07:44:23,167 - logger.py:50 - Epoch: [118][0/500] loss: 3.39427, MAE: 0.21139, time/step=1243ms, lr=6.30e-06
2024-03-22 07:45:15,497 - logger.py:50 - Epoch: [118][50/500] loss: 3.19462, MAE: 0.17638, time/step=1050ms, lr=6.30e-06
2024-03-22 07:46:09,219 - logger.py:50 - Epoch: [118][100/500] loss: 3.18374, MAE: 0.17677, time/step=1062ms, lr=6.30e-06
2024-03-22 07:47:01,948 - logger.py:50 - Epoch: [118][150/500] loss: 3.18467, MAE: 0.17666, time/step=1060ms, lr=6.30e-06
2024-03-22 07:47:54,889 - logger.py:50 - Epoch: [118][200/500] loss: 3.18436, MAE: 0.17658, time/step=1060ms, lr=6.30e-06
2024-03-22 07:48:46,967 - logger.py:50 - Epoch: [118][250/500] loss: 3.62638, MAE: 0.18106, time/step=1056ms, lr=6.30e-06
2024-03-22 07:49:40,123 - logger.py:50 - Epoch: [118][300/500] loss: 3.55654, MAE: 0.18067, time/step=1057ms, lr=6.30e-06
2024-03-22 07:50:32,995 - logger.py:50 - Epoch: [118][350/500] loss: 3.50104, MAE: 0.17965, time/step=1057ms, lr=6.30e-06
2024-03-22 07:51:25,382 - logger.py:50 - Epoch: [118][400/500] loss: 3.46390, MAE: 0.17910, time/step=1056ms, lr=6.30e-06
2024-03-22 07:52:19,001 - logger.py:50 - Epoch: [118][450/500] loss: 3.54481, MAE: 0.18099, time/step=1058ms, lr=6.30e-06
2024-03-22 07:53:10,883 - logger.py:50 - Epoch: [118][499/500] loss: 3.51016, MAE: 0.18064, time/step=1058ms, lr=6.30e-06
2024-03-22 07:54:10,820 - logger.py:50 - Epoch: [118] train loss: 3.51016, train MAE: 0.18064,val loss: 3.16831, val MAE: 0.16998,test loss: 3.18231, test MAE: 0.17617,Time: 588.90s
2024-03-22 07:54:10,820 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 07:55:11,240 - logger.py:50 - Epoch: [118]EMA val MAE: 0.17355, EMA test MAE: 0.17991, Time: 649.32s
2024-03-22 07:55:11,240 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 07:55:12,034 - logger.py:50 - Epoch: [119][0/500] loss: 3.06646, MAE: 0.14217, time/step=792ms, lr=5.99e-06
2024-03-22 07:56:05,844 - logger.py:50 - Epoch: [119][50/500] loss: 3.17519, MAE: 0.18039, time/step=1071ms, lr=5.99e-06
2024-03-22 07:56:58,232 - logger.py:50 - Epoch: [119][100/500] loss: 3.17642, MAE: 0.17660, time/step=1059ms, lr=5.99e-06
2024-03-22 07:57:51,746 - logger.py:50 - Epoch: [119][150/500] loss: 3.18043, MAE: 0.17668, time/step=1063ms, lr=5.99e-06
2024-03-22 07:58:43,964 - logger.py:50 - Epoch: [119][200/500] loss: 3.18514, MAE: 0.17740, time/step=1058ms, lr=5.99e-06
2024-03-22 07:59:36,626 - logger.py:50 - Epoch: [119][250/500] loss: 3.18755, MAE: 0.17671, time/step=1057ms, lr=5.99e-06
2024-03-22 08:00:30,167 - logger.py:50 - Epoch: [119][300/500] loss: 3.35555, MAE: 0.17936, time/step=1060ms, lr=5.99e-06
2024-03-22 08:01:23,204 - logger.py:50 - Epoch: [119][350/500] loss: 3.33230, MAE: 0.17910, time/step=1060ms, lr=5.99e-06
2024-03-22 08:02:16,347 - logger.py:50 - Epoch: [119][400/500] loss: 3.31107, MAE: 0.17827, time/step=1060ms, lr=5.99e-06
2024-03-22 08:03:09,221 - logger.py:50 - Epoch: [119][450/500] loss: 3.54817, MAE: 0.18135, time/step=1060ms, lr=5.99e-06
2024-03-22 08:04:00,921 - logger.py:50 - Epoch: [119][499/500] loss: 3.50946, MAE: 0.18036, time/step=1059ms, lr=5.99e-06
2024-03-22 08:04:59,460 - logger.py:50 - Epoch: [119] train loss: 3.50946, train MAE: 0.18036,val loss: 3.16755, val MAE: 0.17028,test loss: 3.18093, test MAE: 0.17655,Time: 588.22s
2024-03-22 08:04:59,460 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 08:05:58,758 - logger.py:50 - Epoch: [119]EMA val MAE: 0.17333, EMA test MAE: 0.17969, Time: 647.52s
2024-03-22 08:05:58,758 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 08:05:59,532 - logger.py:50 - Epoch: [120][0/500] loss: 3.27124, MAE: 0.15496, time/step=771ms, lr=5.68e-06
2024-03-22 08:06:51,123 - logger.py:50 - Epoch: [120][50/500] loss: 3.19785, MAE: 0.17744, time/step=1027ms, lr=5.68e-06
2024-03-22 08:07:44,148 - logger.py:50 - Epoch: [120][100/500] loss: 3.17961, MAE: 0.17388, time/step=1043ms, lr=5.68e-06
2024-03-22 08:08:36,959 - logger.py:50 - Epoch: [120][150/500] loss: 3.92490, MAE: 0.18181, time/step=1048ms, lr=5.68e-06
2024-03-22 08:09:29,382 - logger.py:50 - Epoch: [120][200/500] loss: 3.74549, MAE: 0.18283, time/step=1048ms, lr=5.68e-06
2024-03-22 08:10:23,458 - logger.py:50 - Epoch: [120][250/500] loss: 3.83060, MAE: 0.18521, time/step=1055ms, lr=5.68e-06
2024-03-22 08:11:16,005 - logger.py:50 - Epoch: [120][300/500] loss: 3.71983, MAE: 0.18360, time/step=1054ms, lr=5.68e-06
2024-03-22 08:12:09,136 - logger.py:50 - Epoch: [120][350/500] loss: 3.64696, MAE: 0.18251, time/step=1055ms, lr=5.68e-06
2024-03-22 08:13:02,583 - logger.py:50 - Epoch: [120][400/500] loss: 3.59153, MAE: 0.18255, time/step=1057ms, lr=5.68e-06
2024-03-22 08:13:56,216 - logger.py:50 - Epoch: [120][450/500] loss: 3.54369, MAE: 0.18102, time/step=1059ms, lr=5.68e-06
2024-03-22 08:14:48,178 - logger.py:50 - Epoch: [120][499/500] loss: 3.50966, MAE: 0.18094, time/step=1059ms, lr=5.68e-06
2024-03-22 08:15:47,808 - logger.py:50 - Epoch: [120] train loss: 3.50966, train MAE: 0.18094,val loss: 3.16763, val MAE: 0.17175,test loss: 3.18050, test MAE: 0.17786,Time: 589.05s
2024-03-22 08:15:47,808 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 08:16:46,589 - logger.py:50 - Epoch: [120]EMA val MAE: 0.17317, EMA test MAE: 0.17952, Time: 647.83s
2024-03-22 08:16:46,589 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 08:16:47,338 - logger.py:50 - Epoch: [121][0/500] loss: 3.05556, MAE: 0.11570, time/step=747ms, lr=5.38e-06
2024-03-22 08:17:40,034 - logger.py:50 - Epoch: [121][50/500] loss: 3.18103, MAE: 0.17258, time/step=1048ms, lr=5.38e-06
2024-03-22 08:18:33,003 - logger.py:50 - Epoch: [121][100/500] loss: 3.68623, MAE: 0.18168, time/step=1054ms, lr=5.38e-06
2024-03-22 08:19:25,330 - logger.py:50 - Epoch: [121][150/500] loss: 3.52475, MAE: 0.18178, time/step=1051ms, lr=5.38e-06
2024-03-22 08:20:18,791 - logger.py:50 - Epoch: [121][200/500] loss: 3.43690, MAE: 0.17979, time/step=1056ms, lr=5.38e-06
2024-03-22 08:21:11,481 - logger.py:50 - Epoch: [121][250/500] loss: 3.39081, MAE: 0.18003, time/step=1055ms, lr=5.38e-06
2024-03-22 08:22:04,440 - logger.py:50 - Epoch: [121][300/500] loss: 3.35414, MAE: 0.17910, time/step=1056ms, lr=5.38e-06
2024-03-22 08:22:57,367 - logger.py:50 - Epoch: [121][350/500] loss: 3.33109, MAE: 0.17808, time/step=1056ms, lr=5.38e-06
2024-03-22 08:23:51,402 - logger.py:50 - Epoch: [121][400/500] loss: 3.31222, MAE: 0.17758, time/step=1059ms, lr=5.38e-06
2024-03-22 08:24:44,658 - logger.py:50 - Epoch: [121][450/500] loss: 3.54588, MAE: 0.18038, time/step=1060ms, lr=5.38e-06
2024-03-22 08:25:36,104 - logger.py:50 - Epoch: [121][499/500] loss: 3.50945, MAE: 0.18026, time/step=1059ms, lr=5.38e-06
2024-03-22 08:26:37,110 - logger.py:50 - Epoch: [121] train loss: 3.50945, train MAE: 0.18026,val loss: 3.16768, val MAE: 0.17154,test loss: 3.18120, test MAE: 0.17765,Time: 590.52s
2024-03-22 08:26:37,111 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 08:27:36,545 - logger.py:50 - Epoch: [121]EMA val MAE: 0.17297, EMA test MAE: 0.17932, Time: 649.96s
2024-03-22 08:27:36,546 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 08:27:37,897 - logger.py:50 - Epoch: [122][0/500] loss: 3.09507, MAE: 0.15491, time/step=1349ms, lr=5.09e-06
2024-03-22 08:28:30,842 - logger.py:50 - Epoch: [122][50/500] loss: 3.19007, MAE: 0.17287, time/step=1065ms, lr=5.09e-06
2024-03-22 08:29:24,635 - logger.py:50 - Epoch: [122][100/500] loss: 3.17760, MAE: 0.17451, time/step=1070ms, lr=5.09e-06
2024-03-22 08:30:18,303 - logger.py:50 - Epoch: [122][150/500] loss: 3.17351, MAE: 0.17276, time/step=1071ms, lr=5.09e-06
2024-03-22 08:31:10,410 - logger.py:50 - Epoch: [122][200/500] loss: 3.17928, MAE: 0.17375, time/step=1064ms, lr=5.09e-06
2024-03-22 08:32:02,769 - logger.py:50 - Epoch: [122][250/500] loss: 3.62673, MAE: 0.18043, time/step=1061ms, lr=5.09e-06
2024-03-22 08:32:57,054 - logger.py:50 - Epoch: [122][300/500] loss: 3.55107, MAE: 0.17938, time/step=1065ms, lr=5.09e-06
2024-03-22 08:33:49,898 - logger.py:50 - Epoch: [122][350/500] loss: 3.49869, MAE: 0.17937, time/step=1064ms, lr=5.09e-06
2024-03-22 08:34:42,562 - logger.py:50 - Epoch: [122][400/500] loss: 3.45872, MAE: 0.17856, time/step=1062ms, lr=5.09e-06
2024-03-22 08:35:36,054 - logger.py:50 - Epoch: [122][450/500] loss: 3.43097, MAE: 0.17866, time/step=1063ms, lr=5.09e-06
2024-03-22 08:36:29,264 - logger.py:50 - Epoch: [122][499/500] loss: 3.50940, MAE: 0.18023, time/step=1065ms, lr=5.09e-06
2024-03-22 08:37:29,019 - logger.py:50 - Epoch: [122] train loss: 3.50940, train MAE: 0.18023,val loss: 3.16740, val MAE: 0.17299,test loss: 3.18105, test MAE: 0.17919,Time: 592.47s
2024-03-22 08:37:29,019 - logger.py:50 - Best -- epoch=112, train loss: 3.51103, val loss: 3.16738, test loss: 3.18153

2024-03-22 08:38:28,713 - logger.py:50 - Epoch: [122]EMA val MAE: 0.17278, EMA test MAE: 0.17913, Time: 652.17s
2024-03-22 08:38:28,714 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 08:38:29,950 - logger.py:50 - Epoch: [123][0/500] loss: 3.11527, MAE: 0.17747, time/step=1234ms, lr=4.81e-06
2024-03-22 08:39:23,339 - logger.py:50 - Epoch: [123][50/500] loss: 3.18821, MAE: 0.18052, time/step=1071ms, lr=4.81e-06
2024-03-22 08:40:15,510 - logger.py:50 - Epoch: [123][100/500] loss: 3.19076, MAE: 0.17855, time/step=1057ms, lr=4.81e-06
2024-03-22 08:41:08,096 - logger.py:50 - Epoch: [123][150/500] loss: 3.53207, MAE: 0.18221, time/step=1055ms, lr=4.81e-06
2024-03-22 08:42:00,291 - logger.py:50 - Epoch: [123][200/500] loss: 4.00754, MAE: 0.18756, time/step=1053ms, lr=4.81e-06
2024-03-22 08:42:53,633 - logger.py:50 - Epoch: [123][250/500] loss: 3.84386, MAE: 0.18515, time/step=1055ms, lr=4.81e-06
2024-03-22 08:43:46,003 - logger.py:50 - Epoch: [123][300/500] loss: 3.73539, MAE: 0.18429, time/step=1054ms, lr=4.81e-06
2024-03-22 08:44:38,912 - logger.py:50 - Epoch: [123][350/500] loss: 3.65188, MAE: 0.18299, time/step=1055ms, lr=4.81e-06
2024-03-22 08:45:32,476 - logger.py:50 - Epoch: [123][400/500] loss: 3.59192, MAE: 0.18158, time/step=1057ms, lr=4.81e-06
2024-03-22 08:46:26,911 - logger.py:50 - Epoch: [123][450/500] loss: 3.54452, MAE: 0.18091, time/step=1060ms, lr=4.81e-06
2024-03-22 08:47:18,075 - logger.py:50 - Epoch: [123][499/500] loss: 3.50930, MAE: 0.18056, time/step=1059ms, lr=4.81e-06
2024-03-22 08:48:18,312 - logger.py:50 - Epoch: [123] train loss: 3.50930, train MAE: 0.18056,val loss: 3.16687, val MAE: 0.17064,test loss: 3.18069, test MAE: 0.17683,Time: 589.60s
2024-03-22 08:48:18,312 - logger.py:50 - Best -- epoch=123, train loss: 3.50930, val loss: 3.16687, test loss: 3.18069

2024-03-22 08:49:16,839 - logger.py:50 - Epoch: [123]EMA val MAE: 0.17264, EMA test MAE: 0.17897, Time: 648.13s
2024-03-22 08:49:16,839 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 08:49:18,117 - logger.py:50 - Epoch: [124][0/500] loss: 3.27112, MAE: 0.19010, time/step=1276ms, lr=4.54e-06
2024-03-22 08:50:10,203 - logger.py:50 - Epoch: [124][50/500] loss: 3.19932, MAE: 0.18280, time/step=1046ms, lr=4.54e-06
2024-03-22 08:51:02,666 - logger.py:50 - Epoch: [124][100/500] loss: 3.19096, MAE: 0.17907, time/step=1048ms, lr=4.54e-06
2024-03-22 08:51:55,721 - logger.py:50 - Epoch: [124][150/500] loss: 3.18469, MAE: 0.17689, time/step=1052ms, lr=4.54e-06
2024-03-22 08:52:49,475 - logger.py:50 - Epoch: [124][200/500] loss: 3.19171, MAE: 0.17575, time/step=1058ms, lr=4.54e-06
2024-03-22 08:53:42,223 - logger.py:50 - Epoch: [124][250/500] loss: 3.39337, MAE: 0.17923, time/step=1057ms, lr=4.54e-06
2024-03-22 08:54:35,719 - logger.py:50 - Epoch: [124][300/500] loss: 3.36055, MAE: 0.17949, time/step=1059ms, lr=4.54e-06
2024-03-22 08:55:28,529 - logger.py:50 - Epoch: [124][350/500] loss: 3.33601, MAE: 0.17893, time/step=1059ms, lr=4.54e-06
2024-03-22 08:56:22,389 - logger.py:50 - Epoch: [124][400/500] loss: 3.31480, MAE: 0.17827, time/step=1061ms, lr=4.54e-06
2024-03-22 08:57:15,099 - logger.py:50 - Epoch: [124][450/500] loss: 3.54431, MAE: 0.18012, time/step=1060ms, lr=4.54e-06
2024-03-22 08:58:07,493 - logger.py:50 - Epoch: [124][499/500] loss: 3.50923, MAE: 0.18007, time/step=1061ms, lr=4.54e-06
2024-03-22 08:59:06,830 - logger.py:50 - Epoch: [124] train loss: 3.50923, train MAE: 0.18007,val loss: 3.16706, val MAE: 0.17091,test loss: 3.18092, test MAE: 0.17720,Time: 589.99s
2024-03-22 08:59:06,830 - logger.py:50 - Best -- epoch=123, train loss: 3.50930, val loss: 3.16687, test loss: 3.18069

2024-03-22 09:00:06,378 - logger.py:50 - Epoch: [124]EMA val MAE: 0.17247, EMA test MAE: 0.17880, Time: 649.54s
2024-03-22 09:00:06,378 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 09:00:07,642 - logger.py:50 - Epoch: [125][0/500] loss: 3.08677, MAE: 0.15338, time/step=1261ms, lr=4.28e-06
2024-03-22 09:01:02,055 - logger.py:50 - Epoch: [125][50/500] loss: 3.15682, MAE: 0.16625, time/step=1092ms, lr=4.28e-06
2024-03-22 09:01:55,792 - logger.py:50 - Epoch: [125][100/500] loss: 3.16205, MAE: 0.17041, time/step=1083ms, lr=4.28e-06
2024-03-22 09:02:49,301 - logger.py:50 - Epoch: [125][150/500] loss: 3.50408, MAE: 0.17893, time/step=1079ms, lr=4.28e-06
2024-03-22 09:03:42,853 - logger.py:50 - Epoch: [125][200/500] loss: 3.41767, MAE: 0.17739, time/step=1077ms, lr=4.28e-06
2024-03-22 09:04:36,576 - logger.py:50 - Epoch: [125][250/500] loss: 3.37440, MAE: 0.17865, time/step=1076ms, lr=4.28e-06
2024-03-22 09:05:30,420 - logger.py:50 - Epoch: [125][300/500] loss: 3.34403, MAE: 0.17783, time/step=1077ms, lr=4.28e-06
2024-03-22 09:06:23,331 - logger.py:50 - Epoch: [125][350/500] loss: 3.32408, MAE: 0.17788, time/step=1074ms, lr=4.28e-06
2024-03-22 09:07:18,483 - logger.py:50 - Epoch: [125][400/500] loss: 3.30790, MAE: 0.17769, time/step=1078ms, lr=4.28e-06
2024-03-22 09:08:11,791 - logger.py:50 - Epoch: [125][450/500] loss: 3.54277, MAE: 0.18079, time/step=1076ms, lr=4.28e-06
2024-03-22 09:09:03,202 - logger.py:50 - Epoch: [125][499/500] loss: 3.50909, MAE: 0.18021, time/step=1074ms, lr=4.28e-06
2024-03-22 09:10:03,646 - logger.py:50 - Epoch: [125] train loss: 3.50909, train MAE: 0.18021,val loss: 3.16702, val MAE: 0.17211,test loss: 3.18093, test MAE: 0.17844,Time: 597.27s
2024-03-22 09:10:03,646 - logger.py:50 - Best -- epoch=123, train loss: 3.50930, val loss: 3.16687, test loss: 3.18069

2024-03-22 09:11:03,765 - logger.py:50 - Epoch: [125]EMA val MAE: 0.17234, EMA test MAE: 0.17866, Time: 657.39s
2024-03-22 09:11:03,765 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 09:11:04,877 - logger.py:50 - Epoch: [126][0/500] loss: 3.58085, MAE: 0.21553, time/step=1109ms, lr=4.03e-06
2024-03-22 09:11:58,625 - logger.py:50 - Epoch: [126][50/500] loss: 3.19371, MAE: 0.17364, time/step=1076ms, lr=4.03e-06
2024-03-22 09:12:51,746 - logger.py:50 - Epoch: [126][100/500] loss: 3.17120, MAE: 0.17101, time/step=1069ms, lr=4.03e-06
2024-03-22 09:13:44,794 - logger.py:50 - Epoch: [126][150/500] loss: 3.92412, MAE: 0.18140, time/step=1066ms, lr=4.03e-06
2024-03-22 09:14:37,675 - logger.py:50 - Epoch: [126][200/500] loss: 3.73935, MAE: 0.18102, time/step=1064ms, lr=4.03e-06
2024-03-22 09:15:30,648 - logger.py:50 - Epoch: [126][250/500] loss: 3.63001, MAE: 0.18083, time/step=1063ms, lr=4.03e-06
2024-03-22 09:16:25,212 - logger.py:50 - Epoch: [126][300/500] loss: 3.55444, MAE: 0.17970, time/step=1068ms, lr=4.03e-06
2024-03-22 09:17:19,089 - logger.py:50 - Epoch: [126][350/500] loss: 3.50032, MAE: 0.17922, time/step=1069ms, lr=4.03e-06
2024-03-22 09:18:12,174 - logger.py:50 - Epoch: [126][400/500] loss: 3.59203, MAE: 0.18152, time/step=1068ms, lr=4.03e-06
2024-03-22 09:19:05,367 - logger.py:50 - Epoch: [126][450/500] loss: 3.54576, MAE: 0.18098, time/step=1068ms, lr=4.03e-06
2024-03-22 09:19:59,538 - logger.py:50 - Epoch: [126][499/500] loss: 3.50903, MAE: 0.18040, time/step=1072ms, lr=4.03e-06
2024-03-22 09:21:00,997 - logger.py:50 - Epoch: [126] train loss: 3.50903, train MAE: 0.18040,val loss: 3.16728, val MAE: 0.17103,test loss: 3.18166, test MAE: 0.17738,Time: 597.23s
2024-03-22 09:21:00,997 - logger.py:50 - Best -- epoch=123, train loss: 3.50930, val loss: 3.16687, test loss: 3.18069

2024-03-22 09:22:02,892 - logger.py:50 - Epoch: [126]EMA val MAE: 0.17222, EMA test MAE: 0.17854, Time: 659.13s
2024-03-22 09:22:02,892 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 09:22:04,268 - logger.py:50 - Epoch: [127][0/500] loss: 3.05707, MAE: 0.15920, time/step=1373ms, lr=3.79e-06
2024-03-22 09:22:59,921 - logger.py:50 - Epoch: [127][50/500] loss: 3.17989, MAE: 0.17555, time/step=1118ms, lr=3.79e-06
2024-03-22 09:23:53,293 - logger.py:50 - Epoch: [127][100/500] loss: 3.18026, MAE: 0.17173, time/step=1093ms, lr=3.79e-06
2024-03-22 09:24:46,490 - logger.py:50 - Epoch: [127][150/500] loss: 3.17901, MAE: 0.17399, time/step=1083ms, lr=3.79e-06
2024-03-22 09:25:41,394 - logger.py:50 - Epoch: [127][200/500] loss: 3.17990, MAE: 0.17478, time/step=1087ms, lr=3.79e-06
2024-03-22 09:26:35,145 - logger.py:50 - Epoch: [127][250/500] loss: 3.38713, MAE: 0.17930, time/step=1085ms, lr=3.79e-06
2024-03-22 09:27:28,529 - logger.py:50 - Epoch: [127][300/500] loss: 3.35318, MAE: 0.17943, time/step=1082ms, lr=3.79e-06
2024-03-22 09:28:23,345 - logger.py:50 - Epoch: [127][350/500] loss: 3.33213, MAE: 0.17958, time/step=1084ms, lr=3.79e-06
2024-03-22 09:29:16,322 - logger.py:50 - Epoch: [127][400/500] loss: 3.31236, MAE: 0.17827, time/step=1081ms, lr=3.79e-06
2024-03-22 09:30:10,062 - logger.py:50 - Epoch: [127][450/500] loss: 3.54236, MAE: 0.18061, time/step=1080ms, lr=3.79e-06
2024-03-22 09:31:03,331 - logger.py:50 - Epoch: [127][499/500] loss: 3.50902, MAE: 0.18013, time/step=1081ms, lr=3.79e-06
2024-03-22 09:32:04,648 - logger.py:50 - Epoch: [127] train loss: 3.50902, train MAE: 0.18013,val loss: 3.16764, val MAE: 0.17220,test loss: 3.18051, test MAE: 0.17831,Time: 601.76s
2024-03-22 09:32:04,649 - logger.py:50 - Best -- epoch=123, train loss: 3.50930, val loss: 3.16687, test loss: 3.18069

2024-03-22 09:33:04,258 - logger.py:50 - Epoch: [127]EMA val MAE: 0.17210, EMA test MAE: 0.17841, Time: 661.37s
2024-03-22 09:33:04,258 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 09:33:05,572 - logger.py:50 - Epoch: [128][0/500] loss: 3.07243, MAE: 0.15441, time/step=1311ms, lr=3.56e-06
2024-03-22 09:33:59,581 - logger.py:50 - Epoch: [128][50/500] loss: 3.17563, MAE: 0.17462, time/step=1085ms, lr=3.56e-06
2024-03-22 09:34:51,965 - logger.py:50 - Epoch: [128][100/500] loss: 3.18436, MAE: 0.17558, time/step=1066ms, lr=3.56e-06
2024-03-22 09:35:45,907 - logger.py:50 - Epoch: [128][150/500] loss: 3.19191, MAE: 0.17666, time/step=1071ms, lr=3.56e-06
2024-03-22 09:36:41,051 - logger.py:50 - Epoch: [128][200/500] loss: 3.18836, MAE: 0.17696, time/step=1079ms, lr=3.56e-06
2024-03-22 09:37:33,941 - logger.py:50 - Epoch: [128][250/500] loss: 3.83265, MAE: 0.18509, time/step=1074ms, lr=3.56e-06
2024-03-22 09:38:27,328 - logger.py:50 - Epoch: [128][300/500] loss: 3.72247, MAE: 0.18337, time/step=1073ms, lr=3.56e-06
2024-03-22 09:39:20,283 - logger.py:50 - Epoch: [128][350/500] loss: 3.64922, MAE: 0.18237, time/step=1071ms, lr=3.56e-06
2024-03-22 09:40:18,269 - logger.py:50 - Epoch: [128][400/500] loss: 3.59163, MAE: 0.18192, time/step=1082ms, lr=3.56e-06
2024-03-22 09:41:15,353 - logger.py:50 - Epoch: [128][450/500] loss: 3.54587, MAE: 0.18089, time/step=1089ms, lr=3.56e-06
2024-03-22 09:42:12,323 - logger.py:50 - Epoch: [128][499/500] loss: 3.50880, MAE: 0.18018, time/step=1096ms, lr=3.56e-06
2024-03-22 09:43:19,592 - logger.py:50 - Epoch: [128] train loss: 3.50880, train MAE: 0.18018,val loss: 3.16726, val MAE: 0.17073,test loss: 3.18103, test MAE: 0.17700,Time: 615.33s
2024-03-22 09:43:19,592 - logger.py:50 - Best -- epoch=123, train loss: 3.50930, val loss: 3.16687, test loss: 3.18069

2024-03-22 09:44:25,480 - logger.py:50 - Epoch: [128]EMA val MAE: 0.17199, EMA test MAE: 0.17830, Time: 681.22s
2024-03-22 09:44:25,480 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 09:44:26,854 - logger.py:50 - Epoch: [129][0/500] loss: 3.40121, MAE: 0.23804, time/step=1372ms, lr=3.33e-06
2024-03-22 09:45:24,843 - logger.py:50 - Epoch: [129][50/500] loss: 3.19811, MAE: 0.17799, time/step=1164ms, lr=3.33e-06
2024-03-22 09:46:23,626 - logger.py:50 - Epoch: [129][100/500] loss: 3.19062, MAE: 0.17545, time/step=1170ms, lr=3.33e-06
2024-03-22 09:47:21,194 - logger.py:50 - Epoch: [129][150/500] loss: 3.92364, MAE: 0.18481, time/step=1164ms, lr=3.33e-06
2024-03-22 09:48:19,295 - logger.py:50 - Epoch: [129][200/500] loss: 3.74432, MAE: 0.18325, time/step=1163ms, lr=3.33e-06
2024-03-22 09:49:17,106 - logger.py:50 - Epoch: [129][250/500] loss: 3.63548, MAE: 0.18289, time/step=1162ms, lr=3.33e-06
2024-03-22 09:50:16,114 - logger.py:50 - Epoch: [129][300/500] loss: 3.55292, MAE: 0.18006, time/step=1165ms, lr=3.33e-06
2024-03-22 09:51:14,052 - logger.py:50 - Epoch: [129][350/500] loss: 3.49688, MAE: 0.17864, time/step=1164ms, lr=3.33e-06
2024-03-22 09:52:09,658 - logger.py:50 - Epoch: [129][400/500] loss: 3.45707, MAE: 0.17796, time/step=1158ms, lr=3.33e-06
2024-03-22 09:53:05,053 - logger.py:50 - Epoch: [129][450/500] loss: 3.42807, MAE: 0.17812, time/step=1152ms, lr=3.33e-06
2024-03-22 09:53:58,988 - logger.py:50 - Epoch: [129][499/500] loss: 3.50873, MAE: 0.18000, time/step=1147ms, lr=3.33e-06
2024-03-22 09:54:59,996 - logger.py:50 - Epoch: [129] train loss: 3.50873, train MAE: 0.18000,val loss: 3.16706, val MAE: 0.17318,test loss: 3.18050, test MAE: 0.17941,Time: 634.52s
2024-03-22 09:54:59,996 - logger.py:50 - Best -- epoch=123, train loss: 3.50930, val loss: 3.16687, test loss: 3.18069

2024-03-22 09:56:01,424 - logger.py:50 - Epoch: [129]EMA val MAE: 0.17188, EMA test MAE: 0.17818, Time: 695.94s
2024-03-22 09:56:01,424 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 09:56:02,174 - logger.py:50 - Epoch: [130][0/500] loss: 3.08352, MAE: 0.15161, time/step=747ms, lr=3.12e-06
2024-03-22 09:56:56,243 - logger.py:50 - Epoch: [130][50/500] loss: 3.15043, MAE: 0.17082, time/step=1075ms, lr=3.12e-06
2024-03-22 09:57:51,137 - logger.py:50 - Epoch: [130][100/500] loss: 3.16996, MAE: 0.17436, time/step=1086ms, lr=3.12e-06
2024-03-22 09:58:46,698 - logger.py:50 - Epoch: [130][150/500] loss: 3.90511, MAE: 0.18109, time/step=1095ms, lr=3.12e-06
2024-03-22 09:59:41,877 - logger.py:50 - Epoch: [130][200/500] loss: 3.73217, MAE: 0.18076, time/step=1097ms, lr=3.12e-06
2024-03-22 10:00:37,968 - logger.py:50 - Epoch: [130][250/500] loss: 3.62040, MAE: 0.17920, time/step=1102ms, lr=3.12e-06
2024-03-22 10:01:31,187 - logger.py:50 - Epoch: [130][300/500] loss: 3.55508, MAE: 0.17968, time/step=1096ms, lr=3.12e-06
2024-03-22 10:02:24,615 - logger.py:50 - Epoch: [130][350/500] loss: 3.50183, MAE: 0.17918, time/step=1092ms, lr=3.12e-06
2024-03-22 10:03:18,808 - logger.py:50 - Epoch: [130][400/500] loss: 3.46222, MAE: 0.17907, time/step=1091ms, lr=3.12e-06
2024-03-22 10:04:13,322 - logger.py:50 - Epoch: [130][450/500] loss: 3.54408, MAE: 0.18050, time/step=1091ms, lr=3.12e-06
2024-03-22 10:05:06,667 - logger.py:50 - Epoch: [130][499/500] loss: 3.50873, MAE: 0.18011, time/step=1090ms, lr=3.12e-06
2024-03-22 10:06:15,885 - logger.py:50 - Epoch: [130] train loss: 3.50873, train MAE: 0.18011,val loss: 3.16678, val MAE: 0.17127,test loss: 3.18070, test MAE: 0.17750,Time: 614.46s
2024-03-22 10:06:15,886 - logger.py:50 - Best -- epoch=130, train loss: 3.50873, val loss: 3.16678, test loss: 3.18070

2024-03-22 10:07:23,715 - logger.py:50 - Epoch: [130]EMA val MAE: 0.17178, EMA test MAE: 0.17808, Time: 682.29s
2024-03-22 10:07:23,715 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 10:07:25,011 - logger.py:50 - Epoch: [131][0/500] loss: 3.17938, MAE: 0.20293, time/step=1293ms, lr=2.91e-06
2024-03-22 10:08:23,148 - logger.py:50 - Epoch: [131][50/500] loss: 3.19987, MAE: 0.17520, time/step=1165ms, lr=2.91e-06
2024-03-22 10:09:23,783 - logger.py:50 - Epoch: [131][100/500] loss: 3.18851, MAE: 0.17359, time/step=1189ms, lr=2.91e-06
2024-03-22 10:10:22,248 - logger.py:50 - Epoch: [131][150/500] loss: 3.91523, MAE: 0.18126, time/step=1182ms, lr=2.91e-06
2024-03-22 10:11:19,897 - logger.py:50 - Epoch: [131][200/500] loss: 3.74108, MAE: 0.18211, time/step=1175ms, lr=2.91e-06
2024-03-22 10:12:16,649 - logger.py:50 - Epoch: [131][250/500] loss: 3.63815, MAE: 0.18182, time/step=1167ms, lr=2.91e-06
2024-03-22 10:13:13,543 - logger.py:50 - Epoch: [131][300/500] loss: 3.56381, MAE: 0.18138, time/step=1162ms, lr=2.91e-06
2024-03-22 10:14:11,640 - logger.py:50 - Epoch: [131][350/500] loss: 3.65269, MAE: 0.18261, time/step=1162ms, lr=2.91e-06
2024-03-22 10:15:10,994 - logger.py:50 - Epoch: [131][400/500] loss: 3.59486, MAE: 0.18211, time/step=1165ms, lr=2.91e-06
2024-03-22 10:16:09,292 - logger.py:50 - Epoch: [131][450/500] loss: 3.54906, MAE: 0.18130, time/step=1165ms, lr=2.91e-06
2024-03-22 10:17:06,185 - logger.py:50 - Epoch: [131][499/500] loss: 3.50867, MAE: 0.17994, time/step=1165ms, lr=2.91e-06
2024-03-22 10:18:14,810 - logger.py:50 - Epoch: [131] train loss: 3.50867, train MAE: 0.17994,val loss: 3.16702, val MAE: 0.17007,test loss: 3.18138, test MAE: 0.17631,Time: 651.09s
2024-03-22 10:18:14,810 - logger.py:50 - Best -- epoch=130, train loss: 3.50873, val loss: 3.16678, test loss: 3.18070

2024-03-22 10:19:21,194 - logger.py:50 - Epoch: [131]EMA val MAE: 0.17169, EMA test MAE: 0.17798, Time: 717.48s
2024-03-22 10:19:21,195 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 10:19:22,543 - logger.py:50 - Epoch: [132][0/500] loss: 3.27559, MAE: 0.15500, time/step=1346ms, lr=2.72e-06
2024-03-22 10:20:17,490 - logger.py:50 - Epoch: [132][50/500] loss: 3.17827, MAE: 0.17868, time/step=1104ms, lr=2.72e-06
2024-03-22 10:21:12,408 - logger.py:50 - Epoch: [132][100/500] loss: 3.18555, MAE: 0.17772, time/step=1101ms, lr=2.72e-06
2024-03-22 10:22:07,181 - logger.py:50 - Epoch: [132][150/500] loss: 3.18461, MAE: 0.17643, time/step=1099ms, lr=2.72e-06
2024-03-22 10:23:02,568 - logger.py:50 - Epoch: [132][200/500] loss: 3.18822, MAE: 0.17593, time/step=1101ms, lr=2.72e-06
2024-03-22 10:23:57,355 - logger.py:50 - Epoch: [132][250/500] loss: 3.19010, MAE: 0.17628, time/step=1100ms, lr=2.72e-06
2024-03-22 10:24:54,327 - logger.py:50 - Epoch: [132][300/500] loss: 3.56002, MAE: 0.18059, time/step=1107ms, lr=2.72e-06
2024-03-22 10:25:50,234 - logger.py:50 - Epoch: [132][350/500] loss: 3.50684, MAE: 0.18066, time/step=1108ms, lr=2.72e-06
2024-03-22 10:26:45,041 - logger.py:50 - Epoch: [132][400/500] loss: 3.46216, MAE: 0.17913, time/step=1107ms, lr=2.72e-06
2024-03-22 10:27:40,452 - logger.py:50 - Epoch: [132][450/500] loss: 3.43291, MAE: 0.17862, time/step=1107ms, lr=2.72e-06
2024-03-22 10:28:34,302 - logger.py:50 - Epoch: [132][499/500] loss: 3.50864, MAE: 0.17959, time/step=1106ms, lr=2.72e-06
2024-03-22 10:29:36,179 - logger.py:50 - Epoch: [132] train loss: 3.50864, train MAE: 0.17959,val loss: 3.16735, val MAE: 0.17471,test loss: 3.18094, test MAE: 0.18089,Time: 614.98s
2024-03-22 10:29:36,179 - logger.py:50 - Best -- epoch=130, train loss: 3.50873, val loss: 3.16678, test loss: 3.18070

2024-03-22 10:30:38,822 - logger.py:50 - Epoch: [132]EMA val MAE: 0.17158, EMA test MAE: 0.17787, Time: 677.63s
2024-03-22 10:30:38,822 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 10:30:40,003 - logger.py:50 - Epoch: [133][0/500] loss: 3.32703, MAE: 0.19652, time/step=1178ms, lr=2.54e-06
2024-03-22 10:31:35,898 - logger.py:50 - Epoch: [133][50/500] loss: 5.42867, MAE: 0.20734, time/step=1119ms, lr=2.54e-06
2024-03-22 10:32:30,648 - logger.py:50 - Epoch: [133][100/500] loss: 4.81937, MAE: 0.20202, time/step=1107ms, lr=2.54e-06
2024-03-22 10:33:25,475 - logger.py:50 - Epoch: [133][150/500] loss: 4.26886, MAE: 0.19372, time/step=1104ms, lr=2.54e-06
2024-03-22 10:34:21,204 - logger.py:50 - Epoch: [133][200/500] loss: 4.00449, MAE: 0.18994, time/step=1106ms, lr=2.54e-06
2024-03-22 10:35:14,628 - logger.py:50 - Epoch: [133][250/500] loss: 3.84090, MAE: 0.18723, time/step=1099ms, lr=2.54e-06
2024-03-22 10:36:10,288 - logger.py:50 - Epoch: [133][300/500] loss: 3.73338, MAE: 0.18499, time/step=1101ms, lr=2.54e-06
2024-03-22 10:37:04,727 - logger.py:50 - Epoch: [133][350/500] loss: 3.65650, MAE: 0.18434, time/step=1099ms, lr=2.54e-06
2024-03-22 10:37:58,519 - logger.py:50 - Epoch: [133][400/500] loss: 3.59550, MAE: 0.18304, time/step=1096ms, lr=2.54e-06
2024-03-22 10:38:53,216 - logger.py:50 - Epoch: [133][450/500] loss: 3.54567, MAE: 0.18134, time/step=1096ms, lr=2.54e-06
2024-03-22 10:39:47,200 - logger.py:50 - Epoch: [133][499/500] loss: 3.50854, MAE: 0.18081, time/step=1097ms, lr=2.54e-06
2024-03-22 10:40:48,747 - logger.py:50 - Epoch: [133] train loss: 3.50854, train MAE: 0.18081,val loss: 3.16676, val MAE: 0.17014,test loss: 3.18047, test MAE: 0.17630,Time: 609.93s
2024-03-22 10:40:48,748 - logger.py:50 - Best -- epoch=133, train loss: 3.50854, val loss: 3.16676, test loss: 3.18047

2024-03-22 10:41:50,664 - logger.py:50 - Epoch: [133]EMA val MAE: 0.17155, EMA test MAE: 0.17783, Time: 671.84s
2024-03-22 10:41:50,664 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 10:41:51,868 - logger.py:50 - Epoch: [134][0/500] loss: 3.31059, MAE: 0.20759, time/step=1201ms, lr=2.36e-06
2024-03-22 10:42:48,789 - logger.py:50 - Epoch: [134][50/500] loss: 3.18575, MAE: 0.17369, time/step=1140ms, lr=2.36e-06
2024-03-22 10:43:43,347 - logger.py:50 - Epoch: [134][100/500] loss: 3.18123, MAE: 0.17450, time/step=1116ms, lr=2.36e-06
2024-03-22 10:44:38,180 - logger.py:50 - Epoch: [134][150/500] loss: 3.51294, MAE: 0.17993, time/step=1109ms, lr=2.36e-06
2024-03-22 10:45:32,490 - logger.py:50 - Epoch: [134][200/500] loss: 3.98322, MAE: 0.18405, time/step=1104ms, lr=2.36e-06
2024-03-22 10:46:26,925 - logger.py:50 - Epoch: [134][250/500] loss: 3.82166, MAE: 0.18210, time/step=1101ms, lr=2.36e-06
2024-03-22 10:47:20,861 - logger.py:50 - Epoch: [134][300/500] loss: 3.71955, MAE: 0.18138, time/step=1097ms, lr=2.36e-06
2024-03-22 10:48:14,065 - logger.py:50 - Epoch: [134][350/500] loss: 3.64400, MAE: 0.18034, time/step=1092ms, lr=2.36e-06
2024-03-22 10:49:08,015 - logger.py:50 - Epoch: [134][400/500] loss: 3.58836, MAE: 0.18052, time/step=1091ms, lr=2.36e-06
2024-03-22 10:50:00,945 - logger.py:50 - Epoch: [134][450/500] loss: 3.54369, MAE: 0.18013, time/step=1087ms, lr=2.36e-06
2024-03-22 10:50:52,689 - logger.py:50 - Epoch: [134][499/500] loss: 3.50857, MAE: 0.17989, time/step=1084ms, lr=2.36e-06
2024-03-22 10:51:53,391 - logger.py:50 - Epoch: [134] train loss: 3.50857, train MAE: 0.17989,val loss: 3.16651, val MAE: 0.17098,test loss: 3.18037, test MAE: 0.17722,Time: 602.73s
2024-03-22 10:51:53,391 - logger.py:50 - Best -- epoch=134, train loss: 3.50857, val loss: 3.16651, test loss: 3.18037

2024-03-22 10:52:52,940 - logger.py:50 - Epoch: [134]EMA val MAE: 0.17147, EMA test MAE: 0.17775, Time: 662.28s
2024-03-22 10:52:52,940 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 10:52:53,609 - logger.py:50 - Epoch: [135][0/500] loss: 3.15326, MAE: 0.15703, time/step=667ms, lr=2.20e-06
2024-03-22 10:53:48,310 - logger.py:50 - Epoch: [135][50/500] loss: 4.16253, MAE: 0.19413, time/step=1086ms, lr=2.20e-06
2024-03-22 10:54:42,218 - logger.py:50 - Epoch: [135][100/500] loss: 3.67402, MAE: 0.18341, time/step=1082ms, lr=2.20e-06
2024-03-22 10:55:36,417 - logger.py:50 - Epoch: [135][150/500] loss: 3.51103, MAE: 0.18125, time/step=1083ms, lr=2.20e-06
2024-03-22 10:56:29,331 - logger.py:50 - Epoch: [135][200/500] loss: 3.43269, MAE: 0.18026, time/step=1077ms, lr=2.20e-06
2024-03-22 10:57:22,750 - logger.py:50 - Epoch: [135][250/500] loss: 3.38395, MAE: 0.17903, time/step=1075ms, lr=2.20e-06
2024-03-22 10:58:16,872 - logger.py:50 - Epoch: [135][300/500] loss: 3.71702, MAE: 0.18208, time/step=1076ms, lr=2.20e-06
2024-03-22 10:59:09,607 - logger.py:50 - Epoch: [135][350/500] loss: 3.64079, MAE: 0.18111, time/step=1073ms, lr=2.20e-06
2024-03-22 11:00:03,031 - logger.py:50 - Epoch: [135][400/500] loss: 3.58354, MAE: 0.18048, time/step=1073ms, lr=2.20e-06
2024-03-22 11:00:55,812 - logger.py:50 - Epoch: [135][450/500] loss: 3.54280, MAE: 0.18047, time/step=1071ms, lr=2.20e-06
2024-03-22 11:01:47,912 - logger.py:50 - Epoch: [135][499/500] loss: 3.50829, MAE: 0.17978, time/step=1070ms, lr=2.20e-06
2024-03-22 11:02:47,997 - logger.py:50 - Epoch: [135] train loss: 3.50829, train MAE: 0.17978,val loss: 3.16709, val MAE: 0.17082,test loss: 3.18043, test MAE: 0.17699,Time: 595.06s
2024-03-22 11:02:47,998 - logger.py:50 - Best -- epoch=134, train loss: 3.50857, val loss: 3.16651, test loss: 3.18037

2024-03-22 11:03:48,941 - logger.py:50 - Epoch: [135]EMA val MAE: 0.17140, EMA test MAE: 0.17768, Time: 656.00s
2024-03-22 11:03:48,942 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 11:03:49,604 - logger.py:50 - Epoch: [136][0/500] loss: 3.04242, MAE: 0.13621, time/step=660ms, lr=2.05e-06
2024-03-22 11:04:43,123 - logger.py:50 - Epoch: [136][50/500] loss: 3.19835, MAE: 0.17625, time/step=1062ms, lr=2.05e-06
2024-03-22 11:05:36,253 - logger.py:50 - Epoch: [136][100/500] loss: 3.18814, MAE: 0.17555, time/step=1062ms, lr=2.05e-06
2024-03-22 11:06:30,335 - logger.py:50 - Epoch: [136][150/500] loss: 3.18365, MAE: 0.17524, time/step=1069ms, lr=2.05e-06
2024-03-22 11:07:23,353 - logger.py:50 - Epoch: [136][200/500] loss: 3.43540, MAE: 0.17837, time/step=1067ms, lr=2.05e-06
2024-03-22 11:08:18,719 - logger.py:50 - Epoch: [136][250/500] loss: 3.38294, MAE: 0.17810, time/step=1075ms, lr=2.05e-06
2024-03-22 11:09:12,415 - logger.py:50 - Epoch: [136][300/500] loss: 3.34835, MAE: 0.17703, time/step=1075ms, lr=2.05e-06
2024-03-22 11:10:06,431 - logger.py:50 - Epoch: [136][350/500] loss: 3.32431, MAE: 0.17730, time/step=1075ms, lr=2.05e-06
2024-03-22 11:10:59,408 - logger.py:50 - Epoch: [136][400/500] loss: 3.58728, MAE: 0.18034, time/step=1073ms, lr=2.05e-06
2024-03-22 11:11:51,198 - logger.py:50 - Epoch: [136][450/500] loss: 3.54311, MAE: 0.18004, time/step=1069ms, lr=2.05e-06
2024-03-22 11:12:43,482 - logger.py:50 - Epoch: [136][499/500] loss: 3.50839, MAE: 0.17969, time/step=1069ms, lr=2.05e-06
2024-03-22 11:13:44,361 - logger.py:50 - Epoch: [136] train loss: 3.50839, train MAE: 0.17969,val loss: 3.16675, val MAE: 0.17090,test loss: 3.18051, test MAE: 0.17720,Time: 595.42s
2024-03-22 11:13:44,361 - logger.py:50 - Best -- epoch=134, train loss: 3.50857, val loss: 3.16651, test loss: 3.18037

2024-03-22 11:14:44,510 - logger.py:50 - Epoch: [136]EMA val MAE: 0.17133, EMA test MAE: 0.17760, Time: 655.57s
2024-03-22 11:14:44,511 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 11:14:45,683 - logger.py:50 - Epoch: [137][0/500] loss: 3.08124, MAE: 0.14549, time/step=1170ms, lr=1.90e-06
2024-03-22 11:15:38,803 - logger.py:50 - Epoch: [137][50/500] loss: 3.17634, MAE: 0.17137, time/step=1065ms, lr=1.90e-06
2024-03-22 11:16:31,318 - logger.py:50 - Epoch: [137][100/500] loss: 3.17925, MAE: 0.17315, time/step=1057ms, lr=1.90e-06
2024-03-22 11:17:24,232 - logger.py:50 - Epoch: [137][150/500] loss: 3.18850, MAE: 0.17530, time/step=1058ms, lr=1.90e-06
2024-03-22 11:18:18,213 - logger.py:50 - Epoch: [137][200/500] loss: 3.18539, MAE: 0.17545, time/step=1063ms, lr=1.90e-06
2024-03-22 11:19:11,785 - logger.py:50 - Epoch: [137][250/500] loss: 3.18418, MAE: 0.17531, time/step=1065ms, lr=1.90e-06
2024-03-22 11:20:07,772 - logger.py:50 - Epoch: [137][300/500] loss: 3.18214, MAE: 0.17490, time/step=1074ms, lr=1.90e-06
2024-03-22 11:21:03,654 - logger.py:50 - Epoch: [137][350/500] loss: 3.18335, MAE: 0.17503, time/step=1080ms, lr=1.90e-06
2024-03-22 11:22:01,287 - logger.py:50 - Epoch: [137][400/500] loss: 3.31139, MAE: 0.17748, time/step=1089ms, lr=1.90e-06
2024-03-22 11:22:54,970 - logger.py:50 - Epoch: [137][450/500] loss: 3.54349, MAE: 0.17940, time/step=1087ms, lr=1.90e-06
2024-03-22 11:23:48,874 - logger.py:50 - Epoch: [137][499/500] loss: 3.50844, MAE: 0.17942, time/step=1089ms, lr=1.90e-06
2024-03-22 11:24:56,484 - logger.py:50 - Epoch: [137] train loss: 3.50844, train MAE: 0.17942,val loss: 3.16752, val MAE: 0.17262,test loss: 3.18063, test MAE: 0.17877,Time: 611.97s
2024-03-22 11:24:56,484 - logger.py:50 - Best -- epoch=134, train loss: 3.50857, val loss: 3.16651, test loss: 3.18037

2024-03-22 11:26:00,278 - logger.py:50 - Epoch: [137]EMA val MAE: 0.17125, EMA test MAE: 0.17752, Time: 675.77s
2024-03-22 11:26:00,279 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 11:26:01,040 - logger.py:50 - Epoch: [138][0/500] loss: 3.19759, MAE: 0.17631, time/step=759ms, lr=1.77e-06
2024-03-22 11:26:53,789 - logger.py:50 - Epoch: [138][50/500] loss: 3.17579, MAE: 0.17877, time/step=1049ms, lr=1.77e-06
2024-03-22 11:27:51,438 - logger.py:50 - Epoch: [138][100/500] loss: 3.17463, MAE: 0.17941, time/step=1101ms, lr=1.77e-06
2024-03-22 11:28:45,019 - logger.py:50 - Epoch: [138][150/500] loss: 3.92265, MAE: 0.18687, time/step=1091ms, lr=1.77e-06
2024-03-22 11:29:39,354 - logger.py:50 - Epoch: [138][200/500] loss: 3.73587, MAE: 0.18417, time/step=1090ms, lr=1.77e-06
2024-03-22 11:30:32,931 - logger.py:50 - Epoch: [138][250/500] loss: 3.83070, MAE: 0.18542, time/step=1086ms, lr=1.77e-06
2024-03-22 11:31:28,531 - logger.py:50 - Epoch: [138][300/500] loss: 3.71903, MAE: 0.18424, time/step=1091ms, lr=1.77e-06
2024-03-22 11:32:22,789 - logger.py:50 - Epoch: [138][350/500] loss: 3.64287, MAE: 0.18312, time/step=1090ms, lr=1.77e-06
2024-03-22 11:33:16,293 - logger.py:50 - Epoch: [138][400/500] loss: 3.58750, MAE: 0.18263, time/step=1087ms, lr=1.77e-06
2024-03-22 11:34:11,391 - logger.py:50 - Epoch: [138][450/500] loss: 3.54427, MAE: 0.18084, time/step=1089ms, lr=1.77e-06
2024-03-22 11:35:05,304 - logger.py:50 - Epoch: [138][499/500] loss: 3.50837, MAE: 0.18025, time/step=1090ms, lr=1.77e-06
2024-03-22 11:36:07,765 - logger.py:50 - Epoch: [138] train loss: 3.50837, train MAE: 0.18025,val loss: 3.16678, val MAE: 0.17075,test loss: 3.18014, test MAE: 0.17688,Time: 607.49s
2024-03-22 11:36:07,765 - logger.py:50 - Best -- epoch=134, train loss: 3.50857, val loss: 3.16651, test loss: 3.18037

2024-03-22 11:37:08,209 - logger.py:50 - Epoch: [138]EMA val MAE: 0.17123, EMA test MAE: 0.17749, Time: 667.93s
2024-03-22 11:37:08,209 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 11:37:09,376 - logger.py:50 - Epoch: [139][0/500] loss: 3.22040, MAE: 0.18648, time/step=1165ms, lr=1.65e-06
2024-03-22 11:38:04,752 - logger.py:50 - Epoch: [139][50/500] loss: 3.15379, MAE: 0.16669, time/step=1109ms, lr=1.65e-06
2024-03-22 11:38:59,346 - logger.py:50 - Epoch: [139][100/500] loss: 3.16259, MAE: 0.16868, time/step=1100ms, lr=1.65e-06
2024-03-22 11:39:53,846 - logger.py:50 - Epoch: [139][150/500] loss: 3.16573, MAE: 0.16952, time/step=1097ms, lr=1.65e-06
2024-03-22 11:40:47,619 - logger.py:50 - Epoch: [139][200/500] loss: 3.43912, MAE: 0.17639, time/step=1092ms, lr=1.65e-06
2024-03-22 11:41:42,782 - logger.py:50 - Epoch: [139][250/500] loss: 3.38500, MAE: 0.17628, time/step=1094ms, lr=1.65e-06
2024-03-22 11:42:37,600 - logger.py:50 - Epoch: [139][300/500] loss: 3.72251, MAE: 0.18044, time/step=1094ms, lr=1.65e-06
2024-03-22 11:43:32,370 - logger.py:50 - Epoch: [139][350/500] loss: 3.64513, MAE: 0.17991, time/step=1094ms, lr=1.65e-06
2024-03-22 11:44:26,993 - logger.py:50 - Epoch: [139][400/500] loss: 3.58690, MAE: 0.17931, time/step=1094ms, lr=1.65e-06
2024-03-22 11:45:24,768 - logger.py:50 - Epoch: [139][450/500] loss: 3.54203, MAE: 0.17887, time/step=1101ms, lr=1.65e-06
2024-03-22 11:46:23,308 - logger.py:50 - Epoch: [139][499/500] loss: 3.50791, MAE: 0.17968, time/step=1110ms, lr=1.65e-06
2024-03-22 11:47:32,535 - logger.py:50 - Epoch: [139] train loss: 3.50791, train MAE: 0.17968,val loss: 3.16663, val MAE: 0.17075,test loss: 3.18029, test MAE: 0.17693,Time: 624.33s
2024-03-22 11:47:32,535 - logger.py:50 - Best -- epoch=134, train loss: 3.50857, val loss: 3.16651, test loss: 3.18037

2024-03-22 11:48:40,802 - logger.py:50 - Epoch: [139]EMA val MAE: 0.17118, EMA test MAE: 0.17744, Time: 692.59s
2024-03-22 11:48:40,802 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 11:48:42,385 - logger.py:50 - Epoch: [140][0/500] loss: 3.08065, MAE: 0.15750, time/step=1580ms, lr=1.54e-06
2024-03-22 11:49:40,744 - logger.py:50 - Epoch: [140][50/500] loss: 3.16788, MAE: 0.17430, time/step=1175ms, lr=1.54e-06
2024-03-22 11:50:38,329 - logger.py:50 - Epoch: [140][100/500] loss: 3.17182, MAE: 0.17663, time/step=1164ms, lr=1.54e-06
2024-03-22 11:51:34,903 - logger.py:50 - Epoch: [140][150/500] loss: 3.90965, MAE: 0.18353, time/step=1153ms, lr=1.54e-06
2024-03-22 11:52:33,593 - logger.py:50 - Epoch: [140][200/500] loss: 3.73493, MAE: 0.18258, time/step=1158ms, lr=1.54e-06
2024-03-22 11:53:29,858 - logger.py:50 - Epoch: [140][250/500] loss: 3.62864, MAE: 0.18150, time/step=1152ms, lr=1.54e-06
2024-03-22 11:54:29,524 - logger.py:50 - Epoch: [140][300/500] loss: 3.55408, MAE: 0.18020, time/step=1159ms, lr=1.54e-06
2024-03-22 11:55:27,542 - logger.py:50 - Epoch: [140][350/500] loss: 3.49982, MAE: 0.17882, time/step=1159ms, lr=1.54e-06
2024-03-22 11:56:24,805 - logger.py:50 - Epoch: [140][400/500] loss: 3.58883, MAE: 0.18096, time/step=1157ms, lr=1.54e-06
2024-03-22 11:57:23,152 - logger.py:50 - Epoch: [140][450/500] loss: 3.54450, MAE: 0.18043, time/step=1158ms, lr=1.54e-06
2024-03-22 11:58:19,163 - logger.py:50 - Epoch: [140][499/500] loss: 3.50823, MAE: 0.17973, time/step=1157ms, lr=1.54e-06
2024-03-22 11:59:27,019 - logger.py:50 - Epoch: [140] train loss: 3.50823, train MAE: 0.17973,val loss: 3.16651, val MAE: 0.17012,test loss: 3.18012, test MAE: 0.17630,Time: 646.22s
2024-03-22 11:59:27,019 - logger.py:50 - Best -- epoch=140, train loss: 3.50823, val loss: 3.16651, test loss: 3.18012

2024-03-22 12:00:32,327 - logger.py:50 - Epoch: [140]EMA val MAE: 0.17114, EMA test MAE: 0.17740, Time: 711.52s
2024-03-22 12:00:32,327 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 12:00:33,485 - logger.py:50 - Epoch: [141][0/500] loss: 3.08584, MAE: 0.15198, time/step=1155ms, lr=1.43e-06
2024-03-22 12:01:31,491 - logger.py:50 - Epoch: [141][50/500] loss: 3.17793, MAE: 0.17295, time/step=1160ms, lr=1.43e-06
2024-03-22 12:02:24,604 - logger.py:50 - Epoch: [141][100/500] loss: 3.17651, MAE: 0.17317, time/step=1112ms, lr=1.43e-06
2024-03-22 12:03:19,271 - logger.py:50 - Epoch: [141][150/500] loss: 3.17781, MAE: 0.17529, time/step=1106ms, lr=1.43e-06
2024-03-22 12:04:12,445 - logger.py:50 - Epoch: [141][200/500] loss: 3.17727, MAE: 0.17410, time/step=1095ms, lr=1.43e-06
2024-03-22 12:05:05,490 - logger.py:50 - Epoch: [141][250/500] loss: 3.18027, MAE: 0.17531, time/step=1088ms, lr=1.43e-06
2024-03-22 12:05:59,733 - logger.py:50 - Epoch: [141][300/500] loss: 3.72525, MAE: 0.18236, time/step=1088ms, lr=1.43e-06
2024-03-22 12:06:54,750 - logger.py:50 - Epoch: [141][350/500] loss: 3.64428, MAE: 0.18138, time/step=1090ms, lr=1.43e-06
2024-03-22 12:07:48,166 - logger.py:50 - Epoch: [141][400/500] loss: 3.58636, MAE: 0.18001, time/step=1087ms, lr=1.43e-06
2024-03-22 12:08:40,730 - logger.py:50 - Epoch: [141][450/500] loss: 3.54612, MAE: 0.18017, time/step=1083ms, lr=1.43e-06
2024-03-22 12:09:34,117 - logger.py:50 - Epoch: [141][499/500] loss: 3.50809, MAE: 0.17976, time/step=1084ms, lr=1.43e-06
2024-03-22 12:10:34,258 - logger.py:50 - Epoch: [141] train loss: 3.50809, train MAE: 0.17976,val loss: 3.16648, val MAE: 0.17035,test loss: 3.18008, test MAE: 0.17652,Time: 601.93s
2024-03-22 12:10:34,259 - logger.py:50 - Best -- epoch=141, train loss: 3.50809, val loss: 3.16648, test loss: 3.18008

2024-03-22 12:11:34,547 - logger.py:50 - Epoch: [141]EMA val MAE: 0.17110, EMA test MAE: 0.17734, Time: 662.22s
2024-03-22 12:11:34,547 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 12:11:35,919 - logger.py:50 - Epoch: [142][0/500] loss: 3.11798, MAE: 0.17306, time/step=1369ms, lr=1.34e-06
2024-03-22 12:12:28,699 - logger.py:50 - Epoch: [142][50/500] loss: 3.19993, MAE: 0.18147, time/step=1062ms, lr=1.34e-06
2024-03-22 12:13:22,851 - logger.py:50 - Epoch: [142][100/500] loss: 3.19736, MAE: 0.18139, time/step=1072ms, lr=1.34e-06
2024-03-22 12:14:15,678 - logger.py:50 - Epoch: [142][150/500] loss: 3.53058, MAE: 0.18595, time/step=1067ms, lr=1.34e-06
2024-03-22 12:15:09,402 - logger.py:50 - Epoch: [142][200/500] loss: 3.44605, MAE: 0.18484, time/step=1069ms, lr=1.34e-06
2024-03-22 12:16:03,007 - logger.py:50 - Epoch: [142][250/500] loss: 3.39642, MAE: 0.18345, time/step=1070ms, lr=1.34e-06
2024-03-22 12:16:56,564 - logger.py:50 - Epoch: [142][300/500] loss: 3.36294, MAE: 0.18168, time/step=1070ms, lr=1.34e-06
2024-03-22 12:17:50,022 - logger.py:50 - Epoch: [142][350/500] loss: 3.65023, MAE: 0.18294, time/step=1070ms, lr=1.34e-06
2024-03-22 12:18:44,204 - logger.py:50 - Epoch: [142][400/500] loss: 3.59002, MAE: 0.18164, time/step=1071ms, lr=1.34e-06
2024-03-22 12:19:36,097 - logger.py:50 - Epoch: [142][450/500] loss: 3.54407, MAE: 0.18060, time/step=1068ms, lr=1.34e-06
2024-03-22 12:20:28,747 - logger.py:50 - Epoch: [142][499/500] loss: 3.50808, MAE: 0.17976, time/step=1068ms, lr=1.34e-06
2024-03-22 12:21:28,775 - logger.py:50 - Epoch: [142] train loss: 3.50808, train MAE: 0.17976,val loss: 3.16641, val MAE: 0.17028,test loss: 3.18026, test MAE: 0.17648,Time: 594.23s
2024-03-22 12:21:28,775 - logger.py:50 - Best -- epoch=142, train loss: 3.50808, val loss: 3.16641, test loss: 3.18026

2024-03-22 12:22:29,031 - logger.py:50 - Epoch: [142]EMA val MAE: 0.17107, EMA test MAE: 0.17732, Time: 654.48s
2024-03-22 12:22:29,031 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 12:22:30,197 - logger.py:50 - Epoch: [143][0/500] loss: 3.16424, MAE: 0.16036, time/step=1163ms, lr=1.26e-06
2024-03-22 12:23:23,619 - logger.py:50 - Epoch: [143][50/500] loss: 6.43626, MAE: 0.21686, time/step=1070ms, lr=1.26e-06
2024-03-22 12:24:19,782 - logger.py:50 - Epoch: [143][100/500] loss: 4.83018, MAE: 0.19675, time/step=1097ms, lr=1.26e-06
2024-03-22 12:25:17,718 - logger.py:50 - Epoch: [143][150/500] loss: 4.27224, MAE: 0.18953, time/step=1117ms, lr=1.26e-06
2024-03-22 12:26:16,118 - logger.py:50 - Epoch: [143][200/500] loss: 3.99356, MAE: 0.18592, time/step=1130ms, lr=1.26e-06
2024-03-22 12:27:15,957 - logger.py:50 - Epoch: [143][250/500] loss: 3.83080, MAE: 0.18424, time/step=1143ms, lr=1.26e-06
2024-03-22 12:28:13,839 - logger.py:50 - Epoch: [143][300/500] loss: 3.71849, MAE: 0.18230, time/step=1146ms, lr=1.26e-06
2024-03-22 12:29:08,320 - logger.py:50 - Epoch: [143][350/500] loss: 3.64595, MAE: 0.18185, time/step=1138ms, lr=1.26e-06
2024-03-22 12:30:01,836 - logger.py:50 - Epoch: [143][400/500] loss: 3.58761, MAE: 0.18096, time/step=1129ms, lr=1.26e-06
2024-03-22 12:30:58,522 - logger.py:50 - Epoch: [143][450/500] loss: 3.54279, MAE: 0.18027, time/step=1130ms, lr=1.26e-06
2024-03-22 12:31:52,024 - logger.py:50 - Epoch: [143][499/500] loss: 3.50810, MAE: 0.17970, time/step=1126ms, lr=1.26e-06
2024-03-22 12:32:54,454 - logger.py:50 - Epoch: [143] train loss: 3.50810, train MAE: 0.17970,val loss: 3.16650, val MAE: 0.17069,test loss: 3.18005, test MAE: 0.17686,Time: 625.42s
2024-03-22 12:32:54,454 - logger.py:50 - Best -- epoch=142, train loss: 3.50808, val loss: 3.16641, test loss: 3.18026

2024-03-22 12:33:55,811 - logger.py:50 - Epoch: [143]EMA val MAE: 0.17104, EMA test MAE: 0.17728, Time: 686.78s
2024-03-22 12:33:55,811 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 12:33:56,601 - logger.py:50 - Epoch: [144][0/500] loss: 3.20655, MAE: 0.18458, time/step=788ms, lr=1.19e-06
2024-03-22 12:34:51,013 - logger.py:50 - Epoch: [144][50/500] loss: 4.19418, MAE: 0.19284, time/step=1082ms, lr=1.19e-06
2024-03-22 12:35:46,692 - logger.py:50 - Epoch: [144][100/500] loss: 3.70279, MAE: 0.18248, time/step=1098ms, lr=1.19e-06
2024-03-22 12:36:41,317 - logger.py:50 - Epoch: [144][150/500] loss: 3.52768, MAE: 0.17957, time/step=1096ms, lr=1.19e-06
2024-03-22 12:37:34,556 - logger.py:50 - Epoch: [144][200/500] loss: 3.44959, MAE: 0.17864, time/step=1088ms, lr=1.19e-06
2024-03-22 12:38:30,208 - logger.py:50 - Epoch: [144][250/500] loss: 3.84481, MAE: 0.18295, time/step=1093ms, lr=1.19e-06
2024-03-22 12:39:25,921 - logger.py:50 - Epoch: [144][300/500] loss: 3.73563, MAE: 0.18306, time/step=1097ms, lr=1.19e-06
2024-03-22 12:40:21,484 - logger.py:50 - Epoch: [144][350/500] loss: 3.65514, MAE: 0.18156, time/step=1099ms, lr=1.19e-06
2024-03-22 12:41:16,738 - logger.py:50 - Epoch: [144][400/500] loss: 3.59234, MAE: 0.18047, time/step=1100ms, lr=1.19e-06
2024-03-22 12:42:10,402 - logger.py:50 - Epoch: [144][450/500] loss: 3.54427, MAE: 0.17986, time/step=1097ms, lr=1.19e-06
2024-03-22 12:43:03,007 - logger.py:50 - Epoch: [144][499/500] loss: 3.50816, MAE: 0.17974, time/step=1094ms, lr=1.19e-06
2024-03-22 12:44:03,101 - logger.py:50 - Epoch: [144] train loss: 3.50816, train MAE: 0.17974,val loss: 3.16655, val MAE: 0.17052,test loss: 3.17996, test MAE: 0.17666,Time: 607.29s
2024-03-22 12:44:03,101 - logger.py:50 - Best -- epoch=142, train loss: 3.50808, val loss: 3.16641, test loss: 3.18026

2024-03-22 12:45:02,272 - logger.py:50 - Epoch: [144]EMA val MAE: 0.17102, EMA test MAE: 0.17726, Time: 666.46s
2024-03-22 12:45:02,272 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 12:45:03,549 - logger.py:50 - Epoch: [145][0/500] loss: 3.27871, MAE: 0.20802, time/step=1275ms, lr=1.13e-06
2024-03-22 12:45:57,753 - logger.py:50 - Epoch: [145][50/500] loss: 3.15876, MAE: 0.16956, time/step=1088ms, lr=1.13e-06
2024-03-22 12:46:51,280 - logger.py:50 - Epoch: [145][100/500] loss: 3.16553, MAE: 0.17200, time/step=1079ms, lr=1.13e-06
2024-03-22 12:47:43,695 - logger.py:50 - Epoch: [145][150/500] loss: 3.17616, MAE: 0.17396, time/step=1069ms, lr=1.13e-06
2024-03-22 12:48:37,537 - logger.py:50 - Epoch: [145][200/500] loss: 3.17259, MAE: 0.17366, time/step=1071ms, lr=1.13e-06
2024-03-22 12:49:29,012 - logger.py:50 - Epoch: [145][250/500] loss: 3.61719, MAE: 0.17790, time/step=1063ms, lr=1.13e-06
2024-03-22 12:50:24,413 - logger.py:50 - Epoch: [145][300/500] loss: 3.54124, MAE: 0.17779, time/step=1070ms, lr=1.13e-06
2024-03-22 12:51:18,888 - logger.py:50 - Epoch: [145][350/500] loss: 3.63744, MAE: 0.18042, time/step=1073ms, lr=1.13e-06
2024-03-22 12:52:12,433 - logger.py:50 - Epoch: [145][400/500] loss: 3.58436, MAE: 0.18028, time/step=1073ms, lr=1.13e-06
2024-03-22 12:53:04,746 - logger.py:50 - Epoch: [145][450/500] loss: 3.54154, MAE: 0.18012, time/step=1070ms, lr=1.13e-06
2024-03-22 12:53:57,619 - logger.py:50 - Epoch: [145][499/500] loss: 3.50809, MAE: 0.17970, time/step=1071ms, lr=1.13e-06
2024-03-22 12:54:57,482 - logger.py:50 - Epoch: [145] train loss: 3.50809, train MAE: 0.17970,val loss: 3.16669, val MAE: 0.17061,test loss: 3.17997, test MAE: 0.17675,Time: 595.21s
2024-03-22 12:54:57,483 - logger.py:50 - Best -- epoch=142, train loss: 3.50808, val loss: 3.16641, test loss: 3.18026

2024-03-22 12:55:56,956 - logger.py:50 - Epoch: [145]EMA val MAE: 0.17099, EMA test MAE: 0.17723, Time: 654.68s
2024-03-22 12:55:56,957 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 12:55:58,117 - logger.py:50 - Epoch: [146][0/500] loss: 3.14177, MAE: 0.17210, time/step=1158ms, lr=1.09e-06
2024-03-22 12:56:51,741 - logger.py:50 - Epoch: [146][50/500] loss: 4.21449, MAE: 0.19818, time/step=1074ms, lr=1.09e-06
2024-03-22 12:57:45,409 - logger.py:50 - Epoch: [146][100/500] loss: 3.71433, MAE: 0.18494, time/step=1074ms, lr=1.09e-06
2024-03-22 12:58:38,927 - logger.py:50 - Epoch: [146][150/500] loss: 3.53844, MAE: 0.18253, time/step=1073ms, lr=1.09e-06
2024-03-22 12:59:32,977 - logger.py:50 - Epoch: [146][200/500] loss: 3.44711, MAE: 0.18013, time/step=1075ms, lr=1.09e-06
2024-03-22 13:00:26,074 - logger.py:50 - Epoch: [146][250/500] loss: 3.39732, MAE: 0.18041, time/step=1072ms, lr=1.09e-06
2024-03-22 13:01:19,659 - logger.py:50 - Epoch: [146][300/500] loss: 3.36041, MAE: 0.17949, time/step=1072ms, lr=1.09e-06
2024-03-22 13:02:13,472 - logger.py:50 - Epoch: [146][350/500] loss: 3.33266, MAE: 0.17849, time/step=1073ms, lr=1.09e-06
2024-03-22 13:03:07,441 - logger.py:50 - Epoch: [146][400/500] loss: 3.31295, MAE: 0.17791, time/step=1074ms, lr=1.09e-06
2024-03-22 13:04:01,236 - logger.py:50 - Epoch: [146][450/500] loss: 3.54392, MAE: 0.18010, time/step=1074ms, lr=1.09e-06
2024-03-22 13:04:53,735 - logger.py:50 - Epoch: [146][499/500] loss: 3.50800, MAE: 0.17960, time/step=1074ms, lr=1.09e-06
2024-03-22 13:05:53,317 - logger.py:50 - Epoch: [146] train loss: 3.50800, train MAE: 0.17960,val loss: 3.16650, val MAE: 0.17095,test loss: 3.18007, test MAE: 0.17713,Time: 596.36s
2024-03-22 13:05:53,317 - logger.py:50 - Best -- epoch=142, train loss: 3.50808, val loss: 3.16641, test loss: 3.18026

2024-03-22 13:06:53,034 - logger.py:50 - Epoch: [146]EMA val MAE: 0.17097, EMA test MAE: 0.17720, Time: 656.08s
2024-03-22 13:06:53,034 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 13:06:54,342 - logger.py:50 - Epoch: [147][0/500] loss: 3.16620, MAE: 0.18448, time/step=1305ms, lr=1.05e-06
2024-03-22 13:07:47,781 - logger.py:50 - Epoch: [147][50/500] loss: 3.20399, MAE: 0.17677, time/step=1073ms, lr=1.05e-06
2024-03-22 13:08:40,892 - logger.py:50 - Epoch: [147][100/500] loss: 3.19616, MAE: 0.17450, time/step=1068ms, lr=1.05e-06
2024-03-22 13:09:35,055 - logger.py:50 - Epoch: [147][150/500] loss: 3.19443, MAE: 0.17655, time/step=1073ms, lr=1.05e-06
2024-03-22 13:10:29,047 - logger.py:50 - Epoch: [147][200/500] loss: 3.19264, MAE: 0.17707, time/step=1075ms, lr=1.05e-06
2024-03-22 13:11:22,630 - logger.py:50 - Epoch: [147][250/500] loss: 3.63089, MAE: 0.18003, time/step=1074ms, lr=1.05e-06
2024-03-22 13:12:15,120 - logger.py:50 - Epoch: [147][300/500] loss: 3.55302, MAE: 0.17878, time/step=1070ms, lr=1.05e-06
2024-03-22 13:13:08,418 - logger.py:50 - Epoch: [147][350/500] loss: 3.49649, MAE: 0.17804, time/step=1069ms, lr=1.05e-06
2024-03-22 13:14:01,097 - logger.py:50 - Epoch: [147][400/500] loss: 3.45752, MAE: 0.17785, time/step=1067ms, lr=1.05e-06
2024-03-22 13:14:55,755 - logger.py:50 - Epoch: [147][450/500] loss: 3.54210, MAE: 0.18006, time/step=1070ms, lr=1.05e-06
2024-03-22 13:15:47,633 - logger.py:50 - Epoch: [147][499/500] loss: 3.50799, MAE: 0.17955, time/step=1069ms, lr=1.05e-06
2024-03-22 13:16:47,542 - logger.py:50 - Epoch: [147] train loss: 3.50799, train MAE: 0.17955,val loss: 3.16654, val MAE: 0.17113,test loss: 3.18002, test MAE: 0.17728,Time: 594.51s
2024-03-22 13:16:47,542 - logger.py:50 - Best -- epoch=142, train loss: 3.50808, val loss: 3.16641, test loss: 3.18026

2024-03-22 13:17:46,485 - logger.py:50 - Epoch: [147]EMA val MAE: 0.17094, EMA test MAE: 0.17717, Time: 653.45s
2024-03-22 13:17:46,485 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 13:17:47,246 - logger.py:50 - Epoch: [148][0/500] loss: 3.22552, MAE: 0.17707, time/step=758ms, lr=1.02e-06
2024-03-22 13:18:41,147 - logger.py:50 - Epoch: [148][50/500] loss: 3.18352, MAE: 0.17190, time/step=1072ms, lr=1.02e-06
2024-03-22 13:19:34,049 - logger.py:50 - Epoch: [148][100/500] loss: 3.18231, MAE: 0.17473, time/step=1065ms, lr=1.02e-06
2024-03-22 13:20:27,223 - logger.py:50 - Epoch: [148][150/500] loss: 3.18799, MAE: 0.17539, time/step=1064ms, lr=1.02e-06
2024-03-22 13:21:20,267 - logger.py:50 - Epoch: [148][200/500] loss: 3.73882, MAE: 0.18086, time/step=1064ms, lr=1.02e-06
2024-03-22 13:22:13,253 - logger.py:50 - Epoch: [148][250/500] loss: 3.83943, MAE: 0.18397, time/step=1063ms, lr=1.02e-06
2024-03-22 13:23:07,421 - logger.py:50 - Epoch: [148][300/500] loss: 3.72975, MAE: 0.18332, time/step=1066ms, lr=1.02e-06
2024-03-22 13:24:00,748 - logger.py:50 - Epoch: [148][350/500] loss: 3.65038, MAE: 0.18190, time/step=1066ms, lr=1.02e-06
2024-03-22 13:24:54,112 - logger.py:50 - Epoch: [148][400/500] loss: 3.58951, MAE: 0.18095, time/step=1066ms, lr=1.02e-06
2024-03-22 13:25:48,390 - logger.py:50 - Epoch: [148][450/500] loss: 3.54372, MAE: 0.18045, time/step=1069ms, lr=1.02e-06
2024-03-22 13:26:40,947 - logger.py:50 - Epoch: [148][499/500] loss: 3.50796, MAE: 0.17991, time/step=1069ms, lr=1.02e-06
2024-03-22 13:27:41,227 - logger.py:50 - Epoch: [148] train loss: 3.50796, train MAE: 0.17991,val loss: 3.16651, val MAE: 0.17031,test loss: 3.18011, test MAE: 0.17648,Time: 594.74s
2024-03-22 13:27:41,228 - logger.py:50 - Best -- epoch=142, train loss: 3.50808, val loss: 3.16641, test loss: 3.18026

2024-03-22 13:28:41,635 - logger.py:50 - Epoch: [148]EMA val MAE: 0.17092, EMA test MAE: 0.17716, Time: 655.15s
2024-03-22 13:28:41,635 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf

2024-03-22 13:28:42,830 - logger.py:50 - Epoch: [149][0/500] loss: 3.08420, MAE: 0.17017, time/step=1192ms, lr=1.01e-06
2024-03-22 13:29:37,822 - logger.py:50 - Epoch: [149][50/500] loss: 3.17088, MAE: 0.17759, time/step=1102ms, lr=1.01e-06
2024-03-22 13:30:31,874 - logger.py:50 - Epoch: [149][100/500] loss: 3.16412, MAE: 0.17568, time/step=1091ms, lr=1.01e-06
2024-03-22 13:31:27,122 - logger.py:50 - Epoch: [149][150/500] loss: 3.17255, MAE: 0.17542, time/step=1096ms, lr=1.01e-06
2024-03-22 13:32:22,255 - logger.py:50 - Epoch: [149][200/500] loss: 3.72075, MAE: 0.17993, time/step=1098ms, lr=1.01e-06
2024-03-22 13:33:17,095 - logger.py:50 - Epoch: [149][250/500] loss: 3.61268, MAE: 0.17847, time/step=1097ms, lr=1.01e-06
2024-03-22 13:34:12,247 - logger.py:50 - Epoch: [149][300/500] loss: 3.71093, MAE: 0.18069, time/step=1098ms, lr=1.01e-06
2024-03-22 13:35:07,319 - logger.py:50 - Epoch: [149][350/500] loss: 3.63679, MAE: 0.18066, time/step=1099ms, lr=1.01e-06
2024-03-22 13:36:03,013 - logger.py:50 - Epoch: [149][400/500] loss: 3.58748, MAE: 0.18062, time/step=1101ms, lr=1.01e-06
2024-03-22 13:36:56,715 - logger.py:50 - Epoch: [149][450/500] loss: 3.54506, MAE: 0.18024, time/step=1098ms, lr=1.01e-06
2024-03-22 13:37:50,864 - logger.py:50 - Epoch: [149][499/500] loss: 3.50808, MAE: 0.17958, time/step=1098ms, lr=1.01e-06
2024-03-22 13:38:53,365 - logger.py:50 - Epoch: [149] train loss: 3.50808, train MAE: 0.17958,val loss: 3.16664, val MAE: 0.17055,test loss: 3.18009, test MAE: 0.17671,Time: 611.73s
2024-03-22 13:38:53,365 - logger.py:50 - Best -- epoch=142, train loss: 3.50808, val loss: 3.16641, test loss: 3.18026

2024-03-22 13:39:54,435 - logger.py:50 - Epoch: [149]EMA val MAE: 0.17091, EMA test MAE: 0.17714, Time: 672.80s
2024-03-22 13:39:54,435 - logger.py:50 - Best EMA -- epoch=0, val MAE: 0.00000, test MAE: inf


2024-05-08 22:18:41,161 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=4, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-05-08 22:19:56,025 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-05-08 22:19:56,386 - logger.py:50 - Number of params: 2978805
2024-05-08 22:20:00,542 - logger.py:50 - Epoch: [0][0/2000] loss: 3.34321, MAE: 0.64035, time/step=4148ms, lr=1.00e-06
2024-05-08 22:21:07,636 - logger.py:50 - Epoch: [0][50/2000] loss: 2.28171, MAE: 0.54578, time/step=1397ms, lr=1.00e-06
2024-05-08 22:22:08,619 - logger.py:50 - Epoch: [0][100/2000] loss: 2.30226, MAE: 0.52915, time/step=1309ms, lr=1.00e-06
2024-05-08 22:23:07,458 - logger.py:50 - Epoch: [0][150/2000] loss: 2.10048, MAE: 0.51122, time/step=1265ms, lr=1.00e-06
2024-05-08 22:24:02,809 - logger.py:50 - Epoch: [0][200/2000] loss: 3.86757, MAE: 0.53511, time/step=1226ms, lr=1.00e-06
2024-05-08 22:25:01,479 - logger.py:50 - Epoch: [0][250/2000] loss: 3.49610, MAE: 0.51707, time/step=1215ms, lr=1.00e-06
2024-05-08 22:25:58,744 - logger.py:50 - Epoch: [0][300/2000] loss: 3.17386, MAE: 0.49805, time/step=1204ms, lr=1.00e-06
2024-05-08 22:26:55,663 - logger.py:50 - Epoch: [0][350/2000] loss: 2.95580, MAE: 0.48409, time/step=1194ms, lr=1.00e-06
2024-05-08 22:27:59,907 - logger.py:50 - Epoch: [0][400/2000] loss: 2.77104, MAE: 0.47443, time/step=1206ms, lr=1.00e-06
2024-05-08 22:28:58,298 - logger.py:50 - Epoch: [0][450/2000] loss: 2.64329, MAE: 0.46577, time/step=1202ms, lr=1.00e-06
2024-05-08 22:30:02,314 - logger.py:50 - Epoch: [0][500/2000] loss: 2.51921, MAE: 0.45712, time/step=1209ms, lr=1.00e-06
2024-05-08 22:31:00,124 - logger.py:50 - Epoch: [0][550/2000] loss: 2.42404, MAE: 0.45043, time/step=1205ms, lr=1.00e-06
2024-05-08 22:32:02,923 - logger.py:50 - Epoch: [0][600/2000] loss: 2.34302, MAE: 0.44429, time/step=1209ms, lr=1.00e-06
2024-05-08 22:32:58,354 - logger.py:50 - Epoch: [0][650/2000] loss: 2.30033, MAE: 0.44061, time/step=1201ms, lr=1.00e-06
2024-05-08 22:33:55,625 - logger.py:50 - Epoch: [0][700/2000] loss: 2.24665, MAE: 0.43555, time/step=1197ms, lr=1.00e-06
2024-05-08 22:34:54,503 - logger.py:50 - Epoch: [0][750/2000] loss: 2.22482, MAE: 0.43326, time/step=1196ms, lr=1.00e-06
2024-05-08 22:35:50,940 - logger.py:50 - Epoch: [0][800/2000] loss: 2.18853, MAE: 0.43007, time/step=1192ms, lr=1.00e-06
2024-05-08 22:36:44,069 - logger.py:50 - Epoch: [0][850/2000] loss: 2.14527, MAE: 0.42657, time/step=1184ms, lr=1.00e-06
2024-05-08 22:37:36,706 - logger.py:50 - Epoch: [0][900/2000] loss: 2.10543, MAE: 0.42297, time/step=1177ms, lr=1.00e-06
2024-05-08 22:38:32,996 - logger.py:50 - Epoch: [0][950/2000] loss: 2.08769, MAE: 0.42039, time/step=1174ms, lr=1.00e-06
2024-05-08 22:39:27,632 - logger.py:50 - Epoch: [0][1000/2000] loss: 2.06265, MAE: 0.41830, time/step=1170ms, lr=1.00e-06
2024-05-08 22:40:18,560 - logger.py:50 - Epoch: [0][1050/2000] loss: 2.03970, MAE: 0.41627, time/step=1163ms, lr=1.00e-06
2024-05-08 22:41:14,156 - logger.py:50 - Epoch: [0][1100/2000] loss: 2.01777, MAE: 0.41472, time/step=1161ms, lr=1.00e-06
2024-05-08 22:42:07,592 - logger.py:50 - Epoch: [0][1150/2000] loss: 1.99560, MAE: 0.41334, time/step=1157ms, lr=1.00e-06
2024-05-08 22:43:02,542 - logger.py:50 - Epoch: [0][1200/2000] loss: 1.98004, MAE: 0.41115, time/step=1154ms, lr=1.00e-06
2024-05-08 22:43:56,636 - logger.py:50 - Epoch: [0][1250/2000] loss: 1.96398, MAE: 0.40937, time/step=1151ms, lr=1.00e-06
2024-05-08 22:44:51,592 - logger.py:50 - Epoch: [0][1300/2000] loss: 1.93851, MAE: 0.40706, time/step=1149ms, lr=1.00e-06
2024-05-08 22:45:46,367 - logger.py:50 - Epoch: [0][1350/2000] loss: 1.92109, MAE: 0.40505, time/step=1147ms, lr=1.00e-06
2024-05-08 22:46:39,614 - logger.py:50 - Epoch: [0][1400/2000] loss: 1.89910, MAE: 0.40261, time/step=1144ms, lr=1.00e-06
2024-05-08 22:47:31,680 - logger.py:50 - Epoch: [0][1450/2000] loss: 1.88857, MAE: 0.40140, time/step=1141ms, lr=1.00e-06
2024-05-08 22:48:21,955 - logger.py:50 - Epoch: [0][1500/2000] loss: 1.86847, MAE: 0.39907, time/step=1136ms, lr=1.00e-06
2024-05-08 22:49:14,856 - logger.py:50 - Epoch: [0][1550/2000] loss: 1.85180, MAE: 0.39750, time/step=1134ms, lr=1.00e-06
2024-05-08 22:50:10,579 - logger.py:50 - Epoch: [0][1600/2000] loss: 1.83867, MAE: 0.39632, time/step=1133ms, lr=1.00e-06
2024-05-08 22:51:05,189 - logger.py:50 - Epoch: [0][1650/2000] loss: 1.82118, MAE: 0.39465, time/step=1132ms, lr=1.00e-06
2024-05-08 22:51:58,701 - logger.py:50 - Epoch: [0][1700/2000] loss: 1.80453, MAE: 0.39265, time/step=1130ms, lr=1.00e-06
2024-05-08 22:52:50,886 - logger.py:50 - Epoch: [0][1750/2000] loss: 1.79326, MAE: 0.39131, time/step=1128ms, lr=1.00e-06
2024-05-08 22:53:48,982 - logger.py:50 - Epoch: [0][1800/2000] loss: 1.77676, MAE: 0.38943, time/step=1129ms, lr=1.00e-06
2024-05-08 22:54:44,264 - logger.py:50 - Epoch: [0][1850/2000] loss: 1.77811, MAE: 0.38857, time/step=1128ms, lr=1.00e-06
2024-05-08 22:55:43,038 - logger.py:50 - Epoch: [0][1900/2000] loss: 1.77320, MAE: 0.38760, time/step=1129ms, lr=1.00e-06
2024-05-08 22:56:35,685 - logger.py:50 - Epoch: [0][1950/2000] loss: 1.77106, MAE: 0.38669, time/step=1127ms, lr=1.00e-06
2024-05-08 22:57:27,916 - logger.py:50 - Epoch: [0][1999/2000] loss: 1.76278, MAE: 0.38534, time/step=1126ms, lr=1.00e-06
2024-05-08 23:01:38,083 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=4, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-05-08 23:02:49,246 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-05-08 23:02:49,672 - logger.py:50 - Number of params: 2978805
2024-05-08 23:02:54,393 - logger.py:50 - Epoch: [0][0/2000] loss: 3.34321, MAE: 0.64035, time/step=4696ms, lr=1.00e-06
2024-05-08 23:04:03,923 - logger.py:50 - Epoch: [0][50/2000] loss: 2.28171, MAE: 0.54578, time/step=1455ms, lr=1.00e-06
2024-05-08 23:05:04,593 - logger.py:50 - Epoch: [0][100/2000] loss: 2.30226, MAE: 0.52915, time/step=1336ms, lr=1.00e-06
2024-05-08 23:06:08,220 - logger.py:50 - Epoch: [0][150/2000] loss: 2.10048, MAE: 0.51122, time/step=1315ms, lr=1.00e-06
2024-05-08 23:07:06,682 - logger.py:50 - Epoch: [0][200/2000] loss: 3.86757, MAE: 0.53511, time/step=1279ms, lr=1.00e-06
2024-05-08 23:08:01,932 - logger.py:50 - Epoch: [0][250/2000] loss: 3.49610, MAE: 0.51707, time/step=1244ms, lr=1.00e-06
2024-05-08 23:08:59,652 - logger.py:50 - Epoch: [0][300/2000] loss: 3.17386, MAE: 0.49805, time/step=1229ms, lr=1.00e-06
2024-05-08 23:09:52,788 - logger.py:50 - Epoch: [0][350/2000] loss: 2.95580, MAE: 0.48409, time/step=1205ms, lr=1.00e-06
2024-05-08 23:10:49,937 - logger.py:50 - Epoch: [0][400/2000] loss: 2.77104, MAE: 0.47443, time/step=1198ms, lr=1.00e-06
2024-05-08 23:11:46,225 - logger.py:50 - Epoch: [0][450/2000] loss: 2.64329, MAE: 0.46577, time/step=1190ms, lr=1.00e-06
2024-05-08 23:12:43,256 - logger.py:50 - Epoch: [0][500/2000] loss: 2.51921, MAE: 0.45712, time/step=1185ms, lr=1.00e-06
2024-05-08 23:13:38,632 - logger.py:50 - Epoch: [0][550/2000] loss: 2.42404, MAE: 0.45043, time/step=1178ms, lr=1.00e-06
2024-05-08 23:14:33,554 - logger.py:50 - Epoch: [0][600/2000] loss: 2.34302, MAE: 0.44429, time/step=1171ms, lr=1.00e-06
2024-05-08 23:15:29,204 - logger.py:50 - Epoch: [0][650/2000] loss: 2.30033, MAE: 0.44061, time/step=1167ms, lr=1.00e-06
2024-05-08 23:16:22,500 - logger.py:50 - Epoch: [0][700/2000] loss: 2.24665, MAE: 0.43555, time/step=1159ms, lr=1.00e-06
2024-05-08 23:17:17,729 - logger.py:50 - Epoch: [0][750/2000] loss: 2.22482, MAE: 0.43326, time/step=1156ms, lr=1.00e-06
2024-05-08 23:18:13,596 - logger.py:50 - Epoch: [0][800/2000] loss: 2.18853, MAE: 0.43007, time/step=1153ms, lr=1.00e-06
2024-05-08 23:19:06,685 - logger.py:50 - Epoch: [0][850/2000] loss: 2.14527, MAE: 0.42657, time/step=1148ms, lr=1.00e-06
2024-05-08 23:20:00,947 - logger.py:50 - Epoch: [0][900/2000] loss: 2.10543, MAE: 0.42297, time/step=1145ms, lr=1.00e-06
2024-05-08 23:20:56,189 - logger.py:50 - Epoch: [0][950/2000] loss: 2.08769, MAE: 0.42039, time/step=1142ms, lr=1.00e-06
2024-05-08 23:21:52,001 - logger.py:50 - Epoch: [0][1000/2000] loss: 2.06265, MAE: 0.41830, time/step=1141ms, lr=1.00e-06
2024-05-08 23:22:46,251 - logger.py:50 - Epoch: [0][1050/2000] loss: 2.03970, MAE: 0.41627, time/step=1138ms, lr=1.00e-06
2024-05-08 23:23:40,320 - logger.py:50 - Epoch: [0][1100/2000] loss: 2.01777, MAE: 0.41472, time/step=1136ms, lr=1.00e-06
2024-05-08 23:24:32,965 - logger.py:50 - Epoch: [0][1150/2000] loss: 1.99560, MAE: 0.41334, time/step=1132ms, lr=1.00e-06
2024-05-08 23:25:27,627 - logger.py:50 - Epoch: [0][1200/2000] loss: 1.98004, MAE: 0.41115, time/step=1131ms, lr=1.00e-06
2024-05-08 23:26:24,133 - logger.py:50 - Epoch: [0][1250/2000] loss: 1.96398, MAE: 0.40937, time/step=1131ms, lr=1.00e-06
2024-05-08 23:27:20,884 - logger.py:50 - Epoch: [0][1300/2000] loss: 1.93851, MAE: 0.40706, time/step=1131ms, lr=1.00e-06
2024-05-08 23:28:18,457 - logger.py:50 - Epoch: [0][1350/2000] loss: 1.92109, MAE: 0.40505, time/step=1132ms, lr=1.00e-06
2024-06-05 12:57:51,042 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-06-05 12:58:13,775 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-06-05 12:58:14,610 - logger.py:50 - Number of params: 2978805
2024-06-05 12:58:17,146 - logger.py:50 - Epoch: [0][0/500] loss: 2.82960, MAE: 0.58284, time/step=2531ms, lr=1.00e-06
2024-06-05 12:59:33,621 - logger.py:50 - Epoch: [0][50/500] loss: 4.11382, MAE: 0.57985, time/step=1549ms, lr=1.00e-06
2024-06-05 13:00:47,892 - logger.py:50 - Epoch: [0][100/500] loss: 3.10607, MAE: 0.54013, time/step=1518ms, lr=1.00e-06
2024-06-05 13:02:01,202 - logger.py:50 - Epoch: [0][150/500] loss: 2.70097, MAE: 0.51674, time/step=1501ms, lr=1.00e-06
2024-06-05 13:03:15,069 - logger.py:50 - Epoch: [0][200/500] loss: 2.52474, MAE: 0.50202, time/step=1495ms, lr=1.00e-06
2024-06-05 13:04:28,748 - logger.py:50 - Epoch: [0][250/500] loss: 2.38055, MAE: 0.48896, time/step=1491ms, lr=1.00e-06
2024-06-05 13:05:54,553 - logger.py:50 - Epoch: [0][300/500] loss: 2.27506, MAE: 0.47888, time/step=1528ms, lr=1.00e-06
2024-06-05 13:07:32,716 - logger.py:50 - Epoch: [0][350/500] loss: 2.18034, MAE: 0.46778, time/step=1590ms, lr=1.00e-06
2024-06-05 13:09:07,209 - logger.py:50 - Epoch: [0][400/500] loss: 2.09987, MAE: 0.45902, time/step=1627ms, lr=1.00e-06
2024-06-05 13:10:48,302 - logger.py:50 - Epoch: [0][450/500] loss: 2.02648, MAE: 0.45009, time/step=1671ms, lr=1.00e-06
2024-06-05 13:12:27,647 - logger.py:50 - Epoch: [0][499/500] loss: 2.00157, MAE: 0.44417, time/step=1706ms, lr=1.00e-06
2024-06-05 13:13:57,377 - logger.py:50 - Epoch: [0] train loss: 2.00157, train MAE: 0.44417,val loss: 0.38896, val MAE: 0.38896,test loss: 0.39972, test MAE: 0.39972,Time: 942.76s
2024-06-05 13:13:57,377 - logger.py:50 - Best -- epoch=0, train loss: 2.00157, val loss: 0.38896, test loss: 0.39972

2024-06-05 13:13:58,622 - logger.py:50 - Epoch: [1][0/500] loss: 1.84921, MAE: 0.38930, time/step=1242ms, lr=1.08e-05
2024-06-05 13:15:36,129 - logger.py:50 - Epoch: [1][50/500] loss: 1.46165, MAE: 0.36166, time/step=1936ms, lr=1.08e-05
2024-06-05 13:17:18,881 - logger.py:50 - Epoch: [1][100/500] loss: 1.52142, MAE: 0.35852, time/step=1995ms, lr=1.08e-05
2024-06-05 13:18:59,903 - logger.py:50 - Epoch: [1][150/500] loss: 1.47318, MAE: 0.35104, time/step=2003ms, lr=1.08e-05
2024-06-05 13:20:44,147 - logger.py:50 - Epoch: [1][200/500] loss: 1.43566, MAE: 0.34863, time/step=2024ms, lr=1.08e-05
2024-06-05 13:22:27,539 - logger.py:50 - Epoch: [1][250/500] loss: 1.43536, MAE: 0.34673, time/step=2033ms, lr=1.08e-05
2024-06-05 13:24:08,476 - logger.py:50 - Epoch: [1][300/500] loss: 1.43567, MAE: 0.34525, time/step=2030ms, lr=1.08e-05
2024-06-05 13:25:51,217 - logger.py:50 - Epoch: [1][350/500] loss: 1.44018, MAE: 0.34372, time/step=2034ms, lr=1.08e-05
2024-06-05 13:27:30,633 - logger.py:50 - Epoch: [1][400/500] loss: 1.45679, MAE: 0.34337, time/step=2028ms, lr=1.08e-05
2024-06-05 13:29:12,746 - logger.py:50 - Epoch: [1][450/500] loss: 1.43880, MAE: 0.34193, time/step=2030ms, lr=1.08e-05
2024-06-05 13:30:54,165 - logger.py:50 - Epoch: [1][499/500] loss: 1.59516, MAE: 0.34332, time/step=2034ms, lr=1.08e-05
2024-06-05 13:32:24,253 - logger.py:50 - Epoch: [1] train loss: 1.59516, train MAE: 0.34332,val loss: 0.33389, val MAE: 0.33389,test loss: 0.34588, test MAE: 0.34588,Time: 1106.88s
2024-06-05 13:32:24,254 - logger.py:50 - Best -- epoch=1, train loss: 1.59516, val loss: 0.33389, test loss: 0.34588

2024-06-05 13:32:25,932 - logger.py:50 - Epoch: [2][0/500] loss: 1.26267, MAE: 0.32889, time/step=1676ms, lr=2.06e-05
2024-06-05 13:34:00,680 - logger.py:50 - Epoch: [2][50/500] loss: 3.11048, MAE: 0.36236, time/step=1891ms, lr=2.06e-05
2024-06-05 13:35:44,358 - logger.py:50 - Epoch: [2][100/500] loss: 2.19936, MAE: 0.34189, time/step=1981ms, lr=2.06e-05
2024-06-05 13:37:28,595 - logger.py:50 - Epoch: [2][150/500] loss: 1.91562, MAE: 0.33345, time/step=2015ms, lr=2.06e-05
2024-06-05 13:39:07,335 - logger.py:50 - Epoch: [2][200/500] loss: 1.75954, MAE: 0.33119, time/step=2005ms, lr=2.06e-05
2024-06-05 13:40:50,714 - logger.py:50 - Epoch: [2][250/500] loss: 1.70886, MAE: 0.33239, time/step=2018ms, lr=2.06e-05
2024-06-05 13:42:33,542 - logger.py:50 - Epoch: [2][300/500] loss: 1.63526, MAE: 0.32964, time/step=2024ms, lr=2.06e-05
2024-06-05 13:44:15,817 - logger.py:50 - Epoch: [2][350/500] loss: 1.60882, MAE: 0.32847, time/step=2027ms, lr=2.06e-05
2024-06-05 13:45:57,820 - logger.py:50 - Epoch: [2][400/500] loss: 1.57779, MAE: 0.32861, time/step=2029ms, lr=2.06e-05
2024-06-05 13:47:40,070 - logger.py:50 - Epoch: [2][450/500] loss: 1.53954, MAE: 0.32628, time/step=2031ms, lr=2.06e-05
2024-06-05 13:49:21,818 - logger.py:50 - Epoch: [2][499/500] loss: 1.51348, MAE: 0.32560, time/step=2035ms, lr=2.06e-05
2024-06-05 13:50:56,546 - logger.py:50 - Epoch: [2] train loss: 1.51348, train MAE: 0.32560,val loss: 0.32256, val MAE: 0.32256,test loss: 0.33460, test MAE: 0.33460,Time: 1112.29s
2024-06-05 13:50:56,547 - logger.py:50 - Best -- epoch=2, train loss: 1.51348, val loss: 0.32256, test loss: 0.33460

2024-06-05 13:50:57,595 - logger.py:50 - Epoch: [3][0/500] loss: 1.79491, MAE: 0.34624, time/step=1044ms, lr=3.04e-05
2024-06-05 13:52:34,048 - logger.py:50 - Epoch: [3][50/500] loss: 1.43894, MAE: 0.32354, time/step=1912ms, lr=3.04e-05
2024-06-05 13:54:17,330 - logger.py:50 - Epoch: [3][100/500] loss: 1.41078, MAE: 0.32470, time/step=1988ms, lr=3.04e-05
2024-06-05 13:55:58,831 - logger.py:50 - Epoch: [3][150/500] loss: 1.33018, MAE: 0.31743, time/step=2002ms, lr=3.04e-05
2024-06-05 13:57:42,792 - logger.py:50 - Epoch: [3][200/500] loss: 1.36205, MAE: 0.31712, time/step=2021ms, lr=3.04e-05
2024-06-05 13:59:25,623 - logger.py:50 - Epoch: [3][250/500] loss: 1.33844, MAE: 0.31722, time/step=2028ms, lr=3.04e-05
2024-06-05 14:01:07,402 - logger.py:50 - Epoch: [3][300/500] loss: 1.34074, MAE: 0.31680, time/step=2029ms, lr=3.04e-05
2024-06-05 14:02:52,024 - logger.py:50 - Epoch: [3][350/500] loss: 1.32412, MAE: 0.31645, time/step=2038ms, lr=3.04e-05
2024-06-05 14:04:34,048 - logger.py:50 - Epoch: [3][400/500] loss: 1.53598, MAE: 0.31991, time/step=2039ms, lr=3.04e-05
2024-06-05 14:06:15,041 - logger.py:50 - Epoch: [3][450/500] loss: 1.50453, MAE: 0.31804, time/step=2037ms, lr=3.04e-05
2024-06-05 14:07:56,445 - logger.py:50 - Epoch: [3][499/500] loss: 1.47887, MAE: 0.31742, time/step=2040ms, lr=3.04e-05
2024-06-05 14:09:28,110 - logger.py:50 - Epoch: [3] train loss: 1.47887, train MAE: 0.31742,val loss: 0.31616, val MAE: 0.31616,test loss: 0.32817, test MAE: 0.32817,Time: 1111.56s
2024-06-05 14:09:28,110 - logger.py:50 - Best -- epoch=3, train loss: 1.47887, val loss: 0.31616, test loss: 0.32817

2024-06-05 14:09:29,623 - logger.py:50 - Epoch: [4][0/500] loss: 0.89345, MAE: 0.27201, time/step=1510ms, lr=4.02e-05
2024-06-05 14:11:09,640 - logger.py:50 - Epoch: [4][50/500] loss: 1.24212, MAE: 0.30290, time/step=1991ms, lr=4.02e-05
2024-06-05 14:12:52,225 - logger.py:50 - Epoch: [4][100/500] loss: 1.22376, MAE: 0.30207, time/step=2021ms, lr=4.02e-05
2024-06-05 14:14:36,121 - logger.py:50 - Epoch: [4][150/500] loss: 1.81740, MAE: 0.31619, time/step=2040ms, lr=4.02e-05
2024-06-05 14:16:19,070 - logger.py:50 - Epoch: [4][200/500] loss: 1.71009, MAE: 0.31796, time/step=2045ms, lr=4.02e-05
2024-06-05 14:18:01,786 - logger.py:50 - Epoch: [4][250/500] loss: 1.60779, MAE: 0.31598, time/step=2047ms, lr=4.02e-05
2024-06-05 14:19:43,763 - logger.py:50 - Epoch: [4][300/500] loss: 1.57580, MAE: 0.31546, time/step=2045ms, lr=4.02e-05
2024-06-05 14:21:25,135 - logger.py:50 - Epoch: [4][350/500] loss: 1.53396, MAE: 0.31450, time/step=2043ms, lr=4.02e-05
2024-06-05 14:23:08,697 - logger.py:50 - Epoch: [4][400/500] loss: 1.49766, MAE: 0.31269, time/step=2046ms, lr=4.02e-05
2024-06-05 14:24:51,231 - logger.py:50 - Epoch: [4][450/500] loss: 1.48227, MAE: 0.31262, time/step=2047ms, lr=4.02e-05
2024-06-05 14:26:31,275 - logger.py:50 - Epoch: [4][499/500] loss: 1.46470, MAE: 0.31285, time/step=2046ms, lr=4.02e-05
2024-06-05 14:28:03,258 - logger.py:50 - Epoch: [4] train loss: 1.46470, train MAE: 0.31285,val loss: 0.31327, val MAE: 0.31327,test loss: 0.32510, test MAE: 0.32510,Time: 1115.15s
2024-06-05 14:28:03,258 - logger.py:50 - Best -- epoch=4, train loss: 1.46470, val loss: 0.31327, test loss: 0.32510

2024-06-05 14:28:05,694 - logger.py:50 - Epoch: [5][0/500] loss: 1.39449, MAE: 0.32095, time/step=2433ms, lr=4.99e-05
2024-06-05 14:29:44,833 - logger.py:50 - Epoch: [5][50/500] loss: 1.40330, MAE: 0.31383, time/step=1992ms, lr=4.99e-05
2024-06-05 14:31:27,164 - logger.py:50 - Epoch: [5][100/500] loss: 1.33061, MAE: 0.30400, time/step=2019ms, lr=4.99e-05
2024-06-05 14:33:10,554 - logger.py:50 - Epoch: [5][150/500] loss: 1.32246, MAE: 0.30758, time/step=2035ms, lr=4.99e-05
2024-06-05 14:34:53,413 - logger.py:50 - Epoch: [5][200/500] loss: 1.32057, MAE: 0.30821, time/step=2041ms, lr=4.99e-05
2024-06-05 14:36:38,792 - logger.py:50 - Epoch: [5][250/500] loss: 1.64384, MAE: 0.31474, time/step=2054ms, lr=4.99e-05
2024-06-05 14:38:20,893 - logger.py:50 - Epoch: [5][300/500] loss: 1.59647, MAE: 0.31431, time/step=2052ms, lr=4.99e-05
2024-06-05 14:40:02,523 - logger.py:50 - Epoch: [5][350/500] loss: 1.53505, MAE: 0.31135, time/step=2049ms, lr=4.99e-05
2024-06-05 14:41:44,335 - logger.py:50 - Epoch: [5][400/500] loss: 1.49264, MAE: 0.31068, time/step=2048ms, lr=4.99e-05
2024-06-05 14:43:27,014 - logger.py:50 - Epoch: [5][450/500] loss: 1.47913, MAE: 0.31086, time/step=2048ms, lr=4.99e-05
2024-06-05 14:45:09,278 - logger.py:50 - Epoch: [5][499/500] loss: 1.45928, MAE: 0.31040, time/step=2052ms, lr=4.99e-05
2024-06-05 14:46:41,268 - logger.py:50 - Epoch: [5] train loss: 1.45928, train MAE: 0.31040,val loss: 0.31143, val MAE: 0.31143,test loss: 0.32335, test MAE: 0.32335,Time: 1118.01s
2024-06-05 14:46:41,268 - logger.py:50 - Best -- epoch=5, train loss: 1.45928, val loss: 0.31143, test loss: 0.32335

2024-06-05 14:46:43,352 - logger.py:50 - Epoch: [6][0/500] loss: 0.67991, MAE: 0.23236, time/step=2079ms, lr=4.98e-05
2024-06-05 14:48:24,171 - logger.py:50 - Epoch: [6][50/500] loss: 2.99829, MAE: 0.34283, time/step=2018ms, lr=4.98e-05
2024-06-05 14:50:06,175 - logger.py:50 - Epoch: [6][100/500] loss: 2.16003, MAE: 0.32573, time/step=2029ms, lr=4.98e-05
2024-06-05 14:51:48,615 - logger.py:50 - Epoch: [6][150/500] loss: 1.85834, MAE: 0.31950, time/step=2035ms, lr=4.98e-05
2024-06-05 14:53:31,002 - logger.py:50 - Epoch: [6][200/500] loss: 1.72909, MAE: 0.31528, time/step=2038ms, lr=4.98e-05
2024-06-05 14:55:16,560 - logger.py:50 - Epoch: [6][250/500] loss: 1.63368, MAE: 0.31409, time/step=2053ms, lr=4.98e-05
2024-06-05 14:56:58,144 - logger.py:50 - Epoch: [6][300/500] loss: 1.58537, MAE: 0.31267, time/step=2049ms, lr=4.98e-05
2024-06-05 14:58:40,709 - logger.py:50 - Epoch: [6][350/500] loss: 1.54439, MAE: 0.31119, time/step=2050ms, lr=4.98e-05
2024-06-05 15:00:21,775 - logger.py:50 - Epoch: [6][400/500] loss: 1.50632, MAE: 0.31077, time/step=2046ms, lr=4.98e-05
2024-06-05 15:02:05,083 - logger.py:50 - Epoch: [6][450/500] loss: 1.48508, MAE: 0.31002, time/step=2048ms, lr=4.98e-05
2024-06-05 15:03:45,287 - logger.py:50 - Epoch: [6][499/500] loss: 1.45678, MAE: 0.30909, time/step=2048ms, lr=4.98e-05
2024-06-05 15:05:22,458 - logger.py:50 - Epoch: [6] train loss: 1.45678, train MAE: 0.30909,val loss: 0.31062, val MAE: 0.31062,test loss: 0.32266, test MAE: 0.32266,Time: 1121.19s
2024-06-05 15:05:22,458 - logger.py:50 - Best -- epoch=6, train loss: 1.45678, val loss: 0.31062, test loss: 0.32266

2024-06-05 15:05:23,957 - logger.py:50 - Epoch: [7][0/500] loss: 0.85913, MAE: 0.29875, time/step=1495ms, lr=4.97e-05
2024-06-05 15:07:02,408 - logger.py:50 - Epoch: [7][50/500] loss: 1.29401, MAE: 0.30510, time/step=1960ms, lr=4.97e-05
2024-06-05 15:08:45,507 - logger.py:50 - Epoch: [7][100/500] loss: 1.25487, MAE: 0.30347, time/step=2010ms, lr=4.97e-05
2024-06-05 15:10:29,126 - logger.py:50 - Epoch: [7][150/500] loss: 1.24695, MAE: 0.30296, time/step=2031ms, lr=4.97e-05
2024-06-05 15:12:09,557 - logger.py:50 - Epoch: [7][200/500] loss: 1.27199, MAE: 0.30295, time/step=2025ms, lr=4.97e-05
2024-06-05 15:13:51,873 - logger.py:50 - Epoch: [7][250/500] loss: 1.28152, MAE: 0.30537, time/step=2030ms, lr=4.97e-05
2024-06-05 15:15:32,320 - logger.py:50 - Epoch: [7][300/500] loss: 1.26562, MAE: 0.30442, time/step=2026ms, lr=4.97e-05
2024-06-05 15:17:15,849 - logger.py:50 - Epoch: [7][350/500] loss: 1.26508, MAE: 0.30430, time/step=2032ms, lr=4.97e-05
2024-06-05 15:19:00,628 - logger.py:50 - Epoch: [7][400/500] loss: 1.26738, MAE: 0.30399, time/step=2040ms, lr=4.97e-05
2024-06-05 15:20:45,164 - logger.py:50 - Epoch: [7][450/500] loss: 1.46243, MAE: 0.30902, time/step=2046ms, lr=4.97e-05
2024-06-05 15:22:28,103 - logger.py:50 - Epoch: [7][499/500] loss: 1.45561, MAE: 0.30862, time/step=2051ms, lr=4.97e-05
2024-06-05 15:24:01,991 - logger.py:50 - Epoch: [7] train loss: 1.45561, train MAE: 0.30862,val loss: 0.31024, val MAE: 0.31024,test loss: 0.32219, test MAE: 0.32219,Time: 1119.53s
2024-06-05 15:24:01,991 - logger.py:50 - Best -- epoch=7, train loss: 1.45561, val loss: 0.31024, test loss: 0.32219

2024-06-05 15:24:04,420 - logger.py:50 - Epoch: [8][0/500] loss: 1.24277, MAE: 0.29500, time/step=2426ms, lr=4.97e-05
2024-06-05 15:25:43,073 - logger.py:50 - Epoch: [8][50/500] loss: 1.29122, MAE: 0.30034, time/step=1982ms, lr=4.97e-05
2024-06-05 15:27:27,163 - logger.py:50 - Epoch: [8][100/500] loss: 1.38579, MAE: 0.30653, time/step=2031ms, lr=4.97e-05
2024-06-05 15:29:09,789 - logger.py:50 - Epoch: [8][150/500] loss: 1.35196, MAE: 0.30755, time/step=2038ms, lr=4.97e-05
2024-06-05 15:30:53,067 - logger.py:50 - Epoch: [8][200/500] loss: 1.33666, MAE: 0.30551, time/step=2045ms, lr=4.97e-05
2024-06-05 15:32:34,734 - logger.py:50 - Epoch: [8][250/500] loss: 1.33218, MAE: 0.30568, time/step=2043ms, lr=4.97e-05
2024-06-05 15:34:18,057 - logger.py:50 - Epoch: [8][300/500] loss: 1.31095, MAE: 0.30378, time/step=2047ms, lr=4.97e-05
2024-06-05 15:36:04,080 - logger.py:50 - Epoch: [8][350/500] loss: 1.54037, MAE: 0.30864, time/step=2057ms, lr=4.97e-05
2024-06-05 15:37:47,700 - logger.py:50 - Epoch: [8][400/500] loss: 1.50259, MAE: 0.30926, time/step=2059ms, lr=4.97e-05
2024-06-05 15:39:28,389 - logger.py:50 - Epoch: [8][450/500] loss: 1.48550, MAE: 0.30997, time/step=2054ms, lr=4.97e-05
2024-06-05 15:41:08,739 - logger.py:50 - Epoch: [8][499/500] loss: 1.45483, MAE: 0.30816, time/step=2053ms, lr=4.97e-05
2024-06-05 15:42:39,848 - logger.py:50 - Epoch: [8] train loss: 1.45483, train MAE: 0.30816,val loss: 0.30902, val MAE: 0.30902,test loss: 0.32090, test MAE: 0.32090,Time: 1117.86s
2024-06-05 15:42:39,849 - logger.py:50 - Best -- epoch=8, train loss: 1.45483, val loss: 0.30902, test loss: 0.32090

2024-06-05 15:42:40,902 - logger.py:50 - Epoch: [9][0/500] loss: 1.62904, MAE: 0.32300, time/step=1050ms, lr=4.96e-05
2024-06-05 15:44:21,322 - logger.py:50 - Epoch: [9][50/500] loss: 1.27680, MAE: 0.30534, time/step=1990ms, lr=4.96e-05
2024-06-05 15:46:04,633 - logger.py:50 - Epoch: [9][100/500] loss: 1.29215, MAE: 0.30645, time/step=2028ms, lr=4.96e-05
2024-06-05 15:47:47,899 - logger.py:50 - Epoch: [9][150/500] loss: 1.28730, MAE: 0.30573, time/step=2040ms, lr=4.96e-05
2024-06-05 15:49:29,792 - logger.py:50 - Epoch: [9][200/500] loss: 1.29911, MAE: 0.30673, time/step=2040ms, lr=4.96e-05
2024-06-05 15:51:13,227 - logger.py:50 - Epoch: [9][250/500] loss: 1.30067, MAE: 0.30743, time/step=2045ms, lr=4.96e-05
2024-06-05 15:52:58,645 - logger.py:50 - Epoch: [9][300/500] loss: 1.28438, MAE: 0.30703, time/step=2056ms, lr=4.96e-05
2024-06-05 15:54:40,147 - logger.py:50 - Epoch: [9][350/500] loss: 1.29390, MAE: 0.30643, time/step=2052ms, lr=4.96e-05
2024-06-05 15:56:22,118 - logger.py:50 - Epoch: [9][400/500] loss: 1.50910, MAE: 0.31045, time/step=2051ms, lr=4.96e-05
2024-06-05 15:58:06,542 - logger.py:50 - Epoch: [9][450/500] loss: 1.48588, MAE: 0.30928, time/step=2055ms, lr=4.96e-05
2024-06-05 15:59:45,935 - logger.py:50 - Epoch: [9][499/500] loss: 1.45409, MAE: 0.30771, time/step=2052ms, lr=4.96e-05
2024-06-05 16:01:17,808 - logger.py:50 - Epoch: [9] train loss: 1.45409, train MAE: 0.30771,val loss: 0.30865, val MAE: 0.30865,test loss: 0.32059, test MAE: 0.32059,Time: 1117.96s
2024-06-05 16:01:17,808 - logger.py:50 - Best -- epoch=9, train loss: 1.45409, val loss: 0.30865, test loss: 0.32059

2024-06-05 16:01:20,025 - logger.py:50 - Epoch: [10][0/500] loss: 1.77976, MAE: 0.35405, time/step=2214ms, lr=4.95e-05
2024-06-05 16:02:58,638 - logger.py:50 - Epoch: [10][50/500] loss: 1.32677, MAE: 0.30015, time/step=1977ms, lr=4.95e-05
2024-06-05 16:04:45,710 - logger.py:50 - Epoch: [10][100/500] loss: 1.30593, MAE: 0.30276, time/step=2058ms, lr=4.95e-05
2024-06-05 16:06:25,806 - logger.py:50 - Epoch: [10][150/500] loss: 1.86889, MAE: 0.31551, time/step=2040ms, lr=4.95e-05
2024-06-05 16:08:04,934 - logger.py:50 - Epoch: [10][200/500] loss: 1.70612, MAE: 0.31284, time/step=2025ms, lr=4.95e-05
2024-06-05 16:09:49,282 - logger.py:50 - Epoch: [10][250/500] loss: 1.61905, MAE: 0.31162, time/step=2038ms, lr=4.95e-05
2024-06-05 16:11:32,834 - logger.py:50 - Epoch: [10][300/500] loss: 1.55377, MAE: 0.31014, time/step=2043ms, lr=4.95e-05
2024-06-05 16:13:16,535 - logger.py:50 - Epoch: [10][350/500] loss: 1.51131, MAE: 0.30901, time/step=2048ms, lr=4.95e-05
2024-06-05 16:15:00,836 - logger.py:50 - Epoch: [10][400/500] loss: 1.49239, MAE: 0.30870, time/step=2052ms, lr=4.95e-05
2024-06-05 16:16:44,608 - logger.py:50 - Epoch: [10][450/500] loss: 1.47753, MAE: 0.30807, time/step=2055ms, lr=4.95e-05
2024-06-05 16:18:24,952 - logger.py:50 - Epoch: [10][499/500] loss: 1.45376, MAE: 0.30753, time/step=2054ms, lr=4.95e-05
2024-06-05 16:19:54,651 - logger.py:50 - Epoch: [10] train loss: 1.45376, train MAE: 0.30753,val loss: 0.30830, val MAE: 0.30830,test loss: 0.32035, test MAE: 0.32035,Time: 1116.84s
2024-06-05 16:19:54,651 - logger.py:50 - Best -- epoch=10, train loss: 1.45376, val loss: 0.30830, test loss: 0.32035

2024-06-05 16:19:56,759 - logger.py:50 - Epoch: [11][0/500] loss: 0.67833, MAE: 0.26273, time/step=2105ms, lr=4.94e-05
2024-06-05 16:21:40,793 - logger.py:50 - Epoch: [11][50/500] loss: 1.19003, MAE: 0.30077, time/step=2081ms, lr=4.94e-05
2024-06-05 16:23:21,420 - logger.py:50 - Epoch: [11][100/500] loss: 1.24292, MAE: 0.30092, time/step=2047ms, lr=4.94e-05
2024-06-05 16:25:04,299 - logger.py:50 - Epoch: [11][150/500] loss: 1.26248, MAE: 0.30144, time/step=2051ms, lr=4.94e-05
2024-06-05 16:26:46,854 - logger.py:50 - Epoch: [11][200/500] loss: 1.24869, MAE: 0.30074, time/step=2051ms, lr=4.94e-05
2024-06-05 16:28:31,280 - logger.py:50 - Epoch: [11][250/500] loss: 1.58357, MAE: 0.30838, time/step=2058ms, lr=4.94e-05
2024-06-05 16:30:14,359 - logger.py:50 - Epoch: [11][300/500] loss: 1.52752, MAE: 0.30772, time/step=2059ms, lr=4.94e-05
2024-06-05 16:31:57,610 - logger.py:50 - Epoch: [11][350/500] loss: 1.51164, MAE: 0.30795, time/step=2060ms, lr=4.94e-05
2024-06-05 16:33:41,413 - logger.py:50 - Epoch: [11][400/500] loss: 1.48425, MAE: 0.30678, time/step=2062ms, lr=4.94e-05
2024-06-05 16:35:24,557 - logger.py:50 - Epoch: [11][450/500] loss: 1.46541, MAE: 0.30757, time/step=2062ms, lr=4.94e-05
2024-06-05 16:37:01,361 - logger.py:50 - Epoch: [11][499/500] loss: 1.45365, MAE: 0.30748, time/step=2053ms, lr=4.94e-05
2024-06-05 16:38:32,817 - logger.py:50 - Epoch: [11] train loss: 1.45365, train MAE: 0.30748,val loss: 0.30814, val MAE: 0.30814,test loss: 0.32003, test MAE: 0.32003,Time: 1118.17s
2024-06-05 16:38:32,817 - logger.py:50 - Best -- epoch=11, train loss: 1.45365, val loss: 0.30814, test loss: 0.32003

2024-06-05 16:38:34,330 - logger.py:50 - Epoch: [12][0/500] loss: 2.05462, MAE: 0.35334, time/step=1511ms, lr=4.92e-05
2024-06-05 16:40:15,612 - logger.py:50 - Epoch: [12][50/500] loss: 1.36191, MAE: 0.30619, time/step=2016ms, lr=4.92e-05
2024-06-05 16:41:58,112 - logger.py:50 - Epoch: [12][100/500] loss: 1.37312, MAE: 0.30822, time/step=2033ms, lr=4.92e-05
2024-06-05 16:43:42,707 - logger.py:50 - Epoch: [12][150/500] loss: 1.36790, MAE: 0.31125, time/step=2052ms, lr=4.92e-05
2024-06-05 16:45:28,127 - logger.py:50 - Epoch: [12][200/500] loss: 1.33229, MAE: 0.30826, time/step=2066ms, lr=4.92e-05
2024-06-05 16:47:09,952 - logger.py:50 - Epoch: [12][250/500] loss: 1.31397, MAE: 0.30488, time/step=2060ms, lr=4.92e-05
2024-06-05 16:48:50,195 - logger.py:50 - Epoch: [12][300/500] loss: 1.32254, MAE: 0.30627, time/step=2051ms, lr=4.92e-05
2024-06-05 16:50:33,972 - logger.py:50 - Epoch: [12][350/500] loss: 1.29700, MAE: 0.30515, time/step=2055ms, lr=4.92e-05
2024-06-05 16:52:14,889 - logger.py:50 - Epoch: [12][400/500] loss: 1.28537, MAE: 0.30411, time/step=2050ms, lr=4.92e-05
2024-06-05 16:53:56,446 - logger.py:50 - Epoch: [12][450/500] loss: 1.27721, MAE: 0.30313, time/step=2048ms, lr=4.92e-05
2024-06-05 16:55:38,469 - logger.py:50 - Epoch: [12][499/500] loss: 1.45343, MAE: 0.30724, time/step=2051ms, lr=4.92e-05
2024-06-05 16:57:11,743 - logger.py:50 - Epoch: [12] train loss: 1.45343, train MAE: 0.30724,val loss: 0.30924, val MAE: 0.30924,test loss: 0.32132, test MAE: 0.32132,Time: 1118.93s
2024-06-05 16:57:11,743 - logger.py:50 - Best -- epoch=11, train loss: 1.45365, val loss: 0.30814, test loss: 0.32003

2024-06-05 16:57:13,989 - logger.py:50 - Epoch: [13][0/500] loss: 0.81559, MAE: 0.29070, time/step=2243ms, lr=4.91e-05
2024-06-05 16:58:52,652 - logger.py:50 - Epoch: [13][50/500] loss: 1.21130, MAE: 0.30134, time/step=1979ms, lr=4.91e-05
2024-06-05 17:00:35,106 - logger.py:50 - Epoch: [13][100/500] loss: 1.31013, MAE: 0.30980, time/step=2013ms, lr=4.91e-05
2024-06-05 17:02:19,340 - logger.py:50 - Epoch: [13][150/500] loss: 1.84733, MAE: 0.31808, time/step=2037ms, lr=4.91e-05
2024-06-05 17:04:03,653 - logger.py:50 - Epoch: [13][200/500] loss: 1.72613, MAE: 0.31535, time/step=2049ms, lr=4.91e-05
2024-06-05 17:05:46,663 - logger.py:50 - Epoch: [13][250/500] loss: 1.63752, MAE: 0.31163, time/step=2051ms, lr=4.91e-05
2024-06-05 17:07:27,883 - logger.py:50 - Epoch: [13][300/500] loss: 1.58167, MAE: 0.31151, time/step=2047ms, lr=4.91e-05
2024-06-05 17:09:10,380 - logger.py:50 - Epoch: [13][350/500] loss: 1.53224, MAE: 0.31043, time/step=2047ms, lr=4.91e-05
2024-06-05 17:10:51,468 - logger.py:50 - Epoch: [13][400/500] loss: 1.49756, MAE: 0.30922, time/step=2044ms, lr=4.91e-05
2024-06-05 17:12:36,852 - logger.py:50 - Epoch: [13][450/500] loss: 1.47557, MAE: 0.30790, time/step=2051ms, lr=4.91e-05
2024-06-05 17:14:16,837 - logger.py:50 - Epoch: [13][499/500] loss: 1.45355, MAE: 0.30716, time/step=2050ms, lr=4.91e-05
2024-06-05 17:15:46,277 - logger.py:50 - Epoch: [13] train loss: 1.45355, train MAE: 0.30716,val loss: 0.30762, val MAE: 0.30762,test loss: 0.31964, test MAE: 0.31964,Time: 1114.53s
2024-06-05 17:15:46,277 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-06-05 17:15:48,457 - logger.py:50 - Epoch: [14][0/500] loss: 0.91917, MAE: 0.34137, time/step=2177ms, lr=4.90e-05
2024-06-05 17:17:28,572 - logger.py:50 - Epoch: [14][50/500] loss: 1.28350, MAE: 0.30143, time/step=2006ms, lr=4.90e-05
2024-06-05 17:19:10,711 - logger.py:50 - Epoch: [14][100/500] loss: 1.24664, MAE: 0.29856, time/step=2024ms, lr=4.90e-05
2024-06-05 17:20:53,959 - logger.py:50 - Epoch: [14][150/500] loss: 1.22295, MAE: 0.29811, time/step=2038ms, lr=4.90e-05
2024-06-05 17:22:34,588 - logger.py:50 - Epoch: [14][200/500] loss: 1.22426, MAE: 0.29859, time/step=2031ms, lr=4.90e-05
2024-06-05 17:24:16,221 - logger.py:50 - Epoch: [14][250/500] loss: 1.24790, MAE: 0.30120, time/step=2032ms, lr=4.90e-05
2024-06-05 17:25:58,599 - logger.py:50 - Epoch: [14][300/500] loss: 1.26643, MAE: 0.30282, time/step=2034ms, lr=4.90e-05
2024-06-05 17:27:40,287 - logger.py:50 - Epoch: [14][350/500] loss: 1.27758, MAE: 0.30352, time/step=2034ms, lr=4.90e-05
2024-06-05 17:29:24,074 - logger.py:50 - Epoch: [14][400/500] loss: 1.49068, MAE: 0.30822, time/step=2039ms, lr=4.90e-05
2024-06-05 17:31:07,389 - logger.py:50 - Epoch: [14][450/500] loss: 1.46507, MAE: 0.30639, time/step=2042ms, lr=4.90e-05
2024-06-05 17:32:48,687 - logger.py:50 - Epoch: [14][499/500] loss: 1.45329, MAE: 0.30723, time/step=2045ms, lr=4.90e-05
2024-06-05 17:34:22,418 - logger.py:50 - Epoch: [14] train loss: 1.45329, train MAE: 0.30723,val loss: 0.30935, val MAE: 0.30935,test loss: 0.32107, test MAE: 0.32107,Time: 1116.14s
2024-06-05 17:34:22,418 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-06-05 17:34:24,141 - logger.py:50 - Epoch: [15][0/500] loss: 1.20373, MAE: 0.29654, time/step=1720ms, lr=4.88e-05
2024-06-05 17:36:00,338 - logger.py:50 - Epoch: [15][50/500] loss: 1.23893, MAE: 0.29649, time/step=1920ms, lr=4.88e-05
2024-06-05 17:37:42,927 - logger.py:50 - Epoch: [15][100/500] loss: 1.25813, MAE: 0.29956, time/step=1985ms, lr=4.88e-05
2024-06-05 17:39:25,947 - logger.py:50 - Epoch: [15][150/500] loss: 1.25800, MAE: 0.30374, time/step=2010ms, lr=4.88e-05
2024-06-05 17:41:06,462 - logger.py:50 - Epoch: [15][200/500] loss: 1.67926, MAE: 0.30977, time/step=2010ms, lr=4.88e-05
2024-06-05 17:42:47,820 - logger.py:50 - Epoch: [15][250/500] loss: 1.58829, MAE: 0.30698, time/step=2014ms, lr=4.88e-05
2024-06-05 17:44:32,617 - logger.py:50 - Epoch: [15][300/500] loss: 1.54979, MAE: 0.30869, time/step=2027ms, lr=4.88e-05
2024-06-05 17:46:15,840 - logger.py:50 - Epoch: [15][350/500] loss: 1.51926, MAE: 0.30897, time/step=2033ms, lr=4.88e-05
2024-06-05 17:47:55,797 - logger.py:50 - Epoch: [15][400/500] loss: 1.48051, MAE: 0.30711, time/step=2028ms, lr=4.88e-05
2024-06-05 17:49:37,603 - logger.py:50 - Epoch: [15][450/500] loss: 1.46336, MAE: 0.30640, time/step=2029ms, lr=4.88e-05
2024-06-05 17:51:19,056 - logger.py:50 - Epoch: [15][499/500] loss: 1.45326, MAE: 0.30695, time/step=2033ms, lr=4.88e-05
2024-06-05 17:52:49,150 - logger.py:50 - Epoch: [15] train loss: 1.45326, train MAE: 0.30695,val loss: 0.30895, val MAE: 0.30895,test loss: 0.32096, test MAE: 0.32096,Time: 1106.73s
2024-06-05 17:52:49,151 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-06-05 17:52:50,127 - logger.py:50 - Epoch: [16][0/500] loss: 0.81375, MAE: 0.26354, time/step=973ms, lr=4.86e-05
2024-06-05 17:54:32,060 - logger.py:50 - Epoch: [16][50/500] loss: 1.23702, MAE: 0.29852, time/step=2018ms, lr=4.86e-05
2024-06-05 17:56:16,972 - logger.py:50 - Epoch: [16][100/500] loss: 1.29558, MAE: 0.30115, time/step=2058ms, lr=4.86e-05
2024-06-05 17:57:57,286 - logger.py:50 - Epoch: [16][150/500] loss: 1.30549, MAE: 0.30306, time/step=2041ms, lr=4.86e-05
2024-06-05 17:59:38,964 - logger.py:50 - Epoch: [16][200/500] loss: 1.27654, MAE: 0.30061, time/step=2039ms, lr=4.86e-05
2024-06-05 18:01:20,681 - logger.py:50 - Epoch: [16][250/500] loss: 1.26986, MAE: 0.29983, time/step=2038ms, lr=4.86e-05
2024-06-05 18:03:03,307 - logger.py:50 - Epoch: [16][300/500] loss: 1.28582, MAE: 0.30260, time/step=2040ms, lr=4.86e-05
2024-06-05 18:04:44,850 - logger.py:50 - Epoch: [16][350/500] loss: 1.27875, MAE: 0.30205, time/step=2039ms, lr=4.86e-05
2024-06-05 18:06:27,453 - logger.py:50 - Epoch: [16][400/500] loss: 1.29039, MAE: 0.30305, time/step=2041ms, lr=4.86e-05
2024-06-05 18:08:05,924 - logger.py:50 - Epoch: [16][450/500] loss: 1.46748, MAE: 0.30604, time/step=2033ms, lr=4.86e-05
2024-06-05 18:09:47,306 - logger.py:50 - Epoch: [16][499/500] loss: 1.45319, MAE: 0.30699, time/step=2036ms, lr=4.86e-05
2024-06-05 18:11:17,506 - logger.py:50 - Epoch: [16] train loss: 1.45319, train MAE: 0.30699,val loss: 0.30880, val MAE: 0.30880,test loss: 0.32077, test MAE: 0.32077,Time: 1108.36s
2024-06-05 18:11:17,506 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-06-05 18:11:19,291 - logger.py:50 - Epoch: [17][0/500] loss: 1.34292, MAE: 0.32214, time/step=1782ms, lr=4.85e-05
2024-06-05 18:12:57,357 - logger.py:50 - Epoch: [17][50/500] loss: 1.26731, MAE: 0.29742, time/step=1958ms, lr=4.85e-05
2024-06-05 18:14:35,560 - logger.py:50 - Epoch: [17][100/500] loss: 1.32179, MAE: 0.31061, time/step=1961ms, lr=4.85e-05
2024-06-05 18:16:16,222 - logger.py:50 - Epoch: [17][150/500] loss: 1.28580, MAE: 0.30589, time/step=1978ms, lr=4.85e-05
2024-06-05 18:17:57,979 - logger.py:50 - Epoch: [17][200/500] loss: 1.31643, MAE: 0.30711, time/step=1992ms, lr=4.85e-05
2024-06-05 18:19:40,756 - logger.py:50 - Epoch: [17][250/500] loss: 1.28504, MAE: 0.30427, time/step=2005ms, lr=4.85e-05
2024-06-05 18:21:23,143 - logger.py:50 - Epoch: [17][300/500] loss: 1.28345, MAE: 0.30271, time/step=2012ms, lr=4.85e-05
2024-06-05 18:23:06,205 - logger.py:50 - Epoch: [17][350/500] loss: 1.51971, MAE: 0.30622, time/step=2019ms, lr=4.85e-05
2024-06-05 18:24:48,742 - logger.py:50 - Epoch: [17][400/500] loss: 1.49266, MAE: 0.30668, time/step=2023ms, lr=4.85e-05
2024-06-05 18:26:28,224 - logger.py:50 - Epoch: [17][450/500] loss: 1.46895, MAE: 0.30617, time/step=2019ms, lr=4.85e-05
2024-06-05 18:28:04,639 - logger.py:50 - Epoch: [17][499/500] loss: 1.45343, MAE: 0.30685, time/step=2014ms, lr=4.85e-05
2024-06-05 18:29:32,654 - logger.py:50 - Epoch: [17] train loss: 1.45343, train MAE: 0.30685,val loss: 0.30962, val MAE: 0.30962,test loss: 0.32159, test MAE: 0.32159,Time: 1095.15s
2024-06-05 18:29:32,654 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-06-05 18:29:33,863 - logger.py:50 - Epoch: [18][0/500] loss: 1.17357, MAE: 0.28343, time/step=1206ms, lr=4.83e-05
2024-06-05 18:31:10,514 - logger.py:50 - Epoch: [18][50/500] loss: 1.36251, MAE: 0.30971, time/step=1919ms, lr=4.83e-05
2024-06-05 18:32:51,018 - logger.py:50 - Epoch: [18][100/500] loss: 1.36022, MAE: 0.30654, time/step=1964ms, lr=4.83e-05
2024-06-05 18:34:30,161 - logger.py:50 - Epoch: [18][150/500] loss: 1.32265, MAE: 0.30607, time/step=1970ms, lr=4.83e-05
2024-06-05 18:36:08,370 - logger.py:50 - Epoch: [18][200/500] loss: 1.33983, MAE: 0.30793, time/step=1969ms, lr=4.83e-05
2024-06-05 18:37:46,850 - logger.py:50 - Epoch: [18][250/500] loss: 1.67116, MAE: 0.31505, time/step=1969ms, lr=4.83e-05
2024-06-05 18:39:20,372 - logger.py:50 - Epoch: [18][300/500] loss: 1.59429, MAE: 0.31164, time/step=1953ms, lr=4.83e-05
2024-06-05 18:40:59,734 - logger.py:50 - Epoch: [18][350/500] loss: 1.53956, MAE: 0.30907, time/step=1957ms, lr=4.83e-05
2024-06-05 18:42:36,572 - logger.py:50 - Epoch: [18][400/500] loss: 1.51394, MAE: 0.30913, time/step=1955ms, lr=4.83e-05
2024-06-05 18:44:11,037 - logger.py:50 - Epoch: [18][450/500] loss: 1.47419, MAE: 0.30762, time/step=1948ms, lr=4.83e-05
2024-06-05 18:45:43,306 - logger.py:50 - Epoch: [18][499/500] loss: 1.45343, MAE: 0.30697, time/step=1941ms, lr=4.83e-05
2024-06-05 18:47:08,010 - logger.py:50 - Epoch: [18] train loss: 1.45343, train MAE: 0.30697,val loss: 0.30825, val MAE: 0.30825,test loss: 0.32023, test MAE: 0.32023,Time: 1055.36s
2024-06-05 18:47:08,010 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-06-05 18:47:10,324 - logger.py:50 - Epoch: [19][0/500] loss: 0.79835, MAE: 0.28999, time/step=2311ms, lr=4.81e-05
2024-06-05 18:48:49,289 - logger.py:50 - Epoch: [19][50/500] loss: 1.22603, MAE: 0.29702, time/step=1986ms, lr=4.81e-05
2024-06-05 18:50:26,136 - logger.py:50 - Epoch: [19][100/500] loss: 1.29754, MAE: 0.30153, time/step=1962ms, lr=4.81e-05
2024-06-05 18:52:01,043 - logger.py:50 - Epoch: [19][150/500] loss: 1.24806, MAE: 0.30183, time/step=1941ms, lr=4.81e-05
2024-06-05 18:53:35,005 - logger.py:50 - Epoch: [19][200/500] loss: 1.27246, MAE: 0.30477, time/step=1925ms, lr=4.81e-05
2024-06-05 18:55:09,974 - logger.py:50 - Epoch: [19][250/500] loss: 1.26323, MAE: 0.30241, time/step=1920ms, lr=4.81e-05
2024-06-05 18:56:44,679 - logger.py:50 - Epoch: [19][300/500] loss: 1.27311, MAE: 0.30214, time/step=1916ms, lr=4.81e-05
2024-06-05 18:58:21,465 - logger.py:50 - Epoch: [19][350/500] loss: 1.27484, MAE: 0.30250, time/step=1919ms, lr=4.81e-05
2024-06-05 18:59:56,181 - logger.py:50 - Epoch: [19][400/500] loss: 1.48872, MAE: 0.30729, time/step=1916ms, lr=4.81e-05
2024-06-05 19:01:30,247 - logger.py:50 - Epoch: [19][450/500] loss: 1.46178, MAE: 0.30648, time/step=1912ms, lr=4.81e-05
2024-06-05 19:02:59,463 - logger.py:50 - Epoch: [19][499/500] loss: 1.45330, MAE: 0.30671, time/step=1903ms, lr=4.81e-05
2024-06-05 19:04:24,255 - logger.py:50 - Epoch: [19] train loss: 1.45330, train MAE: 0.30671,val loss: 0.30957, val MAE: 0.30957,test loss: 0.32116, test MAE: 0.32116,Time: 1036.24s
2024-06-05 19:04:24,255 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-06-05 19:04:25,913 - logger.py:50 - Epoch: [20][0/500] loss: 0.86664, MAE: 0.26591, time/step=1655ms, lr=4.79e-05
2024-06-05 19:05:55,908 - logger.py:50 - Epoch: [20][50/500] loss: 1.40337, MAE: 0.31592, time/step=1797ms, lr=4.79e-05
2024-06-05 19:07:32,043 - logger.py:50 - Epoch: [20][100/500] loss: 1.31813, MAE: 0.31184, time/step=1859ms, lr=4.79e-05
2024-06-05 19:09:03,706 - logger.py:50 - Epoch: [20][150/500] loss: 1.30464, MAE: 0.30857, time/step=1851ms, lr=4.79e-05
2024-06-05 19:10:35,694 - logger.py:50 - Epoch: [20][200/500] loss: 1.32168, MAE: 0.30858, time/step=1848ms, lr=4.79e-05
2024-06-05 19:12:10,668 - logger.py:50 - Epoch: [20][250/500] loss: 1.65333, MAE: 0.31303, time/step=1858ms, lr=4.79e-05
2024-06-05 19:13:49,175 - logger.py:50 - Epoch: [20][300/500] loss: 1.57935, MAE: 0.31208, time/step=1877ms, lr=4.79e-05
2024-06-05 19:15:18,842 - logger.py:50 - Epoch: [20][350/500] loss: 1.54287, MAE: 0.30986, time/step=1865ms, lr=4.79e-05
2024-06-05 19:16:50,166 - logger.py:50 - Epoch: [20][400/500] loss: 1.50463, MAE: 0.30779, time/step=1860ms, lr=4.79e-05
2024-06-05 19:18:24,846 - logger.py:50 - Epoch: [20][450/500] loss: 1.47716, MAE: 0.30729, time/step=1864ms, lr=4.79e-05
2024-06-05 19:19:57,404 - logger.py:50 - Epoch: [20][499/500] loss: 1.45325, MAE: 0.30653, time/step=1866ms, lr=4.79e-05
2024-06-05 19:21:19,121 - logger.py:50 - Epoch: [20] train loss: 1.45325, train MAE: 0.30653,val loss: 0.30784, val MAE: 0.30784,test loss: 0.31985, test MAE: 0.31985,Time: 1014.87s
2024-06-05 19:21:19,121 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-06-05 19:21:20,313 - logger.py:50 - Epoch: [21][0/500] loss: 1.67355, MAE: 0.36536, time/step=1189ms, lr=4.77e-05
2024-06-05 19:22:51,785 - logger.py:50 - Epoch: [21][50/500] loss: 1.22963, MAE: 0.30076, time/step=1817ms, lr=4.77e-05
2024-06-05 19:24:28,075 - logger.py:50 - Epoch: [21][100/500] loss: 1.19108, MAE: 0.29874, time/step=1871ms, lr=4.77e-05
2024-06-05 19:26:04,061 - logger.py:50 - Epoch: [21][150/500] loss: 1.26657, MAE: 0.30758, time/step=1887ms, lr=4.77e-05
2024-06-05 19:27:33,424 - logger.py:50 - Epoch: [21][200/500] loss: 1.25840, MAE: 0.30583, time/step=1862ms, lr=4.77e-05
2024-06-05 19:29:07,670 - logger.py:50 - Epoch: [21][250/500] loss: 1.27614, MAE: 0.30467, time/step=1867ms, lr=4.77e-05
2024-06-05 19:30:39,890 - logger.py:50 - Epoch: [21][300/500] loss: 1.25975, MAE: 0.30394, time/step=1863ms, lr=4.77e-05
2024-06-05 19:32:11,314 - logger.py:50 - Epoch: [21][350/500] loss: 1.26727, MAE: 0.30364, time/step=1858ms, lr=4.77e-05
2024-06-05 19:33:46,043 - logger.py:50 - Epoch: [21][400/500] loss: 1.27047, MAE: 0.30375, time/step=1863ms, lr=4.77e-05
2024-06-05 19:35:18,052 - logger.py:50 - Epoch: [21][450/500] loss: 1.45600, MAE: 0.30637, time/step=1860ms, lr=4.77e-05
2024-06-05 19:36:49,749 - logger.py:50 - Epoch: [21][499/500] loss: 1.45342, MAE: 0.30648, time/step=1861ms, lr=4.77e-05
2024-06-05 19:38:11,197 - logger.py:50 - Epoch: [21] train loss: 1.45342, train MAE: 0.30648,val loss: 0.30971, val MAE: 0.30971,test loss: 0.32151, test MAE: 0.32151,Time: 1012.08s
2024-06-05 19:38:11,198 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-06-05 19:38:12,216 - logger.py:50 - Epoch: [22][0/500] loss: 0.59971, MAE: 0.26053, time/step=1016ms, lr=4.74e-05
2024-06-05 19:39:42,964 - logger.py:50 - Epoch: [22][50/500] loss: 1.31493, MAE: 0.30638, time/step=1799ms, lr=4.74e-05
2024-06-05 19:41:13,208 - logger.py:50 - Epoch: [22][100/500] loss: 1.30104, MAE: 0.30429, time/step=1802ms, lr=4.74e-05
2024-06-05 19:42:45,171 - logger.py:50 - Epoch: [22][150/500] loss: 1.32341, MAE: 0.30328, time/step=1814ms, lr=4.74e-05
2024-06-05 19:44:15,897 - logger.py:50 - Epoch: [22][200/500] loss: 1.31817, MAE: 0.30442, time/step=1814ms, lr=4.74e-05
2024-06-05 19:45:50,682 - logger.py:50 - Epoch: [22][250/500] loss: 1.31907, MAE: 0.30625, time/step=1831ms, lr=4.74e-05
2024-06-05 19:47:21,404 - logger.py:50 - Epoch: [22][300/500] loss: 1.59162, MAE: 0.30980, time/step=1828ms, lr=4.74e-05
2024-06-05 19:48:51,381 - logger.py:50 - Epoch: [22][350/500] loss: 1.53036, MAE: 0.30811, time/step=1824ms, lr=4.74e-05
2024-06-05 19:50:24,198 - logger.py:50 - Epoch: [22][400/500] loss: 1.50227, MAE: 0.30670, time/step=1828ms, lr=4.74e-05
2024-06-05 19:51:59,471 - logger.py:50 - Epoch: [22][450/500] loss: 1.46440, MAE: 0.30598, time/step=1837ms, lr=4.74e-05
2024-06-05 19:53:27,325 - logger.py:50 - Epoch: [22][499/500] loss: 1.45303, MAE: 0.30627, time/step=1832ms, lr=4.74e-05
2024-06-05 19:54:49,389 - logger.py:50 - Epoch: [22] train loss: 1.45303, train MAE: 0.30627,val loss: 0.30731, val MAE: 0.30731,test loss: 0.31940, test MAE: 0.31940,Time: 998.19s
2024-06-05 19:54:49,390 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-06-05 19:54:51,545 - logger.py:50 - Epoch: [23][0/500] loss: 1.81658, MAE: 0.35152, time/step=2153ms, lr=4.72e-05
2024-06-05 19:56:20,276 - logger.py:50 - Epoch: [23][50/500] loss: 1.16733, MAE: 0.30146, time/step=1782ms, lr=4.72e-05
2024-06-05 19:57:53,681 - logger.py:50 - Epoch: [23][100/500] loss: 1.22732, MAE: 0.30256, time/step=1825ms, lr=4.72e-05
2024-06-05 19:59:22,599 - logger.py:50 - Epoch: [23][150/500] loss: 1.21529, MAE: 0.30197, time/step=1809ms, lr=4.72e-05
2024-06-05 20:01:01,970 - logger.py:50 - Epoch: [23][200/500] loss: 1.21093, MAE: 0.30003, time/step=1854ms, lr=4.72e-05
2024-06-05 20:02:29,679 - logger.py:50 - Epoch: [23][250/500] loss: 1.23999, MAE: 0.30102, time/step=1834ms, lr=4.72e-05
2024-06-05 20:03:58,769 - logger.py:50 - Epoch: [23][300/500] loss: 1.25273, MAE: 0.30097, time/step=1825ms, lr=4.72e-05
2024-06-05 20:05:29,955 - logger.py:50 - Epoch: [23][350/500] loss: 1.25940, MAE: 0.30234, time/step=1825ms, lr=4.72e-05
2024-06-05 20:06:58,462 - logger.py:50 - Epoch: [23][400/500] loss: 1.25759, MAE: 0.30257, time/step=1818ms, lr=4.72e-05
2024-06-05 20:08:28,772 - logger.py:50 - Epoch: [23][450/500] loss: 1.45332, MAE: 0.30579, time/step=1817ms, lr=4.72e-05
2024-06-05 20:10:00,426 - logger.py:50 - Epoch: [23][499/500] loss: 1.45331, MAE: 0.30636, time/step=1822ms, lr=4.72e-05
2024-09-22 23:46:10,889 - logger.py:50 - Namespace(output_dir='models/ForceCon/', model_name='graph_attention_transformer_nonlinear_l2_e3_noNorm', input_irreps='86x0e', radius=8.0, num_basis=86, output_channels=1, epochs=150, batch_size=16, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, drop_path=0.0, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.005, sched='cosine', lr=5e-05, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, warmup_lr=1e-06, min_lr=1e-06, decay_epochs=30, warmup_epochs=5, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, print_freq=50, target=0, data_path='datasets', run_fold=1, order_type='all', feature_type='one_hot', compute_stats=False, standardize=True, loss='l1', seed=0, workers=0, pin_mem=True, amp=False, world_size=1, dist_url='env://', distributed=False, rank=0, local_rank=0)
2024-09-22 23:46:38,395 - logger.py:50 - GraphAttentionTransformer(
  (atom_embed): NodeEmbeddingNetwork(
    (atom_type_lin): LinearRS(
      (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
  )
  (rbf): GaussianRadialBasisLayer(mean_init_max=1.0, mean_init_min=0, std_init_max=1.0, std_init_min=0.011627906976744186)
  (edge_deg_embed): EdgeDegreeEmbeddingNetwork(
    (exp): LinearRS(
      (tp): TensorProduct(1x0e x 1x0e -> 128x0e+64x1e+32x2e | 128 paths | 128 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (dw): TensorProductRescale(
      (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
      (bias): ParameterList()
    )
    (rad): RadialProfile(
      (net): Sequential(
        (0): Linear(in_features=86, out_features=64, bias=True)
        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (2): SiLU()
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (5): SiLU()
        (6): Linear(in_features=64, out_features=576, bias=False)
      )
    )
    (proj): LinearRS(
      (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
    )
    (scale_scatter): ScaledScatter(avg_aggregate_num=34.29242574467496)
  )
  (blocks): ModuleList(
    (0-4): 5 x TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 128x0e+64x1e+32x2e | 64512 paths | 64512 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
    )
    (5): TransBlock(
      (ga): GraphAttention(
        rescale_degree=False, 
        (merge_src): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (merge_dst): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList()
        )
        (sep_act): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (dtp_rad): RadialProfile(
            (net): Sequential(
              (0): Linear(in_features=86, out_features=64, bias=True)
              (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (2): SiLU()
              (3): Linear(in_features=64, out_features=64, bias=True)
              (4): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (5): SiLU()
              (6): Linear(in_features=64, out_features=576, bias=False)
            )
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 224x0e+64x1e+32x2e | 54272 paths | 54272 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 224])
          )
          (gate): Gate (224x0e+64x1e+32x2e -> 128x0e+64x1e+32x2e)
        )
        (sep_alpha): LinearRS(
          (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e | 20480 paths | 20480 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
        (sep_value): SeparableFCTP(
          (dtp): TensorProductRescale(
            (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e+1x1o+1x2e -> 160x0e+160x1e+256x2e | 576 paths | 576 weights)
            (bias): ParameterList()
          )
          (lin): LinearRS(
            (tp): TensorProduct(160x0e+160x1e+256x2e x 1x0e -> 128x0e+64x1e+32x2e | 38912 paths | 38912 weights)
            (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
          )
        )
        (vec2heads_alpha): Vec2AttnHeads(irreps_head=16x0e, num_heads=8)
        (vec2heads_value): Vec2AttnHeads(irreps_head=16x0e+8x1e+4x2e, num_heads=8)
        (alpha_act): Activation(
          16x0e -> 16x0e, 
          (acts): ModuleList(
            (0): normalize2mom(
              (f): SmoothLeakyReLU(negative_slope=0.2)
            )
          )
        )
        (heads2vec): AttnHeads2Vec(irreps_head=16x0e+8x1e+4x2e)
        (alpha_dropout): Dropout(p=0.2, inplace=False)
        (proj): LinearRS(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 128x0e+64x1e+32x2e | 21504 paths | 21504 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
        )
      )
      (ffn): FeedForwardNetwork(
        (fctp_1): FullyConnectedTensorProductRescaleSwishGate(
          (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 672x0e+192x1e+96x2e | 101376 paths | 101376 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 672])
          (gate): Gate (672x0e+192x1e+96x2e -> 384x0e+192x1e+96x2e)
        )
        (fctp_2): FullyConnectedTensorProductRescale(
          (tp): TensorProduct(384x0e+192x1e+96x2e x 1x0e -> 512x0e | 196608 paths | 196608 weights)
          (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
        )
      )
      (ffn_shortcut): FullyConnectedTensorProductRescale(
        (tp): TensorProduct(128x0e+64x1e+32x2e x 1x0e -> 512x0e | 65536 paths | 65536 weights)
        (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
      )
    )
  )
  (norm): EquivariantLayerNormV2(512x0e, eps=1e-05)
  (head): Sequential(
    (0): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 512x0e | 262144 paths | 262144 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
    )
    (1): Activation(
      512x0e -> 512x0e, 
      (acts): ModuleList(
        (0): normalize2mom(
          (f): SiLU()
        )
      )
    )
    (2): LinearRS(
      (tp): TensorProduct(512x0e x 1x0e -> 1x0e+1x1o+1x2e | 512 paths | 512 weights)
      (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 1])
    )
  )
  (lrs): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 512x0e | 44032 paths | 44032 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 512])
  )
  (scale_scatter): ScaledScatter(avg_aggregate_num=29.891087392943284)
  (atom_expand): LinearRS(
    (tp): TensorProduct(86x0e x 1x0e -> 128x0e+64x1e+32x2e | 11008 paths | 11008 weights)
    (bias): ParameterList(  (0): Parameter containing: [torch.float32 of size 128])
  )
)
2024-09-22 23:46:39,164 - logger.py:50 - Number of params: 2978805
2024-09-22 23:46:41,971 - logger.py:50 - Epoch: [0][0/500] loss: 2.82960, MAE: 0.58284, time/step=2802ms, lr=1.00e-06
2024-09-22 23:47:58,311 - logger.py:50 - Epoch: [0][50/500] loss: 4.11382, MAE: 0.57985, time/step=1552ms, lr=1.00e-06
2024-09-22 23:49:12,774 - logger.py:50 - Epoch: [0][100/500] loss: 3.10607, MAE: 0.54013, time/step=1521ms, lr=1.00e-06
2024-09-22 23:50:26,522 - logger.py:50 - Epoch: [0][150/500] loss: 2.70097, MAE: 0.51674, time/step=1506ms, lr=1.00e-06
2024-09-22 23:51:40,877 - logger.py:50 - Epoch: [0][200/500] loss: 2.52474, MAE: 0.50202, time/step=1501ms, lr=1.00e-06
2024-09-22 23:52:54,901 - logger.py:50 - Epoch: [0][250/500] loss: 2.38055, MAE: 0.48896, time/step=1497ms, lr=1.00e-06
2024-09-22 23:54:07,554 - logger.py:50 - Epoch: [0][300/500] loss: 2.27506, MAE: 0.47888, time/step=1490ms, lr=1.00e-06
2024-09-22 23:55:20,139 - logger.py:50 - Epoch: [0][350/500] loss: 2.18034, MAE: 0.46778, time/step=1484ms, lr=1.00e-06
2024-09-22 23:56:33,529 - logger.py:50 - Epoch: [0][400/500] loss: 2.09987, MAE: 0.45902, time/step=1482ms, lr=1.00e-06
2024-09-22 23:57:53,541 - logger.py:50 - Epoch: [0][450/500] loss: 2.02648, MAE: 0.45009, time/step=1495ms, lr=1.00e-06
2024-09-22 23:59:13,636 - logger.py:50 - Epoch: [0][499/500] loss: 2.00157, MAE: 0.44417, time/step=1509ms, lr=1.00e-06
2024-09-23 00:00:31,071 - logger.py:50 - Epoch: [0] train loss: 2.00157, train MAE: 0.44417,val loss: 0.38896, val MAE: 0.38896,test loss: 0.39972, test MAE: 0.39972,Time: 831.90s
2024-09-23 00:00:31,071 - logger.py:50 - Best -- epoch=0, train loss: 2.00157, val loss: 0.38896, test loss: 0.39972

2024-09-23 00:00:32,426 - logger.py:50 - Epoch: [1][0/500] loss: 1.84921, MAE: 0.38930, time/step=1352ms, lr=1.08e-05
2024-09-23 00:01:52,125 - logger.py:50 - Epoch: [1][50/500] loss: 1.46165, MAE: 0.36166, time/step=1589ms, lr=1.08e-05
2024-09-23 00:03:14,418 - logger.py:50 - Epoch: [1][100/500] loss: 1.52142, MAE: 0.35852, time/step=1617ms, lr=1.08e-05
2024-09-23 00:04:37,846 - logger.py:50 - Epoch: [1][150/500] loss: 1.47318, MAE: 0.35104, time/step=1634ms, lr=1.08e-05
2024-09-23 00:05:56,375 - logger.py:50 - Epoch: [1][200/500] loss: 1.43566, MAE: 0.34863, time/step=1618ms, lr=1.08e-05
2024-09-23 00:07:19,884 - logger.py:50 - Epoch: [1][250/500] loss: 1.43536, MAE: 0.34673, time/step=1629ms, lr=1.08e-05
2024-09-23 00:08:40,722 - logger.py:50 - Epoch: [1][300/500] loss: 1.43567, MAE: 0.34525, time/step=1627ms, lr=1.08e-05
2024-09-23 00:10:01,058 - logger.py:50 - Epoch: [1][350/500] loss: 1.44018, MAE: 0.34372, time/step=1624ms, lr=1.08e-05
2024-09-23 00:11:19,579 - logger.py:50 - Epoch: [1][400/500] loss: 1.45679, MAE: 0.34337, time/step=1617ms, lr=1.08e-05
2024-09-23 00:12:41,613 - logger.py:50 - Epoch: [1][450/500] loss: 1.43880, MAE: 0.34193, time/step=1620ms, lr=1.08e-05
2024-09-23 00:14:06,507 - logger.py:50 - Epoch: [1][499/500] loss: 1.59516, MAE: 0.34332, time/step=1631ms, lr=1.08e-05
2024-09-23 00:15:22,827 - logger.py:50 - Epoch: [1] train loss: 1.59516, train MAE: 0.34332,val loss: 0.33389, val MAE: 0.33389,test loss: 0.34588, test MAE: 0.34588,Time: 891.76s
2024-09-23 00:15:22,827 - logger.py:50 - Best -- epoch=1, train loss: 1.59516, val loss: 0.33389, test loss: 0.34588

2024-09-23 00:15:24,417 - logger.py:50 - Epoch: [2][0/500] loss: 1.26267, MAE: 0.32889, time/step=1587ms, lr=2.06e-05
2024-09-23 00:16:52,428 - logger.py:50 - Epoch: [2][50/500] loss: 3.11048, MAE: 0.36236, time/step=1757ms, lr=2.06e-05
2024-09-23 00:18:28,208 - logger.py:50 - Epoch: [2][100/500] loss: 2.19936, MAE: 0.34189, time/step=1835ms, lr=2.06e-05
2024-09-23 00:20:08,206 - logger.py:50 - Epoch: [2][150/500] loss: 1.91562, MAE: 0.33345, time/step=1890ms, lr=2.06e-05
2024-09-23 00:21:43,893 - logger.py:50 - Epoch: [2][200/500] loss: 1.75954, MAE: 0.33119, time/step=1896ms, lr=2.06e-05
2024-09-23 00:23:25,683 - logger.py:50 - Epoch: [2][250/500] loss: 1.70886, MAE: 0.33239, time/step=1924ms, lr=2.06e-05
2024-09-23 00:25:05,753 - logger.py:50 - Epoch: [2][300/500] loss: 1.63526, MAE: 0.32964, time/step=1937ms, lr=2.06e-05
2024-09-23 00:26:45,639 - logger.py:50 - Epoch: [2][350/500] loss: 1.60882, MAE: 0.32847, time/step=1945ms, lr=2.06e-05
2024-09-23 00:28:23,965 - logger.py:50 - Epoch: [2][400/500] loss: 1.57779, MAE: 0.32861, time/step=1948ms, lr=2.06e-05
2024-09-23 00:29:59,917 - logger.py:50 - Epoch: [2][450/500] loss: 1.53954, MAE: 0.32628, time/step=1945ms, lr=2.06e-05
2024-09-23 00:31:33,093 - logger.py:50 - Epoch: [2][499/500] loss: 1.51348, MAE: 0.32560, time/step=1941ms, lr=2.06e-05
2024-09-23 00:32:51,912 - logger.py:50 - Epoch: [2] train loss: 1.51348, train MAE: 0.32560,val loss: 0.32256, val MAE: 0.32256,test loss: 0.33460, test MAE: 0.33460,Time: 1049.08s
2024-09-23 00:32:51,912 - logger.py:50 - Best -- epoch=2, train loss: 1.51348, val loss: 0.32256, test loss: 0.33460

2024-09-23 00:32:53,489 - logger.py:50 - Epoch: [3][0/500] loss: 1.79491, MAE: 0.34624, time/step=1575ms, lr=3.04e-05
2024-09-23 00:34:23,823 - logger.py:50 - Epoch: [3][50/500] loss: 1.43894, MAE: 0.32354, time/step=1802ms, lr=3.04e-05
2024-09-23 00:35:49,902 - logger.py:50 - Epoch: [3][100/500] loss: 1.41078, MAE: 0.32470, time/step=1762ms, lr=3.04e-05
2024-09-23 00:37:17,482 - logger.py:50 - Epoch: [3][150/500] loss: 1.33018, MAE: 0.31743, time/step=1759ms, lr=3.04e-05
2024-09-23 00:38:46,847 - logger.py:50 - Epoch: [3][200/500] loss: 1.36205, MAE: 0.31712, time/step=1766ms, lr=3.04e-05
2024-09-23 00:40:17,653 - logger.py:50 - Epoch: [3][250/500] loss: 1.33844, MAE: 0.31722, time/step=1776ms, lr=3.04e-05
2024-09-23 00:41:41,714 - logger.py:50 - Epoch: [3][300/500] loss: 1.34074, MAE: 0.31680, time/step=1760ms, lr=3.04e-05
2024-09-23 00:43:02,860 - logger.py:50 - Epoch: [3][350/500] loss: 1.32412, MAE: 0.31645, time/step=1741ms, lr=3.04e-05
2024-09-23 00:44:31,400 - logger.py:50 - Epoch: [3][400/500] loss: 1.53598, MAE: 0.31991, time/step=1744ms, lr=3.04e-05
2024-09-23 00:45:53,948 - logger.py:50 - Epoch: [3][450/500] loss: 1.50453, MAE: 0.31804, time/step=1734ms, lr=3.04e-05
2024-09-23 00:47:18,077 - logger.py:50 - Epoch: [3][499/500] loss: 1.47887, MAE: 0.31742, time/step=1732ms, lr=3.04e-05
2024-09-23 00:48:33,833 - logger.py:50 - Epoch: [3] train loss: 1.47887, train MAE: 0.31742,val loss: 0.31616, val MAE: 0.31616,test loss: 0.32817, test MAE: 0.32817,Time: 941.92s
2024-09-23 00:48:33,834 - logger.py:50 - Best -- epoch=3, train loss: 1.47887, val loss: 0.31616, test loss: 0.32817

2024-09-23 00:48:34,900 - logger.py:50 - Epoch: [4][0/500] loss: 0.89345, MAE: 0.27201, time/step=1063ms, lr=4.02e-05
2024-09-23 00:49:57,438 - logger.py:50 - Epoch: [4][50/500] loss: 1.24212, MAE: 0.30290, time/step=1639ms, lr=4.02e-05
2024-09-23 00:51:19,631 - logger.py:50 - Epoch: [4][100/500] loss: 1.22376, MAE: 0.30207, time/step=1642ms, lr=4.02e-05
2024-09-23 00:52:44,194 - logger.py:50 - Epoch: [4][150/500] loss: 1.81740, MAE: 0.31619, time/step=1658ms, lr=4.02e-05
2024-09-23 00:54:05,288 - logger.py:50 - Epoch: [4][200/500] loss: 1.71009, MAE: 0.31796, time/step=1649ms, lr=4.02e-05
2024-09-23 00:55:31,720 - logger.py:50 - Epoch: [4][250/500] loss: 1.60779, MAE: 0.31598, time/step=1665ms, lr=4.02e-05
2024-09-23 00:56:52,156 - logger.py:50 - Epoch: [4][300/500] loss: 1.57580, MAE: 0.31546, time/step=1656ms, lr=4.02e-05
2024-09-23 00:58:12,329 - logger.py:50 - Epoch: [4][350/500] loss: 1.53396, MAE: 0.31450, time/step=1648ms, lr=4.02e-05
2024-09-23 00:59:33,706 - logger.py:50 - Epoch: [4][400/500] loss: 1.49766, MAE: 0.31269, time/step=1646ms, lr=4.02e-05
2024-09-23 01:00:55,848 - logger.py:50 - Epoch: [4][450/500] loss: 1.48227, MAE: 0.31262, time/step=1645ms, lr=4.02e-05
2024-09-23 01:02:15,086 - logger.py:50 - Epoch: [4][499/500] loss: 1.46470, MAE: 0.31285, time/step=1642ms, lr=4.02e-05
2024-09-23 01:03:29,597 - logger.py:50 - Epoch: [4] train loss: 1.46470, train MAE: 0.31285,val loss: 0.31327, val MAE: 0.31327,test loss: 0.32510, test MAE: 0.32510,Time: 895.76s
2024-09-23 01:03:29,597 - logger.py:50 - Best -- epoch=4, train loss: 1.46470, val loss: 0.31327, test loss: 0.32510

2024-09-23 01:03:31,189 - logger.py:50 - Epoch: [5][0/500] loss: 1.39449, MAE: 0.32095, time/step=1589ms, lr=4.99e-05
2024-09-23 01:04:48,534 - logger.py:50 - Epoch: [5][50/500] loss: 1.40330, MAE: 0.31383, time/step=1548ms, lr=4.99e-05
2024-09-23 01:06:08,714 - logger.py:50 - Epoch: [5][100/500] loss: 1.33061, MAE: 0.30400, time/step=1575ms, lr=4.99e-05
2024-09-23 01:07:27,164 - logger.py:50 - Epoch: [5][150/500] loss: 1.32246, MAE: 0.30758, time/step=1573ms, lr=4.99e-05
2024-09-23 01:08:51,862 - logger.py:50 - Epoch: [5][200/500] loss: 1.32057, MAE: 0.30821, time/step=1603ms, lr=4.99e-05
2024-09-23 01:10:19,289 - logger.py:50 - Epoch: [5][250/500] loss: 1.64384, MAE: 0.31474, time/step=1632ms, lr=4.99e-05
2024-09-23 01:11:43,721 - logger.py:50 - Epoch: [5][300/500] loss: 1.59647, MAE: 0.31431, time/step=1642ms, lr=4.99e-05
2024-09-23 01:13:12,147 - logger.py:50 - Epoch: [5][350/500] loss: 1.53505, MAE: 0.31135, time/step=1660ms, lr=4.99e-05
2024-09-23 01:14:36,393 - logger.py:50 - Epoch: [5][400/500] loss: 1.49264, MAE: 0.31068, time/step=1663ms, lr=4.99e-05
2024-09-23 01:16:01,914 - logger.py:50 - Epoch: [5][450/500] loss: 1.47913, MAE: 0.31086, time/step=1668ms, lr=4.99e-05
2024-09-23 01:17:29,900 - logger.py:50 - Epoch: [5][499/500] loss: 1.45928, MAE: 0.31040, time/step=1681ms, lr=4.99e-05
2024-09-23 01:18:44,742 - logger.py:50 - Epoch: [5] train loss: 1.45928, train MAE: 0.31040,val loss: 0.31143, val MAE: 0.31143,test loss: 0.32335, test MAE: 0.32335,Time: 915.14s
2024-09-23 01:18:44,742 - logger.py:50 - Best -- epoch=5, train loss: 1.45928, val loss: 0.31143, test loss: 0.32335

2024-09-23 01:18:46,274 - logger.py:50 - Epoch: [6][0/500] loss: 0.67991, MAE: 0.23236, time/step=1529ms, lr=4.98e-05
2024-09-23 01:20:09,924 - logger.py:50 - Epoch: [6][50/500] loss: 2.99829, MAE: 0.34283, time/step=1670ms, lr=4.98e-05
2024-09-23 01:21:29,518 - logger.py:50 - Epoch: [6][100/500] loss: 2.16003, MAE: 0.32573, time/step=1631ms, lr=4.98e-05
2024-09-23 01:22:52,603 - logger.py:50 - Epoch: [6][150/500] loss: 1.85834, MAE: 0.31950, time/step=1641ms, lr=4.98e-05
2024-09-23 01:24:17,572 - logger.py:50 - Epoch: [6][200/500] loss: 1.72909, MAE: 0.31528, time/step=1656ms, lr=4.98e-05
2024-09-23 01:25:42,385 - logger.py:50 - Epoch: [6][250/500] loss: 1.63368, MAE: 0.31409, time/step=1664ms, lr=4.98e-05
2024-09-23 01:27:02,971 - logger.py:50 - Epoch: [6][300/500] loss: 1.58537, MAE: 0.31267, time/step=1655ms, lr=4.98e-05
2024-09-23 01:28:25,543 - logger.py:50 - Epoch: [6][350/500] loss: 1.54439, MAE: 0.31119, time/step=1655ms, lr=4.98e-05
2024-09-23 01:29:42,095 - logger.py:50 - Epoch: [6][400/500] loss: 1.50632, MAE: 0.31077, time/step=1639ms, lr=4.98e-05
2024-09-23 01:31:02,724 - logger.py:50 - Epoch: [6][450/500] loss: 1.48508, MAE: 0.31002, time/step=1636ms, lr=4.98e-05
2024-09-23 01:32:24,473 - logger.py:50 - Epoch: [6][499/500] loss: 1.45678, MAE: 0.30909, time/step=1639ms, lr=4.98e-05
2024-09-23 01:33:38,725 - logger.py:50 - Epoch: [6] train loss: 1.45678, train MAE: 0.30909,val loss: 0.31062, val MAE: 0.31062,test loss: 0.32266, test MAE: 0.32266,Time: 893.98s
2024-09-23 01:33:38,726 - logger.py:50 - Best -- epoch=6, train loss: 1.45678, val loss: 0.31062, test loss: 0.32266

2024-09-23 01:33:40,334 - logger.py:50 - Epoch: [7][0/500] loss: 0.85913, MAE: 0.29875, time/step=1605ms, lr=4.97e-05
2024-09-23 01:34:58,413 - logger.py:50 - Epoch: [7][50/500] loss: 1.29401, MAE: 0.30510, time/step=1562ms, lr=4.97e-05
2024-09-23 01:36:25,983 - logger.py:50 - Epoch: [7][100/500] loss: 1.25487, MAE: 0.30347, time/step=1656ms, lr=4.97e-05
2024-09-23 01:37:49,426 - logger.py:50 - Epoch: [7][150/500] loss: 1.24695, MAE: 0.30296, time/step=1660ms, lr=4.97e-05
2024-09-23 01:39:13,770 - logger.py:50 - Epoch: [7][200/500] loss: 1.27199, MAE: 0.30295, time/step=1667ms, lr=4.97e-05
2024-09-23 01:40:43,623 - logger.py:50 - Epoch: [7][250/500] loss: 1.28152, MAE: 0.30537, time/step=1693ms, lr=4.97e-05
2024-09-23 01:42:16,309 - logger.py:50 - Epoch: [7][300/500] loss: 1.26562, MAE: 0.30442, time/step=1720ms, lr=4.97e-05
2024-09-23 01:43:55,744 - logger.py:50 - Epoch: [7][350/500] loss: 1.26508, MAE: 0.30430, time/step=1758ms, lr=4.97e-05
2024-09-23 01:45:36,837 - logger.py:50 - Epoch: [7][400/500] loss: 1.26738, MAE: 0.30399, time/step=1791ms, lr=4.97e-05
2024-09-23 01:47:18,713 - logger.py:50 - Epoch: [7][450/500] loss: 1.46243, MAE: 0.30902, time/step=1818ms, lr=4.97e-05
2024-09-23 01:48:58,563 - logger.py:50 - Epoch: [7][499/500] loss: 1.45561, MAE: 0.30862, time/step=1840ms, lr=4.97e-05
2024-09-23 01:50:30,504 - logger.py:50 - Epoch: [7] train loss: 1.45561, train MAE: 0.30862,val loss: 0.31024, val MAE: 0.31024,test loss: 0.32219, test MAE: 0.32219,Time: 1011.78s
2024-09-23 01:50:30,504 - logger.py:50 - Best -- epoch=7, train loss: 1.45561, val loss: 0.31024, test loss: 0.32219

2024-09-23 01:50:32,130 - logger.py:50 - Epoch: [8][0/500] loss: 1.24277, MAE: 0.29500, time/step=1623ms, lr=4.97e-05
2024-09-23 01:52:12,229 - logger.py:50 - Epoch: [8][50/500] loss: 1.29122, MAE: 0.30034, time/step=1995ms, lr=4.97e-05
2024-09-23 01:53:53,507 - logger.py:50 - Epoch: [8][100/500] loss: 1.38579, MAE: 0.30653, time/step=2010ms, lr=4.97e-05
2024-09-23 01:55:32,707 - logger.py:50 - Epoch: [8][150/500] loss: 1.35196, MAE: 0.30755, time/step=2001ms, lr=4.97e-05
2024-09-23 01:57:13,131 - logger.py:50 - Epoch: [8][200/500] loss: 1.33666, MAE: 0.30551, time/step=2003ms, lr=4.97e-05
2024-09-23 01:58:51,996 - logger.py:50 - Epoch: [8][250/500] loss: 1.33218, MAE: 0.30568, time/step=1998ms, lr=4.97e-05
2024-09-23 02:00:27,867 - logger.py:50 - Epoch: [8][300/500] loss: 1.31095, MAE: 0.30378, time/step=1985ms, lr=4.97e-05
2024-09-23 02:02:07,816 - logger.py:50 - Epoch: [8][350/500] loss: 1.54037, MAE: 0.30864, time/step=1987ms, lr=4.97e-05
2024-09-23 02:03:42,148 - logger.py:50 - Epoch: [8][400/500] loss: 1.50259, MAE: 0.30926, time/step=1974ms, lr=4.97e-05
2024-09-23 02:05:14,284 - logger.py:50 - Epoch: [8][450/500] loss: 1.48550, MAE: 0.30997, time/step=1960ms, lr=4.97e-05
2024-09-23 02:06:39,916 - logger.py:50 - Epoch: [8][499/500] loss: 1.45483, MAE: 0.30816, time/step=1939ms, lr=4.97e-05
2024-09-23 02:07:56,986 - logger.py:50 - Epoch: [8] train loss: 1.45483, train MAE: 0.30816,val loss: 0.30902, val MAE: 0.30902,test loss: 0.32090, test MAE: 0.32090,Time: 1046.48s
2024-09-23 02:07:56,986 - logger.py:50 - Best -- epoch=8, train loss: 1.45483, val loss: 0.30902, test loss: 0.32090

2024-09-23 02:07:58,598 - logger.py:50 - Epoch: [9][0/500] loss: 1.62904, MAE: 0.32300, time/step=1609ms, lr=4.96e-05
2024-09-23 02:09:27,035 - logger.py:50 - Epoch: [9][50/500] loss: 1.27680, MAE: 0.30534, time/step=1766ms, lr=4.96e-05
2024-09-23 02:10:54,255 - logger.py:50 - Epoch: [9][100/500] loss: 1.29215, MAE: 0.30645, time/step=1755ms, lr=4.96e-05
2024-09-23 02:12:27,153 - logger.py:50 - Epoch: [9][150/500] loss: 1.28730, MAE: 0.30573, time/step=1789ms, lr=4.96e-05
2024-09-23 02:13:47,165 - logger.py:50 - Epoch: [9][200/500] loss: 1.29911, MAE: 0.30673, time/step=1742ms, lr=4.96e-05
2024-09-23 02:15:13,650 - logger.py:50 - Epoch: [9][250/500] loss: 1.30067, MAE: 0.30743, time/step=1740ms, lr=4.96e-05
2024-09-23 02:16:42,742 - logger.py:50 - Epoch: [9][300/500] loss: 1.28438, MAE: 0.30703, time/step=1747ms, lr=4.96e-05
2024-09-23 02:18:04,771 - logger.py:50 - Epoch: [9][350/500] loss: 1.29390, MAE: 0.30643, time/step=1732ms, lr=4.96e-05
2024-09-23 02:19:28,703 - logger.py:50 - Epoch: [9][400/500] loss: 1.50910, MAE: 0.31045, time/step=1725ms, lr=4.96e-05
2024-09-23 02:20:59,386 - logger.py:50 - Epoch: [9][450/500] loss: 1.48588, MAE: 0.30928, time/step=1735ms, lr=4.96e-05
2024-09-23 02:22:18,923 - logger.py:50 - Epoch: [9][499/500] loss: 1.45409, MAE: 0.30771, time/step=1724ms, lr=4.96e-05
2024-09-23 02:23:33,403 - logger.py:50 - Epoch: [9] train loss: 1.45409, train MAE: 0.30771,val loss: 0.30865, val MAE: 0.30865,test loss: 0.32059, test MAE: 0.32059,Time: 936.42s
2024-09-23 02:23:33,403 - logger.py:50 - Best -- epoch=9, train loss: 1.45409, val loss: 0.30865, test loss: 0.32059

2024-09-23 02:23:34,371 - logger.py:50 - Epoch: [10][0/500] loss: 1.77976, MAE: 0.35405, time/step=965ms, lr=4.95e-05
2024-09-23 02:24:55,616 - logger.py:50 - Epoch: [10][50/500] loss: 1.32677, MAE: 0.30015, time/step=1612ms, lr=4.95e-05
2024-09-23 02:26:21,213 - logger.py:50 - Epoch: [10][100/500] loss: 1.30593, MAE: 0.30276, time/step=1661ms, lr=4.95e-05
2024-09-23 02:27:43,628 - logger.py:50 - Epoch: [10][150/500] loss: 1.86889, MAE: 0.31551, time/step=1657ms, lr=4.95e-05
2024-09-23 02:29:02,398 - logger.py:50 - Epoch: [10][200/500] loss: 1.70612, MAE: 0.31284, time/step=1637ms, lr=4.95e-05
2024-09-23 02:30:30,398 - logger.py:50 - Epoch: [10][250/500] loss: 1.61905, MAE: 0.31162, time/step=1661ms, lr=4.95e-05
2024-09-23 02:31:47,613 - logger.py:50 - Epoch: [10][300/500] loss: 1.55377, MAE: 0.31014, time/step=1642ms, lr=4.95e-05
2024-09-23 02:33:08,946 - logger.py:50 - Epoch: [10][350/500] loss: 1.51131, MAE: 0.30901, time/step=1640ms, lr=4.95e-05
2024-09-23 02:34:34,864 - logger.py:50 - Epoch: [10][400/500] loss: 1.49239, MAE: 0.30870, time/step=1650ms, lr=4.95e-05
2024-09-23 02:35:55,613 - logger.py:50 - Epoch: [10][450/500] loss: 1.47753, MAE: 0.30807, time/step=1646ms, lr=4.95e-05
2024-09-23 02:37:13,748 - logger.py:50 - Epoch: [10][499/500] loss: 1.45376, MAE: 0.30753, time/step=1641ms, lr=4.95e-05
2024-09-23 02:38:27,900 - logger.py:50 - Epoch: [10] train loss: 1.45376, train MAE: 0.30753,val loss: 0.30830, val MAE: 0.30830,test loss: 0.32035, test MAE: 0.32035,Time: 894.50s
2024-09-23 02:38:27,901 - logger.py:50 - Best -- epoch=10, train loss: 1.45376, val loss: 0.30830, test loss: 0.32035

2024-09-23 02:38:29,457 - logger.py:50 - Epoch: [11][0/500] loss: 0.67833, MAE: 0.26273, time/step=1554ms, lr=4.94e-05
2024-09-23 02:39:48,475 - logger.py:50 - Epoch: [11][50/500] loss: 1.19003, MAE: 0.30077, time/step=1580ms, lr=4.94e-05
2024-09-23 02:41:08,537 - logger.py:50 - Epoch: [11][100/500] loss: 1.24292, MAE: 0.30092, time/step=1590ms, lr=4.94e-05
2024-09-23 02:42:32,479 - logger.py:50 - Epoch: [11][150/500] loss: 1.26248, MAE: 0.30144, time/step=1620ms, lr=4.94e-05
2024-09-23 02:43:48,528 - logger.py:50 - Epoch: [11][200/500] loss: 1.24869, MAE: 0.30074, time/step=1595ms, lr=4.94e-05
2024-09-23 02:45:10,881 - logger.py:50 - Epoch: [11][250/500] loss: 1.58357, MAE: 0.30838, time/step=1605ms, lr=4.94e-05
2024-09-23 02:46:31,719 - logger.py:50 - Epoch: [11][300/500] loss: 1.52752, MAE: 0.30772, time/step=1607ms, lr=4.94e-05
2024-09-23 02:47:50,349 - logger.py:50 - Epoch: [11][350/500] loss: 1.51164, MAE: 0.30795, time/step=1602ms, lr=4.94e-05
2024-09-23 02:49:09,364 - logger.py:50 - Epoch: [11][400/500] loss: 1.48425, MAE: 0.30678, time/step=1600ms, lr=4.94e-05
2024-09-23 02:50:32,247 - logger.py:50 - Epoch: [11][450/500] loss: 1.46541, MAE: 0.30757, time/step=1606ms, lr=4.94e-05
2024-09-23 02:51:45,717 - logger.py:50 - Epoch: [11][499/500] loss: 1.45365, MAE: 0.30748, time/step=1596ms, lr=4.94e-05
2024-09-23 02:53:03,143 - logger.py:50 - Epoch: [11] train loss: 1.45365, train MAE: 0.30748,val loss: 0.30814, val MAE: 0.30814,test loss: 0.32003, test MAE: 0.32003,Time: 875.24s
2024-09-23 02:53:03,144 - logger.py:50 - Best -- epoch=11, train loss: 1.45365, val loss: 0.30814, test loss: 0.32003

2024-09-23 02:53:04,391 - logger.py:50 - Epoch: [12][0/500] loss: 2.05462, MAE: 0.35334, time/step=1245ms, lr=4.92e-05
2024-09-23 02:54:28,538 - logger.py:50 - Epoch: [12][50/500] loss: 1.36191, MAE: 0.30619, time/step=1674ms, lr=4.92e-05
2024-09-23 02:55:53,065 - logger.py:50 - Epoch: [12][100/500] loss: 1.37312, MAE: 0.30822, time/step=1682ms, lr=4.92e-05
2024-09-23 02:57:26,234 - logger.py:50 - Epoch: [12][150/500] loss: 1.36790, MAE: 0.31125, time/step=1742ms, lr=4.92e-05
2024-09-23 02:58:52,838 - logger.py:50 - Epoch: [12][200/500] loss: 1.33229, MAE: 0.30826, time/step=1740ms, lr=4.92e-05
2024-09-23 03:00:11,637 - logger.py:50 - Epoch: [12][250/500] loss: 1.31397, MAE: 0.30488, time/step=1707ms, lr=4.92e-05
2024-09-23 03:01:38,859 - logger.py:50 - Epoch: [12][300/500] loss: 1.32254, MAE: 0.30627, time/step=1713ms, lr=4.92e-05
2024-09-23 03:02:57,808 - logger.py:50 - Epoch: [12][350/500] loss: 1.29700, MAE: 0.30515, time/step=1694ms, lr=4.92e-05
2024-09-23 03:04:19,499 - logger.py:50 - Epoch: [12][400/500] loss: 1.28537, MAE: 0.30411, time/step=1687ms, lr=4.92e-05
2024-09-23 03:05:42,192 - logger.py:50 - Epoch: [12][450/500] loss: 1.27721, MAE: 0.30313, time/step=1683ms, lr=4.92e-05
2024-09-23 03:07:03,206 - logger.py:50 - Epoch: [12][499/500] loss: 1.45343, MAE: 0.30724, time/step=1680ms, lr=4.92e-05
2024-09-23 03:08:19,743 - logger.py:50 - Epoch: [12] train loss: 1.45343, train MAE: 0.30724,val loss: 0.30924, val MAE: 0.30924,test loss: 0.32132, test MAE: 0.32132,Time: 916.60s
2024-09-23 03:08:19,743 - logger.py:50 - Best -- epoch=11, train loss: 1.45365, val loss: 0.30814, test loss: 0.32003

2024-09-23 03:08:20,851 - logger.py:50 - Epoch: [13][0/500] loss: 0.81559, MAE: 0.29070, time/step=1105ms, lr=4.91e-05
2024-09-23 03:09:43,040 - logger.py:50 - Epoch: [13][50/500] loss: 1.21130, MAE: 0.30134, time/step=1633ms, lr=4.91e-05
2024-09-23 03:10:58,656 - logger.py:50 - Epoch: [13][100/500] loss: 1.31013, MAE: 0.30980, time/step=1573ms, lr=4.91e-05
2024-09-23 03:12:20,858 - logger.py:50 - Epoch: [13][150/500] loss: 1.84733, MAE: 0.31808, time/step=1597ms, lr=4.91e-05
2024-09-23 03:13:44,094 - logger.py:50 - Epoch: [13][200/500] loss: 1.72613, MAE: 0.31535, time/step=1614ms, lr=4.91e-05
2024-09-23 03:15:10,393 - logger.py:50 - Epoch: [13][250/500] loss: 1.63752, MAE: 0.31163, time/step=1636ms, lr=4.91e-05
2024-09-23 03:16:43,732 - logger.py:50 - Epoch: [13][300/500] loss: 1.58167, MAE: 0.31151, time/step=1674ms, lr=4.91e-05
2024-09-23 03:18:17,920 - logger.py:50 - Epoch: [13][350/500] loss: 1.53224, MAE: 0.31043, time/step=1704ms, lr=4.91e-05
2024-09-23 03:19:54,741 - logger.py:50 - Epoch: [13][400/500] loss: 1.49756, MAE: 0.30922, time/step=1733ms, lr=4.91e-05
2024-09-23 03:21:35,795 - logger.py:50 - Epoch: [13][450/500] loss: 1.47557, MAE: 0.30790, time/step=1765ms, lr=4.91e-05
2024-09-23 03:23:14,285 - logger.py:50 - Epoch: [13][499/500] loss: 1.45355, MAE: 0.30716, time/step=1789ms, lr=4.91e-05
2024-09-23 03:24:38,397 - logger.py:50 - Epoch: [13] train loss: 1.45355, train MAE: 0.30716,val loss: 0.30762, val MAE: 0.30762,test loss: 0.31964, test MAE: 0.31964,Time: 978.65s
2024-09-23 03:24:38,397 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-09-23 03:24:39,944 - logger.py:50 - Epoch: [14][0/500] loss: 0.91917, MAE: 0.34137, time/step=1543ms, lr=4.90e-05
2024-09-23 03:26:16,498 - logger.py:50 - Epoch: [14][50/500] loss: 1.28350, MAE: 0.30143, time/step=1923ms, lr=4.90e-05
2024-09-23 03:27:54,053 - logger.py:50 - Epoch: [14][100/500] loss: 1.24664, MAE: 0.29856, time/step=1937ms, lr=4.90e-05
2024-09-23 03:29:31,326 - logger.py:50 - Epoch: [14][150/500] loss: 1.22295, MAE: 0.29811, time/step=1940ms, lr=4.90e-05
2024-09-23 03:31:09,137 - logger.py:50 - Epoch: [14][200/500] loss: 1.22426, MAE: 0.29859, time/step=1944ms, lr=4.90e-05
2024-09-23 03:32:38,425 - logger.py:50 - Epoch: [14][250/500] loss: 1.24790, MAE: 0.30120, time/step=1912ms, lr=4.90e-05
2024-09-23 03:34:09,962 - logger.py:50 - Epoch: [14][300/500] loss: 1.26643, MAE: 0.30282, time/step=1899ms, lr=4.90e-05
2024-09-23 03:35:39,324 - logger.py:50 - Epoch: [14][350/500] loss: 1.27758, MAE: 0.30352, time/step=1883ms, lr=4.90e-05
2024-09-23 03:37:08,780 - logger.py:50 - Epoch: [14][400/500] loss: 1.49068, MAE: 0.30822, time/step=1871ms, lr=4.90e-05
2024-09-23 03:38:36,781 - logger.py:50 - Epoch: [14][450/500] loss: 1.46507, MAE: 0.30639, time/step=1859ms, lr=4.90e-05
2024-09-23 03:40:00,014 - logger.py:50 - Epoch: [14][499/500] loss: 1.45329, MAE: 0.30723, time/step=1843ms, lr=4.90e-05
2024-09-23 03:41:14,615 - logger.py:50 - Epoch: [14] train loss: 1.45329, train MAE: 0.30723,val loss: 0.30935, val MAE: 0.30935,test loss: 0.32107, test MAE: 0.32107,Time: 996.22s
2024-09-23 03:41:14,615 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-09-23 03:41:16,309 - logger.py:50 - Epoch: [15][0/500] loss: 1.20373, MAE: 0.29654, time/step=1691ms, lr=4.88e-05
2024-09-23 03:42:40,332 - logger.py:50 - Epoch: [15][50/500] loss: 1.23893, MAE: 0.29649, time/step=1681ms, lr=4.88e-05
2024-09-23 03:44:04,563 - logger.py:50 - Epoch: [15][100/500] loss: 1.25813, MAE: 0.29956, time/step=1683ms, lr=4.88e-05
2024-09-23 03:45:28,799 - logger.py:50 - Epoch: [15][150/500] loss: 1.25800, MAE: 0.30374, time/step=1683ms, lr=4.88e-05
2024-09-23 03:46:48,202 - logger.py:50 - Epoch: [15][200/500] loss: 1.67926, MAE: 0.30977, time/step=1660ms, lr=4.88e-05
2024-09-23 03:48:11,387 - logger.py:50 - Epoch: [15][250/500] loss: 1.58829, MAE: 0.30698, time/step=1660ms, lr=4.88e-05
2024-09-23 03:49:33,872 - logger.py:50 - Epoch: [15][300/500] loss: 1.54979, MAE: 0.30869, time/step=1659ms, lr=4.88e-05
2024-09-23 03:50:58,457 - logger.py:50 - Epoch: [15][350/500] loss: 1.51926, MAE: 0.30897, time/step=1663ms, lr=4.88e-05
2024-09-23 03:52:19,849 - logger.py:50 - Epoch: [15][400/500] loss: 1.48051, MAE: 0.30711, time/step=1659ms, lr=4.88e-05
2024-09-23 03:53:40,616 - logger.py:50 - Epoch: [15][450/500] loss: 1.46336, MAE: 0.30640, time/step=1654ms, lr=4.88e-05
2024-09-23 03:54:59,400 - logger.py:50 - Epoch: [15][499/500] loss: 1.45326, MAE: 0.30695, time/step=1650ms, lr=4.88e-05
2024-09-23 03:56:15,243 - logger.py:50 - Epoch: [15] train loss: 1.45326, train MAE: 0.30695,val loss: 0.30895, val MAE: 0.30895,test loss: 0.32096, test MAE: 0.32096,Time: 900.63s
2024-09-23 03:56:15,243 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-09-23 03:56:16,784 - logger.py:50 - Epoch: [16][0/500] loss: 0.81375, MAE: 0.26354, time/step=1538ms, lr=4.86e-05
2024-09-23 03:57:38,224 - logger.py:50 - Epoch: [16][50/500] loss: 1.23702, MAE: 0.29852, time/step=1627ms, lr=4.86e-05
2024-09-23 03:59:00,784 - logger.py:50 - Epoch: [16][100/500] loss: 1.29558, MAE: 0.30115, time/step=1639ms, lr=4.86e-05
2024-09-23 04:00:16,911 - logger.py:50 - Epoch: [16][150/500] loss: 1.30549, MAE: 0.30306, time/step=1600ms, lr=4.86e-05
2024-09-23 04:01:34,371 - logger.py:50 - Epoch: [16][200/500] loss: 1.27654, MAE: 0.30061, time/step=1588ms, lr=4.86e-05
2024-09-23 04:02:55,031 - logger.py:50 - Epoch: [16][250/500] loss: 1.26986, MAE: 0.29983, time/step=1593ms, lr=4.86e-05
2024-09-23 04:04:10,758 - logger.py:50 - Epoch: [16][300/500] loss: 1.28582, MAE: 0.30260, time/step=1580ms, lr=4.86e-05
2024-09-23 04:05:27,969 - logger.py:50 - Epoch: [16][350/500] loss: 1.27875, MAE: 0.30205, time/step=1575ms, lr=4.86e-05
2024-09-23 04:06:50,106 - logger.py:50 - Epoch: [16][400/500] loss: 1.29039, MAE: 0.30305, time/step=1583ms, lr=4.86e-05
2024-09-23 04:08:07,465 - logger.py:50 - Epoch: [16][450/500] loss: 1.46748, MAE: 0.30604, time/step=1579ms, lr=4.86e-05
2024-09-23 04:09:21,791 - logger.py:50 - Epoch: [16][499/500] loss: 1.45319, MAE: 0.30699, time/step=1573ms, lr=4.86e-05
2024-09-23 04:10:35,983 - logger.py:50 - Epoch: [16] train loss: 1.45319, train MAE: 0.30699,val loss: 0.30880, val MAE: 0.30880,test loss: 0.32077, test MAE: 0.32077,Time: 860.74s
2024-09-23 04:10:35,983 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-09-23 04:10:37,160 - logger.py:50 - Epoch: [17][0/500] loss: 1.34292, MAE: 0.32214, time/step=1174ms, lr=4.85e-05
2024-09-23 04:11:52,117 - logger.py:50 - Epoch: [17][50/500] loss: 1.26731, MAE: 0.29742, time/step=1493ms, lr=4.85e-05
2024-09-23 04:13:09,989 - logger.py:50 - Epoch: [17][100/500] loss: 1.32179, MAE: 0.31061, time/step=1525ms, lr=4.85e-05
2024-09-23 04:14:25,263 - logger.py:50 - Epoch: [17][150/500] loss: 1.28580, MAE: 0.30589, time/step=1518ms, lr=4.85e-05
2024-09-23 04:15:39,977 - logger.py:50 - Epoch: [17][200/500] loss: 1.31643, MAE: 0.30711, time/step=1512ms, lr=4.85e-05
2024-09-23 04:16:59,705 - logger.py:50 - Epoch: [17][250/500] loss: 1.28504, MAE: 0.30427, time/step=1529ms, lr=4.85e-05
2024-09-23 04:18:15,651 - logger.py:50 - Epoch: [17][300/500] loss: 1.28345, MAE: 0.30271, time/step=1527ms, lr=4.85e-05
2024-09-23 04:19:30,048 - logger.py:50 - Epoch: [17][350/500] loss: 1.51971, MAE: 0.30622, time/step=1522ms, lr=4.85e-05
2024-09-23 04:20:48,190 - logger.py:50 - Epoch: [17][400/500] loss: 1.49266, MAE: 0.30668, time/step=1527ms, lr=4.85e-05
2024-09-23 04:22:05,406 - logger.py:50 - Epoch: [17][450/500] loss: 1.46895, MAE: 0.30617, time/step=1529ms, lr=4.85e-05
2024-09-23 04:23:26,102 - logger.py:50 - Epoch: [17][499/500] loss: 1.45343, MAE: 0.30685, time/step=1540ms, lr=4.85e-05
2024-09-23 04:24:40,951 - logger.py:50 - Epoch: [17] train loss: 1.45343, train MAE: 0.30685,val loss: 0.30962, val MAE: 0.30962,test loss: 0.32159, test MAE: 0.32159,Time: 844.97s
2024-09-23 04:24:40,951 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-09-23 04:24:42,092 - logger.py:50 - Epoch: [18][0/500] loss: 1.17357, MAE: 0.28343, time/step=1138ms, lr=4.83e-05
2024-09-23 04:26:08,263 - logger.py:50 - Epoch: [18][50/500] loss: 1.36251, MAE: 0.30971, time/step=1712ms, lr=4.83e-05
2024-09-23 04:27:24,954 - logger.py:50 - Epoch: [18][100/500] loss: 1.36022, MAE: 0.30654, time/step=1624ms, lr=4.83e-05
2024-09-23 04:28:43,803 - logger.py:50 - Epoch: [18][150/500] loss: 1.32265, MAE: 0.30607, time/step=1608ms, lr=4.83e-05
2024-09-23 04:30:01,418 - logger.py:50 - Epoch: [18][200/500] loss: 1.33983, MAE: 0.30793, time/step=1594ms, lr=4.83e-05
2024-09-23 04:31:23,553 - logger.py:50 - Epoch: [18][250/500] loss: 1.67116, MAE: 0.31505, time/step=1604ms, lr=4.83e-05
2024-09-23 04:32:36,703 - logger.py:50 - Epoch: [18][300/500] loss: 1.59429, MAE: 0.31164, time/step=1581ms, lr=4.83e-05
2024-09-23 04:33:52,741 - logger.py:50 - Epoch: [18][350/500] loss: 1.53956, MAE: 0.30907, time/step=1572ms, lr=4.83e-05
2024-09-23 04:35:08,961 - logger.py:50 - Epoch: [18][400/500] loss: 1.51394, MAE: 0.30913, time/step=1566ms, lr=4.83e-05
2024-09-23 04:36:25,688 - logger.py:50 - Epoch: [18][450/500] loss: 1.47419, MAE: 0.30762, time/step=1563ms, lr=4.83e-05
2024-09-23 04:37:37,814 - logger.py:50 - Epoch: [18][499/500] loss: 1.45343, MAE: 0.30697, time/step=1554ms, lr=4.83e-05
2024-09-23 04:38:51,362 - logger.py:50 - Epoch: [18] train loss: 1.45343, train MAE: 0.30697,val loss: 0.30825, val MAE: 0.30825,test loss: 0.32023, test MAE: 0.32023,Time: 850.41s
2024-09-23 04:38:51,362 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-09-23 04:38:53,188 - logger.py:50 - Epoch: [19][0/500] loss: 0.79835, MAE: 0.28999, time/step=1823ms, lr=4.81e-05
2024-09-23 04:40:08,170 - logger.py:50 - Epoch: [19][50/500] loss: 1.22603, MAE: 0.29702, time/step=1506ms, lr=4.81e-05
2024-09-23 04:41:23,541 - logger.py:50 - Epoch: [19][100/500] loss: 1.29754, MAE: 0.30153, time/step=1507ms, lr=4.81e-05
2024-09-23 04:42:37,176 - logger.py:50 - Epoch: [19][150/500] loss: 1.24806, MAE: 0.30183, time/step=1495ms, lr=4.81e-05
2024-09-23 04:43:51,316 - logger.py:50 - Epoch: [19][200/500] loss: 1.27246, MAE: 0.30477, time/step=1492ms, lr=4.81e-05
2024-09-23 04:45:01,952 - logger.py:50 - Epoch: [19][250/500] loss: 1.26323, MAE: 0.30241, time/step=1476ms, lr=4.81e-05
2024-09-23 04:46:16,393 - logger.py:50 - Epoch: [19][300/500] loss: 1.27311, MAE: 0.30214, time/step=1478ms, lr=4.81e-05
2024-09-23 04:47:28,728 - logger.py:50 - Epoch: [19][350/500] loss: 1.27484, MAE: 0.30250, time/step=1474ms, lr=4.81e-05
2024-09-23 04:48:42,535 - logger.py:50 - Epoch: [19][400/500] loss: 1.48872, MAE: 0.30729, time/step=1474ms, lr=4.81e-05
2024-09-23 04:49:54,327 - logger.py:50 - Epoch: [19][450/500] loss: 1.46178, MAE: 0.30648, time/step=1470ms, lr=4.81e-05
2024-09-23 04:51:04,688 - logger.py:50 - Epoch: [19][499/500] loss: 1.45330, MAE: 0.30671, time/step=1467ms, lr=4.81e-05
2024-09-23 04:52:18,594 - logger.py:50 - Epoch: [19] train loss: 1.45330, train MAE: 0.30671,val loss: 0.30957, val MAE: 0.30957,test loss: 0.32116, test MAE: 0.32116,Time: 807.23s
2024-09-23 04:52:18,595 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-09-23 04:52:19,669 - logger.py:50 - Epoch: [20][0/500] loss: 0.86664, MAE: 0.26591, time/step=1072ms, lr=4.79e-05
2024-09-23 04:53:31,060 - logger.py:50 - Epoch: [20][50/500] loss: 1.40337, MAE: 0.31592, time/step=1421ms, lr=4.79e-05
2024-09-23 04:54:43,865 - logger.py:50 - Epoch: [20][100/500] loss: 1.31813, MAE: 0.31184, time/step=1438ms, lr=4.79e-05
2024-09-23 04:55:58,082 - logger.py:50 - Epoch: [20][150/500] loss: 1.30464, MAE: 0.30857, time/step=1454ms, lr=4.79e-05
2024-09-23 04:57:08,478 - logger.py:50 - Epoch: [20][200/500] loss: 1.32168, MAE: 0.30858, time/step=1442ms, lr=4.79e-05
2024-09-23 04:58:21,122 - logger.py:50 - Epoch: [20][250/500] loss: 1.65333, MAE: 0.31303, time/step=1444ms, lr=4.79e-05
2024-09-23 04:59:33,386 - logger.py:50 - Epoch: [20][300/500] loss: 1.57935, MAE: 0.31208, time/step=1444ms, lr=4.79e-05
2024-09-23 05:00:49,819 - logger.py:50 - Epoch: [20][350/500] loss: 1.54287, MAE: 0.30986, time/step=1456ms, lr=4.79e-05
2024-09-23 05:02:02,380 - logger.py:50 - Epoch: [20][400/500] loss: 1.50463, MAE: 0.30779, time/step=1456ms, lr=4.79e-05
2024-09-23 05:03:19,947 - logger.py:50 - Epoch: [20][450/500] loss: 1.47716, MAE: 0.30729, time/step=1466ms, lr=4.79e-05
2024-09-23 05:04:35,676 - logger.py:50 - Epoch: [20][499/500] loss: 1.45325, MAE: 0.30653, time/step=1474ms, lr=4.79e-05
2024-09-23 05:05:47,771 - logger.py:50 - Epoch: [20] train loss: 1.45325, train MAE: 0.30653,val loss: 0.30784, val MAE: 0.30784,test loss: 0.31985, test MAE: 0.31985,Time: 809.18s
2024-09-23 05:05:47,771 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-09-23 05:05:49,380 - logger.py:50 - Epoch: [21][0/500] loss: 1.67355, MAE: 0.36536, time/step=1606ms, lr=4.77e-05
2024-09-23 05:07:04,140 - logger.py:50 - Epoch: [21][50/500] loss: 1.22963, MAE: 0.30076, time/step=1497ms, lr=4.77e-05
2024-09-23 05:08:19,935 - logger.py:50 - Epoch: [21][100/500] loss: 1.19108, MAE: 0.29874, time/step=1507ms, lr=4.77e-05
2024-09-23 05:09:35,022 - logger.py:50 - Epoch: [21][150/500] loss: 1.26657, MAE: 0.30758, time/step=1505ms, lr=4.77e-05
2024-09-23 05:10:48,762 - logger.py:50 - Epoch: [21][200/500] loss: 1.25840, MAE: 0.30583, time/step=1497ms, lr=4.77e-05
2024-09-23 05:12:04,044 - logger.py:50 - Epoch: [21][250/500] loss: 1.27614, MAE: 0.30467, time/step=1499ms, lr=4.77e-05
2024-09-23 05:13:17,180 - logger.py:50 - Epoch: [21][300/500] loss: 1.25975, MAE: 0.30394, time/step=1493ms, lr=4.77e-05
2024-09-23 05:14:30,222 - logger.py:50 - Epoch: [21][350/500] loss: 1.26727, MAE: 0.30364, time/step=1488ms, lr=4.77e-05
2024-09-23 05:15:44,757 - logger.py:50 - Epoch: [21][400/500] loss: 1.27047, MAE: 0.30375, time/step=1489ms, lr=4.77e-05
2024-09-23 05:16:58,673 - logger.py:50 - Epoch: [21][450/500] loss: 1.45600, MAE: 0.30637, time/step=1488ms, lr=4.77e-05
2024-09-23 05:18:08,637 - logger.py:50 - Epoch: [21][499/500] loss: 1.45342, MAE: 0.30648, time/step=1482ms, lr=4.77e-05
2024-09-23 05:19:24,610 - logger.py:50 - Epoch: [21] train loss: 1.45342, train MAE: 0.30648,val loss: 0.30971, val MAE: 0.30971,test loss: 0.32151, test MAE: 0.32151,Time: 816.84s
2024-09-23 05:19:24,610 - logger.py:50 - Best -- epoch=13, train loss: 1.45355, val loss: 0.30762, test loss: 0.31964

2024-09-23 05:19:25,614 - logger.py:50 - Epoch: [22][0/500] loss: 0.59971, MAE: 0.26053, time/step=1001ms, lr=4.74e-05
2024-09-23 05:20:38,918 - logger.py:50 - Epoch: [22][50/500] loss: 1.31493, MAE: 0.30638, time/step=1457ms, lr=4.74e-05
2024-09-23 05:21:48,900 - logger.py:50 - Epoch: [22][100/500] loss: 1.30104, MAE: 0.30429, time/step=1429ms, lr=4.74e-05
2024-09-23 05:23:01,961 - logger.py:50 - Epoch: [22][150/500] loss: 1.32341, MAE: 0.30328, time/step=1439ms, lr=4.74e-05
2024-09-23 05:24:14,283 - logger.py:50 - Epoch: [22][200/500] loss: 1.31817, MAE: 0.30442, time/step=1441ms, lr=4.74e-05
2024-09-23 05:25:26,781 - logger.py:50 - Epoch: [22][250/500] loss: 1.31907, MAE: 0.30625, time/step=1443ms, lr=4.74e-05
2024-09-23 05:26:36,522 - logger.py:50 - Epoch: [22][300/500] loss: 1.59162, MAE: 0.30980, time/step=1435ms, lr=4.74e-05
2024-09-23 05:27:46,022 - logger.py:50 - Epoch: [22][350/500] loss: 1.53036, MAE: 0.30811, time/step=1429ms, lr=4.74e-05
2024-09-23 05:28:58,762 - logger.py:50 - Epoch: [22][400/500] loss: 1.50227, MAE: 0.30670, time/step=1432ms, lr=4.74e-05
2024-09-23 05:30:11,715 - logger.py:50 - Epoch: [22][450/500] loss: 1.46440, MAE: 0.30598, time/step=1435ms, lr=4.74e-05
2024-09-23 05:31:21,404 - logger.py:50 - Epoch: [22][499/500] loss: 1.45303, MAE: 0.30627, time/step=1434ms, lr=4.74e-05
2024-09-23 05:32:33,440 - logger.py:50 - Epoch: [22] train loss: 1.45303, train MAE: 0.30627,val loss: 0.30731, val MAE: 0.30731,test loss: 0.31940, test MAE: 0.31940,Time: 788.83s
2024-09-23 05:32:33,440 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 05:32:35,076 - logger.py:50 - Epoch: [23][0/500] loss: 1.81658, MAE: 0.35152, time/step=1633ms, lr=4.72e-05
2024-09-23 05:33:45,437 - logger.py:50 - Epoch: [23][50/500] loss: 1.16733, MAE: 0.30146, time/step=1412ms, lr=4.72e-05
2024-09-23 05:34:55,480 - logger.py:50 - Epoch: [23][100/500] loss: 1.22732, MAE: 0.30256, time/step=1406ms, lr=4.72e-05
2024-09-23 05:36:05,612 - logger.py:50 - Epoch: [23][150/500] loss: 1.21529, MAE: 0.30197, time/step=1405ms, lr=4.72e-05
2024-09-23 05:37:17,291 - logger.py:50 - Epoch: [23][200/500] loss: 1.21093, MAE: 0.30003, time/step=1412ms, lr=4.72e-05
2024-09-23 05:38:32,082 - logger.py:50 - Epoch: [23][250/500] loss: 1.23999, MAE: 0.30102, time/step=1429ms, lr=4.72e-05
2024-09-23 05:39:49,894 - logger.py:50 - Epoch: [23][300/500] loss: 1.25273, MAE: 0.30097, time/step=1450ms, lr=4.72e-05
2024-09-23 05:41:05,417 - logger.py:50 - Epoch: [23][350/500] loss: 1.25940, MAE: 0.30234, time/step=1459ms, lr=4.72e-05
2024-09-23 05:42:15,901 - logger.py:50 - Epoch: [23][400/500] loss: 1.25759, MAE: 0.30257, time/step=1453ms, lr=4.72e-05
2024-09-23 05:43:29,216 - logger.py:50 - Epoch: [23][450/500] loss: 1.45332, MAE: 0.30579, time/step=1454ms, lr=4.72e-05
2024-09-23 05:44:41,545 - logger.py:50 - Epoch: [23][499/500] loss: 1.45331, MAE: 0.30636, time/step=1456ms, lr=4.72e-05
2024-09-23 05:45:52,979 - logger.py:50 - Epoch: [23] train loss: 1.45331, train MAE: 0.30636,val loss: 0.31002, val MAE: 0.31002,test loss: 0.32207, test MAE: 0.32207,Time: 799.54s
2024-09-23 05:45:52,980 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 05:45:53,962 - logger.py:50 - Epoch: [24][0/500] loss: 0.69268, MAE: 0.22135, time/step=980ms, lr=4.70e-05
2024-09-23 05:47:05,705 - logger.py:50 - Epoch: [24][50/500] loss: 1.24626, MAE: 0.30696, time/step=1426ms, lr=4.70e-05
2024-09-23 05:48:18,916 - logger.py:50 - Epoch: [24][100/500] loss: 1.20681, MAE: 0.30088, time/step=1445ms, lr=4.70e-05
2024-09-23 05:49:30,278 - logger.py:50 - Epoch: [24][150/500] loss: 1.24171, MAE: 0.30054, time/step=1439ms, lr=4.70e-05
2024-09-23 05:50:39,851 - logger.py:50 - Epoch: [24][200/500] loss: 1.23961, MAE: 0.30144, time/step=1427ms, lr=4.70e-05
2024-09-23 05:51:50,777 - logger.py:50 - Epoch: [24][250/500] loss: 1.27082, MAE: 0.30277, time/step=1425ms, lr=4.70e-05
2024-09-23 05:53:01,765 - logger.py:50 - Epoch: [24][300/500] loss: 1.27315, MAE: 0.30445, time/step=1425ms, lr=4.70e-05
2024-09-23 05:54:14,941 - logger.py:50 - Epoch: [24][350/500] loss: 1.28681, MAE: 0.30410, time/step=1430ms, lr=4.70e-05
2024-09-23 05:55:24,919 - logger.py:50 - Epoch: [24][400/500] loss: 1.29467, MAE: 0.30442, time/step=1426ms, lr=4.70e-05
2024-09-23 05:56:36,566 - logger.py:50 - Epoch: [24][450/500] loss: 1.48316, MAE: 0.30777, time/step=1427ms, lr=4.70e-05
2024-09-23 05:57:45,751 - logger.py:50 - Epoch: [24][499/500] loss: 1.45324, MAE: 0.30611, time/step=1426ms, lr=4.70e-05
2024-09-23 05:58:57,621 - logger.py:50 - Epoch: [24] train loss: 1.45324, train MAE: 0.30611,val loss: 0.30792, val MAE: 0.30792,test loss: 0.31996, test MAE: 0.31996,Time: 784.64s
2024-09-23 05:58:57,622 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 05:58:58,688 - logger.py:50 - Epoch: [25][0/500] loss: 1.16932, MAE: 0.26260, time/step=1064ms, lr=4.67e-05
2024-09-23 06:00:09,050 - logger.py:50 - Epoch: [25][50/500] loss: 1.36626, MAE: 0.30590, time/step=1401ms, lr=4.67e-05
2024-09-23 06:01:17,613 - logger.py:50 - Epoch: [25][100/500] loss: 1.37536, MAE: 0.30987, time/step=1386ms, lr=4.67e-05
2024-09-23 06:02:27,859 - logger.py:50 - Epoch: [25][150/500] loss: 1.31248, MAE: 0.30728, time/step=1392ms, lr=4.67e-05
2024-09-23 06:03:38,471 - logger.py:50 - Epoch: [25][200/500] loss: 1.32533, MAE: 0.30787, time/step=1397ms, lr=4.67e-05
2024-09-23 06:04:49,985 - logger.py:50 - Epoch: [25][250/500] loss: 1.29743, MAE: 0.30633, time/step=1404ms, lr=4.67e-05
2024-09-23 06:05:59,093 - logger.py:50 - Epoch: [25][300/500] loss: 1.27308, MAE: 0.30352, time/step=1400ms, lr=4.67e-05
2024-09-23 06:07:10,737 - logger.py:50 - Epoch: [25][350/500] loss: 1.28341, MAE: 0.30387, time/step=1405ms, lr=4.67e-05
2024-09-23 06:08:21,855 - logger.py:50 - Epoch: [25][400/500] loss: 1.49642, MAE: 0.30759, time/step=1407ms, lr=4.67e-05
2024-09-23 06:09:31,225 - logger.py:50 - Epoch: [25][450/500] loss: 1.47445, MAE: 0.30700, time/step=1405ms, lr=4.67e-05
2024-09-23 06:10:39,168 - logger.py:50 - Epoch: [25][499/500] loss: 1.45311, MAE: 0.30612, time/step=1403ms, lr=4.67e-05
2024-09-23 06:11:50,846 - logger.py:50 - Epoch: [25] train loss: 1.45311, train MAE: 0.30612,val loss: 0.30828, val MAE: 0.30828,test loss: 0.32006, test MAE: 0.32006,Time: 773.22s
2024-09-23 06:11:50,846 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 06:11:51,738 - logger.py:50 - Epoch: [26][0/500] loss: 1.42218, MAE: 0.33147, time/step=889ms, lr=4.65e-05
2024-09-23 06:13:01,209 - logger.py:50 - Epoch: [26][50/500] loss: 1.29104, MAE: 0.30714, time/step=1380ms, lr=4.65e-05
2024-09-23 06:14:11,886 - logger.py:50 - Epoch: [26][100/500] loss: 2.08408, MAE: 0.31846, time/step=1396ms, lr=4.65e-05
2024-09-23 06:15:23,252 - logger.py:50 - Epoch: [26][150/500] loss: 1.82121, MAE: 0.31098, time/step=1407ms, lr=4.65e-05
2024-09-23 06:16:34,942 - logger.py:50 - Epoch: [26][200/500] loss: 1.68906, MAE: 0.30825, time/step=1413ms, lr=4.65e-05
2024-09-23 06:17:48,422 - logger.py:50 - Epoch: [26][250/500] loss: 1.63271, MAE: 0.30927, time/step=1425ms, lr=4.65e-05
2024-09-23 06:19:01,378 - logger.py:50 - Epoch: [26][300/500] loss: 1.57411, MAE: 0.30763, time/step=1430ms, lr=4.65e-05
2024-09-23 06:20:14,311 - logger.py:50 - Epoch: [26][350/500] loss: 1.53720, MAE: 0.30615, time/step=1434ms, lr=4.65e-05
2024-09-23 06:21:26,970 - logger.py:50 - Epoch: [26][400/500] loss: 1.50228, MAE: 0.30652, time/step=1437ms, lr=4.65e-05
2024-09-23 06:22:39,431 - logger.py:50 - Epoch: [26][450/500] loss: 1.47714, MAE: 0.30671, time/step=1438ms, lr=4.65e-05
2024-09-23 06:23:48,306 - logger.py:50 - Epoch: [26][499/500] loss: 1.45335, MAE: 0.30618, time/step=1435ms, lr=4.65e-05
2024-09-23 06:25:01,600 - logger.py:50 - Epoch: [26] train loss: 1.45335, train MAE: 0.30618,val loss: 0.30745, val MAE: 0.30745,test loss: 0.31947, test MAE: 0.31947,Time: 790.75s
2024-09-23 06:25:01,601 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 06:25:03,248 - logger.py:50 - Epoch: [27][0/500] loss: 1.24016, MAE: 0.26852, time/step=1644ms, lr=4.62e-05
2024-09-23 06:26:14,565 - logger.py:50 - Epoch: [27][50/500] loss: 1.19103, MAE: 0.29916, time/step=1431ms, lr=4.62e-05
2024-09-23 06:27:24,615 - logger.py:50 - Epoch: [27][100/500] loss: 1.22259, MAE: 0.30217, time/step=1416ms, lr=4.62e-05
2024-09-23 06:28:36,529 - logger.py:50 - Epoch: [27][150/500] loss: 1.76573, MAE: 0.31022, time/step=1423ms, lr=4.62e-05
2024-09-23 06:29:48,733 - logger.py:50 - Epoch: [27][200/500] loss: 1.62663, MAE: 0.30719, time/step=1429ms, lr=4.62e-05
2024-09-23 06:31:01,395 - logger.py:50 - Epoch: [27][250/500] loss: 1.54631, MAE: 0.30557, time/step=1433ms, lr=4.62e-05
2024-09-23 06:32:12,902 - logger.py:50 - Epoch: [27][300/500] loss: 1.53918, MAE: 0.30668, time/step=1433ms, lr=4.62e-05
2024-09-23 06:33:23,896 - logger.py:50 - Epoch: [27][350/500] loss: 1.49374, MAE: 0.30700, time/step=1431ms, lr=4.62e-05
2024-09-23 06:34:34,938 - logger.py:50 - Epoch: [27][400/500] loss: 1.49574, MAE: 0.30743, time/step=1430ms, lr=4.62e-05
2024-09-23 06:35:44,472 - logger.py:50 - Epoch: [27][450/500] loss: 1.47193, MAE: 0.30688, time/step=1425ms, lr=4.62e-05
2024-09-23 06:36:52,188 - logger.py:50 - Epoch: [27][499/500] loss: 1.45318, MAE: 0.30598, time/step=1421ms, lr=4.62e-05
2024-09-23 06:38:03,995 - logger.py:50 - Epoch: [27] train loss: 1.45318, train MAE: 0.30598,val loss: 0.30808, val MAE: 0.30808,test loss: 0.31987, test MAE: 0.31987,Time: 782.39s
2024-09-23 06:38:03,996 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 06:38:04,933 - logger.py:50 - Epoch: [28][0/500] loss: 0.96832, MAE: 0.27165, time/step=935ms, lr=4.59e-05
2024-09-23 06:39:13,977 - logger.py:50 - Epoch: [28][50/500] loss: 1.33603, MAE: 0.31067, time/step=1372ms, lr=4.59e-05
2024-09-23 06:40:22,981 - logger.py:50 - Epoch: [28][100/500] loss: 1.33297, MAE: 0.30803, time/step=1376ms, lr=4.59e-05
2024-09-23 06:41:32,924 - logger.py:50 - Epoch: [28][150/500] loss: 1.29632, MAE: 0.30527, time/step=1384ms, lr=4.59e-05
2024-09-23 06:42:43,763 - logger.py:50 - Epoch: [28][200/500] loss: 1.27768, MAE: 0.30275, time/step=1392ms, lr=4.59e-05
2024-09-23 06:43:56,252 - logger.py:50 - Epoch: [28][250/500] loss: 1.27424, MAE: 0.30272, time/step=1403ms, lr=4.59e-05
2024-09-23 06:45:06,808 - logger.py:50 - Epoch: [28][300/500] loss: 1.28575, MAE: 0.30420, time/step=1405ms, lr=4.59e-05
2024-09-23 06:46:18,623 - logger.py:50 - Epoch: [28][350/500] loss: 1.28137, MAE: 0.30386, time/step=1409ms, lr=4.59e-05
2024-09-23 06:47:30,072 - logger.py:50 - Epoch: [28][400/500] loss: 1.27224, MAE: 0.30327, time/step=1412ms, lr=4.59e-05
2024-09-23 06:48:40,719 - logger.py:50 - Epoch: [28][450/500] loss: 1.27889, MAE: 0.30354, time/step=1412ms, lr=4.59e-05
2024-09-23 06:49:56,188 - logger.py:50 - Epoch: [28][499/500] loss: 1.45336, MAE: 0.30600, time/step=1424ms, lr=4.59e-05
2024-09-23 06:51:09,730 - logger.py:50 - Epoch: [28] train loss: 1.45336, train MAE: 0.30600,val loss: 0.30744, val MAE: 0.30744,test loss: 0.31942, test MAE: 0.31942,Time: 785.73s
2024-09-23 06:51:09,730 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 06:51:10,816 - logger.py:50 - Epoch: [29][0/500] loss: 0.43219, MAE: 0.24228, time/step=1083ms, lr=4.56e-05
2024-09-23 06:52:21,578 - logger.py:50 - Epoch: [29][50/500] loss: 1.24960, MAE: 0.30025, time/step=1409ms, lr=4.56e-05
2024-09-23 06:53:32,980 - logger.py:50 - Epoch: [29][100/500] loss: 1.30962, MAE: 0.30712, time/step=1418ms, lr=4.56e-05
2024-09-23 06:54:45,407 - logger.py:50 - Epoch: [29][150/500] loss: 1.29851, MAE: 0.30569, time/step=1428ms, lr=4.56e-05
2024-09-23 06:55:57,892 - logger.py:50 - Epoch: [29][200/500] loss: 1.29390, MAE: 0.30555, time/step=1434ms, lr=4.56e-05
2024-09-23 06:57:09,004 - logger.py:50 - Epoch: [29][250/500] loss: 1.31134, MAE: 0.30467, time/step=1431ms, lr=4.56e-05
2024-09-23 06:58:20,408 - logger.py:50 - Epoch: [29][300/500] loss: 1.30584, MAE: 0.30455, time/step=1431ms, lr=4.56e-05
2024-09-23 06:59:31,050 - logger.py:50 - Epoch: [29][350/500] loss: 1.30012, MAE: 0.30393, time/step=1428ms, lr=4.56e-05
2024-09-23 07:00:42,635 - logger.py:50 - Epoch: [29][400/500] loss: 1.29162, MAE: 0.30323, time/step=1429ms, lr=4.56e-05
2024-09-23 07:01:53,603 - logger.py:50 - Epoch: [29][450/500] loss: 1.27765, MAE: 0.30209, time/step=1428ms, lr=4.56e-05
2024-09-23 07:03:03,353 - logger.py:50 - Epoch: [29][499/500] loss: 1.45334, MAE: 0.30600, time/step=1427ms, lr=4.56e-05
2024-09-23 07:04:16,251 - logger.py:50 - Epoch: [29] train loss: 1.45334, train MAE: 0.30600,val loss: 0.30933, val MAE: 0.30933,test loss: 0.32111, test MAE: 0.32111,Time: 786.52s
2024-09-23 07:04:16,251 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 07:04:17,763 - logger.py:50 - Epoch: [30][0/500] loss: 1.32460, MAE: 0.29682, time/step=1509ms, lr=4.53e-05
2024-09-23 07:05:27,765 - logger.py:50 - Epoch: [30][50/500] loss: 1.23100, MAE: 0.29911, time/step=1402ms, lr=4.53e-05
2024-09-23 07:06:37,142 - logger.py:50 - Epoch: [30][100/500] loss: 1.23839, MAE: 0.29819, time/step=1395ms, lr=4.53e-05
2024-09-23 07:07:48,912 - logger.py:50 - Epoch: [30][150/500] loss: 1.27272, MAE: 0.30086, time/step=1408ms, lr=4.53e-05
2024-09-23 07:08:59,742 - logger.py:50 - Epoch: [30][200/500] loss: 1.25241, MAE: 0.29816, time/step=1410ms, lr=4.53e-05
2024-09-23 07:10:10,218 - logger.py:50 - Epoch: [30][250/500] loss: 1.25265, MAE: 0.29998, time/step=1410ms, lr=4.53e-05
2024-09-23 07:11:20,073 - logger.py:50 - Epoch: [30][300/500] loss: 1.26405, MAE: 0.30082, time/step=1408ms, lr=4.53e-05
2024-09-23 07:12:31,101 - logger.py:50 - Epoch: [30][350/500] loss: 1.27684, MAE: 0.30141, time/step=1410ms, lr=4.53e-05
2024-09-23 07:13:41,282 - logger.py:50 - Epoch: [30][400/500] loss: 1.26828, MAE: 0.30066, time/step=1409ms, lr=4.53e-05
2024-09-23 07:14:53,010 - logger.py:50 - Epoch: [30][450/500] loss: 1.28304, MAE: 0.30217, time/step=1412ms, lr=4.53e-05
2024-09-23 07:16:03,314 - logger.py:50 - Epoch: [30][499/500] loss: 1.45319, MAE: 0.30597, time/step=1414ms, lr=4.53e-05
2024-09-23 07:17:15,185 - logger.py:50 - Epoch: [30] train loss: 1.45319, train MAE: 0.30597,val loss: 0.30805, val MAE: 0.30805,test loss: 0.31996, test MAE: 0.31996,Time: 778.93s
2024-09-23 07:17:15,185 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 07:17:16,743 - logger.py:50 - Epoch: [31][0/500] loss: 4.40225, MAE: 0.27709, time/step=1554ms, lr=4.50e-05
2024-09-23 07:18:27,107 - logger.py:50 - Epoch: [31][50/500] loss: 1.27223, MAE: 0.29669, time/step=1410ms, lr=4.50e-05
2024-09-23 07:19:36,458 - logger.py:50 - Epoch: [31][100/500] loss: 1.29025, MAE: 0.29657, time/step=1399ms, lr=4.50e-05
2024-09-23 07:20:45,777 - logger.py:50 - Epoch: [31][150/500] loss: 1.30647, MAE: 0.30206, time/step=1395ms, lr=4.50e-05
2024-09-23 07:21:56,641 - logger.py:50 - Epoch: [31][200/500] loss: 1.28457, MAE: 0.30154, time/step=1400ms, lr=4.50e-05
2024-09-23 07:23:08,938 - logger.py:50 - Epoch: [31][250/500] loss: 1.63006, MAE: 0.30760, time/step=1409ms, lr=4.50e-05
2024-09-23 07:24:19,136 - logger.py:50 - Epoch: [31][300/500] loss: 1.56724, MAE: 0.30559, time/step=1408ms, lr=4.50e-05
2024-09-23 07:25:30,551 - logger.py:50 - Epoch: [31][350/500] loss: 1.52465, MAE: 0.30537, time/step=1411ms, lr=4.50e-05
2024-09-23 07:26:41,694 - logger.py:50 - Epoch: [31][400/500] loss: 1.50444, MAE: 0.30567, time/step=1413ms, lr=4.50e-05
2024-09-23 07:27:52,691 - logger.py:50 - Epoch: [31][450/500] loss: 1.47895, MAE: 0.30635, time/step=1414ms, lr=4.50e-05
2024-09-23 07:29:01,503 - logger.py:50 - Epoch: [31][499/500] loss: 1.45365, MAE: 0.30600, time/step=1413ms, lr=4.50e-05
2024-09-23 07:30:18,121 - logger.py:50 - Epoch: [31] train loss: 1.45365, train MAE: 0.30600,val loss: 0.30821, val MAE: 0.30821,test loss: 0.32034, test MAE: 0.32034,Time: 782.94s
2024-09-23 07:30:18,121 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 07:30:19,728 - logger.py:50 - Epoch: [32][0/500] loss: 1.24430, MAE: 0.28453, time/step=1604ms, lr=4.47e-05
2024-09-23 07:31:30,362 - logger.py:50 - Epoch: [32][50/500] loss: 1.23418, MAE: 0.29854, time/step=1416ms, lr=4.47e-05
2024-09-23 07:32:39,548 - logger.py:50 - Epoch: [32][100/500] loss: 1.20408, MAE: 0.29529, time/step=1400ms, lr=4.47e-05
2024-09-23 07:33:48,188 - logger.py:50 - Epoch: [32][150/500] loss: 1.23881, MAE: 0.30073, time/step=1391ms, lr=4.47e-05
2024-09-23 07:34:58,475 - logger.py:50 - Epoch: [32][200/500] loss: 1.24087, MAE: 0.30022, time/step=1395ms, lr=4.47e-05
2024-09-23 07:36:10,019 - logger.py:50 - Epoch: [32][250/500] loss: 1.56554, MAE: 0.30585, time/step=1402ms, lr=4.47e-05
2024-09-23 07:37:21,216 - logger.py:50 - Epoch: [32][300/500] loss: 1.53108, MAE: 0.30680, time/step=1406ms, lr=4.47e-05
2024-09-23 07:38:33,219 - logger.py:50 - Epoch: [32][350/500] loss: 1.48538, MAE: 0.30577, time/step=1411ms, lr=4.47e-05
2024-09-23 07:39:48,560 - logger.py:50 - Epoch: [32][400/500] loss: 1.47457, MAE: 0.30555, time/step=1423ms, lr=4.47e-05
2024-09-23 07:41:01,586 - logger.py:50 - Epoch: [32][450/500] loss: 1.46226, MAE: 0.30578, time/step=1427ms, lr=4.47e-05
2024-09-23 07:42:12,407 - logger.py:50 - Epoch: [32][499/500] loss: 1.45325, MAE: 0.30580, time/step=1429ms, lr=4.47e-05
2024-09-23 07:43:25,846 - logger.py:50 - Epoch: [32] train loss: 1.45325, train MAE: 0.30580,val loss: 0.30832, val MAE: 0.30832,test loss: 0.32035, test MAE: 0.32035,Time: 787.72s
2024-09-23 07:43:25,846 - logger.py:50 - Best -- epoch=22, train loss: 1.45303, val loss: 0.30731, test loss: 0.31940

2024-09-23 07:43:27,392 - logger.py:50 - Epoch: [33][0/500] loss: 1.69115, MAE: 0.35934, time/step=1543ms, lr=4.44e-05
2024-09-23 07:44:38,754 - logger.py:50 - Epoch: [33][50/500] loss: 1.30569, MAE: 0.30748, time/step=1430ms, lr=4.44e-05
2024-09-23 07:45:49,847 - logger.py:50 - Epoch: [33][100/500] loss: 1.27586, MAE: 0.30351, time/step=1426ms, lr=4.44e-05
2024-09-23 07:47:01,323 - logger.py:50 - Epoch: [33][150/500] loss: 1.80459, MAE: 0.31084, time/step=1427ms, lr=4.44e-05
2024-09-23 07:48:14,062 - logger.py:50 - Epoch: [33][200/500] loss: 1.65022, MAE: 0.30858, time/step=1434ms, lr=4.44e-05
2024-09-23 07:49:28,265 - logger.py:50 - Epoch: [33][250/500] loss: 1.56745, MAE: 0.30611, time/step=1444ms, lr=4.44e-05
2024-09-23 07:50:40,759 - logger.py:50 - Epoch: [33][300/500] loss: 1.53925, MAE: 0.30692, time/step=1445ms, lr=4.44e-05
2024-09-23 07:51:53,403 - logger.py:50 - Epoch: [33][350/500] loss: 1.52016, MAE: 0.30762, time/step=1446ms, lr=4.44e-05
2024-09-23 07:53:06,753 - logger.py:50 - Epoch: [33][400/500] loss: 1.49644, MAE: 0.30754, time/step=1449ms, lr=4.44e-05
2024-09-23 07:54:19,482 - logger.py:50 - Epoch: [33][450/500] loss: 1.45717, MAE: 0.30601, time/step=1449ms, lr=4.44e-05
2024-09-23 07:55:29,837 - logger.py:50 - Epoch: [33][499/500] loss: 1.45342, MAE: 0.30583, time/step=1448ms, lr=4.44e-05
2024-09-23 07:56:43,122 - logger.py:50 - Epoch: [33] train loss: 1.45342, train MAE: 0.30583,val loss: 0.30726, val MAE: 0.30726,test loss: 0.31922, test MAE: 0.31922,Time: 797.28s
2024-09-23 07:56:43,122 - logger.py:50 - Best -- epoch=33, train loss: 1.45342, val loss: 0.30726, test loss: 0.31922

2024-09-23 07:56:44,121 - logger.py:50 - Epoch: [34][0/500] loss: 0.53426, MAE: 0.20340, time/step=996ms, lr=4.40e-05
2024-09-23 07:57:55,591 - logger.py:50 - Epoch: [34][50/500] loss: 1.34592, MAE: 0.30303, time/step=1421ms, lr=4.40e-05
2024-09-23 07:59:09,845 - logger.py:50 - Epoch: [34][100/500] loss: 2.15818, MAE: 0.31701, time/step=1453ms, lr=4.40e-05
2024-09-23 08:00:23,382 - logger.py:50 - Epoch: [34][150/500] loss: 1.87167, MAE: 0.31372, time/step=1459ms, lr=4.40e-05
2024-09-23 08:01:34,939 - logger.py:50 - Epoch: [34][200/500] loss: 1.70300, MAE: 0.30825, time/step=1452ms, lr=4.40e-05
2024-09-23 08:02:47,837 - logger.py:50 - Epoch: [34][250/500] loss: 1.60647, MAE: 0.30652, time/step=1453ms, lr=4.40e-05
2024-09-23 08:03:58,943 - logger.py:50 - Epoch: [34][300/500] loss: 1.56243, MAE: 0.30494, time/step=1448ms, lr=4.40e-05
2024-09-23 08:05:09,327 - logger.py:50 - Epoch: [34][350/500] loss: 1.51978, MAE: 0.30471, time/step=1442ms, lr=4.40e-05
2024-09-23 08:06:22,247 - logger.py:50 - Epoch: [34][400/500] loss: 1.48588, MAE: 0.30478, time/step=1444ms, lr=4.40e-05
2024-09-23 08:07:35,470 - logger.py:50 - Epoch: [34][450/500] loss: 1.46965, MAE: 0.30512, time/step=1446ms, lr=4.40e-05
2024-09-23 08:08:45,432 - logger.py:50 - Epoch: [34][499/500] loss: 1.45339, MAE: 0.30579, time/step=1445ms, lr=4.40e-05
2024-09-23 08:09:58,230 - logger.py:50 - Epoch: [34] train loss: 1.45339, train MAE: 0.30579,val loss: 0.30768, val MAE: 0.30768,test loss: 0.31973, test MAE: 0.31973,Time: 795.11s
2024-09-23 08:09:58,230 - logger.py:50 - Best -- epoch=33, train loss: 1.45342, val loss: 0.30726, test loss: 0.31922

2024-09-23 08:09:59,842 - logger.py:50 - Epoch: [35][0/500] loss: 1.24907, MAE: 0.24604, time/step=1609ms, lr=4.37e-05
2024-09-23 08:11:09,551 - logger.py:50 - Epoch: [35][50/500] loss: 1.33348, MAE: 0.31472, time/step=1398ms, lr=4.37e-05
2024-09-23 08:12:21,302 - logger.py:50 - Epoch: [35][100/500] loss: 1.25229, MAE: 0.30266, time/step=1417ms, lr=4.37e-05
2024-09-23 08:13:33,003 - logger.py:50 - Epoch: [35][150/500] loss: 1.30340, MAE: 0.30711, time/step=1422ms, lr=4.37e-05
2024-09-23 08:14:42,563 - logger.py:50 - Epoch: [35][200/500] loss: 1.30422, MAE: 0.30742, time/step=1415ms, lr=4.37e-05
2024-09-23 08:15:54,646 - logger.py:50 - Epoch: [35][250/500] loss: 1.29123, MAE: 0.30740, time/step=1420ms, lr=4.37e-05
2024-09-23 08:17:08,300 - logger.py:50 - Epoch: [35][300/500] loss: 1.30152, MAE: 0.30720, time/step=1429ms, lr=4.37e-05
2024-09-23 08:18:19,144 - logger.py:50 - Epoch: [35][350/500] loss: 1.30984, MAE: 0.30576, time/step=1427ms, lr=4.37e-05
2024-09-23 08:19:29,665 - logger.py:50 - Epoch: [35][400/500] loss: 1.50828, MAE: 0.30769, time/step=1425ms, lr=4.37e-05
2024-09-23 08:20:41,637 - logger.py:50 - Epoch: [35][450/500] loss: 1.48226, MAE: 0.30645, time/step=1427ms, lr=4.37e-05
2024-09-23 08:21:52,020 - logger.py:50 - Epoch: [35][499/500] loss: 1.45332, MAE: 0.30557, time/step=1428ms, lr=4.37e-05
2024-09-23 08:23:04,174 - logger.py:50 - Epoch: [35] train loss: 1.45332, train MAE: 0.30557,val loss: 0.30748, val MAE: 0.30748,test loss: 0.31943, test MAE: 0.31943,Time: 785.94s
2024-09-23 08:23:04,174 - logger.py:50 - Best -- epoch=33, train loss: 1.45342, val loss: 0.30726, test loss: 0.31922

2024-09-23 08:23:05,665 - logger.py:50 - Epoch: [36][0/500] loss: 1.22233, MAE: 0.28077, time/step=1489ms, lr=4.34e-05
2024-09-23 08:24:15,162 - logger.py:50 - Epoch: [36][50/500] loss: 1.31843, MAE: 0.30343, time/step=1392ms, lr=4.34e-05
2024-09-23 08:25:26,318 - logger.py:50 - Epoch: [36][100/500] loss: 1.26010, MAE: 0.30177, time/step=1407ms, lr=4.34e-05
2024-09-23 08:26:38,806 - logger.py:50 - Epoch: [36][150/500] loss: 1.26407, MAE: 0.30031, time/step=1421ms, lr=4.34e-05
2024-09-23 08:27:50,082 - logger.py:50 - Epoch: [36][200/500] loss: 1.26439, MAE: 0.29790, time/step=1422ms, lr=4.34e-05
2024-09-23 08:29:00,582 - logger.py:50 - Epoch: [36][250/500] loss: 1.27518, MAE: 0.30112, time/step=1420ms, lr=4.34e-05
2024-09-23 08:30:12,303 - logger.py:50 - Epoch: [36][300/500] loss: 1.27672, MAE: 0.30108, time/step=1422ms, lr=4.34e-05
2024-09-23 08:31:23,333 - logger.py:50 - Epoch: [36][350/500] loss: 1.53271, MAE: 0.30718, time/step=1422ms, lr=4.34e-05
2024-09-23 08:32:34,258 - logger.py:50 - Epoch: [36][400/500] loss: 1.50800, MAE: 0.30716, time/step=1422ms, lr=4.34e-05
2024-09-23 08:33:46,464 - logger.py:50 - Epoch: [36][450/500] loss: 1.47109, MAE: 0.30543, time/step=1424ms, lr=4.34e-05
2024-09-23 08:34:56,133 - logger.py:50 - Epoch: [36][499/500] loss: 1.45319, MAE: 0.30566, time/step=1424ms, lr=4.34e-05
2024-09-23 08:36:08,876 - logger.py:50 - Epoch: [36] train loss: 1.45319, train MAE: 0.30566,val loss: 0.30779, val MAE: 0.30779,test loss: 0.31981, test MAE: 0.31981,Time: 784.70s
2024-09-23 08:36:08,876 - logger.py:50 - Best -- epoch=33, train loss: 1.45342, val loss: 0.30726, test loss: 0.31922

2024-09-23 08:36:09,942 - logger.py:50 - Epoch: [37][0/500] loss: 1.25768, MAE: 0.32057, time/step=1064ms, lr=4.30e-05
2024-09-23 08:37:21,164 - logger.py:50 - Epoch: [37][50/500] loss: 1.29519, MAE: 0.30532, time/step=1417ms, lr=4.30e-05
2024-09-23 08:38:31,533 - logger.py:50 - Epoch: [37][100/500] loss: 1.28213, MAE: 0.29854, time/step=1412ms, lr=4.30e-05
2024-09-23 08:39:41,363 - logger.py:50 - Epoch: [37][150/500] loss: 1.34658, MAE: 0.30499, time/step=1407ms, lr=4.30e-05
2024-09-23 08:40:52,072 - logger.py:50 - Epoch: [37][200/500] loss: 1.35373, MAE: 0.30521, time/step=1409ms, lr=4.30e-05
2024-09-23 08:42:04,671 - logger.py:50 - Epoch: [37][250/500] loss: 1.34706, MAE: 0.30487, time/step=1418ms, lr=4.30e-05
2024-09-23 08:43:16,309 - logger.py:50 - Epoch: [37][300/500] loss: 1.32870, MAE: 0.30497, time/step=1420ms, lr=4.30e-05
2024-09-23 08:44:28,898 - logger.py:50 - Epoch: [37][350/500] loss: 1.30234, MAE: 0.30258, time/step=1425ms, lr=4.30e-05
2024-09-23 08:45:40,590 - logger.py:50 - Epoch: [37][400/500] loss: 1.50294, MAE: 0.30599, time/step=1426ms, lr=4.30e-05
2024-09-23 08:46:52,694 - logger.py:50 - Epoch: [37][450/500] loss: 1.47716, MAE: 0.30585, time/step=1428ms, lr=4.30e-05
2024-09-23 08:48:01,818 - logger.py:50 - Epoch: [37][499/500] loss: 1.45354, MAE: 0.30568, time/step=1426ms, lr=4.30e-05
2024-09-23 08:49:15,914 - logger.py:50 - Epoch: [37] train loss: 1.45354, train MAE: 0.30568,val loss: 0.30762, val MAE: 0.30762,test loss: 0.31963, test MAE: 0.31963,Time: 787.04s
2024-09-23 08:49:15,914 - logger.py:50 - Best -- epoch=33, train loss: 1.45342, val loss: 0.30726, test loss: 0.31922

2024-09-23 08:49:17,724 - logger.py:50 - Epoch: [38][0/500] loss: 2.05798, MAE: 0.36752, time/step=1807ms, lr=4.26e-05
2024-09-23 08:50:28,276 - logger.py:50 - Epoch: [38][50/500] loss: 1.37245, MAE: 0.30351, time/step=1419ms, lr=4.26e-05
2024-09-23 08:51:39,046 - logger.py:50 - Epoch: [38][100/500] loss: 1.29093, MAE: 0.30199, time/step=1417ms, lr=4.26e-05
2024-09-23 08:52:49,242 - logger.py:50 - Epoch: [38][150/500] loss: 1.26574, MAE: 0.30018, time/step=1413ms, lr=4.26e-05
2024-09-23 08:54:01,923 - logger.py:50 - Epoch: [38][200/500] loss: 1.68903, MAE: 0.31014, time/step=1423ms, lr=4.26e-05
2024-09-23 08:55:14,182 - logger.py:50 - Epoch: [38][250/500] loss: 1.59406, MAE: 0.30846, time/step=1427ms, lr=4.26e-05
2024-09-23 08:56:25,754 - logger.py:50 - Epoch: [38][300/500] loss: 1.54096, MAE: 0.30779, time/step=1428ms, lr=4.26e-05
2024-09-23 08:57:36,751 - logger.py:50 - Epoch: [38][350/500] loss: 1.50265, MAE: 0.30674, time/step=1427ms, lr=4.26e-05
2024-09-23 08:58:47,673 - logger.py:50 - Epoch: [38][400/500] loss: 1.48386, MAE: 0.30668, time/step=1426ms, lr=4.26e-05
2024-09-23 08:59:59,251 - logger.py:50 - Epoch: [38][450/500] loss: 1.47394, MAE: 0.30621, time/step=1426ms, lr=4.26e-05
2024-09-23 09:01:07,707 - logger.py:50 - Epoch: [38][499/500] loss: 1.45338, MAE: 0.30558, time/step=1424ms, lr=4.26e-05
2024-09-23 09:02:20,273 - logger.py:50 - Epoch: [38] train loss: 1.45338, train MAE: 0.30558,val loss: 0.30770, val MAE: 0.30770,test loss: 0.31976, test MAE: 0.31976,Time: 784.36s
2024-09-23 09:02:20,273 - logger.py:50 - Best -- epoch=33, train loss: 1.45342, val loss: 0.30726, test loss: 0.31922

2024-09-23 09:02:21,960 - logger.py:50 - Epoch: [39][0/500] loss: 1.03510, MAE: 0.33145, time/step=1684ms, lr=4.23e-05
2024-09-23 09:03:32,856 - logger.py:50 - Epoch: [39][50/500] loss: 1.31928, MAE: 0.31098, time/step=1423ms, lr=4.23e-05
2024-09-23 09:04:43,723 - logger.py:50 - Epoch: [39][100/500] loss: 1.31132, MAE: 0.30600, time/step=1420ms, lr=4.23e-05
2024-09-23 09:05:53,473 - logger.py:50 - Epoch: [39][150/500] loss: 1.27613, MAE: 0.30304, time/step=1412ms, lr=4.23e-05
2024-09-23 09:07:04,656 - logger.py:50 - Epoch: [39][200/500] loss: 1.26270, MAE: 0.30128, time/step=1415ms, lr=4.23e-05
2024-09-23 09:08:14,448 - logger.py:50 - Epoch: [39][250/500] loss: 1.27976, MAE: 0.30271, time/step=1411ms, lr=4.23e-05
2024-09-23 09:09:27,154 - logger.py:50 - Epoch: [39][300/500] loss: 1.27214, MAE: 0.30105, time/step=1418ms, lr=4.23e-05
2024-09-23 09:10:37,727 - logger.py:50 - Epoch: [39][350/500] loss: 1.27050, MAE: 0.30132, time/step=1417ms, lr=4.23e-05
2024-09-23 09:11:51,620 - logger.py:50 - Epoch: [39][400/500] loss: 1.27495, MAE: 0.30270, time/step=1425ms, lr=4.23e-05
2024-09-23 09:13:04,855 - logger.py:50 - Epoch: [39][450/500] loss: 1.27339, MAE: 0.30204, time/step=1429ms, lr=4.23e-05
2024-09-23 09:14:13,810 - logger.py:50 - Epoch: [39][499/500] loss: 1.45327, MAE: 0.30539, time/step=1427ms, lr=4.23e-05
2024-09-23 09:15:26,703 - logger.py:50 - Epoch: [39] train loss: 1.45327, train MAE: 0.30539,val loss: 0.30753, val MAE: 0.30753,test loss: 0.31949, test MAE: 0.31949,Time: 786.43s
2024-09-23 09:15:26,703 - logger.py:50 - Best -- epoch=33, train loss: 1.45342, val loss: 0.30726, test loss: 0.31922

2024-09-23 09:15:28,177 - logger.py:50 - Epoch: [40][0/500] loss: 0.94307, MAE: 0.31400, time/step=1472ms, lr=4.19e-05
2024-09-23 09:16:38,927 - logger.py:50 - Epoch: [40][50/500] loss: 1.34380, MAE: 0.30690, time/step=1416ms, lr=4.19e-05
2024-09-23 09:17:50,295 - logger.py:50 - Epoch: [40][100/500] loss: 1.29448, MAE: 0.30296, time/step=1422ms, lr=4.19e-05
2024-09-23 09:19:03,546 - logger.py:50 - Epoch: [40][150/500] loss: 1.27632, MAE: 0.30107, time/step=1436ms, lr=4.19e-05
2024-09-23 09:20:15,156 - logger.py:50 - Epoch: [40][200/500] loss: 1.28972, MAE: 0.30119, time/step=1435ms, lr=4.19e-05
2024-09-23 09:21:26,988 - logger.py:50 - Epoch: [40][250/500] loss: 1.29590, MAE: 0.30430, time/step=1435ms, lr=4.19e-05
2024-09-23 09:22:37,282 - logger.py:50 - Epoch: [40][300/500] loss: 1.29049, MAE: 0.30352, time/step=1430ms, lr=4.19e-05
2024-09-23 09:23:49,076 - logger.py:50 - Epoch: [40][350/500] loss: 1.29033, MAE: 0.30327, time/step=1431ms, lr=4.19e-05
2024-09-23 09:24:58,629 - logger.py:50 - Epoch: [40][400/500] loss: 1.48866, MAE: 0.30627, time/step=1426ms, lr=4.19e-05
2024-09-23 09:26:10,131 - logger.py:50 - Epoch: [40][450/500] loss: 1.47576, MAE: 0.30665, time/step=1427ms, lr=4.19e-05
2024-09-23 09:27:20,931 - logger.py:50 - Epoch: [40][499/500] loss: 1.45298, MAE: 0.30551, time/step=1428ms, lr=4.19e-05
2024-09-23 09:28:34,345 - logger.py:50 - Epoch: [40] train loss: 1.45298, train MAE: 0.30551,val loss: 0.30774, val MAE: 0.30774,test loss: 0.31968, test MAE: 0.31968,Time: 787.64s
2024-09-23 09:28:34,346 - logger.py:50 - Best -- epoch=33, train loss: 1.45342, val loss: 0.30726, test loss: 0.31922

2024-09-23 09:28:35,330 - logger.py:50 - Epoch: [41][0/500] loss: 1.52364, MAE: 0.34016, time/step=982ms, lr=4.15e-05
2024-09-23 09:29:46,008 - logger.py:50 - Epoch: [41][50/500] loss: 1.29917, MAE: 0.29813, time/step=1405ms, lr=4.15e-05
2024-09-23 09:30:57,326 - logger.py:50 - Epoch: [41][100/500] loss: 1.31167, MAE: 0.30017, time/step=1416ms, lr=4.15e-05
2024-09-23 09:32:09,445 - logger.py:50 - Epoch: [41][150/500] loss: 1.86767, MAE: 0.31307, time/step=1424ms, lr=4.15e-05
2024-09-23 09:33:21,479 - logger.py:50 - Epoch: [41][200/500] loss: 1.73079, MAE: 0.31134, time/step=1429ms, lr=4.15e-05
2024-09-23 09:34:30,846 - logger.py:50 - Epoch: [41][250/500] loss: 1.62339, MAE: 0.30707, time/step=1420ms, lr=4.15e-05
2024-09-23 09:35:42,429 - logger.py:50 - Epoch: [41][300/500] loss: 1.58057, MAE: 0.30591, time/step=1422ms, lr=4.15e-05
2024-09-23 09:36:53,559 - logger.py:50 - Epoch: [41][350/500] loss: 1.52408, MAE: 0.30521, time/step=1422ms, lr=4.15e-05
2024-09-23 09:38:06,353 - logger.py:50 - Epoch: [41][400/500] loss: 1.50110, MAE: 0.30612, time/step=1426ms, lr=4.15e-05
2024-09-23 09:39:17,632 - logger.py:50 - Epoch: [41][450/500] loss: 1.47340, MAE: 0.30553, time/step=1426ms, lr=4.15e-05
2024-09-23 09:40:27,140 - logger.py:50 - Epoch: [41][499/500] loss: 1.45319, MAE: 0.30547, time/step=1426ms, lr=4.15e-05
2024-09-23 09:41:40,031 - logger.py:50 - Epoch: [41] train loss: 1.45319, train MAE: 0.30547,val loss: 0.30702, val MAE: 0.30702,test loss: 0.31906, test MAE: 0.31906,Time: 785.69s
2024-09-23 09:41:40,032 - logger.py:50 - Best -- epoch=41, train loss: 1.45319, val loss: 0.30702, test loss: 0.31906

2024-09-23 09:41:41,000 - logger.py:50 - Epoch: [42][0/500] loss: 1.07034, MAE: 0.25978, time/step=966ms, lr=4.11e-05
2024-09-23 09:42:51,382 - logger.py:50 - Epoch: [42][50/500] loss: 1.39952, MAE: 0.31126, time/step=1399ms, lr=4.11e-05
2024-09-23 09:44:01,244 - logger.py:50 - Epoch: [42][100/500] loss: 1.34945, MAE: 0.30748, time/step=1398ms, lr=4.11e-05
2024-09-23 09:45:13,854 - logger.py:50 - Epoch: [42][150/500] loss: 1.35695, MAE: 0.30979, time/step=1416ms, lr=4.11e-05
2024-09-23 09:46:23,722 - logger.py:50 - Epoch: [42][200/500] loss: 1.76370, MAE: 0.31579, time/step=1411ms, lr=4.11e-05
2024-09-23 09:47:33,367 - logger.py:50 - Epoch: [42][250/500] loss: 1.63318, MAE: 0.31056, time/step=1408ms, lr=4.11e-05
2024-09-23 09:48:45,660 - logger.py:50 - Epoch: [42][300/500] loss: 1.55495, MAE: 0.30712, time/step=1414ms, lr=4.11e-05
2024-09-23 09:49:56,071 - logger.py:50 - Epoch: [42][350/500] loss: 1.51135, MAE: 0.30526, time/step=1413ms, lr=4.11e-05
2024-09-23 09:51:07,385 - logger.py:50 - Epoch: [42][400/500] loss: 1.48651, MAE: 0.30570, time/step=1415ms, lr=4.11e-05
2024-09-23 09:52:17,494 - logger.py:50 - Epoch: [42][450/500] loss: 1.46861, MAE: 0.30571, time/step=1413ms, lr=4.11e-05
2024-09-23 09:53:26,395 - logger.py:50 - Epoch: [42][499/500] loss: 1.45313, MAE: 0.30539, time/step=1413ms, lr=4.11e-05
2024-09-23 09:54:38,558 - logger.py:50 - Epoch: [42] train loss: 1.45313, train MAE: 0.30539,val loss: 0.30716, val MAE: 0.30716,test loss: 0.31905, test MAE: 0.31905,Time: 778.53s
2024-09-23 09:54:38,559 - logger.py:50 - Best -- epoch=41, train loss: 1.45319, val loss: 0.30702, test loss: 0.31906

2024-09-23 09:54:39,520 - logger.py:50 - Epoch: [43][0/500] loss: 0.72233, MAE: 0.24131, time/step=959ms, lr=4.07e-05
2024-09-23 09:55:49,968 - logger.py:50 - Epoch: [43][50/500] loss: 1.21130, MAE: 0.29871, time/step=1400ms, lr=4.07e-05
2024-09-23 09:57:01,800 - logger.py:50 - Epoch: [43][100/500] loss: 1.29997, MAE: 0.30669, time/step=1418ms, lr=4.07e-05
2024-09-23 09:58:14,995 - logger.py:50 - Epoch: [43][150/500] loss: 1.27781, MAE: 0.30503, time/step=1433ms, lr=4.07e-05
2024-09-23 09:59:26,709 - logger.py:50 - Epoch: [43][200/500] loss: 1.28074, MAE: 0.30429, time/step=1434ms, lr=4.07e-05
2024-09-23 10:00:37,405 - logger.py:50 - Epoch: [43][250/500] loss: 1.28753, MAE: 0.30504, time/step=1430ms, lr=4.07e-05
2024-09-23 10:01:47,092 - logger.py:50 - Epoch: [43][300/500] loss: 1.28971, MAE: 0.30447, time/step=1424ms, lr=4.07e-05
2024-09-23 10:02:59,738 - logger.py:50 - Epoch: [43][350/500] loss: 1.53666, MAE: 0.30952, time/step=1428ms, lr=4.07e-05
2024-09-23 10:04:10,390 - logger.py:50 - Epoch: [43][400/500] loss: 1.49528, MAE: 0.30722, time/step=1426ms, lr=4.07e-05
2024-09-23 10:05:22,161 - logger.py:50 - Epoch: [43][450/500] loss: 1.46456, MAE: 0.30654, time/step=1427ms, lr=4.07e-05
2024-09-23 10:06:29,876 - logger.py:50 - Epoch: [43][499/500] loss: 1.45314, MAE: 0.30539, time/step=1423ms, lr=4.07e-05
2024-09-23 10:07:42,107 - logger.py:50 - Epoch: [43] train loss: 1.45314, train MAE: 0.30539,val loss: 0.30734, val MAE: 0.30734,test loss: 0.31943, test MAE: 0.31943,Time: 783.55s
2024-09-23 10:07:42,108 - logger.py:50 - Best -- epoch=41, train loss: 1.45319, val loss: 0.30702, test loss: 0.31906

2024-09-23 10:07:43,736 - logger.py:50 - Epoch: [44][0/500] loss: 1.04215, MAE: 0.27995, time/step=1626ms, lr=4.03e-05
2024-09-23 10:08:52,945 - logger.py:50 - Epoch: [44][50/500] loss: 1.31294, MAE: 0.30424, time/step=1389ms, lr=4.03e-05
2024-09-23 10:10:04,045 - logger.py:50 - Epoch: [44][100/500] loss: 1.25990, MAE: 0.30061, time/step=1405ms, lr=4.03e-05
2024-09-23 10:11:14,963 - logger.py:50 - Epoch: [44][150/500] loss: 1.24153, MAE: 0.30075, time/step=1410ms, lr=4.03e-05
2024-09-23 10:12:26,893 - logger.py:50 - Epoch: [44][200/500] loss: 1.29090, MAE: 0.30385, time/step=1417ms, lr=4.03e-05
2024-09-23 10:13:38,323 - logger.py:50 - Epoch: [44][250/500] loss: 1.29126, MAE: 0.30379, time/step=1419ms, lr=4.03e-05
2024-09-23 10:14:49,177 - logger.py:50 - Epoch: [44][300/500] loss: 1.28796, MAE: 0.30372, time/step=1419ms, lr=4.03e-05
2024-09-23 10:16:01,470 - logger.py:50 - Epoch: [44][350/500] loss: 1.27994, MAE: 0.30333, time/step=1423ms, lr=4.03e-05
2024-09-23 10:17:11,289 - logger.py:50 - Epoch: [44][400/500] loss: 1.28362, MAE: 0.30396, time/step=1419ms, lr=4.03e-05
2024-09-23 10:18:22,101 - logger.py:50 - Epoch: [44][450/500] loss: 1.46909, MAE: 0.30533, time/step=1419ms, lr=4.03e-05
2024-09-23 10:19:32,921 - logger.py:50 - Epoch: [44][499/500] loss: 1.45311, MAE: 0.30538, time/step=1422ms, lr=4.03e-05
2024-09-23 10:20:45,010 - logger.py:50 - Epoch: [44] train loss: 1.45311, train MAE: 0.30538,val loss: 0.30749, val MAE: 0.30749,test loss: 0.31952, test MAE: 0.31952,Time: 782.90s
2024-09-23 10:20:45,010 - logger.py:50 - Best -- epoch=41, train loss: 1.45319, val loss: 0.30702, test loss: 0.31906

2024-09-23 10:20:46,429 - logger.py:50 - Epoch: [45][0/500] loss: 1.59782, MAE: 0.39860, time/step=1416ms, lr=3.99e-05
2024-09-23 10:21:56,558 - logger.py:50 - Epoch: [45][50/500] loss: 1.27940, MAE: 0.30743, time/step=1403ms, lr=3.99e-05
2024-09-23 10:23:06,132 - logger.py:50 - Epoch: [45][100/500] loss: 2.10335, MAE: 0.31631, time/step=1397ms, lr=3.99e-05
2024-09-23 10:24:18,732 - logger.py:50 - Epoch: [45][150/500] loss: 1.85087, MAE: 0.31534, time/step=1415ms, lr=3.99e-05
2024-09-23 10:25:30,052 - logger.py:50 - Epoch: [45][200/500] loss: 1.69173, MAE: 0.31054, time/step=1418ms, lr=3.99e-05
2024-09-23 10:26:42,178 - logger.py:50 - Epoch: [45][250/500] loss: 1.59864, MAE: 0.30836, time/step=1423ms, lr=3.99e-05
2024-09-23 10:27:53,388 - logger.py:50 - Epoch: [45][300/500] loss: 1.55230, MAE: 0.30699, time/step=1423ms, lr=3.99e-05
2024-09-23 10:29:03,916 - logger.py:50 - Epoch: [45][350/500] loss: 1.51756, MAE: 0.30634, time/step=1421ms, lr=3.99e-05
2024-09-23 10:30:15,819 - logger.py:50 - Epoch: [45][400/500] loss: 1.49420, MAE: 0.30639, time/step=1423ms, lr=3.99e-05
2024-09-23 10:31:27,804 - logger.py:50 - Epoch: [45][450/500] loss: 1.47051, MAE: 0.30497, time/step=1425ms, lr=3.99e-05
2024-09-23 10:32:38,268 - logger.py:50 - Epoch: [45][499/500] loss: 1.45305, MAE: 0.30534, time/step=1427ms, lr=3.99e-05
2024-09-23 10:33:52,281 - logger.py:50 - Epoch: [45] train loss: 1.45305, train MAE: 0.30534,val loss: 0.30702, val MAE: 0.30702,test loss: 0.31902, test MAE: 0.31902,Time: 787.27s
2024-09-23 10:33:52,281 - logger.py:50 - Best -- epoch=41, train loss: 1.45319, val loss: 0.30702, test loss: 0.31906

2024-09-23 10:33:53,419 - logger.py:50 - Epoch: [46][0/500] loss: 1.78260, MAE: 0.31744, time/step=1135ms, lr=3.95e-05
2024-09-23 10:35:03,373 - logger.py:50 - Epoch: [46][50/500] loss: 3.01668, MAE: 0.34563, time/step=1394ms, lr=3.95e-05
2024-09-23 10:36:22,764 - logger.py:50 - Epoch: [46][100/500] loss: 2.14296, MAE: 0.32629, time/step=1490ms, lr=3.95e-05
2024-09-23 10:37:35,432 - logger.py:50 - Epoch: [46][150/500] loss: 1.85327, MAE: 0.31896, time/step=1478ms, lr=3.95e-05
2024-09-23 10:38:46,456 - logger.py:50 - Epoch: [46][200/500] loss: 1.71672, MAE: 0.31405, time/step=1464ms, lr=3.95e-05
2024-09-23 10:39:58,169 - logger.py:50 - Epoch: [46][250/500] loss: 1.63272, MAE: 0.31111, time/step=1458ms, lr=3.95e-05
2024-09-23 10:41:07,686 - logger.py:50 - Epoch: [46][300/500] loss: 1.55994, MAE: 0.30999, time/step=1447ms, lr=3.95e-05
2024-09-23 10:42:18,284 - logger.py:50 - Epoch: [46][350/500] loss: 1.51725, MAE: 0.30782, time/step=1442ms, lr=3.95e-05
2024-09-23 10:43:29,314 - logger.py:50 - Epoch: [46][400/500] loss: 1.50125, MAE: 0.30789, time/step=1439ms, lr=3.95e-05
2024-09-23 10:44:41,762 - logger.py:50 - Epoch: [46][450/500] loss: 1.47178, MAE: 0.30680, time/step=1440ms, lr=3.95e-05
2024-09-23 10:45:52,808 - logger.py:50 - Epoch: [46][499/500] loss: 1.45292, MAE: 0.30530, time/step=1441ms, lr=3.95e-05
2024-09-23 10:47:07,395 - logger.py:50 - Epoch: [46] train loss: 1.45292, train MAE: 0.30530,val loss: 0.30736, val MAE: 0.30736,test loss: 0.31939, test MAE: 0.31939,Time: 795.11s
2024-09-23 10:47:07,396 - logger.py:50 - Best -- epoch=41, train loss: 1.45319, val loss: 0.30702, test loss: 0.31906

2024-09-23 10:47:08,363 - logger.py:50 - Epoch: [47][0/500] loss: 1.67333, MAE: 0.35703, time/step=965ms, lr=3.91e-05
2024-09-23 10:48:18,431 - logger.py:50 - Epoch: [47][50/500] loss: 1.29310, MAE: 0.30272, time/step=1393ms, lr=3.91e-05
2024-09-23 10:49:29,088 - logger.py:50 - Epoch: [47][100/500] loss: 1.26331, MAE: 0.30173, time/step=1403ms, lr=3.91e-05
2024-09-23 10:50:40,405 - logger.py:50 - Epoch: [47][150/500] loss: 1.85679, MAE: 0.31585, time/step=1411ms, lr=3.91e-05
2024-09-23 10:51:50,151 - logger.py:50 - Epoch: [47][200/500] loss: 1.70421, MAE: 0.31179, time/step=1407ms, lr=3.91e-05
2024-09-23 10:53:00,929 - logger.py:50 - Epoch: [47][250/500] loss: 1.61430, MAE: 0.30903, time/step=1408ms, lr=3.91e-05
2024-09-23 10:54:11,913 - logger.py:50 - Epoch: [47][300/500] loss: 1.57790, MAE: 0.31032, time/step=1410ms, lr=3.91e-05
2024-09-23 10:55:23,115 - logger.py:50 - Epoch: [47][350/500] loss: 1.54254, MAE: 0.30958, time/step=1412ms, lr=3.91e-05
2024-09-23 10:56:34,567 - logger.py:50 - Epoch: [47][400/500] loss: 1.51262, MAE: 0.30784, time/step=1414ms, lr=3.91e-05
2024-09-23 10:57:46,422 - logger.py:50 - Epoch: [47][450/500] loss: 1.47901, MAE: 0.30660, time/step=1417ms, lr=3.91e-05
2024-09-23 10:58:55,081 - logger.py:50 - Epoch: [47][499/500] loss: 1.45279, MAE: 0.30533, time/step=1415ms, lr=3.91e-05
2024-09-23 11:00:07,875 - logger.py:50 - Epoch: [47] train loss: 1.45279, train MAE: 0.30533,val loss: 0.30684, val MAE: 0.30684,test loss: 0.31896, test MAE: 0.31896,Time: 780.48s
2024-09-23 11:00:07,876 - logger.py:50 - Best -- epoch=47, train loss: 1.45279, val loss: 0.30684, test loss: 0.31896

2024-09-23 11:00:09,610 - logger.py:50 - Epoch: [48][0/500] loss: 1.92782, MAE: 0.34706, time/step=1730ms, lr=3.86e-05
2024-09-23 11:01:18,156 - logger.py:50 - Epoch: [48][50/500] loss: 1.31200, MAE: 0.29920, time/step=1378ms, lr=3.86e-05
2024-09-23 11:02:29,094 - logger.py:50 - Epoch: [48][100/500] loss: 1.33884, MAE: 0.30374, time/step=1398ms, lr=3.86e-05
2024-09-23 11:03:39,360 - logger.py:50 - Epoch: [48][150/500] loss: 1.26896, MAE: 0.30168, time/step=1401ms, lr=3.86e-05
2024-09-23 11:04:53,073 - logger.py:50 - Epoch: [48][200/500] loss: 1.27129, MAE: 0.30155, time/step=1419ms, lr=3.86e-05
2024-09-23 11:06:05,089 - logger.py:50 - Epoch: [48][250/500] loss: 1.27850, MAE: 0.30117, time/step=1423ms, lr=3.86e-05
2024-09-23 11:07:16,496 - logger.py:50 - Epoch: [48][300/500] loss: 1.28366, MAE: 0.30134, time/step=1424ms, lr=3.86e-05
2024-09-23 11:08:32,129 - logger.py:50 - Epoch: [48][350/500] loss: 1.28119, MAE: 0.30206, time/step=1437ms, lr=3.86e-05
2024-09-23 11:09:43,485 - logger.py:50 - Epoch: [48][400/500] loss: 1.49849, MAE: 0.30692, time/step=1435ms, lr=3.86e-05
2024-09-23 11:10:56,719 - logger.py:50 - Epoch: [48][450/500] loss: 1.47960, MAE: 0.30645, time/step=1439ms, lr=3.86e-05
2024-09-23 11:12:07,178 - logger.py:50 - Epoch: [48][499/500] loss: 1.45274, MAE: 0.30523, time/step=1439ms, lr=3.86e-05
2024-09-23 11:13:22,125 - logger.py:50 - Epoch: [48] train loss: 1.45274, train MAE: 0.30523,val loss: 0.30715, val MAE: 0.30715,test loss: 0.31923, test MAE: 0.31923,Time: 794.25s
2024-09-23 11:13:22,125 - logger.py:50 - Best -- epoch=47, train loss: 1.45279, val loss: 0.30684, test loss: 0.31896

2024-09-23 11:13:23,261 - logger.py:50 - Epoch: [49][0/500] loss: 1.71050, MAE: 0.36630, time/step=1134ms, lr=3.82e-05
2024-09-23 11:14:34,250 - logger.py:50 - Epoch: [49][50/500] loss: 1.38073, MAE: 0.30929, time/step=1414ms, lr=3.82e-05
2024-09-23 11:15:47,328 - logger.py:50 - Epoch: [49][100/500] loss: 2.15831, MAE: 0.32134, time/step=1438ms, lr=3.82e-05
2024-09-23 11:16:59,054 - logger.py:50 - Epoch: [49][150/500] loss: 1.82407, MAE: 0.31317, time/step=1437ms, lr=3.82e-05
2024-09-23 11:18:08,678 - logger.py:50 - Epoch: [49][200/500] loss: 1.67914, MAE: 0.30818, time/step=1426ms, lr=3.82e-05
2024-09-23 11:19:20,022 - logger.py:50 - Epoch: [49][250/500] loss: 1.58985, MAE: 0.30473, time/step=1426ms, lr=3.82e-05
2024-09-23 11:20:31,531 - logger.py:50 - Epoch: [49][300/500] loss: 1.53531, MAE: 0.30465, time/step=1427ms, lr=3.82e-05
2024-09-23 11:21:41,491 - logger.py:50 - Epoch: [49][350/500] loss: 1.50066, MAE: 0.30420, time/step=1423ms, lr=3.82e-05
2024-09-23 11:22:52,340 - logger.py:50 - Epoch: [49][400/500] loss: 1.48774, MAE: 0.30572, time/step=1422ms, lr=3.82e-05
2024-09-23 11:24:03,161 - logger.py:50 - Epoch: [49][450/500] loss: 1.46435, MAE: 0.30584, time/step=1421ms, lr=3.82e-05
2024-09-23 11:25:14,131 - logger.py:50 - Epoch: [49][499/500] loss: 1.45283, MAE: 0.30521, time/step=1424ms, lr=3.82e-05
2024-09-23 11:26:27,400 - logger.py:50 - Epoch: [49] train loss: 1.45283, train MAE: 0.30521,val loss: 0.30659, val MAE: 0.30659,test loss: 0.31864, test MAE: 0.31864,Time: 785.27s
2024-09-23 11:26:27,400 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 11:26:28,433 - logger.py:50 - Epoch: [50][0/500] loss: 1.84695, MAE: 0.36454, time/step=1029ms, lr=3.78e-05
2024-09-23 11:27:37,261 - logger.py:50 - Epoch: [50][50/500] loss: 3.04317, MAE: 0.33492, time/step=1370ms, lr=3.78e-05
2024-09-23 11:28:47,687 - logger.py:50 - Epoch: [50][100/500] loss: 2.19301, MAE: 0.31776, time/step=1389ms, lr=3.78e-05
2024-09-23 11:29:59,552 - logger.py:50 - Epoch: [50][150/500] loss: 1.88581, MAE: 0.31085, time/step=1405ms, lr=3.78e-05
2024-09-23 11:31:11,453 - logger.py:50 - Epoch: [50][200/500] loss: 1.75327, MAE: 0.31068, time/step=1413ms, lr=3.78e-05
2024-09-23 11:32:21,540 - logger.py:50 - Epoch: [50][250/500] loss: 1.65575, MAE: 0.30844, time/step=1411ms, lr=3.78e-05
2024-09-23 11:33:35,420 - logger.py:50 - Epoch: [50][300/500] loss: 1.58740, MAE: 0.30712, time/step=1422ms, lr=3.78e-05
2024-09-23 11:34:47,294 - logger.py:50 - Epoch: [50][350/500] loss: 1.54140, MAE: 0.30759, time/step=1424ms, lr=3.78e-05
2024-09-23 11:35:57,769 - logger.py:50 - Epoch: [50][400/500] loss: 1.50003, MAE: 0.30653, time/step=1422ms, lr=3.78e-05
2024-09-23 11:37:07,862 - logger.py:50 - Epoch: [50][450/500] loss: 1.48222, MAE: 0.30586, time/step=1420ms, lr=3.78e-05
2024-09-23 11:38:17,365 - logger.py:50 - Epoch: [50][499/500] loss: 1.45265, MAE: 0.30523, time/step=1420ms, lr=3.78e-05
2024-09-23 11:39:29,416 - logger.py:50 - Epoch: [50] train loss: 1.45265, train MAE: 0.30523,val loss: 0.30720, val MAE: 0.30720,test loss: 0.31920, test MAE: 0.31920,Time: 782.02s
2024-09-23 11:39:29,416 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 11:39:31,033 - logger.py:50 - Epoch: [51][0/500] loss: 1.08863, MAE: 0.32446, time/step=1614ms, lr=3.73e-05
2024-09-23 11:40:40,317 - logger.py:50 - Epoch: [51][50/500] loss: 2.91993, MAE: 0.32622, time/step=1390ms, lr=3.73e-05
2024-09-23 11:41:51,216 - logger.py:50 - Epoch: [51][100/500] loss: 2.11303, MAE: 0.31325, time/step=1404ms, lr=3.73e-05
2024-09-23 11:43:02,494 - logger.py:50 - Epoch: [51][150/500] loss: 1.84622, MAE: 0.31028, time/step=1411ms, lr=3.73e-05
2024-09-23 11:44:12,977 - logger.py:50 - Epoch: [51][200/500] loss: 1.72211, MAE: 0.31115, time/step=1411ms, lr=3.73e-05
2024-09-23 11:45:24,476 - logger.py:50 - Epoch: [51][250/500] loss: 1.62122, MAE: 0.30878, time/step=1415ms, lr=3.73e-05
2024-09-23 11:46:34,252 - logger.py:50 - Epoch: [51][300/500] loss: 1.55948, MAE: 0.30705, time/step=1411ms, lr=3.73e-05
2024-09-23 11:47:45,936 - logger.py:50 - Epoch: [51][350/500] loss: 1.52104, MAE: 0.30498, time/step=1415ms, lr=3.73e-05
2024-09-23 11:48:55,956 - logger.py:50 - Epoch: [51][400/500] loss: 1.49699, MAE: 0.30459, time/step=1413ms, lr=3.73e-05
2024-09-23 11:50:06,246 - logger.py:50 - Epoch: [51][450/500] loss: 1.46493, MAE: 0.30451, time/step=1412ms, lr=3.73e-05
2024-09-23 11:51:14,277 - logger.py:50 - Epoch: [51][499/500] loss: 1.45282, MAE: 0.30516, time/step=1410ms, lr=3.73e-05
2024-09-23 11:52:27,123 - logger.py:50 - Epoch: [51] train loss: 1.45282, train MAE: 0.30516,val loss: 0.30687, val MAE: 0.30687,test loss: 0.31893, test MAE: 0.31893,Time: 777.71s
2024-09-23 11:52:27,124 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 11:52:28,838 - logger.py:50 - Epoch: [52][0/500] loss: 1.31851, MAE: 0.32905, time/step=1712ms, lr=3.69e-05
2024-09-23 11:53:39,336 - logger.py:50 - Epoch: [52][50/500] loss: 1.28874, MAE: 0.29763, time/step=1416ms, lr=3.69e-05
2024-09-23 11:54:48,752 - logger.py:50 - Epoch: [52][100/500] loss: 1.29814, MAE: 0.30342, time/step=1402ms, lr=3.69e-05
2024-09-23 11:55:58,773 - logger.py:50 - Epoch: [52][150/500] loss: 1.29337, MAE: 0.30166, time/step=1402ms, lr=3.69e-05
2024-09-23 11:57:10,561 - logger.py:50 - Epoch: [52][200/500] loss: 1.27436, MAE: 0.30089, time/step=1410ms, lr=3.69e-05
2024-09-23 11:58:20,905 - logger.py:50 - Epoch: [52][250/500] loss: 1.27840, MAE: 0.30269, time/step=1409ms, lr=3.69e-05
2024-09-23 11:59:31,680 - logger.py:50 - Epoch: [52][300/500] loss: 1.56350, MAE: 0.30781, time/step=1410ms, lr=3.69e-05
2024-09-23 12:00:41,554 - logger.py:50 - Epoch: [52][350/500] loss: 1.51967, MAE: 0.30627, time/step=1409ms, lr=3.69e-05
2024-09-23 12:01:52,130 - logger.py:50 - Epoch: [52][400/500] loss: 1.50587, MAE: 0.30705, time/step=1409ms, lr=3.69e-05
2024-09-23 12:03:04,622 - logger.py:50 - Epoch: [52][450/500] loss: 1.46779, MAE: 0.30574, time/step=1414ms, lr=3.69e-05
2024-09-23 12:04:13,017 - logger.py:50 - Epoch: [52][499/500] loss: 1.45273, MAE: 0.30522, time/step=1412ms, lr=3.69e-05
2024-09-23 12:05:25,344 - logger.py:50 - Epoch: [52] train loss: 1.45273, train MAE: 0.30522,val loss: 0.30684, val MAE: 0.30684,test loss: 0.31891, test MAE: 0.31891,Time: 778.22s
2024-09-23 12:05:25,345 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 12:05:26,098 - logger.py:50 - Epoch: [53][0/500] loss: 1.66597, MAE: 0.35294, time/step=751ms, lr=3.64e-05
2024-09-23 12:06:37,032 - logger.py:50 - Epoch: [53][50/500] loss: 1.24000, MAE: 0.29700, time/step=1406ms, lr=3.64e-05
2024-09-23 12:07:47,421 - logger.py:50 - Epoch: [53][100/500] loss: 1.25195, MAE: 0.30011, time/step=1407ms, lr=3.64e-05
2024-09-23 12:08:58,830 - logger.py:50 - Epoch: [53][150/500] loss: 1.26206, MAE: 0.29996, time/step=1414ms, lr=3.64e-05
2024-09-23 12:10:09,686 - logger.py:50 - Epoch: [53][200/500] loss: 1.24932, MAE: 0.29855, time/step=1415ms, lr=3.64e-05
2024-09-23 12:11:19,937 - logger.py:50 - Epoch: [53][250/500] loss: 1.25751, MAE: 0.29999, time/step=1413ms, lr=3.64e-05
2024-09-23 12:12:33,679 - logger.py:50 - Epoch: [53][300/500] loss: 1.54136, MAE: 0.30592, time/step=1423ms, lr=3.64e-05
2024-09-23 12:13:45,839 - logger.py:50 - Epoch: [53][350/500] loss: 1.51313, MAE: 0.30613, time/step=1426ms, lr=3.64e-05
2024-09-23 12:14:57,485 - logger.py:50 - Epoch: [53][400/500] loss: 1.48475, MAE: 0.30574, time/step=1427ms, lr=3.64e-05
2024-09-23 12:16:10,528 - logger.py:50 - Epoch: [53][450/500] loss: 1.45790, MAE: 0.30567, time/step=1431ms, lr=3.64e-05
2024-09-23 12:17:21,532 - logger.py:50 - Epoch: [53][499/500] loss: 1.45282, MAE: 0.30519, time/step=1432ms, lr=3.64e-05
2024-09-23 12:18:33,145 - logger.py:50 - Epoch: [53] train loss: 1.45282, train MAE: 0.30519,val loss: 0.30768, val MAE: 0.30768,test loss: 0.31967, test MAE: 0.31967,Time: 787.80s
2024-09-23 12:18:33,145 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 12:18:34,703 - logger.py:50 - Epoch: [54][0/500] loss: 1.29199, MAE: 0.33212, time/step=1555ms, lr=3.59e-05
2024-09-23 12:19:46,300 - logger.py:50 - Epoch: [54][50/500] loss: 1.24180, MAE: 0.30562, time/step=1434ms, lr=3.59e-05
2024-09-23 12:20:57,157 - logger.py:50 - Epoch: [54][100/500] loss: 1.27341, MAE: 0.30338, time/step=1426ms, lr=3.59e-05
2024-09-23 12:22:08,644 - logger.py:50 - Epoch: [54][150/500] loss: 1.89004, MAE: 0.31431, time/step=1427ms, lr=3.59e-05
2024-09-23 12:23:21,999 - logger.py:50 - Epoch: [54][200/500] loss: 1.71530, MAE: 0.30846, time/step=1437ms, lr=3.59e-05
2024-09-23 12:24:32,439 - logger.py:50 - Epoch: [54][250/500] loss: 1.61937, MAE: 0.30515, time/step=1431ms, lr=3.59e-05
2024-09-23 12:25:43,084 - logger.py:50 - Epoch: [54][300/500] loss: 1.54331, MAE: 0.30441, time/step=1428ms, lr=3.59e-05
2024-09-23 12:26:54,969 - logger.py:50 - Epoch: [54][350/500] loss: 1.50500, MAE: 0.30417, time/step=1430ms, lr=3.59e-05
2024-09-23 12:28:05,133 - logger.py:50 - Epoch: [54][400/500] loss: 1.47552, MAE: 0.30382, time/step=1426ms, lr=3.59e-05
2024-09-23 12:29:17,199 - logger.py:50 - Epoch: [54][450/500] loss: 1.46688, MAE: 0.30497, time/step=1428ms, lr=3.59e-05
2024-09-23 12:30:28,968 - logger.py:50 - Epoch: [54][499/500] loss: 1.45274, MAE: 0.30514, time/step=1432ms, lr=3.59e-05
2024-09-23 12:31:41,596 - logger.py:50 - Epoch: [54] train loss: 1.45274, train MAE: 0.30514,val loss: 0.30766, val MAE: 0.30766,test loss: 0.31973, test MAE: 0.31973,Time: 788.45s
2024-09-23 12:31:41,596 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 12:31:42,471 - logger.py:50 - Epoch: [55][0/500] loss: 1.47492, MAE: 0.30382, time/step=872ms, lr=3.55e-05
2024-09-23 12:32:53,554 - logger.py:50 - Epoch: [55][50/500] loss: 1.34153, MAE: 0.30816, time/step=1411ms, lr=3.55e-05
2024-09-23 12:34:05,900 - logger.py:50 - Epoch: [55][100/500] loss: 1.32353, MAE: 0.30616, time/step=1429ms, lr=3.55e-05
2024-09-23 12:35:15,324 - logger.py:50 - Epoch: [55][150/500] loss: 1.31331, MAE: 0.30624, time/step=1415ms, lr=3.55e-05
2024-09-23 12:36:25,096 - logger.py:50 - Epoch: [55][200/500] loss: 1.72232, MAE: 0.31016, time/step=1410ms, lr=3.55e-05
2024-09-23 12:37:36,700 - logger.py:50 - Epoch: [55][250/500] loss: 1.63155, MAE: 0.30895, time/step=1415ms, lr=3.55e-05
2024-09-23 12:38:46,415 - logger.py:50 - Epoch: [55][300/500] loss: 1.57424, MAE: 0.30754, time/step=1411ms, lr=3.55e-05
2024-09-23 12:39:56,981 - logger.py:50 - Epoch: [55][350/500] loss: 1.51999, MAE: 0.30572, time/step=1411ms, lr=3.55e-05
2024-09-23 12:41:07,963 - logger.py:50 - Epoch: [55][400/500] loss: 1.49200, MAE: 0.30518, time/step=1412ms, lr=3.55e-05
2024-09-23 12:42:18,723 - logger.py:50 - Epoch: [55][450/500] loss: 1.46813, MAE: 0.30472, time/step=1413ms, lr=3.55e-05
2024-09-23 12:43:28,945 - logger.py:50 - Epoch: [55][499/500] loss: 1.45259, MAE: 0.30513, time/step=1415ms, lr=3.55e-05
2024-09-23 12:44:40,528 - logger.py:50 - Epoch: [55] train loss: 1.45259, train MAE: 0.30513,val loss: 0.30700, val MAE: 0.30700,test loss: 0.31906, test MAE: 0.31906,Time: 778.93s
2024-09-23 12:44:40,529 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 12:44:42,245 - logger.py:50 - Epoch: [56][0/500] loss: 2.20064, MAE: 0.35805, time/step=1713ms, lr=3.50e-05
2024-09-23 12:45:50,299 - logger.py:50 - Epoch: [56][50/500] loss: 1.19093, MAE: 0.29635, time/step=1368ms, lr=3.50e-05
2024-09-23 12:47:01,131 - logger.py:50 - Epoch: [56][100/500] loss: 1.23003, MAE: 0.30097, time/step=1392ms, lr=3.50e-05
2024-09-23 12:48:11,229 - logger.py:50 - Epoch: [56][150/500] loss: 1.27666, MAE: 0.29955, time/step=1395ms, lr=3.50e-05
2024-09-23 12:49:22,061 - logger.py:50 - Epoch: [56][200/500] loss: 1.28577, MAE: 0.30362, time/step=1401ms, lr=3.50e-05
2024-09-23 12:50:33,974 - logger.py:50 - Epoch: [56][250/500] loss: 1.27987, MAE: 0.30319, time/step=1408ms, lr=3.50e-05
2024-09-23 12:51:44,346 - logger.py:50 - Epoch: [56][300/500] loss: 1.26445, MAE: 0.30268, time/step=1408ms, lr=3.50e-05
2024-09-23 12:52:55,501 - logger.py:50 - Epoch: [56][350/500] loss: 1.51725, MAE: 0.30758, time/step=1410ms, lr=3.50e-05
2024-09-23 12:54:08,061 - logger.py:50 - Epoch: [56][400/500] loss: 1.50146, MAE: 0.30757, time/step=1415ms, lr=3.50e-05
2024-09-23 12:55:21,754 - logger.py:50 - Epoch: [56][450/500] loss: 1.47529, MAE: 0.30726, time/step=1422ms, lr=3.50e-05
2024-09-23 12:56:33,046 - logger.py:50 - Epoch: [56][499/500] loss: 1.45267, MAE: 0.30518, time/step=1425ms, lr=3.50e-05
2024-09-23 12:57:46,752 - logger.py:50 - Epoch: [56] train loss: 1.45267, train MAE: 0.30518,val loss: 0.30689, val MAE: 0.30689,test loss: 0.31892, test MAE: 0.31892,Time: 786.22s
2024-09-23 12:57:46,752 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 12:57:48,394 - logger.py:50 - Epoch: [57][0/500] loss: 0.87865, MAE: 0.23126, time/step=1639ms, lr=3.45e-05
2024-09-23 12:59:00,604 - logger.py:50 - Epoch: [57][50/500] loss: 1.32903, MAE: 0.30423, time/step=1448ms, lr=3.45e-05
2024-09-23 13:00:11,683 - logger.py:50 - Epoch: [57][100/500] loss: 1.32349, MAE: 0.30319, time/step=1435ms, lr=3.45e-05
2024-09-23 13:01:25,016 - logger.py:50 - Epoch: [57][150/500] loss: 1.29558, MAE: 0.30175, time/step=1445ms, lr=3.45e-05
2024-09-23 13:02:35,187 - logger.py:50 - Epoch: [57][200/500] loss: 1.71166, MAE: 0.30972, time/step=1435ms, lr=3.45e-05
2024-09-23 13:03:47,680 - logger.py:50 - Epoch: [57][250/500] loss: 1.61937, MAE: 0.30862, time/step=1438ms, lr=3.45e-05
2024-09-23 13:04:59,640 - logger.py:50 - Epoch: [57][300/500] loss: 1.56256, MAE: 0.30761, time/step=1438ms, lr=3.45e-05
2024-09-23 13:06:12,200 - logger.py:50 - Epoch: [57][350/500] loss: 1.51451, MAE: 0.30489, time/step=1440ms, lr=3.45e-05
2024-09-23 13:07:22,310 - logger.py:50 - Epoch: [57][400/500] loss: 1.50064, MAE: 0.30474, time/step=1435ms, lr=3.45e-05
2024-09-23 13:08:34,070 - logger.py:50 - Epoch: [57][450/500] loss: 1.49043, MAE: 0.30662, time/step=1435ms, lr=3.45e-05
2024-09-23 13:09:43,982 - logger.py:50 - Epoch: [57][499/500] loss: 1.45252, MAE: 0.30513, time/step=1434ms, lr=3.45e-05
2024-09-23 13:10:56,180 - logger.py:50 - Epoch: [57] train loss: 1.45252, train MAE: 0.30513,val loss: 0.30670, val MAE: 0.30670,test loss: 0.31875, test MAE: 0.31875,Time: 789.43s
2024-09-23 13:10:56,180 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 13:10:57,819 - logger.py:50 - Epoch: [58][0/500] loss: 0.91748, MAE: 0.28563, time/step=1636ms, lr=3.40e-05
2024-09-23 13:12:08,470 - logger.py:50 - Epoch: [58][50/500] loss: 1.18053, MAE: 0.29224, time/step=1417ms, lr=3.40e-05
2024-09-23 13:13:18,133 - logger.py:50 - Epoch: [58][100/500] loss: 1.20692, MAE: 0.29853, time/step=1405ms, lr=3.40e-05
2024-09-23 13:14:28,996 - logger.py:50 - Epoch: [58][150/500] loss: 1.21871, MAE: 0.30155, time/step=1409ms, lr=3.40e-05
2024-09-23 13:15:47,142 - logger.py:50 - Epoch: [58][200/500] loss: 1.26340, MAE: 0.30333, time/step=1448ms, lr=3.40e-05
2024-09-23 13:16:58,168 - logger.py:50 - Epoch: [58][250/500] loss: 1.26662, MAE: 0.30283, time/step=1442ms, lr=3.40e-05
2024-09-23 13:18:10,550 - logger.py:50 - Epoch: [58][300/500] loss: 1.55920, MAE: 0.30782, time/step=1443ms, lr=3.40e-05
2024-09-23 13:19:22,838 - logger.py:50 - Epoch: [58][350/500] loss: 1.51590, MAE: 0.30636, time/step=1443ms, lr=3.40e-05
2024-09-23 13:20:35,284 - logger.py:50 - Epoch: [58][400/500] loss: 1.48827, MAE: 0.30504, time/step=1444ms, lr=3.40e-05
2024-09-23 13:21:45,669 - logger.py:50 - Epoch: [58][450/500] loss: 1.46291, MAE: 0.30521, time/step=1440ms, lr=3.40e-05
2024-09-23 13:22:55,480 - logger.py:50 - Epoch: [58][499/500] loss: 1.45250, MAE: 0.30512, time/step=1439ms, lr=3.40e-05
2024-09-23 13:24:07,793 - logger.py:50 - Epoch: [58] train loss: 1.45250, train MAE: 0.30512,val loss: 0.30676, val MAE: 0.30676,test loss: 0.31883, test MAE: 0.31883,Time: 791.61s
2024-09-23 13:24:07,793 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 13:24:09,302 - logger.py:50 - Epoch: [59][0/500] loss: 0.85549, MAE: 0.26648, time/step=1506ms, lr=3.36e-05
2024-09-23 13:25:18,479 - logger.py:50 - Epoch: [59][50/500] loss: 1.17741, MAE: 0.29967, time/step=1386ms, lr=3.36e-05
2024-09-23 13:26:30,251 - logger.py:50 - Epoch: [59][100/500] loss: 1.23499, MAE: 0.30128, time/step=1410ms, lr=3.36e-05
2024-09-23 13:27:39,639 - logger.py:50 - Epoch: [59][150/500] loss: 1.22591, MAE: 0.29943, time/step=1403ms, lr=3.36e-05
2024-09-23 13:28:50,512 - logger.py:50 - Epoch: [59][200/500] loss: 1.24440, MAE: 0.30102, time/step=1407ms, lr=3.36e-05
2024-09-23 13:30:01,718 - logger.py:50 - Epoch: [59][250/500] loss: 1.60183, MAE: 0.30627, time/step=1410ms, lr=3.36e-05
2024-09-23 13:31:12,522 - logger.py:50 - Epoch: [59][300/500] loss: 1.56636, MAE: 0.30708, time/step=1411ms, lr=3.36e-05
2024-09-23 13:32:23,228 - logger.py:50 - Epoch: [59][350/500] loss: 1.51761, MAE: 0.30584, time/step=1411ms, lr=3.36e-05
2024-09-23 13:33:34,492 - logger.py:50 - Epoch: [59][400/500] loss: 1.49520, MAE: 0.30639, time/step=1413ms, lr=3.36e-05
2024-09-23 13:34:46,293 - logger.py:50 - Epoch: [59][450/500] loss: 1.47947, MAE: 0.30608, time/step=1416ms, lr=3.36e-05
2024-09-23 13:35:56,556 - logger.py:50 - Epoch: [59][499/500] loss: 1.45260, MAE: 0.30515, time/step=1418ms, lr=3.36e-05
2024-09-23 13:37:09,050 - logger.py:50 - Epoch: [59] train loss: 1.45260, train MAE: 0.30515,val loss: 0.30715, val MAE: 0.30715,test loss: 0.31920, test MAE: 0.31920,Time: 781.26s
2024-09-23 13:37:09,050 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 13:37:10,044 - logger.py:50 - Epoch: [60][0/500] loss: 0.86043, MAE: 0.20912, time/step=991ms, lr=3.31e-05
2024-09-23 13:38:20,613 - logger.py:50 - Epoch: [60][50/500] loss: 2.88816, MAE: 0.32619, time/step=1403ms, lr=3.31e-05
2024-09-23 13:39:35,111 - logger.py:50 - Epoch: [60][100/500] loss: 2.04641, MAE: 0.31304, time/step=1446ms, lr=3.31e-05
2024-09-23 13:40:45,593 - logger.py:50 - Epoch: [60][150/500] loss: 1.79345, MAE: 0.31027, time/step=1434ms, lr=3.31e-05
2024-09-23 13:41:57,936 - logger.py:50 - Epoch: [60][200/500] loss: 1.65868, MAE: 0.30639, time/step=1437ms, lr=3.31e-05
2024-09-23 13:43:10,858 - logger.py:50 - Epoch: [60][250/500] loss: 1.59307, MAE: 0.30688, time/step=1441ms, lr=3.31e-05
2024-09-23 13:44:21,752 - logger.py:50 - Epoch: [60][300/500] loss: 1.54030, MAE: 0.30521, time/step=1438ms, lr=3.31e-05
2024-09-23 13:45:33,579 - logger.py:50 - Epoch: [60][350/500] loss: 1.50032, MAE: 0.30440, time/step=1437ms, lr=3.31e-05
2024-09-23 13:46:43,928 - logger.py:50 - Epoch: [60][400/500] loss: 1.48097, MAE: 0.30446, time/step=1434ms, lr=3.31e-05
2024-09-23 13:47:55,782 - logger.py:50 - Epoch: [60][450/500] loss: 1.45891, MAE: 0.30470, time/step=1434ms, lr=3.31e-05
2024-09-23 13:49:07,071 - logger.py:50 - Epoch: [60][499/500] loss: 1.45259, MAE: 0.30514, time/step=1436ms, lr=3.31e-05
2024-09-23 13:50:19,386 - logger.py:50 - Epoch: [60] train loss: 1.45259, train MAE: 0.30514,val loss: 0.30720, val MAE: 0.30720,test loss: 0.31924, test MAE: 0.31924,Time: 790.34s
2024-09-23 13:50:19,386 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 13:50:20,877 - logger.py:50 - Epoch: [61][0/500] loss: 2.00389, MAE: 0.36122, time/step=1488ms, lr=3.26e-05
2024-09-23 13:51:30,815 - logger.py:50 - Epoch: [61][50/500] loss: 1.16261, MAE: 0.29695, time/step=1401ms, lr=3.26e-05
2024-09-23 13:52:42,578 - logger.py:50 - Epoch: [61][100/500] loss: 1.31645, MAE: 0.30249, time/step=1418ms, lr=3.26e-05
2024-09-23 13:53:53,272 - logger.py:50 - Epoch: [61][150/500] loss: 1.84994, MAE: 0.31438, time/step=1416ms, lr=3.26e-05
2024-09-23 13:55:04,068 - logger.py:50 - Epoch: [61][200/500] loss: 1.71460, MAE: 0.31202, time/step=1416ms, lr=3.26e-05
2024-09-23 13:56:16,261 - logger.py:50 - Epoch: [61][250/500] loss: 1.63753, MAE: 0.30967, time/step=1422ms, lr=3.26e-05
2024-09-23 13:57:27,424 - logger.py:50 - Epoch: [61][300/500] loss: 1.56074, MAE: 0.30539, time/step=1422ms, lr=3.26e-05
2024-09-23 13:58:37,818 - logger.py:50 - Epoch: [61][350/500] loss: 1.53279, MAE: 0.30562, time/step=1420ms, lr=3.26e-05
2024-09-23 13:59:50,270 - logger.py:50 - Epoch: [61][400/500] loss: 1.49857, MAE: 0.30523, time/step=1424ms, lr=3.26e-05
2024-09-23 14:01:01,219 - logger.py:50 - Epoch: [61][450/500] loss: 1.46748, MAE: 0.30509, time/step=1423ms, lr=3.26e-05
2024-09-23 14:02:10,094 - logger.py:50 - Epoch: [61][499/500] loss: 1.45257, MAE: 0.30512, time/step=1421ms, lr=3.26e-05
2024-09-23 14:03:22,448 - logger.py:50 - Epoch: [61] train loss: 1.45257, train MAE: 0.30512,val loss: 0.30750, val MAE: 0.30750,test loss: 0.31946, test MAE: 0.31946,Time: 783.06s
2024-09-23 14:03:22,448 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 14:03:23,981 - logger.py:50 - Epoch: [62][0/500] loss: 0.86425, MAE: 0.23986, time/step=1531ms, lr=3.21e-05
2024-09-23 14:04:38,526 - logger.py:50 - Epoch: [62][50/500] loss: 1.30896, MAE: 0.30501, time/step=1492ms, lr=3.21e-05
2024-09-23 14:05:51,391 - logger.py:50 - Epoch: [62][100/500] loss: 2.11806, MAE: 0.31927, time/step=1475ms, lr=3.21e-05
2024-09-23 14:07:04,628 - logger.py:50 - Epoch: [62][150/500] loss: 1.83356, MAE: 0.31236, time/step=1471ms, lr=3.21e-05
2024-09-23 14:08:15,766 - logger.py:50 - Epoch: [62][200/500] loss: 1.67394, MAE: 0.30848, time/step=1459ms, lr=3.21e-05
2024-09-23 14:09:30,994 - logger.py:50 - Epoch: [62][250/500] loss: 1.60790, MAE: 0.30714, time/step=1468ms, lr=3.21e-05
2024-09-23 14:10:43,000 - logger.py:50 - Epoch: [62][300/500] loss: 1.55102, MAE: 0.30566, time/step=1464ms, lr=3.21e-05
2024-09-23 14:11:55,361 - logger.py:50 - Epoch: [62][350/500] loss: 1.52177, MAE: 0.30613, time/step=1461ms, lr=3.21e-05
2024-09-23 14:13:07,941 - logger.py:50 - Epoch: [62][400/500] loss: 1.50350, MAE: 0.30601, time/step=1460ms, lr=3.21e-05
2024-09-23 14:14:20,280 - logger.py:50 - Epoch: [62][450/500] loss: 1.48332, MAE: 0.30619, time/step=1459ms, lr=3.21e-05
2024-09-23 14:15:31,072 - logger.py:50 - Epoch: [62][499/500] loss: 1.45250, MAE: 0.30510, time/step=1457ms, lr=3.21e-05
2024-09-23 14:16:42,901 - logger.py:50 - Epoch: [62] train loss: 1.45250, train MAE: 0.30510,val loss: 0.30710, val MAE: 0.30710,test loss: 0.31911, test MAE: 0.31911,Time: 800.45s
2024-09-23 14:16:42,902 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 14:16:44,488 - logger.py:50 - Epoch: [63][0/500] loss: 1.06531, MAE: 0.27142, time/step=1583ms, lr=3.16e-05
2024-09-23 14:17:54,368 - logger.py:50 - Epoch: [63][50/500] loss: 1.27897, MAE: 0.30413, time/step=1401ms, lr=3.16e-05
2024-09-23 14:19:05,611 - logger.py:50 - Epoch: [63][100/500] loss: 1.30759, MAE: 0.30462, time/step=1413ms, lr=3.16e-05
2024-09-23 14:20:17,385 - logger.py:50 - Epoch: [63][150/500] loss: 1.30551, MAE: 0.30408, time/step=1420ms, lr=3.16e-05
2024-09-23 14:21:29,122 - logger.py:50 - Epoch: [63][200/500] loss: 1.29278, MAE: 0.30238, time/step=1424ms, lr=3.16e-05
2024-09-23 14:22:42,820 - logger.py:50 - Epoch: [63][250/500] loss: 1.29171, MAE: 0.30322, time/step=1434ms, lr=3.16e-05
2024-09-23 14:23:54,628 - logger.py:50 - Epoch: [63][300/500] loss: 1.27983, MAE: 0.30172, time/step=1434ms, lr=3.16e-05
2024-09-23 14:25:06,788 - logger.py:50 - Epoch: [63][350/500] loss: 1.29913, MAE: 0.30231, time/step=1436ms, lr=3.16e-05
2024-09-23 14:26:17,450 - logger.py:50 - Epoch: [63][400/500] loss: 1.30673, MAE: 0.30325, time/step=1433ms, lr=3.16e-05
2024-09-23 14:27:28,532 - logger.py:50 - Epoch: [63][450/500] loss: 1.48062, MAE: 0.30618, time/step=1432ms, lr=3.16e-05
2024-09-23 14:28:36,664 - logger.py:50 - Epoch: [63][499/500] loss: 1.45251, MAE: 0.30510, time/step=1428ms, lr=3.16e-05
2024-09-23 14:29:48,835 - logger.py:50 - Epoch: [63] train loss: 1.45251, train MAE: 0.30510,val loss: 0.30684, val MAE: 0.30684,test loss: 0.31889, test MAE: 0.31889,Time: 785.93s
2024-09-23 14:29:48,836 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 14:29:50,245 - logger.py:50 - Epoch: [64][0/500] loss: 1.32365, MAE: 0.34716, time/step=1406ms, lr=3.11e-05
2024-09-23 14:31:01,012 - logger.py:50 - Epoch: [64][50/500] loss: 2.91085, MAE: 0.33071, time/step=1415ms, lr=3.11e-05
2024-09-23 14:32:11,426 - logger.py:50 - Epoch: [64][100/500] loss: 2.07463, MAE: 0.31676, time/step=1412ms, lr=3.11e-05
2024-09-23 14:33:22,226 - logger.py:50 - Epoch: [64][150/500] loss: 1.79785, MAE: 0.31253, time/step=1413ms, lr=3.11e-05
2024-09-23 14:34:33,988 - logger.py:50 - Epoch: [64][200/500] loss: 1.67656, MAE: 0.30992, time/step=1419ms, lr=3.11e-05
2024-09-23 14:35:43,448 - logger.py:50 - Epoch: [64][250/500] loss: 1.58948, MAE: 0.30607, time/step=1413ms, lr=3.11e-05
2024-09-23 14:36:53,595 - logger.py:50 - Epoch: [64][300/500] loss: 1.55027, MAE: 0.30713, time/step=1411ms, lr=3.11e-05
2024-09-23 14:38:05,882 - logger.py:50 - Epoch: [64][350/500] loss: 1.51051, MAE: 0.30536, time/step=1416ms, lr=3.11e-05
2024-09-23 14:39:17,269 - logger.py:50 - Epoch: [64][400/500] loss: 1.47981, MAE: 0.30510, time/step=1418ms, lr=3.11e-05
2024-09-23 14:40:28,598 - logger.py:50 - Epoch: [64][450/500] loss: 1.46941, MAE: 0.30579, time/step=1419ms, lr=3.11e-05
2024-09-23 14:41:38,763 - logger.py:50 - Epoch: [64][499/500] loss: 1.45257, MAE: 0.30507, time/step=1420ms, lr=3.11e-05
2024-09-23 14:42:52,257 - logger.py:50 - Epoch: [64] train loss: 1.45257, train MAE: 0.30507,val loss: 0.30681, val MAE: 0.30681,test loss: 0.31885, test MAE: 0.31885,Time: 783.42s
2024-09-23 14:42:52,257 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 14:42:53,283 - logger.py:50 - Epoch: [65][0/500] loss: 1.26144, MAE: 0.33226, time/step=1022ms, lr=3.06e-05
2024-09-23 14:44:03,127 - logger.py:50 - Epoch: [65][50/500] loss: 2.93450, MAE: 0.32804, time/step=1390ms, lr=3.06e-05
2024-09-23 14:45:14,340 - logger.py:50 - Epoch: [65][100/500] loss: 2.11736, MAE: 0.31246, time/step=1407ms, lr=3.06e-05
2024-09-23 14:46:26,727 - logger.py:50 - Epoch: [65][150/500] loss: 1.80593, MAE: 0.30944, time/step=1420ms, lr=3.06e-05
2024-09-23 14:47:36,200 - logger.py:50 - Epoch: [65][200/500] loss: 1.69626, MAE: 0.30838, time/step=1413ms, lr=3.06e-05
2024-09-23 14:48:47,466 - logger.py:50 - Epoch: [65][250/500] loss: 1.62458, MAE: 0.30906, time/step=1415ms, lr=3.06e-05
2024-09-23 14:49:58,474 - logger.py:50 - Epoch: [65][300/500] loss: 1.54649, MAE: 0.30683, time/step=1416ms, lr=3.06e-05
2024-09-23 14:51:09,617 - logger.py:50 - Epoch: [65][350/500] loss: 1.50668, MAE: 0.30611, time/step=1417ms, lr=3.06e-05
2024-09-23 14:52:20,358 - logger.py:50 - Epoch: [65][400/500] loss: 1.48733, MAE: 0.30569, time/step=1417ms, lr=3.06e-05
2024-09-23 14:53:31,171 - logger.py:50 - Epoch: [65][450/500] loss: 1.46729, MAE: 0.30495, time/step=1417ms, lr=3.06e-05
2024-09-23 14:54:40,013 - logger.py:50 - Epoch: [65][499/500] loss: 1.45260, MAE: 0.30513, time/step=1416ms, lr=3.06e-05
2024-09-23 14:55:52,086 - logger.py:50 - Epoch: [65] train loss: 1.45260, train MAE: 0.30513,val loss: 0.30675, val MAE: 0.30675,test loss: 0.31880, test MAE: 0.31880,Time: 779.83s
2024-09-23 14:55:52,086 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 14:55:53,758 - logger.py:50 - Epoch: [66][0/500] loss: 1.06734, MAE: 0.29771, time/step=1669ms, lr=3.01e-05
2024-09-23 14:57:03,108 - logger.py:50 - Epoch: [66][50/500] loss: 1.20904, MAE: 0.30149, time/step=1393ms, lr=3.01e-05
2024-09-23 14:58:12,679 - logger.py:50 - Epoch: [66][100/500] loss: 1.27060, MAE: 0.30284, time/step=1392ms, lr=3.01e-05
2024-09-23 14:59:23,439 - logger.py:50 - Epoch: [66][150/500] loss: 1.25868, MAE: 0.30200, time/step=1400ms, lr=3.01e-05
2024-09-23 15:00:34,075 - logger.py:50 - Epoch: [66][200/500] loss: 1.26896, MAE: 0.30158, time/step=1403ms, lr=3.01e-05
2024-09-23 15:01:44,945 - logger.py:50 - Epoch: [66][250/500] loss: 1.27003, MAE: 0.30244, time/step=1406ms, lr=3.01e-05
2024-09-23 15:02:55,116 - logger.py:50 - Epoch: [66][300/500] loss: 1.27604, MAE: 0.30221, time/step=1405ms, lr=3.01e-05
2024-09-23 15:04:09,207 - logger.py:50 - Epoch: [66][350/500] loss: 1.52742, MAE: 0.30713, time/step=1416ms, lr=3.01e-05
2024-09-23 15:05:19,959 - logger.py:50 - Epoch: [66][400/500] loss: 1.49334, MAE: 0.30660, time/step=1416ms, lr=3.01e-05
2024-09-23 15:06:31,978 - logger.py:50 - Epoch: [66][450/500] loss: 1.46200, MAE: 0.30479, time/step=1419ms, lr=3.01e-05
2024-09-23 15:07:40,991 - logger.py:50 - Epoch: [66][499/500] loss: 1.45244, MAE: 0.30507, time/step=1418ms, lr=3.01e-05
2024-09-23 15:08:52,411 - logger.py:50 - Epoch: [66] train loss: 1.45244, train MAE: 0.30507,val loss: 0.30706, val MAE: 0.30706,test loss: 0.31907, test MAE: 0.31907,Time: 780.33s
2024-09-23 15:08:52,411 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 15:08:54,155 - logger.py:50 - Epoch: [67][0/500] loss: 0.82926, MAE: 0.28894, time/step=1741ms, lr=2.96e-05
2024-09-23 15:10:04,483 - logger.py:50 - Epoch: [67][50/500] loss: 1.33885, MAE: 0.29995, time/step=1413ms, lr=2.96e-05
2024-09-23 15:11:16,451 - logger.py:50 - Epoch: [67][100/500] loss: 1.28332, MAE: 0.30126, time/step=1426ms, lr=2.96e-05
2024-09-23 15:12:27,305 - logger.py:50 - Epoch: [67][150/500] loss: 1.32991, MAE: 0.30537, time/step=1423ms, lr=2.96e-05
2024-09-23 15:13:37,269 - logger.py:50 - Epoch: [67][200/500] loss: 1.73887, MAE: 0.31133, time/step=1417ms, lr=2.96e-05
2024-09-23 15:14:47,599 - logger.py:50 - Epoch: [67][250/500] loss: 1.64579, MAE: 0.31071, time/step=1415ms, lr=2.96e-05
2024-09-23 15:15:56,228 - logger.py:50 - Epoch: [67][300/500] loss: 1.58334, MAE: 0.30963, time/step=1408ms, lr=2.96e-05
2024-09-23 15:17:09,325 - logger.py:50 - Epoch: [67][350/500] loss: 1.53242, MAE: 0.30746, time/step=1416ms, lr=2.96e-05
2024-09-23 15:18:19,183 - logger.py:50 - Epoch: [67][400/500] loss: 1.49377, MAE: 0.30577, time/step=1413ms, lr=2.96e-05
2024-09-23 15:19:31,052 - logger.py:50 - Epoch: [67][450/500] loss: 1.47813, MAE: 0.30555, time/step=1416ms, lr=2.96e-05
2024-09-23 15:20:44,611 - logger.py:50 - Epoch: [67][499/500] loss: 1.45237, MAE: 0.30508, time/step=1424ms, lr=2.96e-05
2024-09-23 15:21:57,130 - logger.py:50 - Epoch: [67] train loss: 1.45237, train MAE: 0.30508,val loss: 0.30675, val MAE: 0.30675,test loss: 0.31883, test MAE: 0.31883,Time: 784.72s
2024-09-23 15:21:57,131 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 15:21:58,676 - logger.py:50 - Epoch: [68][0/500] loss: 2.34482, MAE: 0.32052, time/step=1543ms, lr=2.91e-05
2024-09-23 15:23:11,547 - logger.py:50 - Epoch: [68][50/500] loss: 1.27678, MAE: 0.29565, time/step=1459ms, lr=2.91e-05
2024-09-23 15:24:24,553 - logger.py:50 - Epoch: [68][100/500] loss: 1.29472, MAE: 0.29725, time/step=1460ms, lr=2.91e-05
2024-09-23 15:25:37,248 - logger.py:50 - Epoch: [68][150/500] loss: 1.27665, MAE: 0.30018, time/step=1458ms, lr=2.91e-05
2024-09-23 15:26:50,287 - logger.py:50 - Epoch: [68][200/500] loss: 1.30406, MAE: 0.30239, time/step=1458ms, lr=2.91e-05
2024-09-23 15:28:03,145 - logger.py:50 - Epoch: [68][250/500] loss: 1.31304, MAE: 0.30501, time/step=1458ms, lr=2.91e-05
2024-09-23 15:29:19,497 - logger.py:50 - Epoch: [68][300/500] loss: 1.27283, MAE: 0.30204, time/step=1470ms, lr=2.91e-05
2024-09-23 15:30:32,823 - logger.py:50 - Epoch: [68][350/500] loss: 1.27211, MAE: 0.30238, time/step=1469ms, lr=2.91e-05
2024-09-23 15:31:43,117 - logger.py:50 - Epoch: [68][400/500] loss: 1.49512, MAE: 0.30574, time/step=1461ms, lr=2.91e-05
2024-09-23 15:32:55,195 - logger.py:50 - Epoch: [68][450/500] loss: 1.46638, MAE: 0.30534, time/step=1459ms, lr=2.91e-05
2024-09-23 15:34:06,392 - logger.py:50 - Epoch: [68][499/500] loss: 1.45237, MAE: 0.30505, time/step=1459ms, lr=2.91e-05
2024-09-23 15:35:19,175 - logger.py:50 - Epoch: [68] train loss: 1.45237, train MAE: 0.30505,val loss: 0.30680, val MAE: 0.30680,test loss: 0.31882, test MAE: 0.31882,Time: 802.04s
2024-09-23 15:35:19,175 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 15:35:20,038 - logger.py:50 - Epoch: [69][0/500] loss: 1.03315, MAE: 0.26974, time/step=861ms, lr=2.86e-05
2024-09-23 15:36:30,860 - logger.py:50 - Epoch: [69][50/500] loss: 1.12553, MAE: 0.28783, time/step=1406ms, lr=2.86e-05
2024-09-23 15:37:42,689 - logger.py:50 - Epoch: [69][100/500] loss: 1.19355, MAE: 0.29689, time/step=1421ms, lr=2.86e-05
2024-09-23 15:38:51,938 - logger.py:50 - Epoch: [69][150/500] loss: 1.22170, MAE: 0.30055, time/step=1409ms, lr=2.86e-05
2024-09-23 15:40:01,683 - logger.py:50 - Epoch: [69][200/500] loss: 1.21292, MAE: 0.29851, time/step=1406ms, lr=2.86e-05
2024-09-23 15:41:13,937 - logger.py:50 - Epoch: [69][250/500] loss: 1.56334, MAE: 0.30531, time/step=1413ms, lr=2.86e-05
2024-09-23 15:42:25,596 - logger.py:50 - Epoch: [69][300/500] loss: 1.52667, MAE: 0.30641, time/step=1417ms, lr=2.86e-05
2024-09-23 15:43:37,058 - logger.py:50 - Epoch: [69][350/500] loss: 1.50956, MAE: 0.30706, time/step=1418ms, lr=2.86e-05
2024-09-23 15:44:48,938 - logger.py:50 - Epoch: [69][400/500] loss: 1.49347, MAE: 0.30702, time/step=1421ms, lr=2.86e-05
2024-09-23 15:46:00,150 - logger.py:50 - Epoch: [69][450/500] loss: 1.47146, MAE: 0.30742, time/step=1421ms, lr=2.86e-05
2024-09-23 15:47:10,586 - logger.py:50 - Epoch: [69][499/500] loss: 1.45234, MAE: 0.30507, time/step=1423ms, lr=2.86e-05
2024-09-23 15:48:23,792 - logger.py:50 - Epoch: [69] train loss: 1.45234, train MAE: 0.30507,val loss: 0.30691, val MAE: 0.30691,test loss: 0.31897, test MAE: 0.31897,Time: 784.62s
2024-09-23 15:48:23,792 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 15:48:25,352 - logger.py:50 - Epoch: [70][0/500] loss: 1.10170, MAE: 0.30466, time/step=1556ms, lr=2.81e-05
2024-09-23 15:49:36,151 - logger.py:50 - Epoch: [70][50/500] loss: 1.22869, MAE: 0.29651, time/step=1419ms, lr=2.81e-05
2024-09-23 15:50:45,068 - logger.py:50 - Epoch: [70][100/500] loss: 2.09305, MAE: 0.31523, time/step=1399ms, lr=2.81e-05
2024-09-23 15:51:57,376 - logger.py:50 - Epoch: [70][150/500] loss: 1.88294, MAE: 0.31437, time/step=1414ms, lr=2.81e-05
2024-09-23 15:53:08,707 - logger.py:50 - Epoch: [70][200/500] loss: 1.75234, MAE: 0.31386, time/step=1417ms, lr=2.81e-05
2024-09-23 15:54:19,654 - logger.py:50 - Epoch: [70][250/500] loss: 1.65319, MAE: 0.31049, time/step=1418ms, lr=2.81e-05
2024-09-23 15:55:31,099 - logger.py:50 - Epoch: [70][300/500] loss: 1.58696, MAE: 0.30865, time/step=1420ms, lr=2.81e-05
2024-09-23 15:56:41,825 - logger.py:50 - Epoch: [70][350/500] loss: 1.55809, MAE: 0.30809, time/step=1419ms, lr=2.81e-05
2024-09-23 15:57:52,245 - logger.py:50 - Epoch: [70][400/500] loss: 1.50991, MAE: 0.30634, time/step=1418ms, lr=2.81e-05
2024-09-23 15:59:02,222 - logger.py:50 - Epoch: [70][450/500] loss: 1.47988, MAE: 0.30549, time/step=1416ms, lr=2.81e-05
2024-09-23 16:00:14,510 - logger.py:50 - Epoch: [70][499/500] loss: 1.45241, MAE: 0.30506, time/step=1421ms, lr=2.81e-05
2024-09-23 16:01:26,242 - logger.py:50 - Epoch: [70] train loss: 1.45241, train MAE: 0.30506,val loss: 0.30670, val MAE: 0.30670,test loss: 0.31872, test MAE: 0.31872,Time: 782.45s
2024-09-23 16:01:26,242 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 16:01:27,725 - logger.py:50 - Epoch: [71][0/500] loss: 0.77777, MAE: 0.30498, time/step=1480ms, lr=2.76e-05
2024-09-23 16:02:40,579 - logger.py:50 - Epoch: [71][50/500] loss: 1.20895, MAE: 0.29230, time/step=1458ms, lr=2.76e-05
2024-09-23 16:03:52,477 - logger.py:50 - Epoch: [71][100/500] loss: 1.24869, MAE: 0.29774, time/step=1448ms, lr=2.76e-05
2024-09-23 16:05:04,137 - logger.py:50 - Epoch: [71][150/500] loss: 1.83381, MAE: 0.30847, time/step=1443ms, lr=2.76e-05
2024-09-23 16:06:16,080 - logger.py:50 - Epoch: [71][200/500] loss: 1.71732, MAE: 0.30968, time/step=1442ms, lr=2.76e-05
2024-09-23 16:07:24,763 - logger.py:50 - Epoch: [71][250/500] loss: 1.61225, MAE: 0.30849, time/step=1428ms, lr=2.76e-05
2024-09-23 16:08:34,283 - logger.py:50 - Epoch: [71][300/500] loss: 1.54796, MAE: 0.30668, time/step=1422ms, lr=2.76e-05
2024-09-23 16:09:44,686 - logger.py:50 - Epoch: [71][350/500] loss: 1.51586, MAE: 0.30666, time/step=1420ms, lr=2.76e-05
2024-09-23 16:10:54,643 - logger.py:50 - Epoch: [71][400/500] loss: 1.48796, MAE: 0.30490, time/step=1417ms, lr=2.76e-05
2024-09-23 16:12:06,193 - logger.py:50 - Epoch: [71][450/500] loss: 1.47440, MAE: 0.30606, time/step=1419ms, lr=2.76e-05
2024-09-23 16:13:14,566 - logger.py:50 - Epoch: [71][499/500] loss: 1.45227, MAE: 0.30508, time/step=1417ms, lr=2.76e-05
2024-09-23 16:14:26,515 - logger.py:50 - Epoch: [71] train loss: 1.45227, train MAE: 0.30508,val loss: 0.30671, val MAE: 0.30671,test loss: 0.31878, test MAE: 0.31878,Time: 780.27s
2024-09-23 16:14:26,515 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 16:14:28,083 - logger.py:50 - Epoch: [72][0/500] loss: 1.28298, MAE: 0.30046, time/step=1565ms, lr=2.70e-05
2024-09-23 16:15:36,835 - logger.py:50 - Epoch: [72][50/500] loss: 1.26931, MAE: 0.30695, time/step=1379ms, lr=2.70e-05
2024-09-23 16:16:48,893 - logger.py:50 - Epoch: [72][100/500] loss: 2.21061, MAE: 0.32279, time/step=1410ms, lr=2.70e-05
2024-09-23 16:17:59,576 - logger.py:50 - Epoch: [72][150/500] loss: 1.90685, MAE: 0.31582, time/step=1411ms, lr=2.70e-05
2024-09-23 16:19:11,914 - logger.py:50 - Epoch: [72][200/500] loss: 1.74537, MAE: 0.31152, time/step=1420ms, lr=2.70e-05
2024-09-23 16:20:28,866 - logger.py:50 - Epoch: [72][250/500] loss: 1.61921, MAE: 0.30786, time/step=1444ms, lr=2.70e-05
2024-09-23 16:21:47,108 - logger.py:50 - Epoch: [72][300/500] loss: 1.55983, MAE: 0.30601, time/step=1464ms, lr=2.70e-05
2024-09-23 16:23:08,877 - logger.py:50 - Epoch: [72][350/500] loss: 1.51550, MAE: 0.30498, time/step=1488ms, lr=2.70e-05
2024-09-23 16:24:29,343 - logger.py:50 - Epoch: [72][400/500] loss: 1.48640, MAE: 0.30506, time/step=1503ms, lr=2.70e-05
2024-09-23 16:25:52,592 - logger.py:50 - Epoch: [72][450/500] loss: 1.46236, MAE: 0.30473, time/step=1521ms, lr=2.70e-05
2024-09-23 16:27:15,128 - logger.py:50 - Epoch: [72][499/500] loss: 1.45222, MAE: 0.30505, time/step=1537ms, lr=2.70e-05
2024-09-23 16:28:30,741 - logger.py:50 - Epoch: [72] train loss: 1.45222, train MAE: 0.30505,val loss: 0.30704, val MAE: 0.30704,test loss: 0.31902, test MAE: 0.31902,Time: 844.23s
2024-09-23 16:28:30,741 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 16:28:32,310 - logger.py:50 - Epoch: [73][0/500] loss: 1.80115, MAE: 0.32533, time/step=1566ms, lr=2.65e-05
2024-09-23 16:29:57,942 - logger.py:50 - Epoch: [73][50/500] loss: 1.31362, MAE: 0.30330, time/step=1710ms, lr=2.65e-05
2024-09-23 16:31:26,425 - logger.py:50 - Epoch: [73][100/500] loss: 1.31396, MAE: 0.30712, time/step=1739ms, lr=2.65e-05
2024-09-23 16:32:52,868 - logger.py:50 - Epoch: [73][150/500] loss: 1.29467, MAE: 0.30567, time/step=1736ms, lr=2.65e-05
2024-09-23 16:34:22,951 - logger.py:50 - Epoch: [73][200/500] loss: 1.32351, MAE: 0.30471, time/step=1752ms, lr=2.65e-05
2024-09-23 16:35:46,123 - logger.py:50 - Epoch: [73][250/500] loss: 1.30954, MAE: 0.30282, time/step=1735ms, lr=2.65e-05
2024-09-23 16:37:07,252 - logger.py:50 - Epoch: [73][300/500] loss: 1.56868, MAE: 0.30713, time/step=1716ms, lr=2.65e-05
2024-09-23 16:38:28,246 - logger.py:50 - Epoch: [73][350/500] loss: 1.51862, MAE: 0.30639, time/step=1702ms, lr=2.65e-05
2024-09-23 16:39:49,931 - logger.py:50 - Epoch: [73][400/500] loss: 1.49855, MAE: 0.30638, time/step=1694ms, lr=2.65e-05
2024-09-23 16:41:09,627 - logger.py:50 - Epoch: [73][450/500] loss: 1.47843, MAE: 0.30588, time/step=1683ms, lr=2.65e-05
2024-09-23 16:42:26,713 - logger.py:50 - Epoch: [73][499/500] loss: 1.45225, MAE: 0.30506, time/step=1672ms, lr=2.65e-05
2024-09-23 16:43:40,736 - logger.py:50 - Epoch: [73] train loss: 1.45225, train MAE: 0.30506,val loss: 0.30676, val MAE: 0.30676,test loss: 0.31876, test MAE: 0.31876,Time: 909.99s
2024-09-23 16:43:40,736 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 16:43:41,808 - logger.py:50 - Epoch: [74][0/500] loss: 0.72378, MAE: 0.25513, time/step=1070ms, lr=2.60e-05
2024-09-23 16:44:56,813 - logger.py:50 - Epoch: [74][50/500] loss: 1.28936, MAE: 0.30622, time/step=1492ms, lr=2.60e-05
2024-09-23 16:46:11,660 - logger.py:50 - Epoch: [74][100/500] loss: 1.25614, MAE: 0.30055, time/step=1494ms, lr=2.60e-05
2024-09-23 16:47:26,918 - logger.py:50 - Epoch: [74][150/500] loss: 1.83032, MAE: 0.31027, time/step=1498ms, lr=2.60e-05
2024-09-23 16:48:42,808 - logger.py:50 - Epoch: [74][200/500] loss: 1.72829, MAE: 0.31308, time/step=1503ms, lr=2.60e-05
2024-09-23 16:49:59,652 - logger.py:50 - Epoch: [74][250/500] loss: 1.63624, MAE: 0.31101, time/step=1510ms, lr=2.60e-05
2024-09-23 16:51:11,776 - logger.py:50 - Epoch: [74][300/500] loss: 1.55758, MAE: 0.30716, time/step=1498ms, lr=2.60e-05
2024-09-23 16:52:26,811 - logger.py:50 - Epoch: [74][350/500] loss: 1.51573, MAE: 0.30599, time/step=1499ms, lr=2.60e-05
2024-09-23 16:53:41,520 - logger.py:50 - Epoch: [74][400/500] loss: 1.47193, MAE: 0.30511, time/step=1498ms, lr=2.60e-05
2024-09-23 16:54:57,479 - logger.py:50 - Epoch: [74][450/500] loss: 1.44098, MAE: 0.30393, time/step=1501ms, lr=2.60e-05
2024-09-23 16:56:10,134 - logger.py:50 - Epoch: [74][499/500] loss: 1.45226, MAE: 0.30503, time/step=1499ms, lr=2.60e-05
2024-09-23 16:57:21,941 - logger.py:50 - Epoch: [74] train loss: 1.45226, train MAE: 0.30503,val loss: 0.30698, val MAE: 0.30698,test loss: 0.31897, test MAE: 0.31897,Time: 821.20s
2024-09-23 16:57:21,941 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 16:57:23,500 - logger.py:50 - Epoch: [75][0/500] loss: 0.92325, MAE: 0.32963, time/step=1557ms, lr=2.55e-05
2024-09-23 16:58:34,443 - logger.py:50 - Epoch: [75][50/500] loss: 1.18007, MAE: 0.29277, time/step=1422ms, lr=2.55e-05
2024-09-23 16:59:47,239 - logger.py:50 - Epoch: [75][100/500] loss: 2.05322, MAE: 0.31506, time/step=1439ms, lr=2.55e-05
2024-09-23 17:00:59,121 - logger.py:50 - Epoch: [75][150/500] loss: 1.77224, MAE: 0.30716, time/step=1438ms, lr=2.55e-05
2024-09-23 17:02:12,955 - logger.py:50 - Epoch: [75][200/500] loss: 1.66466, MAE: 0.30846, time/step=1448ms, lr=2.55e-05
2024-09-23 17:03:26,901 - logger.py:50 - Epoch: [75][250/500] loss: 1.59290, MAE: 0.30638, time/step=1454ms, lr=2.55e-05
2024-09-23 17:04:39,692 - logger.py:50 - Epoch: [75][300/500] loss: 1.55309, MAE: 0.30655, time/step=1454ms, lr=2.55e-05
2024-09-23 17:05:51,317 - logger.py:50 - Epoch: [75][350/500] loss: 1.51893, MAE: 0.30610, time/step=1451ms, lr=2.55e-05
2024-09-23 17:07:02,602 - logger.py:50 - Epoch: [75][400/500] loss: 1.49556, MAE: 0.30664, time/step=1448ms, lr=2.55e-05
2024-09-23 17:08:13,897 - logger.py:50 - Epoch: [75][450/500] loss: 1.47637, MAE: 0.30661, time/step=1446ms, lr=2.55e-05
2024-09-23 17:09:25,572 - logger.py:50 - Epoch: [75][499/500] loss: 1.45222, MAE: 0.30506, time/step=1447ms, lr=2.55e-05
2024-09-23 17:10:37,945 - logger.py:50 - Epoch: [75] train loss: 1.45222, train MAE: 0.30506,val loss: 0.30685, val MAE: 0.30685,test loss: 0.31888, test MAE: 0.31888,Time: 796.00s
2024-09-23 17:10:37,945 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 17:10:39,477 - logger.py:50 - Epoch: [76][0/500] loss: 0.76868, MAE: 0.26150, time/step=1529ms, lr=2.50e-05
2024-09-23 17:11:50,225 - logger.py:50 - Epoch: [76][50/500] loss: 1.50091, MAE: 0.30933, time/step=1417ms, lr=2.50e-05
2024-09-23 17:13:00,368 - logger.py:50 - Epoch: [76][100/500] loss: 1.40401, MAE: 0.30808, time/step=1410ms, lr=2.50e-05
2024-09-23 17:14:12,893 - logger.py:50 - Epoch: [76][150/500] loss: 1.35433, MAE: 0.30146, time/step=1423ms, lr=2.50e-05
2024-09-23 17:15:24,348 - logger.py:50 - Epoch: [76][200/500] loss: 1.32772, MAE: 0.30105, time/step=1425ms, lr=2.50e-05
2024-09-23 17:16:34,803 - logger.py:50 - Epoch: [76][250/500] loss: 1.31608, MAE: 0.30219, time/step=1422ms, lr=2.50e-05
2024-09-23 17:17:45,330 - logger.py:50 - Epoch: [76][300/500] loss: 1.30009, MAE: 0.30074, time/step=1420ms, lr=2.50e-05
2024-09-23 17:18:56,305 - logger.py:50 - Epoch: [76][350/500] loss: 1.28412, MAE: 0.30066, time/step=1420ms, lr=2.50e-05
2024-09-23 17:20:09,575 - logger.py:50 - Epoch: [76][400/500] loss: 1.27095, MAE: 0.29988, time/step=1426ms, lr=2.50e-05
2024-09-23 17:21:21,738 - logger.py:50 - Epoch: [76][450/500] loss: 1.45783, MAE: 0.30397, time/step=1427ms, lr=2.50e-05
2024-09-23 17:22:31,350 - logger.py:50 - Epoch: [76][499/500] loss: 1.45224, MAE: 0.30503, time/step=1427ms, lr=2.50e-05
2024-09-23 17:23:42,204 - logger.py:50 - Epoch: [76] train loss: 1.45224, train MAE: 0.30503,val loss: 0.30680, val MAE: 0.30680,test loss: 0.31881, test MAE: 0.31881,Time: 784.26s
2024-09-23 17:23:42,204 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 17:23:43,732 - logger.py:50 - Epoch: [77][0/500] loss: 0.62943, MAE: 0.23318, time/step=1525ms, lr=2.45e-05
2024-09-23 17:24:52,518 - logger.py:50 - Epoch: [77][50/500] loss: 1.18879, MAE: 0.29814, time/step=1379ms, lr=2.45e-05
2024-09-23 17:26:03,575 - logger.py:50 - Epoch: [77][100/500] loss: 1.22204, MAE: 0.30509, time/step=1400ms, lr=2.45e-05
2024-09-23 17:27:15,035 - logger.py:50 - Epoch: [77][150/500] loss: 1.78398, MAE: 0.31254, time/step=1409ms, lr=2.45e-05
2024-09-23 17:28:26,162 - logger.py:50 - Epoch: [77][200/500] loss: 1.65262, MAE: 0.30735, time/step=1413ms, lr=2.45e-05
2024-09-23 17:29:34,959 - logger.py:50 - Epoch: [77][250/500] loss: 1.58842, MAE: 0.30528, time/step=1405ms, lr=2.45e-05
2024-09-23 17:30:46,086 - logger.py:50 - Epoch: [77][300/500] loss: 1.54830, MAE: 0.30572, time/step=1408ms, lr=2.45e-05
2024-09-23 17:31:58,683 - logger.py:50 - Epoch: [77][350/500] loss: 1.51111, MAE: 0.30482, time/step=1414ms, lr=2.45e-05
2024-09-23 17:33:09,305 - logger.py:50 - Epoch: [77][400/500] loss: 1.48435, MAE: 0.30480, time/step=1414ms, lr=2.45e-05
2024-09-23 17:34:20,677 - logger.py:50 - Epoch: [77][450/500] loss: 1.47453, MAE: 0.30572, time/step=1416ms, lr=2.45e-05
2024-09-23 17:35:29,522 - logger.py:50 - Epoch: [77][499/500] loss: 1.45225, MAE: 0.30503, time/step=1415ms, lr=2.45e-05
2024-09-23 17:36:41,908 - logger.py:50 - Epoch: [77] train loss: 1.45225, train MAE: 0.30503,val loss: 0.30686, val MAE: 0.30686,test loss: 0.31892, test MAE: 0.31892,Time: 779.70s
2024-09-23 17:36:41,908 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 17:36:43,494 - logger.py:50 - Epoch: [78][0/500] loss: 0.93793, MAE: 0.26748, time/step=1582ms, lr=2.40e-05
2024-09-23 17:37:52,676 - logger.py:50 - Epoch: [78][50/500] loss: 1.26036, MAE: 0.29504, time/step=1388ms, lr=2.40e-05
2024-09-23 17:39:03,099 - logger.py:50 - Epoch: [78][100/500] loss: 1.23624, MAE: 0.29526, time/step=1398ms, lr=2.40e-05
2024-09-23 17:40:14,813 - logger.py:50 - Epoch: [78][150/500] loss: 1.31738, MAE: 0.30095, time/step=1410ms, lr=2.40e-05
2024-09-23 17:41:25,523 - logger.py:50 - Epoch: [78][200/500] loss: 1.31762, MAE: 0.30115, time/step=1411ms, lr=2.40e-05
2024-09-23 17:42:35,116 - logger.py:50 - Epoch: [78][250/500] loss: 1.31339, MAE: 0.30179, time/step=1407ms, lr=2.40e-05
2024-09-23 17:43:48,210 - logger.py:50 - Epoch: [78][300/500] loss: 1.29491, MAE: 0.30148, time/step=1416ms, lr=2.40e-05
2024-09-23 17:44:59,515 - logger.py:50 - Epoch: [78][350/500] loss: 1.51838, MAE: 0.30542, time/step=1418ms, lr=2.40e-05
2024-09-23 17:46:09,211 - logger.py:50 - Epoch: [78][400/500] loss: 1.49617, MAE: 0.30549, time/step=1415ms, lr=2.40e-05
2024-09-23 17:47:21,181 - logger.py:50 - Epoch: [78][450/500] loss: 1.46553, MAE: 0.30452, time/step=1417ms, lr=2.40e-05
2024-09-23 17:48:31,492 - logger.py:50 - Epoch: [78][499/500] loss: 1.45219, MAE: 0.30501, time/step=1419ms, lr=2.40e-05
2024-09-23 17:49:44,800 - logger.py:50 - Epoch: [78] train loss: 1.45219, train MAE: 0.30501,val loss: 0.30693, val MAE: 0.30693,test loss: 0.31897, test MAE: 0.31897,Time: 782.89s
2024-09-23 17:49:44,801 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 17:49:46,201 - logger.py:50 - Epoch: [79][0/500] loss: 0.97972, MAE: 0.24083, time/step=1398ms, lr=2.34e-05
2024-09-23 17:50:56,008 - logger.py:50 - Epoch: [79][50/500] loss: 1.25592, MAE: 0.30649, time/step=1396ms, lr=2.34e-05
2024-09-23 17:52:07,522 - logger.py:50 - Epoch: [79][100/500] loss: 1.24531, MAE: 0.30628, time/step=1413ms, lr=2.34e-05
2024-09-23 17:53:18,776 - logger.py:50 - Epoch: [79][150/500] loss: 1.32199, MAE: 0.30696, time/step=1417ms, lr=2.34e-05
2024-09-23 17:54:29,258 - logger.py:50 - Epoch: [79][200/500] loss: 1.28271, MAE: 0.30580, time/step=1415ms, lr=2.34e-05
2024-09-23 17:55:38,927 - logger.py:50 - Epoch: [79][250/500] loss: 1.61735, MAE: 0.30947, time/step=1411ms, lr=2.34e-05
2024-09-23 17:56:48,170 - logger.py:50 - Epoch: [79][300/500] loss: 1.56507, MAE: 0.30821, time/step=1407ms, lr=2.34e-05
2024-09-23 17:57:57,673 - logger.py:50 - Epoch: [79][350/500] loss: 1.52441, MAE: 0.30646, time/step=1404ms, lr=2.34e-05
2024-09-23 17:59:08,115 - logger.py:50 - Epoch: [79][400/500] loss: 1.48877, MAE: 0.30572, time/step=1405ms, lr=2.34e-05
2024-09-23 18:00:17,785 - logger.py:50 - Epoch: [79][450/500] loss: 1.46755, MAE: 0.30492, time/step=1404ms, lr=2.34e-05
2024-09-23 18:01:26,746 - logger.py:50 - Epoch: [79][499/500] loss: 1.45213, MAE: 0.30503, time/step=1404ms, lr=2.34e-05
2024-09-23 18:02:38,204 - logger.py:50 - Epoch: [79] train loss: 1.45213, train MAE: 0.30503,val loss: 0.30666, val MAE: 0.30666,test loss: 0.31869, test MAE: 0.31869,Time: 773.40s
2024-09-23 18:02:38,204 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 18:02:39,851 - logger.py:50 - Epoch: [80][0/500] loss: 0.88678, MAE: 0.23415, time/step=1644ms, lr=2.29e-05
2024-09-23 18:03:48,154 - logger.py:50 - Epoch: [80][50/500] loss: 1.23642, MAE: 0.29917, time/step=1372ms, lr=2.29e-05
2024-09-23 18:04:59,236 - logger.py:50 - Epoch: [80][100/500] loss: 1.25426, MAE: 0.29983, time/step=1396ms, lr=2.29e-05
2024-09-23 18:06:08,980 - logger.py:50 - Epoch: [80][150/500] loss: 1.27186, MAE: 0.30109, time/step=1396ms, lr=2.29e-05
2024-09-23 18:07:20,229 - logger.py:50 - Epoch: [80][200/500] loss: 1.28475, MAE: 0.29996, time/step=1403ms, lr=2.29e-05
2024-09-23 18:08:31,465 - logger.py:50 - Epoch: [80][250/500] loss: 1.27485, MAE: 0.30078, time/step=1407ms, lr=2.29e-05
2024-09-23 18:09:43,686 - logger.py:50 - Epoch: [80][300/500] loss: 1.26866, MAE: 0.30065, time/step=1414ms, lr=2.29e-05
2024-09-23 18:10:53,733 - logger.py:50 - Epoch: [80][350/500] loss: 1.26448, MAE: 0.30001, time/step=1412ms, lr=2.29e-05
2024-09-23 18:12:02,230 - logger.py:50 - Epoch: [80][400/500] loss: 1.47330, MAE: 0.30400, time/step=1407ms, lr=2.29e-05
2024-09-23 18:13:12,681 - logger.py:50 - Epoch: [80][450/500] loss: 1.45240, MAE: 0.30360, time/step=1407ms, lr=2.29e-05
2024-09-23 18:14:21,467 - logger.py:50 - Epoch: [80][499/500] loss: 1.45203, MAE: 0.30503, time/step=1407ms, lr=2.29e-05
2024-09-23 18:15:32,078 - logger.py:50 - Epoch: [80] train loss: 1.45203, train MAE: 0.30503,val loss: 0.30692, val MAE: 0.30692,test loss: 0.31894, test MAE: 0.31894,Time: 773.87s
2024-09-23 18:15:32,078 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 18:15:33,488 - logger.py:50 - Epoch: [81][0/500] loss: 0.61257, MAE: 0.25610, time/step=1407ms, lr=2.24e-05
2024-09-23 18:16:44,293 - logger.py:50 - Epoch: [81][50/500] loss: 1.19080, MAE: 0.29958, time/step=1416ms, lr=2.24e-05
2024-09-23 18:17:54,246 - logger.py:50 - Epoch: [81][100/500] loss: 1.22067, MAE: 0.29313, time/step=1408ms, lr=2.24e-05
2024-09-23 18:19:03,684 - logger.py:50 - Epoch: [81][150/500] loss: 1.23100, MAE: 0.29493, time/step=1401ms, lr=2.24e-05
2024-09-23 18:20:15,286 - logger.py:50 - Epoch: [81][200/500] loss: 1.27792, MAE: 0.29822, time/step=1409ms, lr=2.24e-05
2024-09-23 18:21:25,435 - logger.py:50 - Epoch: [81][250/500] loss: 1.28067, MAE: 0.30004, time/step=1408ms, lr=2.24e-05
2024-09-23 18:22:34,310 - logger.py:50 - Epoch: [81][300/500] loss: 1.30517, MAE: 0.30177, time/step=1403ms, lr=2.24e-05
2024-09-23 18:23:44,318 - logger.py:50 - Epoch: [81][350/500] loss: 1.29718, MAE: 0.30177, time/step=1402ms, lr=2.24e-05
2024-09-23 18:24:56,269 - logger.py:50 - Epoch: [81][400/500] loss: 1.29354, MAE: 0.30196, time/step=1407ms, lr=2.24e-05
2024-09-23 18:26:06,249 - logger.py:50 - Epoch: [81][450/500] loss: 1.28360, MAE: 0.30202, time/step=1406ms, lr=2.24e-05
2024-09-23 18:27:14,908 - logger.py:50 - Epoch: [81][499/500] loss: 1.45208, MAE: 0.30500, time/step=1406ms, lr=2.24e-05
2024-09-23 18:28:27,078 - logger.py:50 - Epoch: [81] train loss: 1.45208, train MAE: 0.30500,val loss: 0.30670, val MAE: 0.30670,test loss: 0.31872, test MAE: 0.31872,Time: 775.00s
2024-09-23 18:28:27,078 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 18:28:28,704 - logger.py:50 - Epoch: [82][0/500] loss: 1.56305, MAE: 0.26392, time/step=1623ms, lr=2.19e-05
2024-09-23 18:29:37,365 - logger.py:50 - Epoch: [82][50/500] loss: 1.23312, MAE: 0.30732, time/step=1378ms, lr=2.19e-05
2024-09-23 18:30:47,099 - logger.py:50 - Epoch: [82][100/500] loss: 1.25730, MAE: 0.30582, time/step=1386ms, lr=2.19e-05
2024-09-23 18:31:56,843 - logger.py:50 - Epoch: [82][150/500] loss: 1.28709, MAE: 0.30487, time/step=1389ms, lr=2.19e-05
2024-09-23 18:33:06,573 - logger.py:50 - Epoch: [82][200/500] loss: 1.28705, MAE: 0.30552, time/step=1391ms, lr=2.19e-05
2024-09-23 18:34:16,396 - logger.py:50 - Epoch: [82][250/500] loss: 1.62253, MAE: 0.31035, time/step=1392ms, lr=2.19e-05
2024-09-23 18:35:26,866 - logger.py:50 - Epoch: [82][300/500] loss: 1.54582, MAE: 0.30578, time/step=1395ms, lr=2.19e-05
2024-09-23 18:36:36,872 - logger.py:50 - Epoch: [82][350/500] loss: 1.51198, MAE: 0.30430, time/step=1395ms, lr=2.19e-05
2024-09-23 18:37:49,887 - logger.py:50 - Epoch: [82][400/500] loss: 1.49013, MAE: 0.30511, time/step=1404ms, lr=2.19e-05
2024-09-23 18:39:00,936 - logger.py:50 - Epoch: [82][450/500] loss: 1.47489, MAE: 0.30543, time/step=1405ms, lr=2.19e-05
2024-09-23 18:40:09,643 - logger.py:50 - Epoch: [82][499/500] loss: 1.45206, MAE: 0.30500, time/step=1405ms, lr=2.19e-05
2024-09-23 18:41:20,927 - logger.py:50 - Epoch: [82] train loss: 1.45206, train MAE: 0.30500,val loss: 0.30675, val MAE: 0.30675,test loss: 0.31878, test MAE: 0.31878,Time: 773.85s
2024-09-23 18:41:20,927 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 18:41:22,007 - logger.py:50 - Epoch: [83][0/500] loss: 0.93334, MAE: 0.30028, time/step=1078ms, lr=2.14e-05
2024-09-23 18:42:31,198 - logger.py:50 - Epoch: [83][50/500] loss: 1.21557, MAE: 0.29453, time/step=1378ms, lr=2.14e-05
2024-09-23 18:43:41,026 - logger.py:50 - Epoch: [83][100/500] loss: 1.26258, MAE: 0.29774, time/step=1387ms, lr=2.14e-05
2024-09-23 18:44:49,439 - logger.py:50 - Epoch: [83][150/500] loss: 1.23774, MAE: 0.29789, time/step=1381ms, lr=2.14e-05
2024-09-23 18:46:00,355 - logger.py:50 - Epoch: [83][200/500] loss: 1.24316, MAE: 0.29848, time/step=1390ms, lr=2.14e-05
2024-09-23 18:47:12,220 - logger.py:50 - Epoch: [83][250/500] loss: 1.26265, MAE: 0.30006, time/step=1400ms, lr=2.14e-05
2024-09-23 18:48:23,203 - logger.py:50 - Epoch: [83][300/500] loss: 1.27492, MAE: 0.30158, time/step=1403ms, lr=2.14e-05
2024-09-23 18:49:33,783 - logger.py:50 - Epoch: [83][350/500] loss: 1.27743, MAE: 0.30216, time/step=1404ms, lr=2.14e-05
2024-09-23 18:50:44,122 - logger.py:50 - Epoch: [83][400/500] loss: 1.27870, MAE: 0.30158, time/step=1404ms, lr=2.14e-05
2024-09-23 18:51:54,668 - logger.py:50 - Epoch: [83][450/500] loss: 1.27436, MAE: 0.30206, time/step=1405ms, lr=2.14e-05
2024-09-23 18:53:04,444 - logger.py:50 - Epoch: [83][499/500] loss: 1.45211, MAE: 0.30499, time/step=1407ms, lr=2.14e-05
2024-09-23 18:54:16,501 - logger.py:50 - Epoch: [83] train loss: 1.45211, train MAE: 0.30499,val loss: 0.30681, val MAE: 0.30681,test loss: 0.31882, test MAE: 0.31882,Time: 775.57s
2024-09-23 18:54:16,501 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 18:54:18,025 - logger.py:50 - Epoch: [84][0/500] loss: 1.28397, MAE: 0.29108, time/step=1521ms, lr=2.09e-05
2024-09-23 18:55:28,038 - logger.py:50 - Epoch: [84][50/500] loss: 1.38840, MAE: 0.30562, time/step=1403ms, lr=2.09e-05
2024-09-23 18:56:38,963 - logger.py:50 - Epoch: [84][100/500] loss: 2.16378, MAE: 0.31312, time/step=1410ms, lr=2.09e-05
2024-09-23 18:57:50,424 - logger.py:50 - Epoch: [84][150/500] loss: 1.87613, MAE: 0.30909, time/step=1417ms, lr=2.09e-05
2024-09-23 18:58:57,699 - logger.py:50 - Epoch: [84][200/500] loss: 1.70867, MAE: 0.30706, time/step=1399ms, lr=2.09e-05
2024-09-23 19:00:08,035 - logger.py:50 - Epoch: [84][250/500] loss: 1.61092, MAE: 0.30581, time/step=1401ms, lr=2.09e-05
2024-09-23 19:01:19,268 - logger.py:50 - Epoch: [84][300/500] loss: 1.57787, MAE: 0.30647, time/step=1405ms, lr=2.09e-05
2024-09-23 19:02:30,260 - logger.py:50 - Epoch: [84][350/500] loss: 1.52723, MAE: 0.30588, time/step=1407ms, lr=2.09e-05
2024-09-23 19:03:41,216 - logger.py:50 - Epoch: [84][400/500] loss: 1.49145, MAE: 0.30565, time/step=1408ms, lr=2.09e-05
2024-09-23 19:04:52,500 - logger.py:50 - Epoch: [84][450/500] loss: 1.46957, MAE: 0.30434, time/step=1410ms, lr=2.09e-05
2024-09-23 19:06:01,336 - logger.py:50 - Epoch: [84][499/500] loss: 1.45200, MAE: 0.30499, time/step=1410ms, lr=2.09e-05
2024-09-23 19:07:12,712 - logger.py:50 - Epoch: [84] train loss: 1.45200, train MAE: 0.30499,val loss: 0.30696, val MAE: 0.30696,test loss: 0.31900, test MAE: 0.31900,Time: 776.21s
2024-09-23 19:07:12,712 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 19:07:14,349 - logger.py:50 - Epoch: [85][0/500] loss: 1.16005, MAE: 0.28462, time/step=1635ms, lr=2.04e-05
2024-09-23 19:08:22,675 - logger.py:50 - Epoch: [85][50/500] loss: 1.30064, MAE: 0.29995, time/step=1372ms, lr=2.04e-05
2024-09-23 19:09:34,361 - logger.py:50 - Epoch: [85][100/500] loss: 1.37280, MAE: 0.30286, time/step=1402ms, lr=2.04e-05
2024-09-23 19:10:45,061 - logger.py:50 - Epoch: [85][150/500] loss: 1.30258, MAE: 0.30157, time/step=1406ms, lr=2.04e-05
2024-09-23 19:11:54,823 - logger.py:50 - Epoch: [85][200/500] loss: 1.70360, MAE: 0.30741, time/step=1404ms, lr=2.04e-05
2024-09-23 19:13:06,899 - logger.py:50 - Epoch: [85][250/500] loss: 1.62019, MAE: 0.30756, time/step=1411ms, lr=2.04e-05
2024-09-23 19:14:19,071 - logger.py:50 - Epoch: [85][300/500] loss: 1.59043, MAE: 0.30825, time/step=1416ms, lr=2.04e-05
2024-09-23 19:15:29,497 - logger.py:50 - Epoch: [85][350/500] loss: 1.53416, MAE: 0.30629, time/step=1415ms, lr=2.04e-05
2024-09-23 19:16:40,181 - logger.py:50 - Epoch: [85][400/500] loss: 1.49997, MAE: 0.30637, time/step=1415ms, lr=2.04e-05
2024-09-23 19:17:48,624 - logger.py:50 - Epoch: [85][450/500] loss: 1.47612, MAE: 0.30699, time/step=1410ms, lr=2.04e-05
2024-09-23 19:18:55,763 - logger.py:50 - Epoch: [85][499/500] loss: 1.45197, MAE: 0.30500, time/step=1406ms, lr=2.04e-05
2024-09-23 19:20:07,735 - logger.py:50 - Epoch: [85] train loss: 1.45197, train MAE: 0.30500,val loss: 0.30678, val MAE: 0.30678,test loss: 0.31884, test MAE: 0.31884,Time: 775.02s
2024-09-23 19:20:07,736 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 19:20:09,341 - logger.py:50 - Epoch: [86][0/500] loss: 1.40281, MAE: 0.36381, time/step=1603ms, lr=1.99e-05
2024-09-23 19:21:19,540 - logger.py:50 - Epoch: [86][50/500] loss: 1.34721, MAE: 0.30798, time/step=1408ms, lr=1.99e-05
2024-09-23 19:22:28,986 - logger.py:50 - Epoch: [86][100/500] loss: 1.28758, MAE: 0.30399, time/step=1398ms, lr=1.99e-05
2024-09-23 19:23:38,197 - logger.py:50 - Epoch: [86][150/500] loss: 1.27544, MAE: 0.30279, time/step=1394ms, lr=1.99e-05
2024-09-23 19:24:48,445 - logger.py:50 - Epoch: [86][200/500] loss: 1.26915, MAE: 0.30039, time/step=1397ms, lr=1.99e-05
2024-09-23 19:25:59,788 - logger.py:50 - Epoch: [86][250/500] loss: 1.60608, MAE: 0.30655, time/step=1403ms, lr=1.99e-05
2024-09-23 19:27:08,815 - logger.py:50 - Epoch: [86][300/500] loss: 1.55934, MAE: 0.30556, time/step=1399ms, lr=1.99e-05
2024-09-23 19:28:20,516 - logger.py:50 - Epoch: [86][350/500] loss: 1.52023, MAE: 0.30456, time/step=1404ms, lr=1.99e-05
2024-09-23 19:29:29,580 - logger.py:50 - Epoch: [86][400/500] loss: 1.47199, MAE: 0.30295, time/step=1401ms, lr=1.99e-05
2024-09-23 19:30:40,166 - logger.py:50 - Epoch: [86][450/500] loss: 1.46402, MAE: 0.30365, time/step=1402ms, lr=1.99e-05
2024-09-23 19:31:49,565 - logger.py:50 - Epoch: [86][499/500] loss: 1.45202, MAE: 0.30498, time/step=1404ms, lr=1.99e-05
2024-09-23 19:33:01,810 - logger.py:50 - Epoch: [86] train loss: 1.45202, train MAE: 0.30498,val loss: 0.30664, val MAE: 0.30664,test loss: 0.31870, test MAE: 0.31870,Time: 774.07s
2024-09-23 19:33:01,810 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 19:33:03,392 - logger.py:50 - Epoch: [87][0/500] loss: 0.77570, MAE: 0.24235, time/step=1579ms, lr=1.94e-05
2024-09-23 19:34:15,076 - logger.py:50 - Epoch: [87][50/500] loss: 1.22709, MAE: 0.29856, time/step=1437ms, lr=1.94e-05
2024-09-23 19:35:28,258 - logger.py:50 - Epoch: [87][100/500] loss: 1.24175, MAE: 0.30106, time/step=1450ms, lr=1.94e-05
2024-09-23 19:36:40,322 - logger.py:50 - Epoch: [87][150/500] loss: 1.25732, MAE: 0.30339, time/step=1447ms, lr=1.94e-05
2024-09-23 19:37:53,058 - logger.py:50 - Epoch: [87][200/500] loss: 1.29625, MAE: 0.30518, time/step=1449ms, lr=1.94e-05
2024-09-23 19:39:05,063 - logger.py:50 - Epoch: [87][250/500] loss: 1.29037, MAE: 0.30375, time/step=1447ms, lr=1.94e-05
2024-09-23 19:40:17,604 - logger.py:50 - Epoch: [87][300/500] loss: 1.28714, MAE: 0.30436, time/step=1448ms, lr=1.94e-05
2024-09-23 19:41:30,807 - logger.py:50 - Epoch: [87][350/500] loss: 1.29559, MAE: 0.30381, time/step=1450ms, lr=1.94e-05
2024-09-23 19:42:42,000 - logger.py:50 - Epoch: [87][400/500] loss: 1.29464, MAE: 0.30185, time/step=1447ms, lr=1.94e-05
2024-09-23 19:43:53,268 - logger.py:50 - Epoch: [87][450/500] loss: 1.47385, MAE: 0.30446, time/step=1444ms, lr=1.94e-05
2024-09-23 19:45:01,025 - logger.py:50 - Epoch: [87][499/500] loss: 1.45199, MAE: 0.30497, time/step=1438ms, lr=1.94e-05
2024-09-23 19:46:14,900 - logger.py:50 - Epoch: [87] train loss: 1.45199, train MAE: 0.30497,val loss: 0.30703, val MAE: 0.30703,test loss: 0.31904, test MAE: 0.31904,Time: 793.09s
2024-09-23 19:46:14,900 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 19:46:16,673 - logger.py:50 - Epoch: [88][0/500] loss: 1.51178, MAE: 0.34767, time/step=1770ms, lr=1.89e-05
2024-09-23 19:47:25,123 - logger.py:50 - Epoch: [88][50/500] loss: 1.23591, MAE: 0.29976, time/step=1377ms, lr=1.89e-05
2024-09-23 19:48:35,989 - logger.py:50 - Epoch: [88][100/500] loss: 1.18276, MAE: 0.29598, time/step=1397ms, lr=1.89e-05
2024-09-23 19:49:47,051 - logger.py:50 - Epoch: [88][150/500] loss: 1.22141, MAE: 0.29754, time/step=1405ms, lr=1.89e-05
2024-09-23 19:50:58,393 - logger.py:50 - Epoch: [88][200/500] loss: 1.25500, MAE: 0.30002, time/step=1410ms, lr=1.89e-05
2024-09-23 19:52:09,290 - logger.py:50 - Epoch: [88][250/500] loss: 1.59343, MAE: 0.30678, time/step=1412ms, lr=1.89e-05
2024-09-23 19:53:19,387 - logger.py:50 - Epoch: [88][300/500] loss: 1.55073, MAE: 0.30705, time/step=1410ms, lr=1.89e-05
2024-09-23 19:54:30,441 - logger.py:50 - Epoch: [88][350/500] loss: 1.51320, MAE: 0.30482, time/step=1412ms, lr=1.89e-05
2024-09-23 19:55:42,366 - logger.py:50 - Epoch: [88][400/500] loss: 1.49784, MAE: 0.30538, time/step=1415ms, lr=1.89e-05
2024-09-23 19:56:52,074 - logger.py:50 - Epoch: [88][450/500] loss: 1.46887, MAE: 0.30456, time/step=1413ms, lr=1.89e-05
2024-09-23 19:58:02,545 - logger.py:50 - Epoch: [88][499/500] loss: 1.45195, MAE: 0.30499, time/step=1415ms, lr=1.89e-05
2024-09-23 19:59:14,427 - logger.py:50 - Epoch: [88] train loss: 1.45195, train MAE: 0.30499,val loss: 0.30680, val MAE: 0.30680,test loss: 0.31881, test MAE: 0.31881,Time: 779.53s
2024-09-23 19:59:14,428 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 19:59:15,755 - logger.py:50 - Epoch: [89][0/500] loss: 0.89759, MAE: 0.27002, time/step=1324ms, lr=1.84e-05
2024-09-23 20:00:25,957 - logger.py:50 - Epoch: [89][50/500] loss: 1.25725, MAE: 0.30837, time/step=1402ms, lr=1.84e-05
2024-09-23 20:01:35,032 - logger.py:50 - Epoch: [89][100/500] loss: 1.23811, MAE: 0.30073, time/step=1392ms, lr=1.84e-05
2024-09-23 20:02:46,148 - logger.py:50 - Epoch: [89][150/500] loss: 1.84703, MAE: 0.30997, time/step=1402ms, lr=1.84e-05
2024-09-23 20:03:55,551 - logger.py:50 - Epoch: [89][200/500] loss: 1.70504, MAE: 0.30717, time/step=1399ms, lr=1.84e-05
2024-09-23 20:05:05,908 - logger.py:50 - Epoch: [89][250/500] loss: 1.60506, MAE: 0.30369, time/step=1400ms, lr=1.84e-05
2024-09-23 20:06:17,665 - logger.py:50 - Epoch: [89][300/500] loss: 1.53979, MAE: 0.30410, time/step=1406ms, lr=1.84e-05
2024-09-23 20:07:27,985 - logger.py:50 - Epoch: [89][350/500] loss: 1.51628, MAE: 0.30533, time/step=1406ms, lr=1.84e-05
2024-09-23 20:08:38,019 - logger.py:50 - Epoch: [89][400/500] loss: 1.49582, MAE: 0.30528, time/step=1405ms, lr=1.84e-05
2024-09-23 20:09:48,364 - logger.py:50 - Epoch: [89][450/500] loss: 1.46945, MAE: 0.30555, time/step=1406ms, lr=1.84e-05
2024-09-23 20:10:57,537 - logger.py:50 - Epoch: [89][499/500] loss: 1.45188, MAE: 0.30498, time/step=1406ms, lr=1.84e-05
2024-09-23 20:12:08,973 - logger.py:50 - Epoch: [89] train loss: 1.45188, train MAE: 0.30498,val loss: 0.30705, val MAE: 0.30705,test loss: 0.31906, test MAE: 0.31906,Time: 774.55s
2024-09-23 20:12:08,973 - logger.py:50 - Best -- epoch=49, train loss: 1.45283, val loss: 0.30659, test loss: 0.31864

2024-09-23 20:12:10,010 - logger.py:50 - Epoch: [90][0/500] loss: 1.52122, MAE: 0.30485, time/step=1034ms, lr=1.79e-05
2024-09-23 20:13:19,257 - logger.py:50 - Epoch: [90][50/500] loss: 2.86430, MAE: 0.32451, time/step=1378ms, lr=1.79e-05
2024-09-23 20:14:29,137 - logger.py:50 - Epoch: [90][100/500] loss: 2.15997, MAE: 0.31441, time/step=1388ms, lr=1.79e-05
2024-09-23 20:15:38,751 - logger.py:50 - Epoch: [90][150/500] loss: 1.89375, MAE: 0.31370, time/step=1389ms, lr=1.79e-05
2024-09-23 20:16:48,615 - logger.py:50 - Epoch: [90][200/500] loss: 1.71510, MAE: 0.31042, time/step=1391ms, lr=1.79e-05
2024-09-23 20:17:56,699 - logger.py:50 - Epoch: [90][250/500] loss: 1.61546, MAE: 0.30781, time/step=1385ms, lr=1.79e-05
2024-09-23 20:19:06,506 - logger.py:50 - Epoch: [90][300/500] loss: 1.55591, MAE: 0.30721, time/step=1387ms, lr=1.79e-05
2024-09-23 20:20:17,135 - logger.py:50 - Epoch: [90][350/500] loss: 1.52616, MAE: 0.30659, time/step=1391ms, lr=1.79e-05
2024-09-23 20:21:28,867 - logger.py:50 - Epoch: [90][400/500] loss: 1.49462, MAE: 0.30557, time/step=1396ms, lr=1.79e-05
2024-09-23 20:22:40,305 - logger.py:50 - Epoch: [90][450/500] loss: 1.47738, MAE: 0.30592, time/step=1400ms, lr=1.79e-05
2024-09-23 20:23:52,241 - logger.py:50 - Epoch: [90][499/500] loss: 1.45192, MAE: 0.30500, time/step=1407ms, lr=1.79e-05
2024-09-23 20:25:05,225 - logger.py:50 - Epoch: [90] train loss: 1.45192, train MAE: 0.30500,val loss: 0.30657, val MAE: 0.30657,test loss: 0.31863, test MAE: 0.31863,Time: 776.25s
2024-09-23 20:25:05,225 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 20:25:06,291 - logger.py:50 - Epoch: [91][0/500] loss: 0.98156, MAE: 0.25224, time/step=1063ms, lr=1.74e-05
2024-09-23 20:26:17,347 - logger.py:50 - Epoch: [91][50/500] loss: 1.24326, MAE: 0.29799, time/step=1414ms, lr=1.74e-05
2024-09-23 20:27:28,301 - logger.py:50 - Epoch: [91][100/500] loss: 1.22510, MAE: 0.30092, time/step=1417ms, lr=1.74e-05
2024-09-23 20:28:41,603 - logger.py:50 - Epoch: [91][150/500] loss: 1.25622, MAE: 0.29837, time/step=1433ms, lr=1.74e-05
2024-09-23 20:29:53,980 - logger.py:50 - Epoch: [91][200/500] loss: 1.67472, MAE: 0.30719, time/step=1437ms, lr=1.74e-05
2024-09-23 20:31:07,088 - logger.py:50 - Epoch: [91][250/500] loss: 1.58191, MAE: 0.30400, time/step=1442ms, lr=1.74e-05
2024-09-23 20:32:17,571 - logger.py:50 - Epoch: [91][300/500] loss: 1.55872, MAE: 0.30565, time/step=1436ms, lr=1.74e-05
2024-09-23 20:33:28,864 - logger.py:50 - Epoch: [91][350/500] loss: 1.52160, MAE: 0.30518, time/step=1435ms, lr=1.74e-05
2024-09-23 20:34:40,573 - logger.py:50 - Epoch: [91][400/500] loss: 1.49345, MAE: 0.30568, time/step=1435ms, lr=1.74e-05
2024-09-23 20:35:52,064 - logger.py:50 - Epoch: [91][450/500] loss: 1.46782, MAE: 0.30467, time/step=1434ms, lr=1.74e-05
2024-09-23 20:37:02,835 - logger.py:50 - Epoch: [91][499/500] loss: 1.45191, MAE: 0.30497, time/step=1435ms, lr=1.74e-05
2024-09-23 20:38:15,045 - logger.py:50 - Epoch: [91] train loss: 1.45191, train MAE: 0.30497,val loss: 0.30688, val MAE: 0.30688,test loss: 0.31892, test MAE: 0.31892,Time: 789.82s
2024-09-23 20:38:15,045 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 20:38:16,053 - logger.py:50 - Epoch: [92][0/500] loss: 1.65770, MAE: 0.33299, time/step=1005ms, lr=1.70e-05
2024-09-23 20:39:27,842 - logger.py:50 - Epoch: [92][50/500] loss: 1.27980, MAE: 0.30387, time/step=1427ms, lr=1.70e-05
2024-09-23 20:40:38,679 - logger.py:50 - Epoch: [92][100/500] loss: 1.29779, MAE: 0.30716, time/step=1422ms, lr=1.70e-05
2024-09-23 20:41:49,674 - logger.py:50 - Epoch: [92][150/500] loss: 1.82464, MAE: 0.31034, time/step=1421ms, lr=1.70e-05
2024-09-23 20:43:00,773 - logger.py:50 - Epoch: [92][200/500] loss: 1.69521, MAE: 0.30900, time/step=1422ms, lr=1.70e-05
2024-09-23 20:44:11,996 - logger.py:50 - Epoch: [92][250/500] loss: 1.60513, MAE: 0.30850, time/step=1422ms, lr=1.70e-05
2024-09-23 20:45:23,058 - logger.py:50 - Epoch: [92][300/500] loss: 1.55379, MAE: 0.30692, time/step=1422ms, lr=1.70e-05
2024-09-23 20:46:33,338 - logger.py:50 - Epoch: [92][350/500] loss: 1.52980, MAE: 0.30709, time/step=1420ms, lr=1.70e-05
2024-09-23 20:47:43,867 - logger.py:50 - Epoch: [92][400/500] loss: 1.50139, MAE: 0.30630, time/step=1419ms, lr=1.70e-05
2024-09-23 20:48:54,467 - logger.py:50 - Epoch: [92][450/500] loss: 1.47949, MAE: 0.30619, time/step=1418ms, lr=1.70e-05
2024-09-23 20:50:04,709 - logger.py:50 - Epoch: [92][499/500] loss: 1.45189, MAE: 0.30499, time/step=1419ms, lr=1.70e-05
2024-09-23 20:51:17,526 - logger.py:50 - Epoch: [92] train loss: 1.45189, train MAE: 0.30499,val loss: 0.30701, val MAE: 0.30701,test loss: 0.31905, test MAE: 0.31905,Time: 782.48s
2024-09-23 20:51:17,527 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 20:51:18,413 - logger.py:50 - Epoch: [93][0/500] loss: 1.19650, MAE: 0.28508, time/step=883ms, lr=1.65e-05
2024-09-23 20:52:29,548 - logger.py:50 - Epoch: [93][50/500] loss: 1.19011, MAE: 0.30225, time/step=1412ms, lr=1.65e-05
2024-09-23 20:53:40,658 - logger.py:50 - Epoch: [93][100/500] loss: 1.20903, MAE: 0.29651, time/step=1417ms, lr=1.65e-05
2024-09-23 20:54:51,735 - logger.py:50 - Epoch: [93][150/500] loss: 1.23159, MAE: 0.29871, time/step=1419ms, lr=1.65e-05
2024-09-23 20:56:03,028 - logger.py:50 - Epoch: [93][200/500] loss: 1.25382, MAE: 0.30195, time/step=1420ms, lr=1.65e-05
2024-09-23 20:57:12,887 - logger.py:50 - Epoch: [93][250/500] loss: 1.24744, MAE: 0.30238, time/step=1416ms, lr=1.65e-05
2024-09-23 20:58:24,764 - logger.py:50 - Epoch: [93][300/500] loss: 1.23240, MAE: 0.30111, time/step=1419ms, lr=1.65e-05
2024-09-23 20:59:37,367 - logger.py:50 - Epoch: [93][350/500] loss: 1.23218, MAE: 0.30086, time/step=1424ms, lr=1.65e-05
2024-09-23 21:00:50,498 - logger.py:50 - Epoch: [93][400/500] loss: 1.26881, MAE: 0.30212, time/step=1429ms, lr=1.65e-05
2024-09-23 21:02:03,207 - logger.py:50 - Epoch: [93][450/500] loss: 1.47023, MAE: 0.30571, time/step=1432ms, lr=1.65e-05
2024-09-23 21:03:13,072 - logger.py:50 - Epoch: [93][499/500] loss: 1.45187, MAE: 0.30495, time/step=1431ms, lr=1.65e-05
2024-09-23 21:04:25,976 - logger.py:50 - Epoch: [93] train loss: 1.45187, train MAE: 0.30495,val loss: 0.30717, val MAE: 0.30717,test loss: 0.31919, test MAE: 0.31919,Time: 788.45s
2024-09-23 21:04:25,976 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 21:04:27,019 - logger.py:50 - Epoch: [94][0/500] loss: 0.62000, MAE: 0.24267, time/step=1040ms, lr=1.60e-05
2024-09-23 21:05:37,675 - logger.py:50 - Epoch: [94][50/500] loss: 1.37142, MAE: 0.31569, time/step=1406ms, lr=1.60e-05
2024-09-23 21:06:48,747 - logger.py:50 - Epoch: [94][100/500] loss: 1.28052, MAE: 0.30467, time/step=1414ms, lr=1.60e-05
2024-09-23 21:08:01,570 - logger.py:50 - Epoch: [94][150/500] loss: 1.29419, MAE: 0.30242, time/step=1428ms, lr=1.60e-05
2024-09-23 21:09:13,284 - logger.py:50 - Epoch: [94][200/500] loss: 1.29728, MAE: 0.30237, time/step=1429ms, lr=1.60e-05
2024-09-23 21:10:23,300 - logger.py:50 - Epoch: [94][250/500] loss: 1.29196, MAE: 0.30140, time/step=1424ms, lr=1.60e-05
2024-09-23 21:11:33,009 - logger.py:50 - Epoch: [94][300/500] loss: 1.56201, MAE: 0.30525, time/step=1419ms, lr=1.60e-05
2024-09-23 21:12:42,464 - logger.py:50 - Epoch: [94][350/500] loss: 1.51780, MAE: 0.30548, time/step=1414ms, lr=1.60e-05
2024-09-23 21:13:53,143 - logger.py:50 - Epoch: [94][400/500] loss: 1.48563, MAE: 0.30433, time/step=1414ms, lr=1.60e-05
2024-09-23 21:15:03,723 - logger.py:50 - Epoch: [94][450/500] loss: 1.46113, MAE: 0.30440, time/step=1414ms, lr=1.60e-05
2024-09-23 21:16:12,899 - logger.py:50 - Epoch: [94][499/500] loss: 1.45184, MAE: 0.30498, time/step=1414ms, lr=1.60e-05
2024-09-23 21:17:23,601 - logger.py:50 - Epoch: [94] train loss: 1.45184, train MAE: 0.30498,val loss: 0.30681, val MAE: 0.30681,test loss: 0.31883, test MAE: 0.31883,Time: 777.62s
2024-09-23 21:17:23,601 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 21:17:25,245 - logger.py:50 - Epoch: [95][0/500] loss: 1.36834, MAE: 0.34145, time/step=1642ms, lr=1.55e-05
2024-09-23 21:18:34,174 - logger.py:50 - Epoch: [95][50/500] loss: 2.82591, MAE: 0.32802, time/step=1384ms, lr=1.55e-05
2024-09-23 21:19:45,098 - logger.py:50 - Epoch: [95][100/500] loss: 2.05166, MAE: 0.31263, time/step=1401ms, lr=1.55e-05
2024-09-23 21:20:56,827 - logger.py:50 - Epoch: [95][150/500] loss: 1.82006, MAE: 0.31252, time/step=1412ms, lr=1.55e-05
2024-09-23 21:22:09,373 - logger.py:50 - Epoch: [95][200/500] loss: 1.67037, MAE: 0.30792, time/step=1422ms, lr=1.55e-05
2024-09-23 21:23:20,347 - logger.py:50 - Epoch: [95][250/500] loss: 1.56844, MAE: 0.30712, time/step=1421ms, lr=1.55e-05
2024-09-23 21:24:30,577 - logger.py:50 - Epoch: [95][300/500] loss: 1.51684, MAE: 0.30546, time/step=1419ms, lr=1.55e-05
2024-09-23 21:25:41,931 - logger.py:50 - Epoch: [95][350/500] loss: 1.50158, MAE: 0.30554, time/step=1420ms, lr=1.55e-05
2024-09-23 21:26:54,512 - logger.py:50 - Epoch: [95][400/500] loss: 1.47804, MAE: 0.30494, time/step=1424ms, lr=1.55e-05
2024-09-23 21:28:05,728 - logger.py:50 - Epoch: [95][450/500] loss: 1.46677, MAE: 0.30465, time/step=1424ms, lr=1.55e-05
2024-09-23 21:29:14,413 - logger.py:50 - Epoch: [95][499/500] loss: 1.45183, MAE: 0.30496, time/step=1422ms, lr=1.55e-05
2024-09-23 21:30:27,990 - logger.py:50 - Epoch: [95] train loss: 1.45183, train MAE: 0.30496,val loss: 0.30691, val MAE: 0.30691,test loss: 0.31893, test MAE: 0.31893,Time: 784.39s
2024-09-23 21:30:27,990 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 21:30:29,596 - logger.py:50 - Epoch: [96][0/500] loss: 1.64820, MAE: 0.34864, time/step=1603ms, lr=1.51e-05
2024-09-23 21:31:39,020 - logger.py:50 - Epoch: [96][50/500] loss: 1.18807, MAE: 0.29464, time/step=1393ms, lr=1.51e-05
2024-09-23 21:32:49,894 - logger.py:50 - Epoch: [96][100/500] loss: 1.33710, MAE: 0.30146, time/step=1405ms, lr=1.51e-05
2024-09-23 21:34:02,151 - logger.py:50 - Epoch: [96][150/500] loss: 1.31842, MAE: 0.30230, time/step=1418ms, lr=1.51e-05
2024-09-23 21:35:13,023 - logger.py:50 - Epoch: [96][200/500] loss: 1.33032, MAE: 0.30488, time/step=1418ms, lr=1.51e-05
2024-09-23 21:36:23,486 - logger.py:50 - Epoch: [96][250/500] loss: 1.31299, MAE: 0.30338, time/step=1416ms, lr=1.51e-05
2024-09-23 21:37:36,200 - logger.py:50 - Epoch: [96][300/500] loss: 1.30896, MAE: 0.30353, time/step=1423ms, lr=1.51e-05
2024-09-23 21:38:48,013 - logger.py:50 - Epoch: [96][350/500] loss: 1.28387, MAE: 0.30186, time/step=1425ms, lr=1.51e-05
2024-09-23 21:39:59,033 - logger.py:50 - Epoch: [96][400/500] loss: 1.27025, MAE: 0.30155, time/step=1424ms, lr=1.51e-05
2024-09-23 21:41:10,368 - logger.py:50 - Epoch: [96][450/500] loss: 1.28671, MAE: 0.30139, time/step=1424ms, lr=1.51e-05
2024-09-23 21:42:20,580 - logger.py:50 - Epoch: [96][499/500] loss: 1.45183, MAE: 0.30495, time/step=1425ms, lr=1.51e-05
2024-09-23 21:43:32,231 - logger.py:50 - Epoch: [96] train loss: 1.45183, train MAE: 0.30495,val loss: 0.30681, val MAE: 0.30681,test loss: 0.31885, test MAE: 0.31885,Time: 784.24s
2024-09-23 21:43:32,231 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 21:43:33,739 - logger.py:50 - Epoch: [97][0/500] loss: 1.58781, MAE: 0.37353, time/step=1506ms, lr=1.46e-05
2024-09-23 21:44:46,026 - logger.py:50 - Epoch: [97][50/500] loss: 1.20880, MAE: 0.29685, time/step=1447ms, lr=1.46e-05
2024-09-23 21:45:58,271 - logger.py:50 - Epoch: [97][100/500] loss: 1.21504, MAE: 0.29456, time/step=1446ms, lr=1.46e-05
2024-09-23 21:47:11,000 - logger.py:50 - Epoch: [97][150/500] loss: 1.21093, MAE: 0.29694, time/step=1449ms, lr=1.46e-05
2024-09-23 21:48:23,061 - logger.py:50 - Epoch: [97][200/500] loss: 1.21707, MAE: 0.29690, time/step=1447ms, lr=1.46e-05
2024-09-23 21:49:34,887 - logger.py:50 - Epoch: [97][250/500] loss: 1.20114, MAE: 0.29648, time/step=1445ms, lr=1.46e-05
2024-09-23 21:50:45,915 - logger.py:50 - Epoch: [97][300/500] loss: 1.21552, MAE: 0.29740, time/step=1441ms, lr=1.46e-05
2024-09-23 21:51:57,005 - logger.py:50 - Epoch: [97][350/500] loss: 1.23649, MAE: 0.29882, time/step=1438ms, lr=1.46e-05
2024-09-23 21:53:08,215 - logger.py:50 - Epoch: [97][400/500] loss: 1.25578, MAE: 0.29892, time/step=1436ms, lr=1.46e-05
2024-09-23 21:54:20,953 - logger.py:50 - Epoch: [97][450/500] loss: 1.26577, MAE: 0.29983, time/step=1438ms, lr=1.46e-05
2024-09-23 21:55:31,086 - logger.py:50 - Epoch: [97][499/500] loss: 1.45179, MAE: 0.30497, time/step=1438ms, lr=1.46e-05
2024-09-23 21:56:43,508 - logger.py:50 - Epoch: [97] train loss: 1.45179, train MAE: 0.30497,val loss: 0.30683, val MAE: 0.30683,test loss: 0.31888, test MAE: 0.31888,Time: 791.28s
2024-09-23 21:56:43,508 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 21:56:44,603 - logger.py:50 - Epoch: [98][0/500] loss: 1.16710, MAE: 0.33112, time/step=1092ms, lr=1.41e-05
2024-09-23 21:57:55,740 - logger.py:50 - Epoch: [98][50/500] loss: 1.20212, MAE: 0.29633, time/step=1416ms, lr=1.41e-05
2024-09-23 21:59:06,835 - logger.py:50 - Epoch: [98][100/500] loss: 1.25585, MAE: 0.30149, time/step=1419ms, lr=1.41e-05
2024-09-23 22:00:18,627 - logger.py:50 - Epoch: [98][150/500] loss: 1.25025, MAE: 0.30302, time/step=1425ms, lr=1.41e-05
2024-09-23 22:01:31,170 - logger.py:50 - Epoch: [98][200/500] loss: 1.25932, MAE: 0.30309, time/step=1431ms, lr=1.41e-05
2024-09-23 22:02:43,211 - logger.py:50 - Epoch: [98][250/500] loss: 1.59650, MAE: 0.30799, time/step=1433ms, lr=1.41e-05
2024-09-23 22:03:55,002 - logger.py:50 - Epoch: [98][300/500] loss: 1.54129, MAE: 0.30645, time/step=1434ms, lr=1.41e-05
2024-09-23 22:05:03,782 - logger.py:50 - Epoch: [98][350/500] loss: 1.49654, MAE: 0.30637, time/step=1425ms, lr=1.41e-05
2024-09-23 22:06:15,303 - logger.py:50 - Epoch: [98][400/500] loss: 1.45822, MAE: 0.30521, time/step=1426ms, lr=1.41e-05
2024-09-23 22:07:27,640 - logger.py:50 - Epoch: [98][450/500] loss: 1.44571, MAE: 0.30405, time/step=1428ms, lr=1.41e-05
2024-09-23 22:08:38,846 - logger.py:50 - Epoch: [98][499/500] loss: 1.45176, MAE: 0.30496, time/step=1431ms, lr=1.41e-05
2024-09-23 22:09:57,484 - logger.py:50 - Epoch: [98] train loss: 1.45176, train MAE: 0.30496,val loss: 0.30670, val MAE: 0.30670,test loss: 0.31876, test MAE: 0.31876,Time: 793.98s
2024-09-23 22:09:57,485 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 22:09:58,571 - logger.py:50 - Epoch: [99][0/500] loss: 1.68536, MAE: 0.35503, time/step=1083ms, lr=1.37e-05
2024-09-23 22:11:11,544 - logger.py:50 - Epoch: [99][50/500] loss: 1.28983, MAE: 0.30741, time/step=1452ms, lr=1.37e-05
2024-09-23 22:12:30,127 - logger.py:50 - Epoch: [99][100/500] loss: 1.26519, MAE: 0.30182, time/step=1511ms, lr=1.37e-05
2024-09-23 22:13:41,573 - logger.py:50 - Epoch: [99][150/500] loss: 1.26040, MAE: 0.30144, time/step=1484ms, lr=1.37e-05
2024-09-23 22:14:53,757 - logger.py:50 - Epoch: [99][200/500] loss: 1.67926, MAE: 0.30912, time/step=1474ms, lr=1.37e-05
2024-09-23 22:16:04,721 - logger.py:50 - Epoch: [99][250/500] loss: 1.63666, MAE: 0.30828, time/step=1463ms, lr=1.37e-05
2024-09-23 22:17:14,915 - logger.py:50 - Epoch: [99][300/500] loss: 1.58006, MAE: 0.30699, time/step=1453ms, lr=1.37e-05
2024-09-23 22:18:27,184 - logger.py:50 - Epoch: [99][350/500] loss: 1.56095, MAE: 0.30873, time/step=1452ms, lr=1.37e-05
2024-09-23 22:19:37,175 - logger.py:50 - Epoch: [99][400/500] loss: 1.51878, MAE: 0.30651, time/step=1446ms, lr=1.37e-05
2024-09-23 22:20:46,702 - logger.py:50 - Epoch: [99][450/500] loss: 1.48240, MAE: 0.30586, time/step=1440ms, lr=1.37e-05
2024-09-23 22:21:56,393 - logger.py:50 - Epoch: [99][499/500] loss: 1.45174, MAE: 0.30495, time/step=1438ms, lr=1.37e-05
2024-09-23 22:23:08,848 - logger.py:50 - Epoch: [99] train loss: 1.45174, train MAE: 0.30495,val loss: 0.30697, val MAE: 0.30697,test loss: 0.31899, test MAE: 0.31899,Time: 791.36s
2024-09-23 22:23:08,848 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 22:23:10,566 - logger.py:50 - Epoch: [100][0/500] loss: 1.62564, MAE: 0.33344, time/step=1716ms, lr=1.32e-05
2024-09-23 22:24:21,148 - logger.py:50 - Epoch: [100][50/500] loss: 1.24506, MAE: 0.30214, time/step=1418ms, lr=1.32e-05
2024-09-23 22:25:30,961 - logger.py:50 - Epoch: [100][100/500] loss: 2.15224, MAE: 0.31996, time/step=1407ms, lr=1.32e-05
2024-09-23 22:26:40,174 - logger.py:50 - Epoch: [100][150/500] loss: 1.83697, MAE: 0.31354, time/step=1399ms, lr=1.32e-05
2024-09-23 22:27:53,223 - logger.py:50 - Epoch: [100][200/500] loss: 1.71027, MAE: 0.31152, time/step=1415ms, lr=1.32e-05
2024-09-23 22:29:08,388 - logger.py:50 - Epoch: [100][250/500] loss: 1.62510, MAE: 0.31130, time/step=1432ms, lr=1.32e-05
2024-09-23 22:30:22,539 - logger.py:50 - Epoch: [100][300/500] loss: 1.56421, MAE: 0.30890, time/step=1441ms, lr=1.32e-05
2024-09-23 22:31:37,558 - logger.py:50 - Epoch: [100][350/500] loss: 1.50888, MAE: 0.30602, time/step=1449ms, lr=1.32e-05
2024-09-23 22:32:49,566 - logger.py:50 - Epoch: [100][400/500] loss: 1.49180, MAE: 0.30601, time/step=1448ms, lr=1.32e-05
2024-09-23 22:34:01,951 - logger.py:50 - Epoch: [100][450/500] loss: 1.47050, MAE: 0.30576, time/step=1448ms, lr=1.32e-05
2024-09-23 22:35:13,008 - logger.py:50 - Epoch: [100][499/500] loss: 1.45173, MAE: 0.30496, time/step=1448ms, lr=1.32e-05
2024-09-23 22:36:25,601 - logger.py:50 - Epoch: [100] train loss: 1.45173, train MAE: 0.30496,val loss: 0.30663, val MAE: 0.30663,test loss: 0.31867, test MAE: 0.31867,Time: 796.75s
2024-09-23 22:36:25,602 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 22:36:27,221 - logger.py:50 - Epoch: [101][0/500] loss: 1.62789, MAE: 0.32467, time/step=1616ms, lr=1.28e-05
2024-09-23 22:37:37,160 - logger.py:50 - Epoch: [101][50/500] loss: 1.29724, MAE: 0.30278, time/step=1403ms, lr=1.28e-05
2024-09-23 22:38:48,018 - logger.py:50 - Epoch: [101][100/500] loss: 1.33966, MAE: 0.30836, time/step=1410ms, lr=1.28e-05
2024-09-23 22:40:01,061 - logger.py:50 - Epoch: [101][150/500] loss: 1.31675, MAE: 0.30511, time/step=1427ms, lr=1.28e-05
2024-09-23 22:41:11,904 - logger.py:50 - Epoch: [101][200/500] loss: 1.28632, MAE: 0.30358, time/step=1424ms, lr=1.28e-05
2024-09-23 22:42:22,346 - logger.py:50 - Epoch: [101][250/500] loss: 1.63605, MAE: 0.31074, time/step=1421ms, lr=1.28e-05
2024-09-23 22:43:36,480 - logger.py:50 - Epoch: [101][300/500] loss: 1.55917, MAE: 0.30781, time/step=1431ms, lr=1.28e-05
2024-09-23 22:44:47,490 - logger.py:50 - Epoch: [101][350/500] loss: 1.51083, MAE: 0.30685, time/step=1430ms, lr=1.28e-05
2024-09-23 22:45:59,620 - logger.py:50 - Epoch: [101][400/500] loss: 1.48318, MAE: 0.30697, time/step=1431ms, lr=1.28e-05
2024-09-23 22:47:10,421 - logger.py:50 - Epoch: [101][450/500] loss: 1.47084, MAE: 0.30576, time/step=1430ms, lr=1.28e-05
2024-09-23 22:48:20,731 - logger.py:50 - Epoch: [101][499/500] loss: 1.45169, MAE: 0.30495, time/step=1430ms, lr=1.28e-05
2024-09-23 22:49:32,514 - logger.py:50 - Epoch: [101] train loss: 1.45169, train MAE: 0.30495,val loss: 0.30667, val MAE: 0.30667,test loss: 0.31872, test MAE: 0.31872,Time: 786.91s
2024-09-23 22:49:32,514 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 22:49:33,440 - logger.py:50 - Epoch: [102][0/500] loss: 0.68499, MAE: 0.24549, time/step=924ms, lr=1.24e-05
2024-09-23 22:50:44,639 - logger.py:50 - Epoch: [102][50/500] loss: 1.24065, MAE: 0.29187, time/step=1414ms, lr=1.24e-05
2024-09-23 22:51:57,916 - logger.py:50 - Epoch: [102][100/500] loss: 2.09894, MAE: 0.31063, time/step=1440ms, lr=1.24e-05
2024-09-23 22:53:09,875 - logger.py:50 - Epoch: [102][150/500] loss: 1.81366, MAE: 0.30975, time/step=1439ms, lr=1.24e-05
2024-09-23 22:54:20,799 - logger.py:50 - Epoch: [102][200/500] loss: 1.67461, MAE: 0.30550, time/step=1434ms, lr=1.24e-05
2024-09-23 22:55:34,324 - logger.py:50 - Epoch: [102][250/500] loss: 1.57087, MAE: 0.30462, time/step=1441ms, lr=1.24e-05
2024-09-23 22:56:43,067 - logger.py:50 - Epoch: [102][300/500] loss: 1.52473, MAE: 0.30392, time/step=1430ms, lr=1.24e-05
2024-09-23 22:57:54,749 - logger.py:50 - Epoch: [102][350/500] loss: 1.48939, MAE: 0.30303, time/step=1431ms, lr=1.24e-05
2024-09-23 22:59:03,916 - logger.py:50 - Epoch: [102][400/500] loss: 1.47491, MAE: 0.30316, time/step=1425ms, lr=1.24e-05
2024-09-23 23:00:14,013 - logger.py:50 - Epoch: [102][450/500] loss: 1.45922, MAE: 0.30422, time/step=1422ms, lr=1.24e-05
2024-09-23 23:01:22,601 - logger.py:50 - Epoch: [102][499/500] loss: 1.45170, MAE: 0.30493, time/step=1420ms, lr=1.24e-05
2024-09-23 23:02:34,213 - logger.py:50 - Epoch: [102] train loss: 1.45170, train MAE: 0.30493,val loss: 0.30693, val MAE: 0.30693,test loss: 0.31896, test MAE: 0.31896,Time: 781.70s
2024-09-23 23:02:34,213 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 23:02:35,369 - logger.py:50 - Epoch: [103][0/500] loss: 1.63431, MAE: 0.36453, time/step=1153ms, lr=1.19e-05
2024-09-23 23:03:45,076 - logger.py:50 - Epoch: [103][50/500] loss: 1.36791, MAE: 0.31028, time/step=1389ms, lr=1.19e-05
2024-09-23 23:04:54,988 - logger.py:50 - Epoch: [103][100/500] loss: 1.33313, MAE: 0.30562, time/step=1394ms, lr=1.19e-05
2024-09-23 23:06:07,752 - logger.py:50 - Epoch: [103][150/500] loss: 1.32851, MAE: 0.30611, time/step=1414ms, lr=1.19e-05
2024-09-23 23:07:17,822 - logger.py:50 - Epoch: [103][200/500] loss: 1.30518, MAE: 0.30488, time/step=1411ms, lr=1.19e-05
2024-09-23 23:08:29,993 - logger.py:50 - Epoch: [103][250/500] loss: 1.66016, MAE: 0.31148, time/step=1417ms, lr=1.19e-05
2024-09-23 23:09:40,651 - logger.py:50 - Epoch: [103][300/500] loss: 1.59939, MAE: 0.31126, time/step=1417ms, lr=1.19e-05
2024-09-23 23:10:48,652 - logger.py:50 - Epoch: [103][350/500] loss: 1.55194, MAE: 0.30885, time/step=1409ms, lr=1.19e-05
2024-09-23 23:12:00,705 - logger.py:50 - Epoch: [103][400/500] loss: 1.51436, MAE: 0.30682, time/step=1413ms, lr=1.19e-05
2024-09-23 23:13:12,051 - logger.py:50 - Epoch: [103][450/500] loss: 1.48335, MAE: 0.30617, time/step=1414ms, lr=1.19e-05
2024-09-23 23:14:20,437 - logger.py:50 - Epoch: [103][499/500] loss: 1.45166, MAE: 0.30495, time/step=1412ms, lr=1.19e-05
2024-09-23 23:15:33,321 - logger.py:50 - Epoch: [103] train loss: 1.45166, train MAE: 0.30495,val loss: 0.30678, val MAE: 0.30678,test loss: 0.31884, test MAE: 0.31884,Time: 779.11s
2024-09-23 23:15:33,321 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 23:15:35,146 - logger.py:50 - Epoch: [104][0/500] loss: 1.36010, MAE: 0.29074, time/step=1822ms, lr=1.15e-05
2024-09-23 23:16:43,693 - logger.py:50 - Epoch: [104][50/500] loss: 1.26427, MAE: 0.30688, time/step=1380ms, lr=1.15e-05
2024-09-23 23:17:56,305 - logger.py:50 - Epoch: [104][100/500] loss: 1.33521, MAE: 0.30630, time/step=1416ms, lr=1.15e-05
2024-09-23 23:19:06,507 - logger.py:50 - Epoch: [104][150/500] loss: 1.34031, MAE: 0.30250, time/step=1412ms, lr=1.15e-05
2024-09-23 23:20:18,079 - logger.py:50 - Epoch: [104][200/500] loss: 1.72790, MAE: 0.30626, time/step=1417ms, lr=1.15e-05
2024-09-23 23:21:32,227 - logger.py:50 - Epoch: [104][250/500] loss: 1.64556, MAE: 0.30709, time/step=1430ms, lr=1.15e-05
2024-09-23 23:22:44,954 - logger.py:50 - Epoch: [104][300/500] loss: 1.57886, MAE: 0.30633, time/step=1434ms, lr=1.15e-05
2024-09-23 23:23:55,750 - logger.py:50 - Epoch: [104][350/500] loss: 1.54502, MAE: 0.30666, time/step=1431ms, lr=1.15e-05
2024-09-23 23:25:06,340 - logger.py:50 - Epoch: [104][400/500] loss: 1.50332, MAE: 0.30567, time/step=1429ms, lr=1.15e-05
2024-09-23 23:26:17,578 - logger.py:50 - Epoch: [104][450/500] loss: 1.46318, MAE: 0.30428, time/step=1429ms, lr=1.15e-05
2024-09-23 23:27:28,287 - logger.py:50 - Epoch: [104][499/500] loss: 1.45172, MAE: 0.30494, time/step=1430ms, lr=1.15e-05
2024-09-23 23:28:39,911 - logger.py:50 - Epoch: [104] train loss: 1.45172, train MAE: 0.30494,val loss: 0.30684, val MAE: 0.30684,test loss: 0.31888, test MAE: 0.31888,Time: 786.59s
2024-09-23 23:28:39,911 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 23:28:41,505 - logger.py:50 - Epoch: [105][0/500] loss: 2.84843, MAE: 0.28269, time/step=1591ms, lr=1.11e-05
2024-09-23 23:29:49,271 - logger.py:50 - Epoch: [105][50/500] loss: 1.17719, MAE: 0.29456, time/step=1360ms, lr=1.11e-05
2024-09-23 23:30:59,696 - logger.py:50 - Epoch: [105][100/500] loss: 1.23664, MAE: 0.30081, time/step=1384ms, lr=1.11e-05
2024-09-23 23:32:09,473 - logger.py:50 - Epoch: [105][150/500] loss: 1.78437, MAE: 0.30982, time/step=1388ms, lr=1.11e-05
2024-09-23 23:33:19,694 - logger.py:50 - Epoch: [105][200/500] loss: 1.68625, MAE: 0.30982, time/step=1392ms, lr=1.11e-05
2024-09-23 23:34:29,569 - logger.py:50 - Epoch: [105][250/500] loss: 1.59485, MAE: 0.30920, time/step=1393ms, lr=1.11e-05
2024-09-23 23:35:40,072 - logger.py:50 - Epoch: [105][300/500] loss: 1.55060, MAE: 0.30827, time/step=1396ms, lr=1.11e-05
2024-09-23 23:36:52,356 - logger.py:50 - Epoch: [105][350/500] loss: 1.52467, MAE: 0.30717, time/step=1403ms, lr=1.11e-05
2024-09-23 23:38:00,983 - logger.py:50 - Epoch: [105][400/500] loss: 1.50293, MAE: 0.30721, time/step=1399ms, lr=1.11e-05
2024-09-23 23:39:11,543 - logger.py:50 - Epoch: [105][450/500] loss: 1.48072, MAE: 0.30625, time/step=1401ms, lr=1.11e-05
2024-09-23 23:40:19,127 - logger.py:50 - Epoch: [105][499/500] loss: 1.45162, MAE: 0.30495, time/step=1398ms, lr=1.11e-05
2024-09-23 23:41:29,817 - logger.py:50 - Epoch: [105] train loss: 1.45162, train MAE: 0.30495,val loss: 0.30675, val MAE: 0.30675,test loss: 0.31879, test MAE: 0.31879,Time: 769.91s
2024-09-23 23:41:29,817 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 23:41:30,835 - logger.py:50 - Epoch: [106][0/500] loss: 1.31721, MAE: 0.31206, time/step=1015ms, lr=1.07e-05
2024-09-23 23:42:39,986 - logger.py:50 - Epoch: [106][50/500] loss: 1.27029, MAE: 0.30147, time/step=1376ms, lr=1.07e-05
2024-09-23 23:43:49,869 - logger.py:50 - Epoch: [106][100/500] loss: 2.15247, MAE: 0.31813, time/step=1387ms, lr=1.07e-05
2024-09-23 23:44:59,334 - logger.py:50 - Epoch: [106][150/500] loss: 1.85540, MAE: 0.31161, time/step=1388ms, lr=1.07e-05
2024-09-23 23:46:08,231 - logger.py:50 - Epoch: [106][200/500] loss: 1.70298, MAE: 0.30829, time/step=1385ms, lr=1.07e-05
2024-09-23 23:47:20,156 - logger.py:50 - Epoch: [106][250/500] loss: 1.63476, MAE: 0.30756, time/step=1396ms, lr=1.07e-05
2024-09-23 23:48:34,579 - logger.py:50 - Epoch: [106][300/500] loss: 1.57424, MAE: 0.30746, time/step=1411ms, lr=1.07e-05
2024-09-23 23:49:45,790 - logger.py:50 - Epoch: [106][350/500] loss: 1.52116, MAE: 0.30607, time/step=1413ms, lr=1.07e-05
2024-09-23 23:50:54,687 - logger.py:50 - Epoch: [106][400/500] loss: 1.49183, MAE: 0.30557, time/step=1409ms, lr=1.07e-05
2024-09-23 23:52:04,567 - logger.py:50 - Epoch: [106][450/500] loss: 1.46335, MAE: 0.30474, time/step=1407ms, lr=1.07e-05
2024-09-23 23:53:14,145 - logger.py:50 - Epoch: [106][499/500] loss: 1.45166, MAE: 0.30495, time/step=1409ms, lr=1.07e-05
2024-09-23 23:54:28,427 - logger.py:50 - Epoch: [106] train loss: 1.45166, train MAE: 0.30495,val loss: 0.30672, val MAE: 0.30672,test loss: 0.31877, test MAE: 0.31877,Time: 778.61s
2024-09-23 23:54:28,427 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-23 23:54:29,354 - logger.py:50 - Epoch: [107][0/500] loss: 1.27967, MAE: 0.27370, time/step=925ms, lr=1.03e-05
2024-09-23 23:55:40,442 - logger.py:50 - Epoch: [107][50/500] loss: 1.19450, MAE: 0.29827, time/step=1412ms, lr=1.03e-05
2024-09-23 23:56:52,829 - logger.py:50 - Epoch: [107][100/500] loss: 1.23358, MAE: 0.29569, time/step=1430ms, lr=1.03e-05
2024-09-23 23:58:06,559 - logger.py:50 - Epoch: [107][150/500] loss: 1.25210, MAE: 0.29963, time/step=1445ms, lr=1.03e-05
2024-09-23 23:59:17,320 - logger.py:50 - Epoch: [107][200/500] loss: 1.27826, MAE: 0.30061, time/step=1437ms, lr=1.03e-05
2024-09-24 00:00:30,639 - logger.py:50 - Epoch: [107][250/500] loss: 1.27678, MAE: 0.30125, time/step=1443ms, lr=1.03e-05
2024-09-24 00:01:43,457 - logger.py:50 - Epoch: [107][300/500] loss: 1.27228, MAE: 0.30193, time/step=1445ms, lr=1.03e-05
2024-09-24 00:02:57,617 - logger.py:50 - Epoch: [107][350/500] loss: 1.29204, MAE: 0.30224, time/step=1451ms, lr=1.03e-05
2024-09-24 00:04:09,079 - logger.py:50 - Epoch: [107][400/500] loss: 1.50892, MAE: 0.30660, time/step=1448ms, lr=1.03e-05
2024-09-24 00:05:22,737 - logger.py:50 - Epoch: [107][450/500] loss: 1.47408, MAE: 0.30526, time/step=1451ms, lr=1.03e-05
2024-09-24 00:06:32,686 - logger.py:50 - Epoch: [107][499/500] loss: 1.45163, MAE: 0.30493, time/step=1449ms, lr=1.03e-05
2024-09-24 00:07:45,396 - logger.py:50 - Epoch: [107] train loss: 1.45163, train MAE: 0.30493,val loss: 0.30683, val MAE: 0.30683,test loss: 0.31886, test MAE: 0.31886,Time: 796.97s
2024-09-24 00:07:45,396 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 00:07:46,413 - logger.py:50 - Epoch: [108][0/500] loss: 1.02013, MAE: 0.27634, time/step=1015ms, lr=9.88e-06
2024-09-24 00:08:56,359 - logger.py:50 - Epoch: [108][50/500] loss: 3.06468, MAE: 0.33424, time/step=1391ms, lr=9.88e-06
2024-09-24 00:10:06,364 - logger.py:50 - Epoch: [108][100/500] loss: 2.19828, MAE: 0.31923, time/step=1396ms, lr=9.88e-06
2024-09-24 00:11:21,925 - logger.py:50 - Epoch: [108][150/500] loss: 1.89024, MAE: 0.31308, time/step=1434ms, lr=9.88e-06
2024-09-24 00:12:35,651 - logger.py:50 - Epoch: [108][200/500] loss: 1.74991, MAE: 0.31246, time/step=1444ms, lr=9.88e-06
2024-09-24 00:13:45,232 - logger.py:50 - Epoch: [108][250/500] loss: 1.64594, MAE: 0.30950, time/step=1434ms, lr=9.88e-06
2024-09-24 00:14:57,281 - logger.py:50 - Epoch: [108][300/500] loss: 1.59028, MAE: 0.30870, time/step=1435ms, lr=9.88e-06
2024-09-24 00:16:07,975 - logger.py:50 - Epoch: [108][350/500] loss: 1.53123, MAE: 0.30745, time/step=1432ms, lr=9.88e-06
2024-09-24 00:17:19,243 - logger.py:50 - Epoch: [108][400/500] loss: 1.51010, MAE: 0.30613, time/step=1431ms, lr=9.88e-06
2024-09-24 00:18:32,812 - logger.py:50 - Epoch: [108][450/500] loss: 1.48051, MAE: 0.30632, time/step=1436ms, lr=9.88e-06
2024-09-24 00:19:42,263 - logger.py:50 - Epoch: [108][499/500] loss: 1.45159, MAE: 0.30495, time/step=1434ms, lr=9.88e-06
2024-09-24 00:20:54,500 - logger.py:50 - Epoch: [108] train loss: 1.45159, train MAE: 0.30495,val loss: 0.30679, val MAE: 0.30679,test loss: 0.31882, test MAE: 0.31882,Time: 789.10s
2024-09-24 00:20:54,500 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 00:20:56,069 - logger.py:50 - Epoch: [109][0/500] loss: 0.54677, MAE: 0.20044, time/step=1566ms, lr=9.49e-06
2024-09-24 00:22:05,241 - logger.py:50 - Epoch: [109][50/500] loss: 1.25408, MAE: 0.29602, time/step=1387ms, lr=9.49e-06
2024-09-24 00:23:15,146 - logger.py:50 - Epoch: [109][100/500] loss: 1.21798, MAE: 0.29657, time/step=1393ms, lr=9.49e-06
2024-09-24 00:24:26,782 - logger.py:50 - Epoch: [109][150/500] loss: 1.84016, MAE: 0.31063, time/step=1406ms, lr=9.49e-06
2024-09-24 00:25:35,783 - logger.py:50 - Epoch: [109][200/500] loss: 1.70378, MAE: 0.30803, time/step=1399ms, lr=9.49e-06
2024-09-24 00:26:48,093 - logger.py:50 - Epoch: [109][250/500] loss: 1.63855, MAE: 0.30875, time/step=1409ms, lr=9.49e-06
2024-09-24 00:27:59,641 - logger.py:50 - Epoch: [109][300/500] loss: 1.57264, MAE: 0.30709, time/step=1412ms, lr=9.49e-06
2024-09-24 00:29:10,436 - logger.py:50 - Epoch: [109][350/500] loss: 1.51350, MAE: 0.30529, time/step=1413ms, lr=9.49e-06
2024-09-24 00:30:20,744 - logger.py:50 - Epoch: [109][400/500] loss: 1.48530, MAE: 0.30461, time/step=1412ms, lr=9.49e-06
2024-09-24 00:31:31,614 - logger.py:50 - Epoch: [109][450/500] loss: 1.46975, MAE: 0.30449, time/step=1413ms, lr=9.49e-06
2024-09-24 00:32:42,538 - logger.py:50 - Epoch: [109][499/500] loss: 1.45158, MAE: 0.30494, time/step=1416ms, lr=9.49e-06
2024-09-24 00:33:54,998 - logger.py:50 - Epoch: [109] train loss: 1.45158, train MAE: 0.30494,val loss: 0.30665, val MAE: 0.30665,test loss: 0.31870, test MAE: 0.31870,Time: 780.50s
2024-09-24 00:33:54,998 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 00:33:55,999 - logger.py:50 - Epoch: [110][0/500] loss: 0.98778, MAE: 0.30607, time/step=998ms, lr=9.11e-06
2024-09-24 00:35:06,915 - logger.py:50 - Epoch: [110][50/500] loss: 1.29337, MAE: 0.30047, time/step=1410ms, lr=9.11e-06
2024-09-24 00:36:21,736 - logger.py:50 - Epoch: [110][100/500] loss: 1.34726, MAE: 0.30811, time/step=1453ms, lr=9.11e-06
2024-09-24 00:37:31,961 - logger.py:50 - Epoch: [110][150/500] loss: 1.34021, MAE: 0.30630, time/step=1437ms, lr=9.11e-06
2024-09-24 00:38:43,461 - logger.py:50 - Epoch: [110][200/500] loss: 1.34049, MAE: 0.30574, time/step=1435ms, lr=9.11e-06
2024-09-24 00:39:55,894 - logger.py:50 - Epoch: [110][250/500] loss: 1.30945, MAE: 0.30305, time/step=1438ms, lr=9.11e-06
2024-09-24 00:41:08,834 - logger.py:50 - Epoch: [110][300/500] loss: 1.56694, MAE: 0.30712, time/step=1441ms, lr=9.11e-06
2024-09-24 00:42:22,423 - logger.py:50 - Epoch: [110][350/500] loss: 1.54242, MAE: 0.30682, time/step=1446ms, lr=9.11e-06
2024-09-24 00:43:33,521 - logger.py:50 - Epoch: [110][400/500] loss: 1.49537, MAE: 0.30544, time/step=1443ms, lr=9.11e-06
2024-09-24 00:44:44,489 - logger.py:50 - Epoch: [110][450/500] loss: 1.47181, MAE: 0.30563, time/step=1440ms, lr=9.11e-06
2024-09-24 00:45:54,595 - logger.py:50 - Epoch: [110][499/500] loss: 1.45158, MAE: 0.30493, time/step=1439ms, lr=9.11e-06
2024-09-24 00:47:08,992 - logger.py:50 - Epoch: [110] train loss: 1.45158, train MAE: 0.30493,val loss: 0.30683, val MAE: 0.30683,test loss: 0.31887, test MAE: 0.31887,Time: 793.99s
2024-09-24 00:47:08,992 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 00:47:10,777 - logger.py:50 - Epoch: [111][0/500] loss: 1.18692, MAE: 0.30376, time/step=1783ms, lr=8.73e-06
2024-09-24 00:48:22,902 - logger.py:50 - Epoch: [111][50/500] loss: 1.19103, MAE: 0.30694, time/step=1449ms, lr=8.73e-06
2024-09-24 00:49:33,986 - logger.py:50 - Epoch: [111][100/500] loss: 1.20318, MAE: 0.29994, time/step=1436ms, lr=8.73e-06
2024-09-24 00:50:47,150 - logger.py:50 - Epoch: [111][150/500] loss: 1.22606, MAE: 0.30112, time/step=1445ms, lr=8.73e-06
2024-09-24 00:52:02,210 - logger.py:50 - Epoch: [111][200/500] loss: 1.68064, MAE: 0.31016, time/step=1459ms, lr=8.73e-06
2024-09-24 00:53:15,072 - logger.py:50 - Epoch: [111][250/500] loss: 1.60331, MAE: 0.30843, time/step=1458ms, lr=8.73e-06
2024-09-24 00:54:27,627 - logger.py:50 - Epoch: [111][300/500] loss: 1.56220, MAE: 0.30804, time/step=1457ms, lr=8.73e-06
2024-09-24 00:55:41,116 - logger.py:50 - Epoch: [111][350/500] loss: 1.51777, MAE: 0.30689, time/step=1459ms, lr=8.73e-06
2024-09-24 00:56:53,102 - logger.py:50 - Epoch: [111][400/500] loss: 1.49123, MAE: 0.30600, time/step=1457ms, lr=8.73e-06
2024-09-24 00:58:05,332 - logger.py:50 - Epoch: [111][450/500] loss: 1.46694, MAE: 0.30521, time/step=1455ms, lr=8.73e-06
2024-09-24 00:59:15,738 - logger.py:50 - Epoch: [111][499/500] loss: 1.45153, MAE: 0.30493, time/step=1453ms, lr=8.73e-06
2024-09-24 01:00:28,172 - logger.py:50 - Epoch: [111] train loss: 1.45153, train MAE: 0.30493,val loss: 0.30658, val MAE: 0.30658,test loss: 0.31865, test MAE: 0.31865,Time: 799.18s
2024-09-24 01:00:28,172 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 01:00:29,070 - logger.py:50 - Epoch: [112][0/500] loss: 1.24709, MAE: 0.29160, time/step=895ms, lr=8.36e-06
2024-09-24 01:01:39,983 - logger.py:50 - Epoch: [112][50/500] loss: 1.34217, MAE: 0.30613, time/step=1408ms, lr=8.36e-06
2024-09-24 01:02:50,955 - logger.py:50 - Epoch: [112][100/500] loss: 1.28792, MAE: 0.30325, time/step=1414ms, lr=8.36e-06
2024-09-24 01:04:03,659 - logger.py:50 - Epoch: [112][150/500] loss: 1.26940, MAE: 0.30433, time/step=1427ms, lr=8.36e-06
2024-09-24 01:05:14,949 - logger.py:50 - Epoch: [112][200/500] loss: 1.26869, MAE: 0.30384, time/step=1427ms, lr=8.36e-06
2024-09-24 01:06:27,377 - logger.py:50 - Epoch: [112][250/500] loss: 1.27320, MAE: 0.30280, time/step=1431ms, lr=8.36e-06
2024-09-24 01:07:44,761 - logger.py:50 - Epoch: [112][300/500] loss: 1.26818, MAE: 0.30170, time/step=1450ms, lr=8.36e-06
2024-09-24 01:08:54,667 - logger.py:50 - Epoch: [112][350/500] loss: 1.53169, MAE: 0.30593, time/step=1443ms, lr=8.36e-06
2024-09-24 01:10:04,901 - logger.py:50 - Epoch: [112][400/500] loss: 1.49616, MAE: 0.30594, time/step=1438ms, lr=8.36e-06
2024-09-24 01:11:16,437 - logger.py:50 - Epoch: [112][450/500] loss: 1.46079, MAE: 0.30514, time/step=1437ms, lr=8.36e-06
2024-09-24 01:12:27,847 - logger.py:50 - Epoch: [112][499/500] loss: 1.45160, MAE: 0.30493, time/step=1439ms, lr=8.36e-06
2024-09-24 01:13:39,603 - logger.py:50 - Epoch: [112] train loss: 1.45160, train MAE: 0.30493,val loss: 0.30680, val MAE: 0.30680,test loss: 0.31885, test MAE: 0.31885,Time: 791.43s
2024-09-24 01:13:39,603 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 01:13:41,355 - logger.py:50 - Epoch: [113][0/500] loss: 2.17741, MAE: 0.31579, time/step=1749ms, lr=8.00e-06
2024-09-24 01:14:50,020 - logger.py:50 - Epoch: [113][50/500] loss: 1.29646, MAE: 0.30815, time/step=1381ms, lr=8.00e-06
2024-09-24 01:16:01,183 - logger.py:50 - Epoch: [113][100/500] loss: 1.25270, MAE: 0.30321, time/step=1402ms, lr=8.00e-06
2024-09-24 01:17:12,900 - logger.py:50 - Epoch: [113][150/500] loss: 1.27387, MAE: 0.30583, time/step=1413ms, lr=8.00e-06
2024-09-24 01:18:23,861 - logger.py:50 - Epoch: [113][200/500] loss: 1.28703, MAE: 0.30247, time/step=1414ms, lr=8.00e-06
2024-09-24 01:19:34,625 - logger.py:50 - Epoch: [113][250/500] loss: 1.28659, MAE: 0.30212, time/step=1414ms, lr=8.00e-06
2024-09-24 01:20:48,061 - logger.py:50 - Epoch: [113][300/500] loss: 1.29415, MAE: 0.30364, time/step=1423ms, lr=8.00e-06
2024-09-24 01:21:58,555 - logger.py:50 - Epoch: [113][350/500] loss: 1.28589, MAE: 0.30219, time/step=1422ms, lr=8.00e-06
2024-09-24 01:23:09,572 - logger.py:50 - Epoch: [113][400/500] loss: 1.26621, MAE: 0.30151, time/step=1421ms, lr=8.00e-06
2024-09-24 01:24:20,628 - logger.py:50 - Epoch: [113][450/500] loss: 1.45946, MAE: 0.30576, time/step=1421ms, lr=8.00e-06
2024-09-24 01:25:30,291 - logger.py:50 - Epoch: [113][499/500] loss: 1.45157, MAE: 0.30494, time/step=1421ms, lr=8.00e-06
2024-09-24 01:26:41,139 - logger.py:50 - Epoch: [113] train loss: 1.45157, train MAE: 0.30494,val loss: 0.30668, val MAE: 0.30668,test loss: 0.31873, test MAE: 0.31873,Time: 781.54s
2024-09-24 01:26:41,139 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 01:26:42,127 - logger.py:50 - Epoch: [114][0/500] loss: 1.65226, MAE: 0.35574, time/step=986ms, lr=7.64e-06
2024-09-24 01:27:52,744 - logger.py:50 - Epoch: [114][50/500] loss: 1.18759, MAE: 0.29265, time/step=1404ms, lr=7.64e-06
2024-09-24 01:29:02,987 - logger.py:50 - Epoch: [114][100/500] loss: 1.28017, MAE: 0.29754, time/step=1404ms, lr=7.64e-06
2024-09-24 01:30:13,612 - logger.py:50 - Epoch: [114][150/500] loss: 1.25538, MAE: 0.29778, time/step=1407ms, lr=7.64e-06
2024-09-24 01:31:24,472 - logger.py:50 - Epoch: [114][200/500] loss: 1.69458, MAE: 0.30882, time/step=1410ms, lr=7.64e-06
2024-09-24 01:32:35,610 - logger.py:50 - Epoch: [114][250/500] loss: 1.64740, MAE: 0.30942, time/step=1412ms, lr=7.64e-06
2024-09-24 01:33:45,106 - logger.py:50 - Epoch: [114][300/500] loss: 1.58132, MAE: 0.30796, time/step=1409ms, lr=7.64e-06
2024-09-24 01:34:56,731 - logger.py:50 - Epoch: [114][350/500] loss: 1.53557, MAE: 0.30628, time/step=1412ms, lr=7.64e-06
2024-09-24 01:36:07,012 - logger.py:50 - Epoch: [114][400/500] loss: 1.49664, MAE: 0.30495, time/step=1411ms, lr=7.64e-06
2024-09-24 01:37:17,288 - logger.py:50 - Epoch: [114][450/500] loss: 1.47182, MAE: 0.30525, time/step=1411ms, lr=7.64e-06
2024-09-24 01:38:25,857 - logger.py:50 - Epoch: [114][499/500] loss: 1.45153, MAE: 0.30491, time/step=1409ms, lr=7.64e-06
2024-09-24 01:39:39,319 - logger.py:50 - Epoch: [114] train loss: 1.45153, train MAE: 0.30491,val loss: 0.30696, val MAE: 0.30696,test loss: 0.31899, test MAE: 0.31899,Time: 778.18s
2024-09-24 01:39:39,320 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 01:39:40,402 - logger.py:50 - Epoch: [115][0/500] loss: 1.57133, MAE: 0.34468, time/step=1080ms, lr=7.29e-06
2024-09-24 01:40:48,283 - logger.py:50 - Epoch: [115][50/500] loss: 1.28679, MAE: 0.30983, time/step=1352ms, lr=7.29e-06
2024-09-24 01:42:01,151 - logger.py:50 - Epoch: [115][100/500] loss: 1.30998, MAE: 0.30861, time/step=1404ms, lr=7.29e-06
2024-09-24 01:43:11,316 - logger.py:50 - Epoch: [115][150/500] loss: 1.29667, MAE: 0.30645, time/step=1404ms, lr=7.29e-06
2024-09-24 01:44:22,769 - logger.py:50 - Epoch: [115][200/500] loss: 1.32009, MAE: 0.30688, time/step=1410ms, lr=7.29e-06
2024-09-24 01:45:33,480 - logger.py:50 - Epoch: [115][250/500] loss: 1.65857, MAE: 0.31282, time/step=1411ms, lr=7.29e-06
2024-09-24 01:46:44,586 - logger.py:50 - Epoch: [115][300/500] loss: 1.59525, MAE: 0.31109, time/step=1413ms, lr=7.29e-06
2024-09-24 01:47:58,613 - logger.py:50 - Epoch: [115][350/500] loss: 1.54062, MAE: 0.30836, time/step=1422ms, lr=7.29e-06
2024-09-24 01:49:08,587 - logger.py:50 - Epoch: [115][400/500] loss: 1.49864, MAE: 0.30563, time/step=1420ms, lr=7.29e-06
2024-09-24 01:50:18,632 - logger.py:50 - Epoch: [115][450/500] loss: 1.47526, MAE: 0.30540, time/step=1418ms, lr=7.29e-06
2024-09-24 01:51:31,807 - logger.py:50 - Epoch: [115][499/500] loss: 1.45150, MAE: 0.30493, time/step=1425ms, lr=7.29e-06
2024-09-24 01:52:49,075 - logger.py:50 - Epoch: [115] train loss: 1.45150, train MAE: 0.30493,val loss: 0.30683, val MAE: 0.30683,test loss: 0.31887, test MAE: 0.31887,Time: 789.76s
2024-09-24 01:52:49,076 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 01:52:50,663 - logger.py:50 - Epoch: [116][0/500] loss: 1.18392, MAE: 0.27528, time/step=1585ms, lr=6.95e-06
2024-09-24 01:54:01,056 - logger.py:50 - Epoch: [116][50/500] loss: 1.24571, MAE: 0.29278, time/step=1411ms, lr=6.95e-06
2024-09-24 01:55:09,992 - logger.py:50 - Epoch: [116][100/500] loss: 1.27173, MAE: 0.30177, time/step=1395ms, lr=6.95e-06
2024-09-24 01:56:21,778 - logger.py:50 - Epoch: [116][150/500] loss: 1.26584, MAE: 0.30082, time/step=1409ms, lr=6.95e-06
2024-09-24 01:57:36,277 - logger.py:50 - Epoch: [116][200/500] loss: 1.23438, MAE: 0.29775, time/step=1429ms, lr=6.95e-06
2024-09-24 01:58:45,673 - logger.py:50 - Epoch: [116][250/500] loss: 1.59352, MAE: 0.30559, time/step=1421ms, lr=6.95e-06
2024-09-24 01:59:56,588 - logger.py:50 - Epoch: [116][300/500] loss: 1.54806, MAE: 0.30603, time/step=1420ms, lr=6.95e-06
2024-09-24 02:01:05,414 - logger.py:50 - Epoch: [116][350/500] loss: 1.51144, MAE: 0.30565, time/step=1414ms, lr=6.95e-06
2024-09-24 02:02:17,977 - logger.py:50 - Epoch: [116][400/500] loss: 1.48970, MAE: 0.30558, time/step=1419ms, lr=6.95e-06
2024-09-24 02:03:26,819 - logger.py:50 - Epoch: [116][450/500] loss: 1.47264, MAE: 0.30521, time/step=1414ms, lr=6.95e-06
2024-09-24 02:04:35,824 - logger.py:50 - Epoch: [116][499/500] loss: 1.45150, MAE: 0.30492, time/step=1413ms, lr=6.95e-06
2024-09-24 02:05:47,355 - logger.py:50 - Epoch: [116] train loss: 1.45150, train MAE: 0.30492,val loss: 0.30673, val MAE: 0.30673,test loss: 0.31878, test MAE: 0.31878,Time: 778.28s
2024-09-24 02:05:47,356 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 02:05:48,883 - logger.py:50 - Epoch: [117][0/500] loss: 0.95872, MAE: 0.32048, time/step=1525ms, lr=6.62e-06
2024-09-24 02:06:58,870 - logger.py:50 - Epoch: [117][50/500] loss: 1.21011, MAE: 0.30756, time/step=1402ms, lr=6.62e-06
2024-09-24 02:08:07,364 - logger.py:50 - Epoch: [117][100/500] loss: 1.26488, MAE: 0.30504, time/step=1386ms, lr=6.62e-06
2024-09-24 02:09:17,093 - logger.py:50 - Epoch: [117][150/500] loss: 1.26363, MAE: 0.30409, time/step=1389ms, lr=6.62e-06
2024-09-24 02:10:28,792 - logger.py:50 - Epoch: [117][200/500] loss: 1.69323, MAE: 0.31155, time/step=1400ms, lr=6.62e-06
2024-09-24 02:11:38,231 - logger.py:50 - Epoch: [117][250/500] loss: 1.59280, MAE: 0.30854, time/step=1398ms, lr=6.62e-06
2024-09-24 02:12:50,167 - logger.py:50 - Epoch: [117][300/500] loss: 1.54982, MAE: 0.30843, time/step=1405ms, lr=6.62e-06
2024-09-24 02:14:04,517 - logger.py:50 - Epoch: [117][350/500] loss: 1.52983, MAE: 0.30802, time/step=1416ms, lr=6.62e-06
2024-09-24 02:15:16,076 - logger.py:50 - Epoch: [117][400/500] loss: 1.49695, MAE: 0.30679, time/step=1418ms, lr=6.62e-06
2024-09-24 02:16:29,852 - logger.py:50 - Epoch: [117][450/500] loss: 1.47196, MAE: 0.30568, time/step=1425ms, lr=6.62e-06
2024-09-24 02:17:41,111 - logger.py:50 - Epoch: [117][499/500] loss: 1.45151, MAE: 0.30491, time/step=1428ms, lr=6.62e-06
2024-09-24 02:18:53,223 - logger.py:50 - Epoch: [117] train loss: 1.45151, train MAE: 0.30491,val loss: 0.30685, val MAE: 0.30685,test loss: 0.31889, test MAE: 0.31889,Time: 785.87s
2024-09-24 02:18:53,223 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 02:18:54,209 - logger.py:50 - Epoch: [118][0/500] loss: 1.53227, MAE: 0.35052, time/step=983ms, lr=6.30e-06
2024-09-24 02:20:07,169 - logger.py:50 - Epoch: [118][50/500] loss: 2.94287, MAE: 0.32933, time/step=1450ms, lr=6.30e-06
2024-09-24 02:21:17,722 - logger.py:50 - Epoch: [118][100/500] loss: 2.10460, MAE: 0.31218, time/step=1431ms, lr=6.30e-06
2024-09-24 02:22:27,772 - logger.py:50 - Epoch: [118][150/500] loss: 1.80460, MAE: 0.30775, time/step=1421ms, lr=6.30e-06
2024-09-24 02:23:39,958 - logger.py:50 - Epoch: [118][200/500] loss: 1.68273, MAE: 0.30710, time/step=1427ms, lr=6.30e-06
2024-09-24 02:24:49,603 - logger.py:50 - Epoch: [118][250/500] loss: 1.59962, MAE: 0.30495, time/step=1420ms, lr=6.30e-06
2024-09-24 02:26:00,466 - logger.py:50 - Epoch: [118][300/500] loss: 1.56951, MAE: 0.30582, time/step=1419ms, lr=6.30e-06
2024-09-24 02:27:10,952 - logger.py:50 - Epoch: [118][350/500] loss: 1.51636, MAE: 0.30423, time/step=1418ms, lr=6.30e-06
2024-09-24 02:28:20,089 - logger.py:50 - Epoch: [118][400/500] loss: 1.48951, MAE: 0.30420, time/step=1414ms, lr=6.30e-06
2024-09-24 02:29:32,495 - logger.py:50 - Epoch: [118][450/500] loss: 1.46489, MAE: 0.30458, time/step=1417ms, lr=6.30e-06
2024-09-24 02:30:42,049 - logger.py:50 - Epoch: [118][499/500] loss: 1.45151, MAE: 0.30493, time/step=1418ms, lr=6.30e-06
2024-09-24 02:31:53,826 - logger.py:50 - Epoch: [118] train loss: 1.45151, train MAE: 0.30493,val loss: 0.30660, val MAE: 0.30660,test loss: 0.31866, test MAE: 0.31866,Time: 780.60s
2024-09-24 02:31:53,826 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 02:31:55,221 - logger.py:50 - Epoch: [119][0/500] loss: 1.74306, MAE: 0.38314, time/step=1392ms, lr=5.99e-06
2024-09-24 02:33:05,792 - logger.py:50 - Epoch: [119][50/500] loss: 2.99391, MAE: 0.33302, time/step=1411ms, lr=5.99e-06
2024-09-24 02:34:16,352 - logger.py:50 - Epoch: [119][100/500] loss: 2.18525, MAE: 0.31879, time/step=1411ms, lr=5.99e-06
2024-09-24 02:35:26,148 - logger.py:50 - Epoch: [119][150/500] loss: 1.86848, MAE: 0.31119, time/step=1406ms, lr=5.99e-06
2024-09-24 02:36:37,921 - logger.py:50 - Epoch: [119][200/500] loss: 1.73125, MAE: 0.31127, time/step=1413ms, lr=5.99e-06
2024-09-24 02:37:47,993 - logger.py:50 - Epoch: [119][250/500] loss: 1.64344, MAE: 0.30966, time/step=1411ms, lr=5.99e-06
2024-09-24 02:38:59,776 - logger.py:50 - Epoch: [119][300/500] loss: 1.58873, MAE: 0.30986, time/step=1415ms, lr=5.99e-06
2024-09-24 02:40:10,419 - logger.py:50 - Epoch: [119][350/500] loss: 1.54501, MAE: 0.30938, time/step=1415ms, lr=5.99e-06
2024-09-24 02:41:21,718 - logger.py:50 - Epoch: [119][400/500] loss: 1.50672, MAE: 0.30789, time/step=1416ms, lr=5.99e-06
2024-09-24 02:42:31,252 - logger.py:50 - Epoch: [119][450/500] loss: 1.47086, MAE: 0.30599, time/step=1413ms, lr=5.99e-06
2024-09-24 02:43:38,554 - logger.py:50 - Epoch: [119][499/500] loss: 1.45151, MAE: 0.30491, time/step=1409ms, lr=5.99e-06
2024-09-24 02:44:49,668 - logger.py:50 - Epoch: [119] train loss: 1.45151, train MAE: 0.30491,val loss: 0.30672, val MAE: 0.30672,test loss: 0.31877, test MAE: 0.31877,Time: 775.84s
2024-09-24 02:44:49,668 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 02:44:51,311 - logger.py:50 - Epoch: [120][0/500] loss: 0.94834, MAE: 0.28593, time/step=1640ms, lr=5.68e-06
2024-09-24 02:46:01,496 - logger.py:50 - Epoch: [120][50/500] loss: 1.35126, MAE: 0.30944, time/step=1408ms, lr=5.68e-06
2024-09-24 02:47:09,901 - logger.py:50 - Epoch: [120][100/500] loss: 1.25548, MAE: 0.30236, time/step=1388ms, lr=5.68e-06
2024-09-24 02:48:21,327 - logger.py:50 - Epoch: [120][150/500] loss: 1.25821, MAE: 0.30226, time/step=1402ms, lr=5.68e-06
2024-09-24 02:49:30,705 - logger.py:50 - Epoch: [120][200/500] loss: 1.25071, MAE: 0.30314, time/step=1398ms, lr=5.68e-06
2024-09-24 02:50:41,431 - logger.py:50 - Epoch: [120][250/500] loss: 1.25935, MAE: 0.30249, time/step=1401ms, lr=5.68e-06
2024-09-24 02:51:52,447 - logger.py:50 - Epoch: [120][300/500] loss: 1.27397, MAE: 0.30347, time/step=1405ms, lr=5.68e-06
2024-09-24 02:53:03,078 - logger.py:50 - Epoch: [120][350/500] loss: 1.29472, MAE: 0.30464, time/step=1406ms, lr=5.68e-06
2024-09-24 02:54:13,519 - logger.py:50 - Epoch: [120][400/500] loss: 1.29803, MAE: 0.30361, time/step=1406ms, lr=5.68e-06
2024-09-24 02:55:25,748 - logger.py:50 - Epoch: [120][450/500] loss: 1.47279, MAE: 0.30604, time/step=1410ms, lr=5.68e-06
2024-09-24 02:56:36,463 - logger.py:50 - Epoch: [120][499/500] loss: 1.45144, MAE: 0.30492, time/step=1414ms, lr=5.68e-06
2024-09-24 02:57:49,130 - logger.py:50 - Epoch: [120] train loss: 1.45144, train MAE: 0.30492,val loss: 0.30680, val MAE: 0.30680,test loss: 0.31882, test MAE: 0.31882,Time: 779.46s
2024-09-24 02:57:49,130 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 02:57:50,740 - logger.py:50 - Epoch: [121][0/500] loss: 1.37526, MAE: 0.30818, time/step=1608ms, lr=5.38e-06
2024-09-24 02:59:03,711 - logger.py:50 - Epoch: [121][50/500] loss: 3.03451, MAE: 0.33774, time/step=1462ms, lr=5.38e-06
2024-09-24 03:00:15,818 - logger.py:50 - Epoch: [121][100/500] loss: 2.18682, MAE: 0.32188, time/step=1452ms, lr=5.38e-06
2024-09-24 03:01:28,034 - logger.py:50 - Epoch: [121][150/500] loss: 1.91518, MAE: 0.31419, time/step=1450ms, lr=5.38e-06
2024-09-24 03:02:38,734 - logger.py:50 - Epoch: [121][200/500] loss: 1.77747, MAE: 0.31349, time/step=1441ms, lr=5.38e-06
2024-09-24 03:03:51,811 - logger.py:50 - Epoch: [121][250/500] loss: 1.65733, MAE: 0.30823, time/step=1445ms, lr=5.38e-06
2024-09-24 03:05:03,487 - logger.py:50 - Epoch: [121][300/500] loss: 1.60470, MAE: 0.30892, time/step=1443ms, lr=5.38e-06
2024-09-24 03:06:13,814 - logger.py:50 - Epoch: [121][350/500] loss: 1.55062, MAE: 0.30653, time/step=1438ms, lr=5.38e-06
2024-09-24 03:07:24,602 - logger.py:50 - Epoch: [121][400/500] loss: 1.50385, MAE: 0.30558, time/step=1435ms, lr=5.38e-06
2024-09-24 03:08:36,528 - logger.py:50 - Epoch: [121][450/500] loss: 1.47076, MAE: 0.30509, time/step=1435ms, lr=5.38e-06
2024-09-24 03:09:47,529 - logger.py:50 - Epoch: [121][499/500] loss: 1.45148, MAE: 0.30492, time/step=1437ms, lr=5.38e-06
2024-09-24 03:10:59,972 - logger.py:50 - Epoch: [121] train loss: 1.45148, train MAE: 0.30492,val loss: 0.30670, val MAE: 0.30670,test loss: 0.31875, test MAE: 0.31875,Time: 790.84s
2024-09-24 03:10:59,972 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 03:11:01,040 - logger.py:50 - Epoch: [122][0/500] loss: 0.56252, MAE: 0.24575, time/step=1065ms, lr=5.09e-06
2024-09-24 03:12:12,017 - logger.py:50 - Epoch: [122][50/500] loss: 1.33744, MAE: 0.31383, time/step=1413ms, lr=5.09e-06
2024-09-24 03:13:21,658 - logger.py:50 - Epoch: [122][100/500] loss: 1.34676, MAE: 0.30624, time/step=1403ms, lr=5.09e-06
2024-09-24 03:14:31,862 - logger.py:50 - Epoch: [122][150/500] loss: 1.85793, MAE: 0.31430, time/step=1403ms, lr=5.09e-06
2024-09-24 03:15:42,017 - logger.py:50 - Epoch: [122][200/500] loss: 1.71775, MAE: 0.31106, time/step=1403ms, lr=5.09e-06
2024-09-24 03:16:52,258 - logger.py:50 - Epoch: [122][250/500] loss: 1.61465, MAE: 0.30809, time/step=1404ms, lr=5.09e-06
2024-09-24 03:18:03,018 - logger.py:50 - Epoch: [122][300/500] loss: 1.55087, MAE: 0.30522, time/step=1405ms, lr=5.09e-06
2024-09-24 03:19:13,812 - logger.py:50 - Epoch: [122][350/500] loss: 1.52726, MAE: 0.30538, time/step=1407ms, lr=5.09e-06
2024-09-24 03:20:23,678 - logger.py:50 - Epoch: [122][400/500] loss: 1.50367, MAE: 0.30640, time/step=1406ms, lr=5.09e-06
2024-09-24 03:21:33,201 - logger.py:50 - Epoch: [122][450/500] loss: 1.47560, MAE: 0.30562, time/step=1404ms, lr=5.09e-06
2024-09-24 03:22:42,458 - logger.py:50 - Epoch: [122][499/500] loss: 1.45143, MAE: 0.30491, time/step=1405ms, lr=5.09e-06
2024-09-24 03:23:54,244 - logger.py:50 - Epoch: [122] train loss: 1.45143, train MAE: 0.30491,val loss: 0.30677, val MAE: 0.30677,test loss: 0.31882, test MAE: 0.31882,Time: 774.27s
2024-09-24 03:23:54,244 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 03:23:55,745 - logger.py:50 - Epoch: [123][0/500] loss: 0.61331, MAE: 0.23131, time/step=1499ms, lr=4.81e-06
2024-09-24 03:25:05,565 - logger.py:50 - Epoch: [123][50/500] loss: 1.28685, MAE: 0.30736, time/step=1398ms, lr=4.81e-06
2024-09-24 03:26:16,574 - logger.py:50 - Epoch: [123][100/500] loss: 1.23975, MAE: 0.30025, time/step=1409ms, lr=4.81e-06
2024-09-24 03:27:26,147 - logger.py:50 - Epoch: [123][150/500] loss: 1.81930, MAE: 0.31081, time/step=1403ms, lr=4.81e-06
2024-09-24 03:28:36,109 - logger.py:50 - Epoch: [123][200/500] loss: 1.70822, MAE: 0.31002, time/step=1402ms, lr=4.81e-06
2024-09-24 03:29:47,977 - logger.py:50 - Epoch: [123][250/500] loss: 1.63017, MAE: 0.30927, time/step=1409ms, lr=4.81e-06
2024-09-24 03:31:00,339 - logger.py:50 - Epoch: [123][300/500] loss: 1.55721, MAE: 0.30704, time/step=1416ms, lr=4.81e-06
2024-09-24 03:32:12,212 - logger.py:50 - Epoch: [123][350/500] loss: 1.52720, MAE: 0.30650, time/step=1419ms, lr=4.81e-06
2024-09-24 03:33:25,333 - logger.py:50 - Epoch: [123][400/500] loss: 1.48337, MAE: 0.30528, time/step=1424ms, lr=4.81e-06
2024-09-24 03:34:40,631 - logger.py:50 - Epoch: [123][450/500] loss: 1.46467, MAE: 0.30498, time/step=1433ms, lr=4.81e-06
2024-09-24 03:35:51,773 - logger.py:50 - Epoch: [123][499/500] loss: 1.45143, MAE: 0.30492, time/step=1435ms, lr=4.81e-06
2024-09-24 03:37:04,770 - logger.py:50 - Epoch: [123] train loss: 1.45143, train MAE: 0.30492,val loss: 0.30674, val MAE: 0.30674,test loss: 0.31878, test MAE: 0.31878,Time: 790.53s
2024-09-24 03:37:04,770 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 03:37:06,317 - logger.py:50 - Epoch: [124][0/500] loss: 1.13124, MAE: 0.27906, time/step=1545ms, lr=4.54e-06
2024-09-24 03:38:16,220 - logger.py:50 - Epoch: [124][50/500] loss: 1.22102, MAE: 0.30134, time/step=1401ms, lr=4.54e-06
2024-09-24 03:39:26,875 - logger.py:50 - Epoch: [124][100/500] loss: 1.30390, MAE: 0.30474, time/step=1407ms, lr=4.54e-06
2024-09-24 03:40:37,336 - logger.py:50 - Epoch: [124][150/500] loss: 1.26767, MAE: 0.30177, time/step=1408ms, lr=4.54e-06
2024-09-24 03:41:48,275 - logger.py:50 - Epoch: [124][200/500] loss: 1.26226, MAE: 0.30109, time/step=1410ms, lr=4.54e-06
2024-09-24 03:42:59,412 - logger.py:50 - Epoch: [124][250/500] loss: 1.58928, MAE: 0.30698, time/step=1413ms, lr=4.54e-06
2024-09-24 03:44:10,024 - logger.py:50 - Epoch: [124][300/500] loss: 1.54393, MAE: 0.30646, time/step=1413ms, lr=4.54e-06
2024-09-24 03:45:20,660 - logger.py:50 - Epoch: [124][350/500] loss: 1.52468, MAE: 0.30728, time/step=1413ms, lr=4.54e-06
2024-09-24 03:46:32,379 - logger.py:50 - Epoch: [124][400/500] loss: 1.48082, MAE: 0.30473, time/step=1415ms, lr=4.54e-06
2024-09-24 03:47:44,415 - logger.py:50 - Epoch: [124][450/500] loss: 1.46672, MAE: 0.30486, time/step=1418ms, lr=4.54e-06
2024-09-24 03:48:54,484 - logger.py:50 - Epoch: [124][499/500] loss: 1.45141, MAE: 0.30492, time/step=1419ms, lr=4.54e-06
2024-09-24 03:50:06,611 - logger.py:50 - Epoch: [124] train loss: 1.45141, train MAE: 0.30492,val loss: 0.30662, val MAE: 0.30662,test loss: 0.31868, test MAE: 0.31868,Time: 781.84s
2024-09-24 03:50:06,611 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 03:50:08,294 - logger.py:50 - Epoch: [125][0/500] loss: 1.10555, MAE: 0.27726, time/step=1680ms, lr=4.28e-06
2024-09-24 03:51:16,744 - logger.py:50 - Epoch: [125][50/500] loss: 1.28597, MAE: 0.30402, time/step=1375ms, lr=4.28e-06
2024-09-24 03:52:26,502 - logger.py:50 - Epoch: [125][100/500] loss: 1.25837, MAE: 0.30068, time/step=1385ms, lr=4.28e-06
2024-09-24 03:53:37,913 - logger.py:50 - Epoch: [125][150/500] loss: 1.31832, MAE: 0.30550, time/step=1399ms, lr=4.28e-06
2024-09-24 03:54:49,069 - logger.py:50 - Epoch: [125][200/500] loss: 1.29391, MAE: 0.30217, time/step=1405ms, lr=4.28e-06
2024-09-24 03:55:58,712 - logger.py:50 - Epoch: [125][250/500] loss: 1.28661, MAE: 0.30300, time/step=1403ms, lr=4.28e-06
2024-09-24 03:57:10,028 - logger.py:50 - Epoch: [125][300/500] loss: 1.58073, MAE: 0.30767, time/step=1407ms, lr=4.28e-06
2024-09-24 03:58:20,955 - logger.py:50 - Epoch: [125][350/500] loss: 1.53126, MAE: 0.30697, time/step=1408ms, lr=4.28e-06
2024-09-24 03:59:31,549 - logger.py:50 - Epoch: [125][400/500] loss: 1.51201, MAE: 0.30636, time/step=1409ms, lr=4.28e-06
2024-09-24 04:00:43,987 - logger.py:50 - Epoch: [125][450/500] loss: 1.48338, MAE: 0.30606, time/step=1413ms, lr=4.28e-06
2024-09-24 04:01:51,996 - logger.py:50 - Epoch: [125][499/500] loss: 1.45141, MAE: 0.30490, time/step=1411ms, lr=4.28e-06
2024-09-24 04:03:05,264 - logger.py:50 - Epoch: [125] train loss: 1.45141, train MAE: 0.30490,val loss: 0.30677, val MAE: 0.30677,test loss: 0.31881, test MAE: 0.31881,Time: 778.65s
2024-09-24 04:03:05,265 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 04:03:07,080 - logger.py:50 - Epoch: [126][0/500] loss: 1.07720, MAE: 0.28059, time/step=1813ms, lr=4.03e-06
2024-09-24 04:04:18,375 - logger.py:50 - Epoch: [126][50/500] loss: 1.20441, MAE: 0.29818, time/step=1433ms, lr=4.03e-06
2024-09-24 04:05:32,694 - logger.py:50 - Epoch: [126][100/500] loss: 1.20166, MAE: 0.30113, time/step=1460ms, lr=4.03e-06
2024-09-24 04:06:43,882 - logger.py:50 - Epoch: [126][150/500] loss: 1.24664, MAE: 0.30387, time/step=1448ms, lr=4.03e-06
2024-09-24 04:07:58,625 - logger.py:50 - Epoch: [126][200/500] loss: 1.24850, MAE: 0.30379, time/step=1459ms, lr=4.03e-06
2024-09-24 04:09:10,076 - logger.py:50 - Epoch: [126][250/500] loss: 1.26105, MAE: 0.30274, time/step=1453ms, lr=4.03e-06
2024-09-24 04:10:23,208 - logger.py:50 - Epoch: [126][300/500] loss: 1.25702, MAE: 0.30219, time/step=1455ms, lr=4.03e-06
2024-09-24 04:11:33,891 - logger.py:50 - Epoch: [126][350/500] loss: 1.51035, MAE: 0.30664, time/step=1449ms, lr=4.03e-06
2024-09-24 04:12:44,990 - logger.py:50 - Epoch: [126][400/500] loss: 1.48474, MAE: 0.30595, time/step=1446ms, lr=4.03e-06
2024-09-24 04:13:55,812 - logger.py:50 - Epoch: [126][450/500] loss: 1.47628, MAE: 0.30603, time/step=1442ms, lr=4.03e-06
2024-09-24 04:15:06,927 - logger.py:50 - Epoch: [126][499/500] loss: 1.45139, MAE: 0.30490, time/step=1443ms, lr=4.03e-06
2024-09-24 04:16:18,773 - logger.py:50 - Epoch: [126] train loss: 1.45139, train MAE: 0.30490,val loss: 0.30674, val MAE: 0.30674,test loss: 0.31878, test MAE: 0.31878,Time: 793.51s
2024-09-24 04:16:18,773 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 04:16:20,107 - logger.py:50 - Epoch: [127][0/500] loss: 1.44219, MAE: 0.35910, time/step=1331ms, lr=3.79e-06
2024-09-24 04:17:30,112 - logger.py:50 - Epoch: [127][50/500] loss: 1.20098, MAE: 0.30351, time/step=1399ms, lr=3.79e-06
2024-09-24 04:18:42,848 - logger.py:50 - Epoch: [127][100/500] loss: 1.26276, MAE: 0.30328, time/step=1426ms, lr=3.79e-06
2024-09-24 04:19:51,826 - logger.py:50 - Epoch: [127][150/500] loss: 1.22772, MAE: 0.30010, time/step=1411ms, lr=3.79e-06
2024-09-24 04:21:05,584 - logger.py:50 - Epoch: [127][200/500] loss: 1.25261, MAE: 0.30218, time/step=1427ms, lr=3.79e-06
2024-09-24 04:22:15,722 - logger.py:50 - Epoch: [127][250/500] loss: 1.27961, MAE: 0.30239, time/step=1422ms, lr=3.79e-06
2024-09-24 04:23:25,053 - logger.py:50 - Epoch: [127][300/500] loss: 1.26748, MAE: 0.30157, time/step=1416ms, lr=3.79e-06
2024-09-24 04:24:35,983 - logger.py:50 - Epoch: [127][350/500] loss: 1.27543, MAE: 0.30224, time/step=1417ms, lr=3.79e-06
2024-09-24 04:25:47,253 - logger.py:50 - Epoch: [127][400/500] loss: 1.49903, MAE: 0.30598, time/step=1418ms, lr=3.79e-06
2024-09-24 04:26:56,767 - logger.py:50 - Epoch: [127][450/500] loss: 1.48230, MAE: 0.30641, time/step=1415ms, lr=3.79e-06
2024-09-24 04:28:05,325 - logger.py:50 - Epoch: [127][499/500] loss: 1.45140, MAE: 0.30491, time/step=1413ms, lr=3.79e-06
2024-09-24 04:29:17,146 - logger.py:50 - Epoch: [127] train loss: 1.45140, train MAE: 0.30491,val loss: 0.30671, val MAE: 0.30671,test loss: 0.31876, test MAE: 0.31876,Time: 778.37s
2024-09-24 04:29:17,146 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 04:29:18,210 - logger.py:50 - Epoch: [128][0/500] loss: 1.37730, MAE: 0.31076, time/step=1061ms, lr=3.56e-06
2024-09-24 04:30:29,139 - logger.py:50 - Epoch: [128][50/500] loss: 1.33762, MAE: 0.30643, time/step=1412ms, lr=3.56e-06
2024-09-24 04:31:38,218 - logger.py:50 - Epoch: [128][100/500] loss: 2.15544, MAE: 0.32294, time/step=1397ms, lr=3.56e-06
2024-09-24 04:32:48,428 - logger.py:50 - Epoch: [128][150/500] loss: 1.84857, MAE: 0.31485, time/step=1399ms, lr=3.56e-06
2024-09-24 04:33:59,852 - logger.py:50 - Epoch: [128][200/500] loss: 1.70415, MAE: 0.31167, time/step=1406ms, lr=3.56e-06
2024-09-24 04:35:11,448 - logger.py:50 - Epoch: [128][250/500] loss: 1.63334, MAE: 0.30886, time/step=1412ms, lr=3.56e-06
2024-09-24 04:36:26,437 - logger.py:50 - Epoch: [128][300/500] loss: 1.57236, MAE: 0.30827, time/step=1426ms, lr=3.56e-06
2024-09-24 04:37:38,864 - logger.py:50 - Epoch: [128][350/500] loss: 1.53087, MAE: 0.30776, time/step=1429ms, lr=3.56e-06
2024-09-24 04:38:54,171 - logger.py:50 - Epoch: [128][400/500] loss: 1.50562, MAE: 0.30611, time/step=1439ms, lr=3.56e-06
2024-09-24 04:40:05,300 - logger.py:50 - Epoch: [128][450/500] loss: 1.47049, MAE: 0.30500, time/step=1437ms, lr=3.56e-06
2024-09-24 04:41:15,335 - logger.py:50 - Epoch: [128][499/500] loss: 1.45137, MAE: 0.30491, time/step=1436ms, lr=3.56e-06
2024-09-24 04:42:27,372 - logger.py:50 - Epoch: [128] train loss: 1.45137, train MAE: 0.30491,val loss: 0.30663, val MAE: 0.30663,test loss: 0.31869, test MAE: 0.31869,Time: 790.23s
2024-09-24 04:42:27,372 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 04:42:29,063 - logger.py:50 - Epoch: [129][0/500] loss: 1.26677, MAE: 0.34226, time/step=1689ms, lr=3.33e-06
2024-09-24 04:43:38,922 - logger.py:50 - Epoch: [129][50/500] loss: 1.31072, MAE: 0.30186, time/step=1403ms, lr=3.33e-06
2024-09-24 04:44:51,411 - logger.py:50 - Epoch: [129][100/500] loss: 1.27772, MAE: 0.30228, time/step=1426ms, lr=3.33e-06
2024-09-24 04:46:02,597 - logger.py:50 - Epoch: [129][150/500] loss: 1.25698, MAE: 0.29899, time/step=1425ms, lr=3.33e-06
2024-09-24 04:47:14,489 - logger.py:50 - Epoch: [129][200/500] loss: 1.25860, MAE: 0.29980, time/step=1428ms, lr=3.33e-06
2024-09-24 04:48:25,385 - logger.py:50 - Epoch: [129][250/500] loss: 1.26118, MAE: 0.30111, time/step=1426ms, lr=3.33e-06
2024-09-24 04:49:34,534 - logger.py:50 - Epoch: [129][300/500] loss: 1.24983, MAE: 0.30070, time/step=1419ms, lr=3.33e-06
2024-09-24 04:50:44,535 - logger.py:50 - Epoch: [129][350/500] loss: 1.24809, MAE: 0.30144, time/step=1416ms, lr=3.33e-06
2024-09-24 04:51:56,311 - logger.py:50 - Epoch: [129][400/500] loss: 1.25388, MAE: 0.30191, time/step=1419ms, lr=3.33e-06
2024-09-24 04:53:07,650 - logger.py:50 - Epoch: [129][450/500] loss: 1.27235, MAE: 0.30135, time/step=1420ms, lr=3.33e-06
2024-09-24 04:54:17,277 - logger.py:50 - Epoch: [129][499/500] loss: 1.45138, MAE: 0.30489, time/step=1420ms, lr=3.33e-06
2024-09-24 04:55:28,969 - logger.py:50 - Epoch: [129] train loss: 1.45138, train MAE: 0.30489,val loss: 0.30667, val MAE: 0.30667,test loss: 0.31872, test MAE: 0.31872,Time: 781.60s
2024-09-24 04:55:28,969 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 04:55:30,633 - logger.py:50 - Epoch: [130][0/500] loss: 0.90402, MAE: 0.32250, time/step=1661ms, lr=3.12e-06
2024-09-24 04:56:38,948 - logger.py:50 - Epoch: [130][50/500] loss: 1.24041, MAE: 0.30448, time/step=1372ms, lr=3.12e-06
2024-09-24 04:57:49,497 - logger.py:50 - Epoch: [130][100/500] loss: 1.29534, MAE: 0.30554, time/step=1391ms, lr=3.12e-06
2024-09-24 04:58:59,356 - logger.py:50 - Epoch: [130][150/500] loss: 1.33026, MAE: 0.30596, time/step=1393ms, lr=3.12e-06
2024-09-24 05:00:08,748 - logger.py:50 - Epoch: [130][200/500] loss: 1.31713, MAE: 0.30584, time/step=1392ms, lr=3.12e-06
2024-09-24 05:01:19,665 - logger.py:50 - Epoch: [130][250/500] loss: 1.32544, MAE: 0.30570, time/step=1397ms, lr=3.12e-06
2024-09-24 05:02:30,862 - logger.py:50 - Epoch: [130][300/500] loss: 1.31449, MAE: 0.30506, time/step=1402ms, lr=3.12e-06
2024-09-24 05:03:41,200 - logger.py:50 - Epoch: [130][350/500] loss: 1.29153, MAE: 0.30370, time/step=1402ms, lr=3.12e-06
2024-09-24 05:04:50,454 - logger.py:50 - Epoch: [130][400/500] loss: 1.28423, MAE: 0.30109, time/step=1400ms, lr=3.12e-06
2024-09-24 05:06:01,441 - logger.py:50 - Epoch: [130][450/500] loss: 1.46440, MAE: 0.30402, time/step=1402ms, lr=3.12e-06
2024-09-24 05:07:09,034 - logger.py:50 - Epoch: [130][499/500] loss: 1.45136, MAE: 0.30491, time/step=1400ms, lr=3.12e-06
2024-09-24 05:08:20,271 - logger.py:50 - Epoch: [130] train loss: 1.45136, train MAE: 0.30491,val loss: 0.30666, val MAE: 0.30666,test loss: 0.31872, test MAE: 0.31872,Time: 771.30s
2024-09-24 05:08:20,271 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 05:08:21,806 - logger.py:50 - Epoch: [131][0/500] loss: 0.66132, MAE: 0.25792, time/step=1532ms, lr=2.91e-06
2024-09-24 05:09:30,979 - logger.py:50 - Epoch: [131][50/500] loss: 1.24252, MAE: 0.30229, time/step=1386ms, lr=2.91e-06
2024-09-24 05:10:41,914 - logger.py:50 - Epoch: [131][100/500] loss: 1.25296, MAE: 0.30745, time/step=1402ms, lr=2.91e-06
2024-09-24 05:11:53,268 - logger.py:50 - Epoch: [131][150/500] loss: 1.24829, MAE: 0.30207, time/step=1411ms, lr=2.91e-06
2024-09-24 05:13:05,674 - logger.py:50 - Epoch: [131][200/500] loss: 1.25234, MAE: 0.30023, time/step=1420ms, lr=2.91e-06
2024-09-24 05:14:17,779 - logger.py:50 - Epoch: [131][250/500] loss: 1.25713, MAE: 0.30078, time/step=1424ms, lr=2.91e-06
2024-09-24 05:15:30,224 - logger.py:50 - Epoch: [131][300/500] loss: 1.27035, MAE: 0.30216, time/step=1428ms, lr=2.91e-06
2024-09-24 05:16:42,775 - logger.py:50 - Epoch: [131][350/500] loss: 1.26359, MAE: 0.30186, time/step=1432ms, lr=2.91e-06
2024-09-24 05:17:56,977 - logger.py:50 - Epoch: [131][400/500] loss: 1.28215, MAE: 0.30236, time/step=1438ms, lr=2.91e-06
2024-09-24 05:19:09,713 - logger.py:50 - Epoch: [131][450/500] loss: 1.28641, MAE: 0.30233, time/step=1440ms, lr=2.91e-06
2024-09-24 05:20:19,344 - logger.py:50 - Epoch: [131][499/500] loss: 1.45137, MAE: 0.30490, time/step=1438ms, lr=2.91e-06
2024-09-24 05:21:31,595 - logger.py:50 - Epoch: [131] train loss: 1.45137, train MAE: 0.30490,val loss: 0.30675, val MAE: 0.30675,test loss: 0.31879, test MAE: 0.31879,Time: 791.32s
2024-09-24 05:21:31,595 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 05:21:32,530 - logger.py:50 - Epoch: [132][0/500] loss: 1.45083, MAE: 0.31110, time/step=932ms, lr=2.72e-06
2024-09-24 05:22:42,651 - logger.py:50 - Epoch: [132][50/500] loss: 1.36775, MAE: 0.30932, time/step=1393ms, lr=2.72e-06
2024-09-24 05:23:53,150 - logger.py:50 - Epoch: [132][100/500] loss: 1.33754, MAE: 0.30453, time/step=1402ms, lr=2.72e-06
2024-09-24 05:25:03,201 - logger.py:50 - Epoch: [132][150/500] loss: 1.30526, MAE: 0.30246, time/step=1401ms, lr=2.72e-06
2024-09-24 05:26:12,634 - logger.py:50 - Epoch: [132][200/500] loss: 1.29171, MAE: 0.30111, time/step=1398ms, lr=2.72e-06
2024-09-24 05:27:24,124 - logger.py:50 - Epoch: [132][250/500] loss: 1.28935, MAE: 0.30220, time/step=1404ms, lr=2.72e-06
2024-09-24 05:28:35,784 - logger.py:50 - Epoch: [132][300/500] loss: 1.28948, MAE: 0.30270, time/step=1409ms, lr=2.72e-06
2024-09-24 05:29:46,125 - logger.py:50 - Epoch: [132][350/500] loss: 1.29929, MAE: 0.30308, time/step=1409ms, lr=2.72e-06
2024-09-24 05:30:56,120 - logger.py:50 - Epoch: [132][400/500] loss: 1.29232, MAE: 0.30201, time/step=1408ms, lr=2.72e-06
2024-09-24 05:32:07,417 - logger.py:50 - Epoch: [132][450/500] loss: 1.27297, MAE: 0.30113, time/step=1410ms, lr=2.72e-06
2024-09-24 05:33:15,824 - logger.py:50 - Epoch: [132][499/500] loss: 1.45135, MAE: 0.30491, time/step=1408ms, lr=2.72e-06
2024-09-24 05:34:27,716 - logger.py:50 - Epoch: [132] train loss: 1.45135, train MAE: 0.30491,val loss: 0.30671, val MAE: 0.30671,test loss: 0.31875, test MAE: 0.31875,Time: 776.12s
2024-09-24 05:34:27,717 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 05:34:28,660 - logger.py:50 - Epoch: [133][0/500] loss: 1.95895, MAE: 0.28577, time/step=940ms, lr=2.54e-06
2024-09-24 05:35:38,379 - logger.py:50 - Epoch: [133][50/500] loss: 1.31246, MAE: 0.30508, time/step=1385ms, lr=2.54e-06
2024-09-24 05:36:49,010 - logger.py:50 - Epoch: [133][100/500] loss: 1.28372, MAE: 0.30584, time/step=1399ms, lr=2.54e-06
2024-09-24 05:37:59,932 - logger.py:50 - Epoch: [133][150/500] loss: 1.31251, MAE: 0.30629, time/step=1405ms, lr=2.54e-06
2024-09-24 05:39:09,530 - logger.py:50 - Epoch: [133][200/500] loss: 1.28903, MAE: 0.30442, time/step=1402ms, lr=2.54e-06
2024-09-24 05:40:19,791 - logger.py:50 - Epoch: [133][250/500] loss: 1.25751, MAE: 0.30142, time/step=1403ms, lr=2.54e-06
2024-09-24 05:41:29,519 - logger.py:50 - Epoch: [133][300/500] loss: 1.52568, MAE: 0.30473, time/step=1401ms, lr=2.54e-06
2024-09-24 05:42:42,044 - logger.py:50 - Epoch: [133][350/500] loss: 1.49730, MAE: 0.30556, time/step=1408ms, lr=2.54e-06
2024-09-24 05:43:54,587 - logger.py:50 - Epoch: [133][400/500] loss: 1.48032, MAE: 0.30531, time/step=1414ms, lr=2.54e-06
2024-09-24 05:45:12,768 - logger.py:50 - Epoch: [133][450/500] loss: 1.46102, MAE: 0.30475, time/step=1430ms, lr=2.54e-06
2024-09-24 05:46:21,950 - logger.py:50 - Epoch: [133][499/500] loss: 1.45133, MAE: 0.30491, time/step=1428ms, lr=2.54e-06
2024-09-24 05:47:35,165 - logger.py:50 - Epoch: [133] train loss: 1.45133, train MAE: 0.30491,val loss: 0.30669, val MAE: 0.30669,test loss: 0.31874, test MAE: 0.31874,Time: 787.45s
2024-09-24 05:47:35,165 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 05:47:36,646 - logger.py:50 - Epoch: [134][0/500] loss: 0.95753, MAE: 0.30231, time/step=1478ms, lr=2.36e-06
2024-09-24 05:48:50,337 - logger.py:50 - Epoch: [134][50/500] loss: 1.27183, MAE: 0.30310, time/step=1474ms, lr=2.36e-06
2024-09-24 05:50:04,972 - logger.py:50 - Epoch: [134][100/500] loss: 1.28985, MAE: 0.30073, time/step=1483ms, lr=2.36e-06
2024-09-24 05:51:25,191 - logger.py:50 - Epoch: [134][150/500] loss: 1.90833, MAE: 0.31329, time/step=1523ms, lr=2.36e-06
2024-09-24 05:52:46,593 - logger.py:50 - Epoch: [134][200/500] loss: 1.73698, MAE: 0.31073, time/step=1549ms, lr=2.36e-06
2024-09-24 05:54:07,087 - logger.py:50 - Epoch: [134][250/500] loss: 1.63698, MAE: 0.31035, time/step=1561ms, lr=2.36e-06
2024-09-24 05:55:32,808 - logger.py:50 - Epoch: [134][300/500] loss: 1.59699, MAE: 0.30973, time/step=1587ms, lr=2.36e-06
2024-09-24 05:57:01,511 - logger.py:50 - Epoch: [134][350/500] loss: 1.55410, MAE: 0.30740, time/step=1614ms, lr=2.36e-06
2024-09-24 05:58:27,133 - logger.py:50 - Epoch: [134][400/500] loss: 1.51857, MAE: 0.30620, time/step=1626ms, lr=2.36e-06
2024-09-24 05:59:58,248 - logger.py:50 - Epoch: [134][450/500] loss: 1.47819, MAE: 0.30565, time/step=1648ms, lr=2.36e-06
2024-09-24 06:01:21,493 - logger.py:50 - Epoch: [134][499/500] loss: 1.45134, MAE: 0.30491, time/step=1653ms, lr=2.36e-06
2024-09-24 06:02:36,103 - logger.py:50 - Epoch: [134] train loss: 1.45134, train MAE: 0.30491,val loss: 0.30661, val MAE: 0.30661,test loss: 0.31867, test MAE: 0.31867,Time: 900.94s
2024-09-24 06:02:36,103 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 06:02:37,672 - logger.py:50 - Epoch: [135][0/500] loss: 0.69691, MAE: 0.22794, time/step=1566ms, lr=2.20e-06
2024-09-24 06:03:59,078 - logger.py:50 - Epoch: [135][50/500] loss: 1.41811, MAE: 0.31304, time/step=1627ms, lr=2.20e-06
2024-09-24 06:05:19,498 - logger.py:50 - Epoch: [135][100/500] loss: 1.29785, MAE: 0.30409, time/step=1618ms, lr=2.20e-06
2024-09-24 06:06:37,272 - logger.py:50 - Epoch: [135][150/500] loss: 1.27409, MAE: 0.30061, time/step=1597ms, lr=2.20e-06
2024-09-24 06:07:53,919 - logger.py:50 - Epoch: [135][200/500] loss: 1.29527, MAE: 0.30108, time/step=1581ms, lr=2.20e-06
2024-09-24 06:09:13,722 - logger.py:50 - Epoch: [135][250/500] loss: 1.29987, MAE: 0.30303, time/step=1584ms, lr=2.20e-06
2024-09-24 06:10:28,467 - logger.py:50 - Epoch: [135][300/500] loss: 1.29076, MAE: 0.30092, time/step=1569ms, lr=2.20e-06
2024-09-24 06:11:44,607 - logger.py:50 - Epoch: [135][350/500] loss: 1.28666, MAE: 0.30097, time/step=1563ms, lr=2.20e-06
2024-09-24 06:12:59,944 - logger.py:50 - Epoch: [135][400/500] loss: 1.29819, MAE: 0.30201, time/step=1556ms, lr=2.20e-06
2024-09-24 06:14:13,666 - logger.py:50 - Epoch: [135][450/500] loss: 1.28914, MAE: 0.30136, time/step=1547ms, lr=2.20e-06
2024-09-24 06:15:27,939 - logger.py:50 - Epoch: [135][499/500] loss: 1.45134, MAE: 0.30490, time/step=1544ms, lr=2.20e-06
2024-09-24 06:16:39,679 - logger.py:50 - Epoch: [135] train loss: 1.45134, train MAE: 0.30490,val loss: 0.30669, val MAE: 0.30669,test loss: 0.31874, test MAE: 0.31874,Time: 843.58s
2024-09-24 06:16:39,679 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 06:16:41,222 - logger.py:50 - Epoch: [136][0/500] loss: 1.58056, MAE: 0.31978, time/step=1541ms, lr=2.05e-06
2024-09-24 06:17:52,790 - logger.py:50 - Epoch: [136][50/500] loss: 1.26730, MAE: 0.29008, time/step=1434ms, lr=2.05e-06
2024-09-24 06:19:04,588 - logger.py:50 - Epoch: [136][100/500] loss: 1.28327, MAE: 0.29491, time/step=1435ms, lr=2.05e-06
2024-09-24 06:20:16,316 - logger.py:50 - Epoch: [136][150/500] loss: 1.32516, MAE: 0.29705, time/step=1435ms, lr=2.05e-06
2024-09-24 06:21:29,925 - logger.py:50 - Epoch: [136][200/500] loss: 1.29961, MAE: 0.29758, time/step=1444ms, lr=2.05e-06
2024-09-24 06:22:42,092 - logger.py:50 - Epoch: [136][250/500] loss: 1.64164, MAE: 0.30508, time/step=1444ms, lr=2.05e-06
2024-09-24 06:23:53,758 - logger.py:50 - Epoch: [136][300/500] loss: 1.58237, MAE: 0.30374, time/step=1442ms, lr=2.05e-06
2024-09-24 06:25:05,538 - logger.py:50 - Epoch: [136][350/500] loss: 1.54148, MAE: 0.30386, time/step=1441ms, lr=2.05e-06
2024-09-24 06:26:16,565 - logger.py:50 - Epoch: [136][400/500] loss: 1.49227, MAE: 0.30366, time/step=1439ms, lr=2.05e-06
2024-09-24 06:27:29,168 - logger.py:50 - Epoch: [136][450/500] loss: 1.46506, MAE: 0.30390, time/step=1440ms, lr=2.05e-06
2024-09-24 06:28:39,511 - logger.py:50 - Epoch: [136][499/500] loss: 1.45133, MAE: 0.30491, time/step=1440ms, lr=2.05e-06
2024-09-24 06:29:52,023 - logger.py:50 - Epoch: [136] train loss: 1.45133, train MAE: 0.30491,val loss: 0.30671, val MAE: 0.30671,test loss: 0.31875, test MAE: 0.31875,Time: 792.34s
2024-09-24 06:29:52,023 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 06:29:53,681 - logger.py:50 - Epoch: [137][0/500] loss: 2.54487, MAE: 0.37858, time/step=1655ms, lr=1.90e-06
2024-09-24 06:31:02,874 - logger.py:50 - Epoch: [137][50/500] loss: 1.32842, MAE: 0.30203, time/step=1389ms, lr=1.90e-06
2024-09-24 06:32:13,441 - logger.py:50 - Epoch: [137][100/500] loss: 1.30449, MAE: 0.30185, time/step=1400ms, lr=1.90e-06
2024-09-24 06:33:24,015 - logger.py:50 - Epoch: [137][150/500] loss: 1.33663, MAE: 0.30333, time/step=1404ms, lr=1.90e-06
2024-09-24 06:34:35,950 - logger.py:50 - Epoch: [137][200/500] loss: 1.32465, MAE: 0.30297, time/step=1413ms, lr=1.90e-06
2024-09-24 06:35:47,248 - logger.py:50 - Epoch: [137][250/500] loss: 1.65122, MAE: 0.30939, time/step=1415ms, lr=1.90e-06
2024-09-24 06:36:58,853 - logger.py:50 - Epoch: [137][300/500] loss: 1.57200, MAE: 0.30755, time/step=1418ms, lr=1.90e-06
2024-09-24 06:38:09,466 - logger.py:50 - Epoch: [137][350/500] loss: 1.53105, MAE: 0.30692, time/step=1417ms, lr=1.90e-06
2024-09-24 06:39:20,023 - logger.py:50 - Epoch: [137][400/500] loss: 1.48998, MAE: 0.30516, time/step=1416ms, lr=1.90e-06
2024-09-24 06:40:30,799 - logger.py:50 - Epoch: [137][450/500] loss: 1.46589, MAE: 0.30528, time/step=1416ms, lr=1.90e-06
2024-09-24 06:41:39,601 - logger.py:50 - Epoch: [137][499/500] loss: 1.45133, MAE: 0.30489, time/step=1415ms, lr=1.90e-06
2024-09-24 06:42:52,810 - logger.py:50 - Epoch: [137] train loss: 1.45133, train MAE: 0.30489,val loss: 0.30676, val MAE: 0.30676,test loss: 0.31880, test MAE: 0.31880,Time: 780.79s
2024-09-24 06:42:52,810 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 06:42:53,847 - logger.py:50 - Epoch: [138][0/500] loss: 1.51046, MAE: 0.36859, time/step=1035ms, lr=1.77e-06
2024-09-24 06:44:03,799 - logger.py:50 - Epoch: [138][50/500] loss: 1.19020, MAE: 0.30103, time/step=1392ms, lr=1.77e-06
2024-09-24 06:45:14,923 - logger.py:50 - Epoch: [138][100/500] loss: 1.20280, MAE: 0.30022, time/step=1407ms, lr=1.77e-06
2024-09-24 06:46:26,829 - logger.py:50 - Epoch: [138][150/500] loss: 1.21033, MAE: 0.29762, time/step=1417ms, lr=1.77e-06
2024-09-24 06:47:37,771 - logger.py:50 - Epoch: [138][200/500] loss: 1.23927, MAE: 0.29884, time/step=1418ms, lr=1.77e-06
2024-09-24 06:48:50,554 - logger.py:50 - Epoch: [138][250/500] loss: 1.26359, MAE: 0.29997, time/step=1425ms, lr=1.77e-06
2024-09-24 06:50:01,839 - logger.py:50 - Epoch: [138][300/500] loss: 1.25206, MAE: 0.29947, time/step=1425ms, lr=1.77e-06
2024-09-24 06:51:12,411 - logger.py:50 - Epoch: [138][350/500] loss: 1.26238, MAE: 0.29971, time/step=1423ms, lr=1.77e-06
2024-09-24 06:52:21,915 - logger.py:50 - Epoch: [138][400/500] loss: 1.26975, MAE: 0.29990, time/step=1419ms, lr=1.77e-06
2024-09-24 06:53:32,435 - logger.py:50 - Epoch: [138][450/500] loss: 1.27095, MAE: 0.30030, time/step=1418ms, lr=1.77e-06
2024-09-24 06:54:40,845 - logger.py:50 - Epoch: [138][499/500] loss: 1.45132, MAE: 0.30490, time/step=1416ms, lr=1.77e-06
2024-09-24 06:55:53,909 - logger.py:50 - Epoch: [138] train loss: 1.45132, train MAE: 0.30490,val loss: 0.30671, val MAE: 0.30671,test loss: 0.31876, test MAE: 0.31876,Time: 781.10s
2024-09-24 06:55:53,909 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 06:55:54,993 - logger.py:50 - Epoch: [139][0/500] loss: 1.32328, MAE: 0.32723, time/step=1081ms, lr=1.65e-06
2024-09-24 06:57:05,049 - logger.py:50 - Epoch: [139][50/500] loss: 1.21112, MAE: 0.29948, time/step=1395ms, lr=1.65e-06
2024-09-24 06:58:16,236 - logger.py:50 - Epoch: [139][100/500] loss: 1.26475, MAE: 0.29811, time/step=1409ms, lr=1.65e-06
2024-09-24 06:59:26,687 - logger.py:50 - Epoch: [139][150/500] loss: 1.82066, MAE: 0.30907, time/step=1409ms, lr=1.65e-06
2024-09-24 07:00:36,748 - logger.py:50 - Epoch: [139][200/500] loss: 1.67666, MAE: 0.30723, time/step=1407ms, lr=1.65e-06
2024-09-24 07:01:47,221 - logger.py:50 - Epoch: [139][250/500] loss: 1.59963, MAE: 0.30690, time/step=1408ms, lr=1.65e-06
2024-09-24 07:02:56,428 - logger.py:50 - Epoch: [139][300/500] loss: 1.57252, MAE: 0.30739, time/step=1404ms, lr=1.65e-06
2024-09-24 07:04:05,752 - logger.py:50 - Epoch: [139][350/500] loss: 1.52959, MAE: 0.30640, time/step=1401ms, lr=1.65e-06
2024-09-24 07:05:16,364 - logger.py:50 - Epoch: [139][400/500] loss: 1.49767, MAE: 0.30550, time/step=1403ms, lr=1.65e-06
2024-09-24 07:06:28,152 - logger.py:50 - Epoch: [139][450/500] loss: 1.47136, MAE: 0.30555, time/step=1406ms, lr=1.65e-06
2024-09-24 07:07:39,294 - logger.py:50 - Epoch: [139][499/500] loss: 1.45131, MAE: 0.30491, time/step=1411ms, lr=1.65e-06
2024-09-24 07:08:50,929 - logger.py:50 - Epoch: [139] train loss: 1.45131, train MAE: 0.30491,val loss: 0.30670, val MAE: 0.30670,test loss: 0.31874, test MAE: 0.31874,Time: 777.02s
2024-09-24 07:08:50,929 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 07:08:52,490 - logger.py:50 - Epoch: [140][0/500] loss: 1.23255, MAE: 0.33302, time/step=1558ms, lr=1.54e-06
2024-09-24 07:10:01,464 - logger.py:50 - Epoch: [140][50/500] loss: 1.30212, MAE: 0.30194, time/step=1383ms, lr=1.54e-06
2024-09-24 07:11:11,959 - logger.py:50 - Epoch: [140][100/500] loss: 1.26274, MAE: 0.30220, time/step=1396ms, lr=1.54e-06
2024-09-24 07:12:22,607 - logger.py:50 - Epoch: [140][150/500] loss: 1.30636, MAE: 0.30675, time/step=1402ms, lr=1.54e-06
2024-09-24 07:13:32,397 - logger.py:50 - Epoch: [140][200/500] loss: 1.27532, MAE: 0.30502, time/step=1400ms, lr=1.54e-06
2024-09-24 07:14:44,195 - logger.py:50 - Epoch: [140][250/500] loss: 1.29560, MAE: 0.30591, time/step=1407ms, lr=1.54e-06
2024-09-24 07:15:55,085 - logger.py:50 - Epoch: [140][300/500] loss: 1.29402, MAE: 0.30396, time/step=1409ms, lr=1.54e-06
2024-09-24 07:17:07,570 - logger.py:50 - Epoch: [140][350/500] loss: 1.28403, MAE: 0.30138, time/step=1415ms, lr=1.54e-06
2024-09-24 07:18:19,479 - logger.py:50 - Epoch: [140][400/500] loss: 1.49374, MAE: 0.30470, time/step=1418ms, lr=1.54e-06
2024-09-24 07:19:32,688 - logger.py:50 - Epoch: [140][450/500] loss: 1.47758, MAE: 0.30542, time/step=1423ms, lr=1.54e-06
2024-09-24 07:20:44,016 - logger.py:50 - Epoch: [140][499/500] loss: 1.45131, MAE: 0.30489, time/step=1426ms, lr=1.54e-06
2024-09-24 07:21:56,097 - logger.py:50 - Epoch: [140] train loss: 1.45131, train MAE: 0.30489,val loss: 0.30673, val MAE: 0.30673,test loss: 0.31878, test MAE: 0.31878,Time: 785.17s
2024-09-24 07:21:56,097 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 07:21:57,243 - logger.py:50 - Epoch: [141][0/500] loss: 0.40091, MAE: 0.20342, time/step=1143ms, lr=1.43e-06
2024-09-24 07:23:07,870 - logger.py:50 - Epoch: [141][50/500] loss: 1.26071, MAE: 0.30614, time/step=1407ms, lr=1.43e-06
2024-09-24 07:24:18,198 - logger.py:50 - Epoch: [141][100/500] loss: 2.10981, MAE: 0.32104, time/step=1407ms, lr=1.43e-06
2024-09-24 07:25:29,103 - logger.py:50 - Epoch: [141][150/500] loss: 1.84032, MAE: 0.31697, time/step=1411ms, lr=1.43e-06
2024-09-24 07:26:40,200 - logger.py:50 - Epoch: [141][200/500] loss: 1.68644, MAE: 0.31082, time/step=1413ms, lr=1.43e-06
2024-09-24 07:27:51,212 - logger.py:50 - Epoch: [141][250/500] loss: 1.60093, MAE: 0.31003, time/step=1415ms, lr=1.43e-06
2024-09-24 07:29:02,410 - logger.py:50 - Epoch: [141][300/500] loss: 1.53371, MAE: 0.30656, time/step=1416ms, lr=1.43e-06
2024-09-24 07:30:12,593 - logger.py:50 - Epoch: [141][350/500] loss: 1.48973, MAE: 0.30468, time/step=1415ms, lr=1.43e-06
2024-09-24 07:31:24,660 - logger.py:50 - Epoch: [141][400/500] loss: 1.47998, MAE: 0.30598, time/step=1418ms, lr=1.43e-06
2024-09-24 07:32:34,920 - logger.py:50 - Epoch: [141][450/500] loss: 1.47383, MAE: 0.30547, time/step=1416ms, lr=1.43e-06
2024-09-24 07:33:45,897 - logger.py:50 - Epoch: [141][499/500] loss: 1.45129, MAE: 0.30490, time/step=1420ms, lr=1.43e-06
2024-09-24 07:35:00,736 - logger.py:50 - Epoch: [141] train loss: 1.45129, train MAE: 0.30490,val loss: 0.30678, val MAE: 0.30678,test loss: 0.31882, test MAE: 0.31882,Time: 784.64s
2024-09-24 07:35:00,736 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 07:35:01,704 - logger.py:50 - Epoch: [142][0/500] loss: 1.05776, MAE: 0.28138, time/step=965ms, lr=1.34e-06
2024-09-24 07:36:11,732 - logger.py:50 - Epoch: [142][50/500] loss: 1.21351, MAE: 0.30223, time/step=1392ms, lr=1.34e-06
2024-09-24 07:37:23,146 - logger.py:50 - Epoch: [142][100/500] loss: 1.24664, MAE: 0.30516, time/step=1410ms, lr=1.34e-06
2024-09-24 07:38:31,742 - logger.py:50 - Epoch: [142][150/500] loss: 1.23499, MAE: 0.30116, time/step=1397ms, lr=1.34e-06
2024-09-24 07:39:41,270 - logger.py:50 - Epoch: [142][200/500] loss: 1.22265, MAE: 0.29896, time/step=1396ms, lr=1.34e-06
2024-09-24 07:40:51,976 - logger.py:50 - Epoch: [142][250/500] loss: 1.24719, MAE: 0.29979, time/step=1399ms, lr=1.34e-06
2024-09-24 07:42:03,517 - logger.py:50 - Epoch: [142][300/500] loss: 1.53926, MAE: 0.30540, time/step=1405ms, lr=1.34e-06
2024-09-24 07:43:14,370 - logger.py:50 - Epoch: [142][350/500] loss: 1.51002, MAE: 0.30438, time/step=1406ms, lr=1.34e-06
2024-09-24 07:44:26,267 - logger.py:50 - Epoch: [142][400/500] loss: 1.48778, MAE: 0.30499, time/step=1410ms, lr=1.34e-06
2024-09-24 07:45:36,491 - logger.py:50 - Epoch: [142][450/500] loss: 1.47846, MAE: 0.30544, time/step=1410ms, lr=1.34e-06
2024-09-24 07:46:45,762 - logger.py:50 - Epoch: [142][499/500] loss: 1.45129, MAE: 0.30491, time/step=1410ms, lr=1.34e-06
2024-09-24 07:47:58,724 - logger.py:50 - Epoch: [142] train loss: 1.45129, train MAE: 0.30491,val loss: 0.30665, val MAE: 0.30665,test loss: 0.31870, test MAE: 0.31870,Time: 777.99s
2024-09-24 07:47:58,725 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 07:47:59,784 - logger.py:50 - Epoch: [143][0/500] loss: 0.75662, MAE: 0.23295, time/step=1056ms, lr=1.26e-06
2024-09-24 07:49:10,702 - logger.py:50 - Epoch: [143][50/500] loss: 1.28370, MAE: 0.30596, time/step=1411ms, lr=1.26e-06
2024-09-24 07:50:23,981 - logger.py:50 - Epoch: [143][100/500] loss: 1.31820, MAE: 0.30532, time/step=1438ms, lr=1.26e-06
2024-09-24 07:51:37,948 - logger.py:50 - Epoch: [143][150/500] loss: 1.26480, MAE: 0.29981, time/step=1452ms, lr=1.26e-06
2024-09-24 07:52:49,519 - logger.py:50 - Epoch: [143][200/500] loss: 1.27486, MAE: 0.30157, time/step=1447ms, lr=1.26e-06
2024-09-24 07:54:02,375 - logger.py:50 - Epoch: [143][250/500] loss: 1.28523, MAE: 0.30211, time/step=1449ms, lr=1.26e-06
2024-09-24 07:55:14,156 - logger.py:50 - Epoch: [143][300/500] loss: 1.28844, MAE: 0.30272, time/step=1447ms, lr=1.26e-06
2024-09-24 07:56:25,573 - logger.py:50 - Epoch: [143][350/500] loss: 1.29083, MAE: 0.30192, time/step=1444ms, lr=1.26e-06
2024-09-24 07:57:36,863 - logger.py:50 - Epoch: [143][400/500] loss: 1.28811, MAE: 0.30163, time/step=1442ms, lr=1.26e-06
2024-09-24 07:58:49,807 - logger.py:50 - Epoch: [143][450/500] loss: 1.47816, MAE: 0.30613, time/step=1444ms, lr=1.26e-06
2024-09-24 07:59:59,316 - logger.py:50 - Epoch: [143][499/500] loss: 1.45130, MAE: 0.30488, time/step=1441ms, lr=1.26e-06
2024-09-24 08:01:11,487 - logger.py:50 - Epoch: [143] train loss: 1.45130, train MAE: 0.30488,val loss: 0.30679, val MAE: 0.30679,test loss: 0.31883, test MAE: 0.31883,Time: 792.76s
2024-09-24 08:01:11,487 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 08:01:12,482 - logger.py:50 - Epoch: [144][0/500] loss: 1.50509, MAE: 0.29595, time/step=993ms, lr=1.19e-06
2024-09-24 08:02:22,367 - logger.py:50 - Epoch: [144][50/500] loss: 1.21026, MAE: 0.30235, time/step=1390ms, lr=1.19e-06
2024-09-24 08:03:32,313 - logger.py:50 - Epoch: [144][100/500] loss: 1.20096, MAE: 0.30022, time/step=1394ms, lr=1.19e-06
2024-09-24 08:04:43,467 - logger.py:50 - Epoch: [144][150/500] loss: 1.23308, MAE: 0.29864, time/step=1404ms, lr=1.19e-06
2024-09-24 08:05:55,532 - logger.py:50 - Epoch: [144][200/500] loss: 1.67788, MAE: 0.30669, time/step=1413ms, lr=1.19e-06
2024-09-24 08:07:05,736 - logger.py:50 - Epoch: [144][250/500] loss: 1.60271, MAE: 0.30609, time/step=1411ms, lr=1.19e-06
2024-09-24 08:08:16,245 - logger.py:50 - Epoch: [144][300/500] loss: 1.54721, MAE: 0.30570, time/step=1411ms, lr=1.19e-06
2024-09-24 08:09:26,597 - logger.py:50 - Epoch: [144][350/500] loss: 1.50284, MAE: 0.30402, time/step=1411ms, lr=1.19e-06
2024-09-24 08:10:38,018 - logger.py:50 - Epoch: [144][400/500] loss: 1.48896, MAE: 0.30388, time/step=1413ms, lr=1.19e-06
2024-09-24 08:11:49,383 - logger.py:50 - Epoch: [144][450/500] loss: 1.46795, MAE: 0.30391, time/step=1414ms, lr=1.19e-06
2024-09-24 08:12:59,696 - logger.py:50 - Epoch: [144][499/500] loss: 1.45129, MAE: 0.30491, time/step=1416ms, lr=1.19e-06
2024-09-24 08:14:11,692 - logger.py:50 - Epoch: [144] train loss: 1.45129, train MAE: 0.30491,val loss: 0.30670, val MAE: 0.30670,test loss: 0.31875, test MAE: 0.31875,Time: 780.20s
2024-09-24 08:14:11,692 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 08:14:13,490 - logger.py:50 - Epoch: [145][0/500] loss: 1.49894, MAE: 0.26178, time/step=1795ms, lr=1.13e-06
2024-09-24 08:15:23,320 - logger.py:50 - Epoch: [145][50/500] loss: 1.27804, MAE: 0.29495, time/step=1404ms, lr=1.13e-06
2024-09-24 08:16:33,619 - logger.py:50 - Epoch: [145][100/500] loss: 1.27923, MAE: 0.30062, time/step=1405ms, lr=1.13e-06
2024-09-24 08:17:44,069 - logger.py:50 - Epoch: [145][150/500] loss: 1.28401, MAE: 0.30158, time/step=1406ms, lr=1.13e-06
2024-09-24 08:18:54,062 - logger.py:50 - Epoch: [145][200/500] loss: 1.28472, MAE: 0.29976, time/step=1405ms, lr=1.13e-06
2024-09-24 08:20:04,502 - logger.py:50 - Epoch: [145][250/500] loss: 1.29241, MAE: 0.30080, time/step=1406ms, lr=1.13e-06
2024-09-24 08:21:13,278 - logger.py:50 - Epoch: [145][300/500] loss: 1.28524, MAE: 0.30056, time/step=1401ms, lr=1.13e-06
2024-09-24 08:22:22,787 - logger.py:50 - Epoch: [145][350/500] loss: 1.28509, MAE: 0.30155, time/step=1399ms, lr=1.13e-06
2024-09-24 08:23:34,697 - logger.py:50 - Epoch: [145][400/500] loss: 1.27820, MAE: 0.30191, time/step=1404ms, lr=1.13e-06
2024-09-24 08:24:47,521 - logger.py:50 - Epoch: [145][450/500] loss: 1.46747, MAE: 0.30510, time/step=1410ms, lr=1.13e-06
2024-09-24 08:25:59,480 - logger.py:50 - Epoch: [145][499/500] loss: 1.45129, MAE: 0.30490, time/step=1416ms, lr=1.13e-06
2024-09-24 08:27:11,373 - logger.py:50 - Epoch: [145] train loss: 1.45129, train MAE: 0.30490,val loss: 0.30671, val MAE: 0.30671,test loss: 0.31875, test MAE: 0.31875,Time: 779.68s
2024-09-24 08:27:11,374 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 08:27:12,255 - logger.py:50 - Epoch: [146][0/500] loss: 0.86267, MAE: 0.29422, time/step=878ms, lr=1.09e-06
2024-09-24 08:28:22,465 - logger.py:50 - Epoch: [146][50/500] loss: 1.33945, MAE: 0.30573, time/step=1394ms, lr=1.09e-06
2024-09-24 08:29:32,771 - logger.py:50 - Epoch: [146][100/500] loss: 1.30532, MAE: 0.30420, time/step=1400ms, lr=1.09e-06
2024-09-24 08:30:46,242 - logger.py:50 - Epoch: [146][150/500] loss: 1.26965, MAE: 0.30074, time/step=1423ms, lr=1.09e-06
2024-09-24 08:31:57,382 - logger.py:50 - Epoch: [146][200/500] loss: 1.73597, MAE: 0.31254, time/step=1423ms, lr=1.09e-06
2024-09-24 08:33:08,602 - logger.py:50 - Epoch: [146][250/500] loss: 1.62006, MAE: 0.30799, time/step=1423ms, lr=1.09e-06
2024-09-24 08:34:20,114 - logger.py:50 - Epoch: [146][300/500] loss: 1.55419, MAE: 0.30619, time/step=1424ms, lr=1.09e-06
2024-09-24 08:35:30,705 - logger.py:50 - Epoch: [146][350/500] loss: 1.51170, MAE: 0.30515, time/step=1423ms, lr=1.09e-06
2024-09-24 08:36:42,070 - logger.py:50 - Epoch: [146][400/500] loss: 1.47876, MAE: 0.30435, time/step=1423ms, lr=1.09e-06
2024-09-24 08:37:53,558 - logger.py:50 - Epoch: [146][450/500] loss: 1.46671, MAE: 0.30490, time/step=1424ms, lr=1.09e-06
2024-09-24 08:39:03,155 - logger.py:50 - Epoch: [146][499/500] loss: 1.45129, MAE: 0.30489, time/step=1424ms, lr=1.09e-06
2024-09-24 08:40:13,912 - logger.py:50 - Epoch: [146] train loss: 1.45129, train MAE: 0.30489,val loss: 0.30672, val MAE: 0.30672,test loss: 0.31877, test MAE: 0.31877,Time: 782.54s
2024-09-24 08:40:13,912 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 08:40:15,768 - logger.py:50 - Epoch: [147][0/500] loss: 0.76692, MAE: 0.27140, time/step=1853ms, lr=1.05e-06
2024-09-24 08:41:25,368 - logger.py:50 - Epoch: [147][50/500] loss: 1.17359, MAE: 0.30156, time/step=1401ms, lr=1.05e-06
2024-09-24 08:42:36,212 - logger.py:50 - Epoch: [147][100/500] loss: 1.30446, MAE: 0.30828, time/step=1409ms, lr=1.05e-06
2024-09-24 08:43:46,752 - logger.py:50 - Epoch: [147][150/500] loss: 1.30864, MAE: 0.30702, time/step=1410ms, lr=1.05e-06
2024-09-24 08:44:56,520 - logger.py:50 - Epoch: [147][200/500] loss: 1.30887, MAE: 0.30630, time/step=1406ms, lr=1.05e-06
2024-09-24 08:46:08,936 - logger.py:50 - Epoch: [147][250/500] loss: 1.30106, MAE: 0.30557, time/step=1414ms, lr=1.05e-06
2024-09-24 08:47:23,638 - logger.py:50 - Epoch: [147][300/500] loss: 1.28782, MAE: 0.30384, time/step=1428ms, lr=1.05e-06
2024-09-24 08:48:33,928 - logger.py:50 - Epoch: [147][350/500] loss: 1.26883, MAE: 0.30146, time/step=1425ms, lr=1.05e-06
2024-09-24 08:49:43,409 - logger.py:50 - Epoch: [147][400/500] loss: 1.27704, MAE: 0.30131, time/step=1420ms, lr=1.05e-06
2024-09-24 08:50:54,452 - logger.py:50 - Epoch: [147][450/500] loss: 1.47180, MAE: 0.30553, time/step=1420ms, lr=1.05e-06
2024-09-24 08:52:03,704 - logger.py:50 - Epoch: [147][499/500] loss: 1.45129, MAE: 0.30490, time/step=1420ms, lr=1.05e-06
2024-09-24 08:53:16,655 - logger.py:50 - Epoch: [147] train loss: 1.45129, train MAE: 0.30490,val loss: 0.30670, val MAE: 0.30670,test loss: 0.31875, test MAE: 0.31875,Time: 782.74s
2024-09-24 08:53:16,655 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 08:53:18,222 - logger.py:50 - Epoch: [148][0/500] loss: 1.02279, MAE: 0.28142, time/step=1565ms, lr=1.02e-06
2024-09-24 08:54:30,084 - logger.py:50 - Epoch: [148][50/500] loss: 1.30401, MAE: 0.29910, time/step=1440ms, lr=1.02e-06
2024-09-24 08:55:40,983 - logger.py:50 - Epoch: [148][100/500] loss: 1.30896, MAE: 0.30146, time/step=1429ms, lr=1.02e-06
2024-09-24 08:56:52,872 - logger.py:50 - Epoch: [148][150/500] loss: 1.30401, MAE: 0.29971, time/step=1432ms, lr=1.02e-06
2024-09-24 08:58:06,799 - logger.py:50 - Epoch: [148][200/500] loss: 1.29531, MAE: 0.30197, time/step=1443ms, lr=1.02e-06
2024-09-24 08:59:18,974 - logger.py:50 - Epoch: [148][250/500] loss: 1.31941, MAE: 0.30389, time/step=1443ms, lr=1.02e-06
2024-09-24 09:00:32,122 - logger.py:50 - Epoch: [148][300/500] loss: 1.31413, MAE: 0.30503, time/step=1447ms, lr=1.02e-06
2024-09-24 09:01:43,958 - logger.py:50 - Epoch: [148][350/500] loss: 1.53447, MAE: 0.30655, time/step=1445ms, lr=1.02e-06
2024-09-24 09:02:56,454 - logger.py:50 - Epoch: [148][400/500] loss: 1.50703, MAE: 0.30710, time/step=1446ms, lr=1.02e-06
2024-09-24 09:04:07,017 - logger.py:50 - Epoch: [148][450/500] loss: 1.47700, MAE: 0.30648, time/step=1442ms, lr=1.02e-06
2024-09-24 09:05:17,059 - logger.py:50 - Epoch: [148][499/500] loss: 1.45128, MAE: 0.30491, time/step=1441ms, lr=1.02e-06
2024-09-24 09:06:30,155 - logger.py:50 - Epoch: [148] train loss: 1.45128, train MAE: 0.30491,val loss: 0.30667, val MAE: 0.30667,test loss: 0.31872, test MAE: 0.31872,Time: 793.50s
2024-09-24 09:06:30,155 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 09:06:31,786 - logger.py:50 - Epoch: [149][0/500] loss: 0.46590, MAE: 0.19582, time/step=1629ms, lr=1.01e-06
2024-09-24 09:07:43,204 - logger.py:50 - Epoch: [149][50/500] loss: 1.42244, MAE: 0.31196, time/step=1432ms, lr=1.01e-06
2024-09-24 09:08:52,382 - logger.py:50 - Epoch: [149][100/500] loss: 1.34046, MAE: 0.30688, time/step=1408ms, lr=1.01e-06
2024-09-24 09:10:02,777 - logger.py:50 - Epoch: [149][150/500] loss: 1.30816, MAE: 0.29924, time/step=1408ms, lr=1.01e-06
2024-09-24 09:11:11,979 - logger.py:50 - Epoch: [149][200/500] loss: 1.28073, MAE: 0.29935, time/step=1402ms, lr=1.01e-06
2024-09-24 09:12:22,154 - logger.py:50 - Epoch: [149][250/500] loss: 1.28574, MAE: 0.30113, time/step=1402ms, lr=1.01e-06
2024-09-24 09:13:33,921 - logger.py:50 - Epoch: [149][300/500] loss: 1.27678, MAE: 0.30079, time/step=1408ms, lr=1.01e-06
2024-09-24 09:14:43,265 - logger.py:50 - Epoch: [149][350/500] loss: 1.51112, MAE: 0.30490, time/step=1405ms, lr=1.01e-06
2024-09-24 09:15:54,209 - logger.py:50 - Epoch: [149][400/500] loss: 1.47334, MAE: 0.30437, time/step=1407ms, lr=1.01e-06
2024-09-24 09:17:05,142 - logger.py:50 - Epoch: [149][450/500] loss: 1.45604, MAE: 0.30455, time/step=1408ms, lr=1.01e-06
2024-09-24 09:18:15,244 - logger.py:50 - Epoch: [149][499/500] loss: 1.45128, MAE: 0.30489, time/step=1410ms, lr=1.01e-06
2024-09-24 09:19:27,856 - logger.py:50 - Epoch: [149] train loss: 1.45128, train MAE: 0.30489,val loss: 0.30669, val MAE: 0.30669,test loss: 0.31874, test MAE: 0.31874,Time: 777.70s
2024-09-24 09:19:27,856 - logger.py:50 - Best -- epoch=90, train loss: 1.45192, val loss: 0.30657, test loss: 0.31863

2024-09-24 09:19:27,856 - logger.py:50 - fold_1 test LOSS:0.31863
